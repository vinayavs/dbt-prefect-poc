

============================== 2022-01-22 04:32:04.651284 | ecdc36ec-d475-4187-9073-07c5bb69df99 ==============================
04:32:04.651284 [info ] [MainThread]: Running with dbt=1.0.1
04:32:04.652662 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.debug.DebugTask'>, config_dir=False, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='debug', write_json=None)
04:32:04.656969 [debug] [MainThread]: Tracking: tracking
04:32:04.658794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41fa235b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41fd98b210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41fd98b1d0>]}
04:32:05.267300 [debug] [MainThread]: Executing "git --help"
04:32:05.290936 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-c name=value]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThe most commonly used git commands are:\n   add        Add file contents to the index\n   bisect     Find by binary search the change that introduced a bug\n   branch     List, create, or delete branches\n   checkout   Checkout a branch or paths to the working tree\n   clone      Clone a repository into a new directory\n   commit     Record changes to the repository\n   diff       Show changes between commits, commit and working tree, etc\n   fetch      Download objects and refs from another repository\n   grep       Print lines matching a pattern\n   init       Create an empty Git repository or reinitialize an existing one\n   log        Show commit logs\n   merge      Join two or more development histories together\n   mv         Move or rename a file, a directory, or a symlink\n   pull       Fetch from and merge with another repository or a local branch\n   push       Update remote refs along with associated objects\n   rebase     Forward-port local commits to the updated upstream head\n   reset      Reset current HEAD to the specified state\n   rm         Remove files from the working tree and from the index\n   show       Show various types of objects\n   status     Show the working tree status\n   tag        Create, list, delete or verify a tag object signed with GPG\n\n'git help -a' and 'git help -g' lists available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\n""
04:32:05.291916 [debug] [MainThread]: STDERR: "b''"
04:32:05.307567 [debug] [MainThread]: Acquiring new snowflake connection "debug"
04:32:05.310134 [debug] [MainThread]: Using snowflake connection "debug"
04:32:05.310788 [debug] [MainThread]: On debug: select 1 as id
04:32:05.311205 [debug] [MainThread]: Opening a new connection, currently in state init
04:32:06.616563 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.31 seconds
04:32:06.623666 [debug] [MainThread]: On debug: Close
04:32:06.853275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41f42be5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41f42be490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41f42be510>]}
04:32:07.957976 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-01-22 05:55:21.164607 | 0bbc9c40-99e4-4f0a-9524-a2d89fe6a2a9 ==============================
05:55:21.164607 [info ] [MainThread]: Running with dbt=1.0.1
05:55:21.166248 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:55:21.167181 [debug] [MainThread]: Tracking: tracking
05:55:21.168447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b15cf4c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b15cf45d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b15cf4c90>]}
05:55:21.202953 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
05:55:21.204188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0bbc9c40-99e4-4f0a-9524-a2d89fe6a2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b15cf4d50>]}
05:55:21.281160 [debug] [MainThread]: Parsing macros/adapters.sql
05:55:21.435154 [debug] [MainThread]: Parsing macros/catalog.sql
05:55:21.442486 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
05:55:21.469919 [debug] [MainThread]: Parsing macros/materializations/merge.sql
05:55:21.481729 [debug] [MainThread]: Parsing macros/materializations/seed.sql
05:55:21.499402 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
05:55:21.502372 [debug] [MainThread]: Parsing macros/materializations/table.sql
05:55:21.512728 [debug] [MainThread]: Parsing macros/materializations/view.sql
05:55:21.517480 [debug] [MainThread]: Parsing macros/adapters/columns.sql
05:55:21.551352 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
05:55:21.559442 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
05:55:21.567709 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
05:55:21.590883 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
05:55:21.606060 [debug] [MainThread]: Parsing macros/adapters/relation.sql
05:55:21.637489 [debug] [MainThread]: Parsing macros/adapters/schema.sql
05:55:21.644835 [debug] [MainThread]: Parsing macros/etc/datetime.sql
05:55:21.673457 [debug] [MainThread]: Parsing macros/etc/statement.sql
05:55:21.686755 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
05:55:21.690487 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
05:55:21.692878 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
05:55:21.695081 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
05:55:21.696728 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
05:55:21.701698 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
05:55:21.706920 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
05:55:21.713640 [debug] [MainThread]: Parsing macros/materializations/configs.sql
05:55:21.720386 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
05:55:21.732433 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
05:55:21.792860 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
05:55:21.814495 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
05:55:21.858149 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
05:55:21.900932 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
05:55:21.906953 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
05:55:21.966120 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
05:55:21.971704 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
05:55:21.984535 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
05:55:21.989691 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
05:55:22.004306 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
05:55:22.040104 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
05:55:22.044799 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
05:55:22.084325 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
05:55:22.146246 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
05:55:22.154460 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
05:55:22.181720 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
05:55:22.189946 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
05:55:22.197231 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
05:55:22.201705 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
05:55:22.232462 [debug] [MainThread]: Parsing tests/generic/builtin.sql
05:55:22.907214 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
05:55:22.939643 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
05:55:23.092990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0bbc9c40-99e4-4f0a-9524-a2d89fe6a2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b15d6ced0>]}
05:55:23.110569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0bbc9c40-99e4-4f0a-9524-a2d89fe6a2a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1c5e3250>]}
05:55:23.111981 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:55:23.115194 [info ] [MainThread]: 
05:55:23.116992 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:55:23.123436 [debug] [ThreadPool]: Acquiring new snowflake connection "list_snowflake"
05:55:23.162837 [debug] [ThreadPool]: Using snowflake connection "list_snowflake"
05:55:23.163699 [debug] [ThreadPool]: On list_snowflake: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_snowflake"} */

    show terse schemas in database snowflake
    limit 10000
05:55:23.164250 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:55:24.439053 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.27 seconds
05:55:24.447858 [debug] [ThreadPool]: On list_snowflake: Close
05:55:24.624308 [debug] [ThreadPool]: Acquiring new snowflake connection "create_snowflake_public"
05:55:24.625662 [debug] [ThreadPool]: Acquiring new snowflake connection "create_snowflake_public"
05:55:24.627035 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='snowflake', schema='public', identifier=None)"
05:55:24.648353 [debug] [ThreadPool]: Using snowflake connection "create_snowflake_public"
05:55:24.649608 [debug] [ThreadPool]: On create_snowflake_public: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_snowflake_public"} */
create schema if not exists snowflake.public
05:55:24.650442 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:55:25.555264 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1cb23-0000-1e54-0000-000298a240f5
05:55:25.556017 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003540 (42501): SQL execution error: Creating schema on shared database 'SNOWFLAKE' is not allowed.
05:55:25.556930 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
05:55:25.557619 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
05:55:25.558146 [debug] [ThreadPool]: On create_snowflake_public: Close
05:55:25.717925 [debug] [MainThread]: Connection 'master' was properly closed.
05:55:25.718990 [debug] [MainThread]: Connection 'create_snowflake_public' was properly closed.
05:55:25.720131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b15db0190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b14044d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b0f320810>]}


============================== 2022-01-22 05:57:48.530004 | 6170ffe7-85a5-4f5a-96fb-6b199e10aae7 ==============================
05:57:48.530004 [info ] [MainThread]: Running with dbt=1.0.1
05:57:48.531191 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.debug.DebugTask'>, config_dir=False, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='debug', write_json=None)
05:57:48.531974 [debug] [MainThread]: Tracking: tracking
05:57:48.533495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f909b6c93d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9097f780d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f909b6bedd0>]}
05:57:49.160475 [debug] [MainThread]: Executing "git --help"
05:57:49.174216 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-c name=value]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThe most commonly used git commands are:\n   add        Add file contents to the index\n   bisect     Find by binary search the change that introduced a bug\n   branch     List, create, or delete branches\n   checkout   Checkout a branch or paths to the working tree\n   clone      Clone a repository into a new directory\n   commit     Record changes to the repository\n   diff       Show changes between commits, commit and working tree, etc\n   fetch      Download objects and refs from another repository\n   grep       Print lines matching a pattern\n   init       Create an empty Git repository or reinitialize an existing one\n   log        Show commit logs\n   merge      Join two or more development histories together\n   mv         Move or rename a file, a directory, or a symlink\n   pull       Fetch from and merge with another repository or a local branch\n   push       Update remote refs along with associated objects\n   rebase     Forward-port local commits to the updated upstream head\n   reset      Reset current HEAD to the specified state\n   rm         Remove files from the working tree and from the index\n   show       Show various types of objects\n   status     Show the working tree status\n   tag        Create, list, delete or verify a tag object signed with GPG\n\n'git help -a' and 'git help -g' lists available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\n""
05:57:49.175258 [debug] [MainThread]: STDERR: "b''"
05:57:49.180512 [debug] [MainThread]: Acquiring new snowflake connection "debug"
05:57:49.185092 [debug] [MainThread]: Using snowflake connection "debug"
05:57:49.186255 [debug] [MainThread]: On debug: select 1 as id
05:57:49.187272 [debug] [MainThread]: Opening a new connection, currently in state init
05:57:50.543679 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.36 seconds
05:57:50.546315 [debug] [MainThread]: On debug: Close
05:57:50.722586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9090fbf650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9090fbf590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9090fbf5d0>]}
05:57:51.794612 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-01-22 05:58:02.773397 | ed8d126b-7274-4111-8865-854ad3e63f57 ==============================
05:58:02.773397 [info ] [MainThread]: Running with dbt=1.0.1
05:58:02.774601 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:58:02.775414 [debug] [MainThread]: Tracking: tracking
05:58:02.776600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1e134d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1e134a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1e134d90>]}
05:58:02.833975 [info ] [MainThread]: Unable to do partial parsing because profile has changed
05:58:02.835138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed8d126b-7274-4111-8865-854ad3e63f57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1e0cbf10>]}
05:58:02.885494 [debug] [MainThread]: Parsing macros/adapters.sql
05:58:03.040391 [debug] [MainThread]: Parsing macros/catalog.sql
05:58:03.046198 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
05:58:03.083455 [debug] [MainThread]: Parsing macros/materializations/merge.sql
05:58:03.095634 [debug] [MainThread]: Parsing macros/materializations/seed.sql
05:58:03.114065 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
05:58:03.116892 [debug] [MainThread]: Parsing macros/materializations/table.sql
05:58:03.127228 [debug] [MainThread]: Parsing macros/materializations/view.sql
05:58:03.133137 [debug] [MainThread]: Parsing macros/adapters/columns.sql
05:58:03.167503 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
05:58:03.177279 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
05:58:03.185957 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
05:58:03.211207 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
05:58:03.226614 [debug] [MainThread]: Parsing macros/adapters/relation.sql
05:58:03.257585 [debug] [MainThread]: Parsing macros/adapters/schema.sql
05:58:03.264584 [debug] [MainThread]: Parsing macros/etc/datetime.sql
05:58:03.294919 [debug] [MainThread]: Parsing macros/etc/statement.sql
05:58:03.308335 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
05:58:03.313122 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
05:58:03.315337 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
05:58:03.317633 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
05:58:03.319533 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
05:58:03.324073 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
05:58:03.328067 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
05:58:03.337021 [debug] [MainThread]: Parsing macros/materializations/configs.sql
05:58:03.344017 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
05:58:03.356796 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
05:58:03.417900 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
05:58:03.440041 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
05:58:03.481849 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
05:58:03.524896 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
05:58:03.529866 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
05:58:03.585728 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
05:58:03.590909 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
05:58:03.605437 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
05:58:03.610850 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
05:58:03.625742 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
05:58:03.663354 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
05:58:03.668767 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
05:58:03.709530 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
05:58:03.771825 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
05:58:03.780183 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
05:58:03.810067 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
05:58:03.818066 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
05:58:03.825311 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
05:58:03.829676 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
05:58:03.856743 [debug] [MainThread]: Parsing tests/generic/builtin.sql
05:58:04.536421 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
05:58:04.569789 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
05:58:04.717565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed8d126b-7274-4111-8865-854ad3e63f57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1dc75050>]}
05:58:04.732795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed8d126b-7274-4111-8865-854ad3e63f57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1dc4a850>]}
05:58:04.733908 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:58:04.736982 [info ] [MainThread]: 
05:58:04.738945 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:58:04.742477 [debug] [ThreadPool]: Acquiring new snowflake connection "list_bigdata"
05:58:04.781135 [debug] [ThreadPool]: Using snowflake connection "list_bigdata"
05:58:04.781987 [debug] [ThreadPool]: On list_bigdata: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_bigdata"} */

    show terse schemas in database bigdata
    limit 10000
05:58:04.782551 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:58:05.904498 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1cb26-0000-1e52-0000-000298a23125
05:58:05.905293 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
05:58:05.906193 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
05:58:05.906846 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
05:58:05.907647 [debug] [ThreadPool]: On list_bigdata: Close
05:58:06.204188 [debug] [MainThread]: Connection 'master' was properly closed.
05:58:06.205143 [debug] [MainThread]: Connection 'list_bigdata' was properly closed.
05:58:06.206046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1dc4abd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1e0a4850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f1e0ffe50>]}


============================== 2022-01-22 06:01:25.093985 | d60dbf6c-5770-4863-bda7-ba923bee39ff ==============================
06:01:25.093985 [info ] [MainThread]: Running with dbt=1.0.1
06:01:25.095260 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
06:01:25.095863 [debug] [MainThread]: Tracking: tracking
06:01:25.097112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14be3f49d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14be3f4d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14be3f4d50>]}
06:01:25.149699 [info ] [MainThread]: Unable to do partial parsing because profile has changed
06:01:25.150910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd60dbf6c-5770-4863-bda7-ba923bee39ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14be38ce90>]}
06:01:25.205077 [debug] [MainThread]: Parsing macros/adapters.sql
06:01:25.353077 [debug] [MainThread]: Parsing macros/catalog.sql
06:01:25.358174 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
06:01:25.386098 [debug] [MainThread]: Parsing macros/materializations/merge.sql
06:01:25.400197 [debug] [MainThread]: Parsing macros/materializations/seed.sql
06:01:25.416815 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
06:01:25.419923 [debug] [MainThread]: Parsing macros/materializations/table.sql
06:01:25.429253 [debug] [MainThread]: Parsing macros/materializations/view.sql
06:01:25.433874 [debug] [MainThread]: Parsing macros/adapters/columns.sql
06:01:25.466846 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
06:01:25.475839 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
06:01:25.483348 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
06:01:25.506585 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
06:01:25.522826 [debug] [MainThread]: Parsing macros/adapters/relation.sql
06:01:25.552788 [debug] [MainThread]: Parsing macros/adapters/schema.sql
06:01:25.559721 [debug] [MainThread]: Parsing macros/etc/datetime.sql
06:01:25.589922 [debug] [MainThread]: Parsing macros/etc/statement.sql
06:01:25.604961 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
06:01:25.609028 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
06:01:25.611334 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
06:01:25.614610 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
06:01:25.616715 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
06:01:25.620979 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
06:01:25.625934 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
06:01:25.634071 [debug] [MainThread]: Parsing macros/materializations/configs.sql
06:01:25.640666 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
06:01:25.651721 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
06:01:25.711201 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
06:01:25.731860 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
06:01:25.773763 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
06:01:25.818052 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
06:01:25.823355 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
06:01:25.881061 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
06:01:25.887115 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
06:01:25.900928 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
06:01:25.906227 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
06:01:25.920608 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
06:01:25.956688 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
06:01:25.962230 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
06:01:26.004575 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
06:01:26.067011 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
06:01:26.075841 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
06:01:26.103397 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
06:01:26.112967 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
06:01:26.120518 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
06:01:26.124118 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
06:01:26.151476 [debug] [MainThread]: Parsing tests/generic/builtin.sql
06:01:26.848011 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
06:01:26.879701 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
06:01:27.025041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd60dbf6c-5770-4863-bda7-ba923bee39ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bdf26990>]}
06:01:27.040053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd60dbf6c-5770-4863-bda7-ba923bee39ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bdf36310>]}
06:01:27.041100 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
06:01:27.043764 [info ] [MainThread]: 
06:01:27.045414 [debug] [MainThread]: Acquiring new snowflake connection "master"
06:01:27.048324 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
06:01:27.088053 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
06:01:27.088923 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
06:01:27.089499 [debug] [ThreadPool]: Opening a new connection, currently in state init
06:01:28.231806 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.14 seconds
06:01:28.236545 [debug] [ThreadPool]: On list_analytics: Close
06:01:28.402336 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
06:01:28.426495 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
06:01:28.427182 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
06:01:28.427684 [debug] [ThreadPool]: Opening a new connection, currently in state closed
06:01:29.254561 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.83 seconds
06:01:29.259266 [debug] [ThreadPool]: On list_analytics_dbt: Close
06:01:29.452461 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
06:01:29.453618 [info ] [MainThread]: 
06:01:29.462535 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
06:01:29.463323 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
06:01:29.464559 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
06:01:29.465582 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
06:01:29.466577 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
06:01:29.474810 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
06:01:29.483589 [debug] [Thread-1  ]: finished collecting timing info
06:01:29.484733 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
06:01:29.571688 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
06:01:29.583246 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
06:01:29.584102 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
06:01:29.584626 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
06:01:33.661694 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 4.08 seconds
06:01:33.690349 [debug] [Thread-1  ]: finished collecting timing info
06:01:33.691227 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
06:01:33.951855 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd60dbf6c-5770-4863-bda7-ba923bee39ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bc54ad10>]}
06:01:33.954662 [info ] [Thread-1  ]: 1 of 2 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 4.49s]
06:01:33.957020 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
06:01:33.960265 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
06:01:33.962059 [info ] [Thread-1  ]: 2 of 2 START view model dbt.my_second_dbt_model................................. [RUN]
06:01:33.964086 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
06:01:33.965528 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
06:01:33.967120 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
06:01:33.975326 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
06:01:33.978902 [debug] [Thread-1  ]: finished collecting timing info
06:01:33.979751 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
06:01:34.036914 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
06:01:34.041633 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
06:01:34.042448 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
06:01:34.043083 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
06:01:34.924101 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
06:01:34.935869 [debug] [Thread-1  ]: finished collecting timing info
06:01:34.937372 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
06:01:35.067308 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd60dbf6c-5770-4863-bda7-ba923bee39ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bc556710>]}
06:01:35.068493 [info ] [Thread-1  ]: 2 of 2 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.10s]
06:01:35.069435 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
06:01:35.116161 [debug] [MainThread]: Acquiring new snowflake connection "master"
06:01:35.117182 [info ] [MainThread]: 
06:01:35.118060 [info ] [MainThread]: Finished running 1 table model, 1 view model in 8.07s.
06:01:35.119169 [debug] [MainThread]: Connection 'master' was properly closed.
06:01:35.119929 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
06:01:35.139172 [info ] [MainThread]: 
06:01:35.140489 [info ] [MainThread]: [32mCompleted successfully[0m
06:01:35.141944 [info ] [MainThread]: 
06:01:35.143314 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
06:01:35.144743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bca85c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bc556150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14bc556110>]}


============================== 2022-01-22 07:07:43.214728 | 1dc5882a-2110-477e-86cf-f8a1525cec9f ==============================
07:07:43.214728 [info ] [MainThread]: Running with dbt=1.0.1
07:07:43.215882 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
07:07:43.216779 [debug] [MainThread]: Tracking: tracking
07:07:43.218076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7b04dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7b04cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7b04e50>]}
07:07:43.313991 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
07:07:43.315233 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/snowflake_customer_purchases.sql
07:07:43.316380 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
07:07:43.354342 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
07:07:43.469621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1dc5882a-2110-477e-86cf-f8a1525cec9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7a24410>]}
07:07:43.490529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1dc5882a-2110-477e-86cf-f8a1525cec9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7b10d90>]}
07:07:43.491916 [info ] [MainThread]: Found 3 models, 6 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
07:07:43.495522 [info ] [MainThread]: 
07:07:43.497827 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:07:43.500914 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
07:07:43.540396 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
07:07:43.541227 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
07:07:43.541924 [debug] [ThreadPool]: Opening a new connection, currently in state init
07:07:44.796022 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.25 seconds
07:07:44.800366 [debug] [ThreadPool]: On list_analytics: Close
07:07:44.972740 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
07:07:44.991850 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
07:07:44.992876 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
07:07:44.993635 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:07:46.009766 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1.02 seconds
07:07:46.017219 [debug] [ThreadPool]: On list_analytics_dbt: Close
07:07:46.192451 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
07:07:46.193357 [info ] [MainThread]: 
07:07:46.197692 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
07:07:46.198973 [info ] [Thread-1  ]: 1 of 3 START table model dbt.my_first_dbt_model................................. [RUN]
07:07:46.200532 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
07:07:46.201320 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
07:07:46.202634 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
07:07:46.210817 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
07:07:46.215568 [debug] [Thread-1  ]: finished collecting timing info
07:07:46.216682 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
07:07:46.296711 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
07:07:46.302650 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
07:07:46.303785 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
07:07:46.304705 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:07:48.166139 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
07:07:48.192861 [debug] [Thread-1  ]: finished collecting timing info
07:07:48.193852 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
07:07:48.357155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dc5882a-2110-477e-86cf-f8a1525cec9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fce4289d0>]}
07:07:48.358319 [info ] [Thread-1  ]: 1 of 3 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.16s]
07:07:48.359300 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
07:07:48.360368 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
07:07:48.362254 [info ] [Thread-1  ]: 2 of 3 START table model dbt.snowflake_customer_purchases....................... [RUN]
07:07:48.363626 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
07:07:48.364621 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
07:07:48.365369 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
07:07:48.372690 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
07:07:48.379994 [debug] [Thread-1  ]: finished collecting timing info
07:07:48.381043 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
07:07:48.388664 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
07:07:48.394599 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
07:07:48.395567 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
07:07:48.396300 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:07:50.875700 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.48 seconds
07:07:50.890674 [debug] [Thread-1  ]: finished collecting timing info
07:07:50.892704 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
07:07:51.041824 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dc5882a-2110-477e-86cf-f8a1525cec9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc4452a90>]}
07:07:51.044461 [info ] [Thread-1  ]: 2 of 3 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.68s]
07:07:51.048203 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
07:07:51.049596 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
07:07:51.052133 [info ] [Thread-1  ]: 3 of 3 START view model dbt.my_second_dbt_model................................. [RUN]
07:07:51.053766 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
07:07:51.056743 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
07:07:51.057808 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
07:07:51.065127 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
07:07:51.070492 [debug] [Thread-1  ]: finished collecting timing info
07:07:51.072155 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
07:07:51.131214 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
07:07:51.142346 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
07:07:51.143268 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
07:07:51.143843 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:07:52.054522 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
07:07:52.057688 [debug] [Thread-1  ]: finished collecting timing info
07:07:52.058519 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
07:07:52.220790 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dc5882a-2110-477e-86cf-f8a1525cec9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc5191ed0>]}
07:07:52.222634 [info ] [Thread-1  ]: 3 of 3 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.17s]
07:07:52.224438 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
07:07:52.266083 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:07:52.267440 [info ] [MainThread]: 
07:07:52.268221 [info ] [MainThread]: Finished running 2 table models, 1 view model in 8.77s.
07:07:52.269566 [debug] [MainThread]: Connection 'master' was properly closed.
07:07:52.271280 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
07:07:52.292240 [info ] [MainThread]: 
07:07:52.293377 [info ] [MainThread]: [32mCompleted successfully[0m
07:07:52.295009 [info ] [MainThread]: 
07:07:52.296267 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
07:07:52.297820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc5186310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7a37dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fc7a37350>]}


============================== 2022-01-22 07:37:43.802132 | d77e5acf-171b-4daf-ba51-be3d95d757be ==============================
07:37:43.802132 [info ] [MainThread]: Running with dbt=1.0.1
07:37:43.803362 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
07:37:43.804530 [debug] [MainThread]: Tracking: tracking
07:37:43.805766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d461f1d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d461f1bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d461f1d10>]}
07:37:43.903997 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
07:37:43.905263 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/cumulative_orders_by_date.sql
07:37:43.906601 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
07:37:43.942008 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
07:37:44.058507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd77e5acf-171b-4daf-ba51-be3d95d757be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d460f70d0>]}
07:37:44.081017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd77e5acf-171b-4daf-ba51-be3d95d757be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d45c946d0>]}
07:37:44.082303 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
07:37:44.086214 [info ] [MainThread]: 
07:37:44.088430 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:37:44.092145 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
07:37:44.193728 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
07:37:44.194697 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
07:37:44.195416 [debug] [ThreadPool]: Opening a new connection, currently in state init
07:37:45.354615 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.16 seconds
07:37:45.359663 [debug] [ThreadPool]: On list_analytics: Close
07:37:45.510970 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
07:37:45.531682 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
07:37:45.532534 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
07:37:45.533410 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:37:46.340092 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
07:37:46.352034 [debug] [ThreadPool]: On list_analytics_dbt: Close
07:37:46.528990 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
07:37:46.532021 [info ] [MainThread]: 
07:37:46.540933 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
07:37:46.542269 [info ] [Thread-1  ]: 1 of 4 START table model dbt.cumulative_orders_by_date.......................... [RUN]
07:37:46.544029 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
07:37:46.545219 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
07:37:46.546998 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
07:37:46.553808 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
07:37:46.558468 [debug] [Thread-1  ]: finished collecting timing info
07:37:46.559655 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
07:37:46.647109 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
07:37:46.660399 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
07:37:46.661556 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
07:37:46.662530 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:37:48.666995 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
07:37:48.698645 [debug] [Thread-1  ]: finished collecting timing info
07:37:48.699611 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
07:37:48.852872 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd77e5acf-171b-4daf-ba51-be3d95d757be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4490d750>]}
07:37:48.854779 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.31s]
07:37:48.856338 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
07:37:48.857226 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
07:37:48.858251 [info ] [Thread-1  ]: 2 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
07:37:48.860934 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
07:37:48.862276 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
07:37:48.863189 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
07:37:48.875196 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
07:37:48.879500 [debug] [Thread-1  ]: finished collecting timing info
07:37:48.880510 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
07:37:48.891885 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
07:37:48.899148 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
07:37:48.899910 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
07:37:48.900539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:37:50.358151 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
07:37:50.361755 [debug] [Thread-1  ]: finished collecting timing info
07:37:50.362455 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
07:37:50.518451 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd77e5acf-171b-4daf-ba51-be3d95d757be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d44312310>]}
07:37:50.521758 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.66s]
07:37:50.524198 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
07:37:50.526556 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
07:37:50.529217 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
07:37:50.531380 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
07:37:50.532743 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
07:37:50.533669 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
07:37:50.541610 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
07:37:50.546413 [debug] [Thread-1  ]: finished collecting timing info
07:37:50.547542 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
07:37:50.563760 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
07:37:50.569518 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
07:37:50.570455 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
07:37:50.571101 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:37:52.450136 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
07:37:52.461054 [debug] [Thread-1  ]: finished collecting timing info
07:37:52.462285 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
07:37:52.615562 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd77e5acf-171b-4daf-ba51-be3d95d757be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d521ca890>]}
07:37:52.618126 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.08s]
07:37:52.620106 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
07:37:52.622051 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
07:37:52.624168 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
07:37:52.626441 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
07:37:52.627891 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
07:37:52.629100 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
07:37:52.636289 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
07:37:52.640203 [debug] [Thread-1  ]: finished collecting timing info
07:37:52.641430 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
07:37:52.702046 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
07:37:52.706960 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
07:37:52.707799 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
07:37:52.708631 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:37:53.686868 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
07:37:53.690022 [debug] [Thread-1  ]: finished collecting timing info
07:37:53.690709 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
07:37:53.868748 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd77e5acf-171b-4daf-ba51-be3d95d757be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d472b8950>]}
07:37:53.870215 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.24s]
07:37:53.871781 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
07:37:53.910001 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:37:53.912018 [info ] [MainThread]: 
07:37:53.913449 [info ] [MainThread]: Finished running 3 table models, 1 view model in 9.82s.
07:37:53.915405 [debug] [MainThread]: Connection 'master' was properly closed.
07:37:53.916770 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
07:37:53.941963 [info ] [MainThread]: 
07:37:53.944072 [info ] [MainThread]: [32mCompleted successfully[0m
07:37:53.946455 [info ] [MainThread]: 
07:37:53.948525 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
07:37:53.950581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d44827a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d44322510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d44322690>]}


============================== 2022-01-22 12:33:41.197036 | 36c9da55-6562-4091-875c-3d45433702a8 ==============================
12:33:41.197036 [info ] [MainThread]: Running with dbt=1.0.1
12:33:41.198411 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.debug.DebugTask'>, config_dir=False, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='debug', write_json=None)
12:33:41.199253 [debug] [MainThread]: Tracking: tracking
12:33:41.201277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc809b76350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc809b6bd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc809b6bd50>]}
12:33:41.868126 [debug] [MainThread]: Executing "git --help"
12:33:41.887985 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-c name=value]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThe most commonly used git commands are:\n   add        Add file contents to the index\n   bisect     Find by binary search the change that introduced a bug\n   branch     List, create, or delete branches\n   checkout   Checkout a branch or paths to the working tree\n   clone      Clone a repository into a new directory\n   commit     Record changes to the repository\n   diff       Show changes between commits, commit and working tree, etc\n   fetch      Download objects and refs from another repository\n   grep       Print lines matching a pattern\n   init       Create an empty Git repository or reinitialize an existing one\n   log        Show commit logs\n   merge      Join two or more development histories together\n   mv         Move or rename a file, a directory, or a symlink\n   pull       Fetch from and merge with another repository or a local branch\n   push       Update remote refs along with associated objects\n   rebase     Forward-port local commits to the updated upstream head\n   reset      Reset current HEAD to the specified state\n   rm         Remove files from the working tree and from the index\n   show       Show various types of objects\n   status     Show the working tree status\n   tag        Create, list, delete or verify a tag object signed with GPG\n\n'git help -a' and 'git help -g' lists available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\n""
12:33:41.889398 [debug] [MainThread]: STDERR: "b''"
12:33:41.904411 [debug] [MainThread]: Acquiring new snowflake connection "debug"
12:33:41.907924 [debug] [MainThread]: Using snowflake connection "debug"
12:33:41.908748 [debug] [MainThread]: On debug: select 1 as id
12:33:41.909541 [debug] [MainThread]: Opening a new connection, currently in state init
12:33:43.120294 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.21 seconds
12:33:43.127593 [debug] [MainThread]: On debug: Close
12:33:43.312115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8004321d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8004b6050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8004b6110>]}
12:33:44.406126 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-01-22 13:57:51.849246 | 0dd2ff0e-8314-4d05-a486-a238accb247b ==============================
13:57:51.849246 [info ] [MainThread]: Running with dbt=1.0.1
13:57:51.850728 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:57:51.851602 [debug] [MainThread]: Tracking: tracking
13:57:51.853484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f2deccd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f2deca10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f2decd50>]}
13:57:51.915317 [info ] [MainThread]: Unable to do partial parsing because profile has changed
13:57:51.916430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f2d51f10>]}
13:57:51.976034 [debug] [MainThread]: Parsing macros/adapters.sql
13:57:52.139565 [debug] [MainThread]: Parsing macros/catalog.sql
13:57:52.144485 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:57:52.172078 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:57:52.185298 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:57:52.201338 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:57:52.204420 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:57:52.215340 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:57:52.218887 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:57:52.253078 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:57:52.263404 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:57:52.272979 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:57:52.298831 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:57:52.313864 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:57:52.345458 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:57:52.352055 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:57:52.383047 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:57:52.396176 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:57:52.400758 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:57:52.402453 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:57:52.405364 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:57:52.408117 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:57:52.413448 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:57:52.418153 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:57:52.424854 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:57:52.431074 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:57:52.442925 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:57:52.503225 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:57:52.524281 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:57:52.565047 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:57:52.610685 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:57:52.615672 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:57:52.674118 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:57:52.679394 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:57:52.694190 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:57:52.699926 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:57:52.714483 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:57:52.751365 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:57:52.756203 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:57:52.798070 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:57:52.858744 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:57:52.866873 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:57:52.894370 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:57:52.903669 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:57:52.910073 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:57:52.913988 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:57:52.995718 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:57:53.672304 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
13:57:53.704284 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
13:57:53.726256 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
13:57:53.728737 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
13:57:53.735611 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:57:53.743321 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
13:57:53.916722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f2d70750>]}
13:57:53.934389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f9ca08d0>]}
13:57:53.935486 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:57:53.939213 [info ] [MainThread]: 
13:57:53.941155 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:57:53.944894 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:57:53.984040 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:57:53.984738 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:57:53.985413 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:57:55.512703 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.53 seconds
13:57:55.516749 [debug] [ThreadPool]: On list_analytics: Close
13:57:55.705721 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:57:55.728930 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:57:55.729764 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:57:55.730262 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:57:56.469149 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.74 seconds
13:57:56.480211 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:57:56.618455 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:57:56.621989 [info ] [MainThread]: 
13:57:56.634019 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:57:56.635979 [info ] [Thread-1  ]: 1 of 5 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:57:56.638355 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:57:56.639678 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:57:56.640968 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:57:56.650383 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:57:56.654941 [debug] [Thread-1  ]: finished collecting timing info
13:57:56.656066 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:57:56.733098 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:57:56.749034 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:57:56.749862 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:57:56.750778 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:57:58.700885 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
13:57:58.740163 [debug] [Thread-1  ]: finished collecting timing info
13:57:58.741127 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:57:58.914440 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f1430dd0>]}
13:57:58.915508 [info ] [Thread-1  ]: 1 of 5 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.28s]
13:57:58.916455 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:57:58.917244 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:57:58.918551 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.dates........................................ [RUN]
13:57:58.920073 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:57:58.920902 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:57:58.921693 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:57:58.930739 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:57:58.934802 [debug] [Thread-1  ]: finished collecting timing info
13:57:58.935687 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:57:59.021851 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:57:59.026720 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:57:59.027670 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
13:57:59.028315 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:00.646724 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
13:58:00.663167 [debug] [Thread-1  ]: finished collecting timing info
13:58:00.665164 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:58:00.802586 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f0724d50>]}
13:58:00.804594 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 1.88s]
13:58:00.806640 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:58:00.808624 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:58:00.811135 [info ] [Thread-1  ]: 3 of 5 START table model dbt.my_first_dbt_model................................. [RUN]
13:58:00.813083 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:58:00.814126 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:58:00.815226 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:58:00.823856 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
13:58:00.829226 [debug] [Thread-1  ]: finished collecting timing info
13:58:00.830556 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
13:58:00.835873 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
13:58:00.841772 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
13:58:00.842788 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
13:58:00.843927 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:02.471291 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
13:58:02.474715 [debug] [Thread-1  ]: finished collecting timing info
13:58:02.475515 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
13:58:02.648108 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f143ded0>]}
13:58:02.651228 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.83s]
13:58:02.653982 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:58:02.656019 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:58:02.658568 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:58:02.660624 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:58:02.661907 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:58:02.663211 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:58:02.670180 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:58:02.675146 [debug] [Thread-1  ]: finished collecting timing info
13:58:02.676741 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:58:02.683643 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:58:02.689500 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:58:02.690294 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:58:02.690763 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:04.627727 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.94 seconds
13:58:04.631034 [debug] [Thread-1  ]: finished collecting timing info
13:58:04.631886 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:58:04.812505 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f139cd10>]}
13:58:04.814783 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.15s]
13:58:04.816425 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:58:04.818289 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:58:04.820641 [info ] [Thread-1  ]: 5 of 5 START view model dbt.my_second_dbt_model................................. [RUN]
13:58:04.823449 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
13:58:04.824810 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
13:58:04.827039 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
13:58:04.835339 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
13:58:04.839390 [debug] [Thread-1  ]: finished collecting timing info
13:58:04.840658 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
13:58:04.899114 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
13:58:04.904113 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
13:58:04.904985 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
13:58:04.905712 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:06.081710 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.18 seconds
13:58:06.087553 [debug] [Thread-1  ]: finished collecting timing info
13:58:06.088437 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
13:58:06.256216 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dd2ff0e-8314-4d05-a486-a238accb247b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f06fb8d0>]}
13:58:06.257627 [info ] [Thread-1  ]: 5 of 5 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.43s]
13:58:06.258822 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:58:06.339673 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:58:06.341096 [info ] [MainThread]: 
13:58:06.342291 [info ] [MainThread]: Finished running 3 table models, 1 incremental model, 1 view model in 12.40s.
13:58:06.343351 [debug] [MainThread]: Connection 'master' was properly closed.
13:58:06.344138 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
13:58:06.363625 [info ] [MainThread]: 
13:58:06.364582 [info ] [MainThread]: [32mCompleted successfully[0m
13:58:06.366033 [info ] [MainThread]: 
13:58:06.367348 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
13:58:06.368905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f1463410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f3e44ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54f3e44690>]}


============================== 2022-01-22 13:59:57.575383 | 855a1943-a647-4aa0-a53e-fcb17e793136 ==============================
13:59:57.575383 [info ] [MainThread]: Running with dbt=1.0.1
13:59:57.576486 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:59:57.577208 [debug] [MainThread]: Tracking: tracking
13:59:57.578341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8b9f0c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8b9f0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8b9f0d10>]}
13:59:57.680731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:59:57.681606 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:59:57.698296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8b909310>]}
13:59:57.715953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8ca2b350>]}
13:59:57.717123 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:59:57.721155 [info ] [MainThread]: 
13:59:57.723228 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:59:57.726598 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:59:57.764840 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:59:57.765643 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:59:57.766357 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:59:58.933153 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.17 seconds
13:59:58.937390 [debug] [ThreadPool]: On list_analytics: Close
13:59:59.075048 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:59:59.093995 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:59:59.094677 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:59:59.095157 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:59:59.825664 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.73 seconds
13:59:59.829399 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:59:59.960788 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:59:59.962963 [info ] [MainThread]: 
13:59:59.969543 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:59:59.970722 [info ] [Thread-1  ]: 1 of 5 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:59:59.972939 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:59:59.974268 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:59:59.975521 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:59:59.982138 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:59:59.986969 [debug] [Thread-1  ]: finished collecting timing info
13:59:59.987946 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
14:00:00.064426 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
14:00:00.071264 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
14:00:00.072334 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
14:00:00.073355 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:00:02.192474 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
14:00:02.237310 [debug] [Thread-1  ]: finished collecting timing info
14:00:02.238223 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
14:00:02.414535 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8878bad0>]}
14:00:02.416654 [info ] [Thread-1  ]: 1 of 5 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.44s]
14:00:02.418474 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
14:00:02.419948 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
14:00:02.421587 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.dates........................................ [RUN]
14:00:02.423272 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
14:00:02.424354 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
14:00:02.425153 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
14:00:02.454710 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
14:00:02.459248 [debug] [Thread-1  ]: finished collecting timing info
14:00:02.460269 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
14:00:02.535329 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:02.536074 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
14:00:02.536563 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:00:03.778285 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
14:00:03.806315 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:03.807091 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:00:03.913413 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
14:00:03.938822 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:03.939641 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
14:00:04.048152 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
14:00:04.080981 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:04.081899 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:00:04.183223 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:00:04.263755 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
14:00:04.275704 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:04.276768 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
14:00:04.389435 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
14:00:04.392491 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:04.394707 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:00:05.013619 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.62 seconds
14:00:05.014488 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:00:05.015030 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
14:00:05.171716 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
14:00:05.183156 [debug] [Thread-1  ]: finished collecting timing info
14:00:05.184767 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
14:00:05.344449 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8879cb10>]}
14:00:05.345793 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.92s]
14:00:05.347357 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
14:00:05.348673 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:00:05.350085 [info ] [Thread-1  ]: 3 of 5 START table model dbt.my_first_dbt_model................................. [RUN]
14:00:05.351681 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:00:05.352838 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:00:05.353680 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:00:05.362497 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:00:05.366091 [debug] [Thread-1  ]: finished collecting timing info
14:00:05.367084 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:00:05.377455 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:00:05.383029 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:00:05.383913 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:00:05.384568 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:00:06.748493 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
14:00:06.751620 [debug] [Thread-1  ]: finished collecting timing info
14:00:06.752281 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:00:06.932526 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8a4ab290>]}
14:00:06.934927 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.58s]
14:00:06.936394 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:00:06.937982 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
14:00:06.939871 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:00:06.941839 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
14:00:06.942941 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
14:00:06.943968 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
14:00:06.950622 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
14:00:06.955148 [debug] [Thread-1  ]: finished collecting timing info
14:00:06.956123 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
14:00:06.962663 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
14:00:06.968611 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
14:00:06.969809 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
14:00:06.970697 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:00:08.917121 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
14:00:08.920402 [debug] [Thread-1  ]: finished collecting timing info
14:00:08.921293 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
14:00:09.043420 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d88782290>]}
14:00:09.045248 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.10s]
14:00:09.046955 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
14:00:09.048530 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
14:00:09.050574 [info ] [Thread-1  ]: 5 of 5 START view model dbt.my_second_dbt_model................................. [RUN]
14:00:09.052868 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
14:00:09.054273 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
14:00:09.055566 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
14:00:09.062946 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
14:00:09.068431 [debug] [Thread-1  ]: finished collecting timing info
14:00:09.069967 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
14:00:09.129937 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
14:00:09.135051 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
14:00:09.135890 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
14:00:09.136674 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:00:10.241059 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
14:00:10.250590 [debug] [Thread-1  ]: finished collecting timing info
14:00:10.251587 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
14:00:10.413017 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '855a1943-a647-4aa0-a53e-fcb17e793136', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8879c790>]}
14:00:10.414269 [info ] [Thread-1  ]: 5 of 5 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.36s]
14:00:10.415743 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
14:00:10.541485 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:00:10.542614 [info ] [MainThread]: 
14:00:10.543533 [info ] [MainThread]: Finished running 3 table models, 1 incremental model, 1 view model in 12.82s.
14:00:10.544678 [debug] [MainThread]: Connection 'master' was properly closed.
14:00:10.546073 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
14:00:10.565149 [info ] [MainThread]: 
14:00:10.566509 [info ] [MainThread]: [32mCompleted successfully[0m
14:00:10.569299 [info ] [MainThread]: 
14:00:10.571172 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
14:00:10.572872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8871ab90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8879cc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8879c950>]}


============================== 2022-01-22 14:10:26.559514 | f7528b37-28ab-44b3-a84f-8ced532acff1 ==============================
14:10:26.559514 [info ] [MainThread]: Running with dbt=1.0.1
14:10:26.560742 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:10:26.561980 [debug] [MainThread]: Tracking: tracking
14:10:26.563266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca0cf4d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca0cf4d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca0cf4c90>]}
14:10:26.616659 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:10:26.617761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca0c53f90>]}
14:10:26.675232 [debug] [MainThread]: Parsing macros/adapters.sql
14:10:26.825503 [debug] [MainThread]: Parsing macros/catalog.sql
14:10:26.832010 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:10:26.861218 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:10:26.873667 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:10:26.894218 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:10:26.897900 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:10:26.908745 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:10:26.912517 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:10:26.952671 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:10:26.963807 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:10:26.974904 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:10:27.001384 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:10:27.017680 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:10:27.049638 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:10:27.055656 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:10:27.084578 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:10:27.104118 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:10:27.108161 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:10:27.109959 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:10:27.112987 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:10:27.114685 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:10:27.119521 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:10:27.125306 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:10:27.134011 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:10:27.142335 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:10:27.153420 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:10:27.212860 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:10:27.232777 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:10:27.274594 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:10:27.319470 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:10:27.324275 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:10:27.381523 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:10:27.387451 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:10:27.402919 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:10:27.407665 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:10:27.422212 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:10:27.461696 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:10:27.466661 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:10:27.508914 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:10:27.570106 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:10:27.578389 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:10:27.605807 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:10:27.614713 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:10:27.623775 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:10:27.628838 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:10:27.709736 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:10:28.374098 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
14:10:28.406142 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
14:10:28.427167 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
14:10:28.429834 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
14:10:28.436540 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:10:28.443631 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:10:28.623649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca6b7fc90>]}
14:10:28.644023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca0c3c090>]}
14:10:28.644948 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:10:28.648937 [info ] [MainThread]: 
14:10:28.651186 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:10:28.653989 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:10:28.693856 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:10:28.694613 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:10:28.695321 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:10:29.896765 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.2 seconds
14:10:29.902617 [debug] [ThreadPool]: On list_analytics: Close
14:10:30.079336 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:10:30.103975 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:10:30.104615 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:10:30.105122 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:10:30.872595 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.77 seconds
14:10:30.883322 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:10:31.026359 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:10:31.027731 [info ] [MainThread]: 
14:10:31.033004 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
14:10:31.034255 [info ] [Thread-1  ]: 1 of 4 START table model dbt.cumulative_orders_by_date.......................... [RUN]
14:10:31.035680 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
14:10:31.036962 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
14:10:31.037928 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
14:10:31.045711 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
14:10:31.049451 [debug] [Thread-1  ]: finished collecting timing info
14:10:31.050355 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
14:10:31.132088 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
14:10:31.138147 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
14:10:31.139127 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
14:10:31.139877 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:10:33.211122 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
14:10:33.260006 [debug] [Thread-1  ]: finished collecting timing info
14:10:33.260876 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
14:10:33.421055 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c9e35f650>]}
14:10:33.423387 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.39s]
14:10:33.425746 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
14:10:33.427655 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
14:10:33.429610 [info ] [Thread-1  ]: 2 of 4 START incremental model dbt.dates........................................ [RUN]
14:10:33.431957 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
14:10:33.433156 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
14:10:33.434035 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
14:10:33.450337 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
14:10:33.454829 [debug] [Thread-1  ]: finished collecting timing info
14:10:33.456500 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
14:10:33.532006 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:33.532945 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
14:10:33.533573 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:10:34.951879 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
14:10:34.978676 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:34.979327 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:10:35.086042 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
14:10:35.098430 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:35.099132 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
14:10:35.199227 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:10:35.234812 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:35.235805 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:10:35.335654 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:10:35.441065 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
14:10:35.451129 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:35.452117 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
14:10:35.571991 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:10:35.574639 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:35.576409 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:10:35.940256 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
14:10:35.941595 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:10:35.942380 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
14:10:36.113774 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
14:10:36.118474 [debug] [Thread-1  ]: finished collecting timing info
14:10:36.119327 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
14:10:36.288066 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c9c5faed0>]}
14:10:36.289887 [info ] [Thread-1  ]: 2 of 4 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.86s]
14:10:36.292360 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
14:10:36.294649 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:10:36.298234 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:10:36.299997 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:10:36.301572 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:10:36.312483 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:10:36.316568 [debug] [Thread-1  ]: finished collecting timing info
14:10:36.317925 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:10:36.318866 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
14:10:36.320153 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:10:36.321662 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
14:10:36.322386 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
14:10:36.323357 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
14:10:36.336505 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
14:10:36.340219 [debug] [Thread-1  ]: finished collecting timing info
14:10:36.340996 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
14:10:36.355810 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
14:10:36.362153 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
14:10:36.363046 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
14:10:36.363916 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:10:38.688270 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.32 seconds
14:10:38.695472 [debug] [Thread-1  ]: finished collecting timing info
14:10:38.696734 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
14:10:38.870982 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c9c5a4650>]}
14:10:38.873756 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.55s]
14:10:38.876685 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
14:10:38.879607 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
14:10:38.882826 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
14:10:38.885225 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
14:10:38.886740 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
14:10:38.888063 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
14:10:38.915113 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
14:10:38.919415 [debug] [Thread-1  ]: finished collecting timing info
14:10:38.920488 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
14:10:38.925867 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" because it is of type view
14:10:38.943989 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
14:10:38.945405 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" cascade
14:10:38.946238 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:10:39.763721 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
14:10:39.775078 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
14:10:39.786304 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
14:10:39.787730 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
14:10:40.401741 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.61 seconds
14:10:40.412784 [debug] [Thread-1  ]: finished collecting timing info
14:10:40.414221 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
14:10:40.582058 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7528b37-28ab-44b3-a84f-8ced532acff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca0cd9610>]}
14:10:40.584896 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.70s]
14:10:40.587017 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
14:10:40.684501 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:10:40.688537 [info ] [MainThread]: 
14:10:40.692161 [info ] [MainThread]: Finished running 3 table models, 1 incremental model in 12.04s.
14:10:40.696094 [debug] [MainThread]: Connection 'master' was properly closed.
14:10:40.699336 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
14:10:40.726210 [info ] [MainThread]: 
14:10:40.727419 [info ] [MainThread]: [32mCompleted successfully[0m
14:10:40.728655 [info ] [MainThread]: 
14:10:40.730024 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
14:10:40.731358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c9c5951d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c9e329590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c9e329490>]}


============================== 2022-01-23 12:10:52.356518 | b91a30b5-d5d1-468e-9a34-360430bbb164 ==============================
12:10:52.356518 [info ] [MainThread]: Running with dbt=1.0.1
12:10:52.357762 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:10:52.358730 [debug] [MainThread]: Tracking: tracking
12:10:52.359825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec0a1d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec0a1c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec0a1e10>]}
12:10:52.469114 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
12:10:52.470046 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/incremental_time.sql
12:10:52.502270 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:10:52.550238 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:10:52.577259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2beaf000d0>]}
12:10:52.594677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec0c4650>]}
12:10:52.595796 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:10:52.599710 [info ] [MainThread]: 
12:10:52.601715 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:10:52.605058 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:10:52.699636 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:10:52.700636 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:10:52.701254 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:10:53.888301 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.19 seconds
12:10:53.892913 [debug] [ThreadPool]: On list_analytics: Close
12:10:54.054563 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:10:54.075512 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:10:54.076362 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:10:54.076832 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:10:55.062521 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.99 seconds
12:10:55.076669 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:10:55.235157 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:10:55.237955 [info ] [MainThread]: 
12:10:55.245771 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:10:55.247231 [info ] [Thread-1  ]: 1 of 5 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:10:55.248926 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:10:55.249645 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:10:55.250871 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:10:55.257950 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:10:55.263211 [debug] [Thread-1  ]: finished collecting timing info
12:10:55.264214 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:10:55.340410 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:10:55.347342 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:10:55.348240 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:10:55.348729 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:10:58.489082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.14 seconds
12:10:58.527896 [debug] [Thread-1  ]: finished collecting timing info
12:10:58.528995 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:10:58.672830 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec1090d0>]}
12:10:58.676621 [info ] [Thread-1  ]: 1 of 5 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 3.42s]
12:10:58.679956 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:10:58.682421 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:10:58.684987 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.dates........................................ [RUN]
12:10:58.687402 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:10:58.688611 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:10:58.689937 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:10:58.709418 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:10:58.713879 [debug] [Thread-1  ]: finished collecting timing info
12:10:58.714938 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:10:58.793380 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:10:58.794435 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:10:58.795305 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:01.446306 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.65 seconds
12:11:01.477170 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:11:01.478026 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:11:01.578083 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:11:01.595289 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:11:01.596214 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:11:01.699170 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:11:01.731040 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:11:01.731934 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:11:01.826791 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
12:11:01.906886 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:11:01.917781 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:11:01.918588 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:11:02.032805 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
12:11:02.035844 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:11:02.037576 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:11:02.679973 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
12:11:02.681421 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:11:02.682512 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:11:02.938468 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:11:02.942438 [debug] [Thread-1  ]: finished collecting timing info
12:11:02.943378 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:11:03.108975 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2be9aab950>]}
12:11:03.110001 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.42s]
12:11:03.110816 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:11:03.111364 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:11:03.112607 [info ] [Thread-1  ]: 3 of 5 START incremental model dbt.incremental_time............................. [RUN]
12:11:03.114320 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:11:03.115172 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:11:03.115910 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:11:03.127218 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:11:03.130838 [debug] [Thread-1  ]: finished collecting timing info
12:11:03.131778 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:11:03.138707 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:11:03.144616 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:11:03.145591 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
12:11:03.146349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:04.840278 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
12:11:04.851985 [debug] [Thread-1  ]: finished collecting timing info
12:11:04.854237 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:11:04.982979 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2be8509d10>]}
12:11:04.986477 [info ] [Thread-1  ]: 3 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 1.87s]
12:11:04.989517 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:11:04.992006 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:11:04.996327 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:11:04.998542 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:11:05.000405 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:11:05.012835 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:11:05.017908 [debug] [Thread-1  ]: finished collecting timing info
12:11:05.019444 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:11:05.020575 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:11:05.021837 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:11:05.023330 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:11:05.024012 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:11:05.024835 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:11:05.030926 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:11:05.034209 [debug] [Thread-1  ]: finished collecting timing info
12:11:05.035257 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:11:05.042751 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:11:05.049182 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:11:05.050228 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:11:05.051155 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:07.039460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
12:11:07.046118 [debug] [Thread-1  ]: finished collecting timing info
12:11:07.047588 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:11:07.194116 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec0d20d0>]}
12:11:07.197950 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.17s]
12:11:07.201056 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:11:07.203049 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:11:07.205788 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
12:11:07.207595 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:11:07.208816 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:11:07.210162 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:11:07.240209 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:11:07.245170 [debug] [Thread-1  ]: finished collecting timing info
12:11:07.246532 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:11:07.252399 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:11:07.259073 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:11:07.259957 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
12:11:07.260844 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:08.540102 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
12:11:08.544459 [debug] [Thread-1  ]: finished collecting timing info
12:11:08.545324 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:11:08.672953 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b91a30b5-d5d1-468e-9a34-360430bbb164', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2be9ad1690>]}
12:11:08.674035 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.47s]
12:11:08.675116 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:11:08.737793 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:11:08.739043 [info ] [MainThread]: 
12:11:08.739978 [info ] [MainThread]: Finished running 3 table models, 2 incremental models in 16.14s.
12:11:08.741085 [debug] [MainThread]: Connection 'master' was properly closed.
12:11:08.741763 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:11:08.760820 [info ] [MainThread]: 
12:11:08.761859 [info ] [MainThread]: [32mCompleted successfully[0m
12:11:08.762989 [info ] [MainThread]: 
12:11:08.764152 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
12:11:08.765399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bec0c4d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2be85550d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2be9aab210>]}


============================== 2022-01-23 12:15:01.974533 | cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa ==============================
12:15:01.974533 [info ] [MainThread]: Running with dbt=1.0.1
12:15:01.976275 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:15:01.978009 [debug] [MainThread]: Tracking: tracking
12:15:01.980216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91aacd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91aac650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91aaccd0>]}
12:15:02.133181 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:15:02.134762 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
12:15:02.179904 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:15:02.330464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd90978a10>]}
12:15:02.357433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd90511ad0>]}
12:15:02.358924 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:15:02.363808 [info ] [MainThread]: 
12:15:02.366026 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:15:02.369943 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:15:02.492110 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:15:02.493247 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:15:02.493975 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:15:04.136966 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.64 seconds
12:15:04.146348 [debug] [ThreadPool]: On list_analytics: Close
12:15:04.346778 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:15:04.396809 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:15:04.398053 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:15:04.399220 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:15:05.804162 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.4 seconds
12:15:05.811110 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:15:06.007876 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:15:06.011139 [info ] [MainThread]: 
12:15:06.026274 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:15:06.027399 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:15:06.028675 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:15:06.030212 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:15:06.031642 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:15:06.040405 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:15:06.045755 [debug] [Thread-1  ]: finished collecting timing info
12:15:06.047705 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:15:06.305616 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:15:06.312572 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:15:06.313609 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:15:06.314569 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:15:08.356139 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
12:15:08.406002 [debug] [Thread-1  ]: finished collecting timing info
12:15:08.406684 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:15:08.538986 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91b31b50>]}
12:15:08.540273 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.51s]
12:15:08.541337 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:15:08.542309 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:15:08.543788 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
12:15:08.547081 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:15:08.549206 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:15:08.550741 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:15:08.592971 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:15:08.597190 [debug] [Thread-1  ]: finished collecting timing info
12:15:08.598447 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:15:08.693806 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:08.694723 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:15:08.695601 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:15:10.443042 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
12:15:10.475078 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:10.476028 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:15:10.589682 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:15:10.605266 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:10.606347 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:15:10.699941 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
12:15:10.731169 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:10.732202 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:15:10.821942 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
12:15:10.918450 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:15:10.929664 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:10.930688 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:15:11.048781 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:15:11.051651 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:11.053045 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:15:11.567882 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.51 seconds
12:15:11.569075 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:15:11.569965 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:15:11.741391 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:15:11.755886 [debug] [Thread-1  ]: finished collecting timing info
12:15:11.757360 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:15:11.965366 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd830dc550>]}
12:15:11.966600 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.42s]
12:15:11.967372 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:15:11.967837 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:15:11.969319 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:15:11.971143 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:15:11.971811 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:15:11.972595 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:15:11.986227 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:15:11.989625 [debug] [Thread-1  ]: finished collecting timing info
12:15:11.990419 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:15:11.999421 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:12.001805 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:15:12.002465 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:15:13.499288 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
12:15:13.507805 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:13.508903 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:15:13.601782 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
12:15:13.615494 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:13.616243 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:15:13.711742 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
12:15:13.728093 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:13.729324 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:15:13.809718 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
12:15:13.828654 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:15:13.836453 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:13.837403 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
12:15:13.940450 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
12:15:13.944289 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:13.945899 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:15:14.528304 [debug] [Thread-1  ]: SQL status: SUCCESS 248 in 0.58 seconds
12:15:14.529042 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:15:14.529703 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
12:15:14.760592 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
12:15:14.773605 [debug] [Thread-1  ]: finished collecting timing info
12:15:14.774561 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:15:14.905579 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd81344710>]}
12:15:14.906685 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.93s]
12:15:14.908090 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:15:14.909323 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:15:14.911350 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
12:15:14.913850 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:15:14.914644 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:15:14.915685 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:15:14.923113 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:15:14.929484 [debug] [Thread-1  ]: finished collecting timing info
12:15:14.931051 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:15:14.938261 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:15:14.950654 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:15:14.951722 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

--


with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:15:14.952824 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:15:16.474778 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:15:16.479993 [debug] [Thread-1  ]: finished collecting timing info
12:15:16.480784 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:15:16.599203 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd81361a90>]}
12:15:16.600417 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.69s]
12:15:16.601727 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:15:16.602861 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:15:16.604840 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:15:16.606000 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:15:16.606664 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:15:16.607254 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:15:16.615953 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:15:16.619955 [debug] [Thread-1  ]: finished collecting timing info
12:15:16.620809 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:15:16.628454 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:15:16.634282 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:15:16.635116 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:15:16.635771 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:15:19.153058 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.52 seconds
12:15:19.159315 [debug] [Thread-1  ]: finished collecting timing info
12:15:19.160741 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:15:19.320217 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd812cddd0>]}
12:15:19.321571 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.71s]
12:15:19.323045 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:15:19.324599 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:15:19.326545 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:15:19.328586 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:15:19.329627 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:15:19.330640 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:15:19.336292 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:15:19.342008 [debug] [Thread-1  ]: finished collecting timing info
12:15:19.343474 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:15:19.350275 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:15:19.355685 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:15:19.357130 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:15:19.358628 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:15:20.865340 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
12:15:20.869079 [debug] [Thread-1  ]: finished collecting timing info
12:15:20.869907 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:15:21.078433 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfa41fd9-a50c-4aef-b0f5-9fb8e5d000fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91b29e50>]}
12:15:21.081566 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.75s]
12:15:21.083307 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:15:21.170144 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:15:21.173006 [info ] [MainThread]: 
12:15:21.174818 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 18.81s.
12:15:21.176802 [debug] [MainThread]: Connection 'master' was properly closed.
12:15:21.178991 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:15:21.203139 [info ] [MainThread]: 
12:15:21.204054 [info ] [MainThread]: [32mCompleted successfully[0m
12:15:21.205760 [info ] [MainThread]: 
12:15:21.208073 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:15:21.211018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd81376d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd8307cd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd8307c550>]}


============================== 2022-01-23 12:46:42.359869 | 9530d163-c7e1-4acf-8857-63728db61282 ==============================
12:46:42.359869 [info ] [MainThread]: Running with dbt=1.0.1
12:46:42.361378 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:46:42.362366 [debug] [MainThread]: Tracking: tracking
12:46:42.364324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e11befc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e11befb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e11befcd0>]}
12:46:42.475131 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:46:42.476713 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
12:46:42.511930 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:46:42.632939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e11adae90>]}
12:46:42.652540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e1168f850>]}
12:46:42.653454 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:46:42.657538 [info ] [MainThread]: 
12:46:42.659458 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:46:42.663374 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:46:42.766812 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:46:42.767731 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:46:42.768270 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:46:44.038401 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.27 seconds
12:46:44.043198 [debug] [ThreadPool]: On list_analytics: Close
12:46:44.210848 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:46:44.216936 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:46:44.217867 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:46:44.218657 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:46:45.216316 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.0 seconds
12:46:45.225039 [debug] [ThreadPool]: On list_analytics: Close
12:46:45.429196 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_vtests"
12:46:45.435091 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_vtests"
12:46:45.437850 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt_vtests', identifier=None)"
12:46:45.474115 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt_vtests"
12:46:45.476925 [debug] [ThreadPool]: On create_analytics_dbt_vtests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt_vtests"} */
create schema if not exists analytics.dbt_vtests
12:46:45.478271 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:46:46.619552 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.14 seconds
12:46:46.622869 [debug] [ThreadPool]: On create_analytics_dbt_vtests: Close
12:46:46.799301 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:46:46.829221 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:46:46.830282 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:46:46.831243 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:46:47.892614 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.06 seconds
12:46:47.896974 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:46:48.033356 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_vtests"
12:46:48.039456 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_vtests"
12:46:48.041023 [debug] [ThreadPool]: On list_analytics_dbt_vtests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_vtests"} */

    show terse objects in analytics.dbt_vtests
12:46:48.042983 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:46:48.921092 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.88 seconds
12:46:48.934663 [debug] [ThreadPool]: On list_analytics_dbt_vtests: Close
12:46:49.087138 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:46:49.089685 [info ] [MainThread]: 
12:46:49.100974 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:46:49.102773 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:46:49.104480 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:46:49.105028 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:46:49.106227 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:46:49.118629 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:46:49.124215 [debug] [Thread-1  ]: finished collecting timing info
12:46:49.126904 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:46:49.257354 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:46:49.267722 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:46:49.268434 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:46:49.269095 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:46:51.647687 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.38 seconds
12:46:51.712148 [debug] [Thread-1  ]: finished collecting timing info
12:46:51.712880 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:46:51.959011 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e10137d90>]}
12:46:51.963220 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.85s]
12:46:51.966875 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:46:51.969684 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:46:51.972109 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
12:46:51.977130 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:46:51.978751 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:46:51.979974 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:46:52.016834 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:46:52.020228 [debug] [Thread-1  ]: finished collecting timing info
12:46:52.021801 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:46:52.115543 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:52.116210 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:46:52.116628 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:46:54.046705 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.93 seconds
12:46:54.082745 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:54.083355 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:46:54.194376 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:46:54.213475 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:54.214158 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:46:54.302795 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
12:46:54.378947 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:54.380083 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:46:54.466740 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
12:46:54.638863 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:46:54.650383 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:54.651357 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:46:54.763361 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
12:46:54.764199 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:54.764728 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:46:55.152183 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.39 seconds
12:46:55.153550 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:46:55.154872 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:46:55.368828 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
12:46:55.381767 [debug] [Thread-1  ]: finished collecting timing info
12:46:55.382921 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:46:55.552842 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e100fd490>]}
12:46:55.555594 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.58s]
12:46:55.557956 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:46:55.559842 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:46:55.562323 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:46:55.565292 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:46:55.566342 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:46:55.567324 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:46:55.580221 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:46:55.584085 [debug] [Thread-1  ]: finished collecting timing info
12:46:55.584885 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:46:55.601766 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:55.602399 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:46:55.603129 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:46:57.772382 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.17 seconds
12:46:57.782578 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:57.783436 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:46:57.880626 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:46:57.893474 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:57.894157 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:46:57.985356 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
12:46:57.997426 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:57.998212 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:46:58.080115 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
12:46:58.093140 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:46:58.102712 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:58.104190 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
12:46:58.212570 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
12:46:58.213464 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:58.214131 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:46:58.675487 [debug] [Thread-1  ]: SQL status: SUCCESS 1904 in 0.46 seconds
12:46:58.676342 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:46:58.676922 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
12:46:58.906724 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
12:46:58.913234 [debug] [Thread-1  ]: finished collecting timing info
12:46:58.914135 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:46:59.090249 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e100d6710>]}
12:46:59.091848 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.52s]
12:46:59.093610 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:46:59.094791 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:46:59.096224 [info ] [Thread-1  ]: 4 of 6 START table model dbt_vtests.first_model................................. [RUN]
12:46:59.098886 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:46:59.099866 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:46:59.100915 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:46:59.145567 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:46:59.151221 [debug] [Thread-1  ]: finished collecting timing info
12:46:59.153510 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:46:59.162450 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:46:59.167680 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:46:59.168572 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_vtests.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

--


with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:46:59.169600 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:47:01.044767 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
12:47:01.048990 [debug] [Thread-1  ]: finished collecting timing info
12:47:01.049658 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:47:01.305716 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e10144150>]}
12:47:01.309243 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt_vtests.first_model............................ [[32mSUCCESS 1[0m in 2.21s]
12:47:01.312076 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:47:01.314049 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:47:01.316587 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:47:01.321383 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:47:01.323465 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:47:01.326280 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:47:01.338067 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:47:01.341744 [debug] [Thread-1  ]: finished collecting timing info
12:47:01.342453 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:47:01.348792 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:47:01.358088 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:47:01.359278 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:47:01.359965 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:47:03.895993 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.54 seconds
12:47:03.905807 [debug] [Thread-1  ]: finished collecting timing info
12:47:03.907163 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:47:04.067806 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e1012d250>]}
12:47:04.069747 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.75s]
12:47:04.071449 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:47:04.072541 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:47:04.074032 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:47:04.075354 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:47:04.076186 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:47:04.077326 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:47:04.087704 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:47:04.093467 [debug] [Thread-1  ]: finished collecting timing info
12:47:04.094830 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:47:04.103398 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:47:04.110661 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:47:04.111637 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_vtests.first_model
where id = 1
      );
12:47:04.112438 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:47:05.896382 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
12:47:05.902379 [debug] [Thread-1  ]: finished collecting timing info
12:47:05.903775 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:47:06.075866 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9530d163-c7e1-4acf-8857-63728db61282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e100aa6d0>]}
12:47:06.077075 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.00s]
12:47:06.078008 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:47:06.085668 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:47:06.087728 [info ] [MainThread]: 
12:47:06.089091 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 23.43s.
12:47:06.091029 [debug] [MainThread]: Connection 'master' was properly closed.
12:47:06.091994 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:47:06.115456 [info ] [MainThread]: 
12:47:06.116985 [info ] [MainThread]: [32mCompleted successfully[0m
12:47:06.118916 [info ] [MainThread]: 
12:47:06.121463 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:47:06.123944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e1014b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e100aa6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e100aa590>]}


============================== 2022-01-23 13:09:19.614553 | fd172dbd-22a1-4fa8-8e77-e06916d56a02 ==============================
13:09:19.614553 [info ] [MainThread]: Running with dbt=1.0.1
13:09:19.615863 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:09:19.616875 [debug] [MainThread]: Tracking: tracking
13:09:19.618134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8de88d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8de889d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8de88cd0>]}
13:09:19.675598 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
13:09:19.676414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fd172dbd-22a1-4fa8-8e77-e06916d56a02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8de31f90>]}
13:09:19.738829 [debug] [MainThread]: Parsing macros/adapters.sql
13:09:19.893824 [debug] [MainThread]: Parsing macros/catalog.sql
13:09:19.901408 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:09:19.930924 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:09:19.944514 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:09:19.963275 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:09:19.967037 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:09:19.977363 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:09:19.982355 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:09:20.017814 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:09:20.027583 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:09:20.036792 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:09:20.061007 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:09:20.077576 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:09:20.108393 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:09:20.115994 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:09:20.149776 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:09:20.163200 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:09:20.170602 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:09:20.176323 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:09:20.181494 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:09:20.185412 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:09:20.192563 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:09:20.201000 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:09:20.223737 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:09:20.231726 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:09:20.242456 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:09:20.303563 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:09:20.325451 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:09:20.369613 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:09:20.426071 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:09:20.431086 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:09:20.489663 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:09:20.494931 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:09:20.510767 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:09:20.516137 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:09:20.532369 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:09:20.568714 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:09:20.573579 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:09:20.615680 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:09:20.679551 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:09:20.688927 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:09:20.718971 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:09:20.727177 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:09:20.735578 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:09:20.739016 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:09:20.821955 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:09:21.476317 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
13:09:21.511915 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
13:09:21.535188 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
13:09:21.537558 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
13:09:21.547976 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
13:09:21.550971 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:09:21.563694 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:09:21.566720 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:09:21.572701 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
13:09:21.739778 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:09:21.757638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd172dbd-22a1-4fa8-8e77-e06916d56a02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8deb17d0>]}
13:09:21.776453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd172dbd-22a1-4fa8-8e77-e06916d56a02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8de22310>]}
13:09:21.777699 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:09:21.783283 [info ] [MainThread]: 
13:09:21.785511 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:09:21.788243 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
13:09:21.830634 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
13:09:21.831613 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
13:09:21.832598 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:09:22.926607 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1d275-0000-1e54-0000-000298a24dc9
13:09:22.928099 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
13:09:22.930672 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
13:09:22.931666 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
13:09:22.933230 [debug] [ThreadPool]: On list_analytics_test: Close
13:09:23.082091 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:09:23.095564 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:09:23.096547 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:09:23.097368 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:09:23.857715 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.76 seconds
13:09:23.861932 [debug] [ThreadPool]: On list_analytics: Close
13:09:23.988941 [debug] [MainThread]: Connection 'master' was properly closed.
13:09:23.990022 [debug] [MainThread]: Connection 'list_analytics' was properly closed.
13:09:23.991132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d8de5b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d86f72bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d86f72550>]}


============================== 2022-01-23 13:10:49.710958 | dcda5300-11cc-46f7-aa2f-aa1405f6e34f ==============================
13:10:49.710958 [info ] [MainThread]: Running with dbt=1.0.1
13:10:49.712419 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:10:49.713367 [debug] [MainThread]: Tracking: tracking
13:10:49.714742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf2bb55d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf2bb55c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf2bb55d90>]}
13:10:49.819150 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:10:49.820329 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
13:10:49.855708 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:10:49.897061 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:10:49.968630 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:10:49.987697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dcda5300-11cc-46f7-aa2f-aa1405f6e34f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf2a58a690>]}
13:10:50.067516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dcda5300-11cc-46f7-aa2f-aa1405f6e34f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf2bba8250>]}
13:10:50.068538 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:10:50.072446 [info ] [MainThread]: 
13:10:50.074699 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:50.078475 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
13:10:50.120177 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
13:10:50.120890 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
13:10:50.121436 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:10:51.173605 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1d276-0000-1e52-0000-000298a23dfd
13:10:51.175149 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
13:10:51.176722 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
13:10:51.177741 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
13:10:51.179186 [debug] [ThreadPool]: On list_analytics_test: Close
13:10:51.309794 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:10:51.328151 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:10:51.329150 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:10:51.329852 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:10:52.335998 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.01 seconds
13:10:52.340310 [debug] [ThreadPool]: On list_analytics: Close
13:10:52.493123 [debug] [MainThread]: Connection 'master' was properly closed.
13:10:52.494428 [debug] [MainThread]: Connection 'list_analytics' was properly closed.
13:10:52.495893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf2bba8690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf28c2ca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf28c2c490>]}


============================== 2022-01-23 13:12:19.575366 | d1f8dd56-3f65-4d6a-8301-636ef6e76195 ==============================
13:12:19.575366 [info ] [MainThread]: Running with dbt=1.0.1
13:12:19.576539 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:12:19.577441 [debug] [MainThread]: Tracking: tracking
13:12:19.578949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e9ff1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e9ff1a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e9ff1d50>]}
13:12:19.691589 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:12:19.692436 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:12:19.693668 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:12:19.711882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1f8dd56-3f65-4d6a-8301-636ef6e76195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e9ed05d0>]}
13:12:19.732037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1f8dd56-3f65-4d6a-8301-636ef6e76195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e9f8e790>]}
13:12:19.733375 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:12:19.738311 [info ] [MainThread]: 
13:12:19.739999 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:12:19.743428 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:12:19.785000 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:12:19.786215 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:12:19.786825 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:12:20.999039 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.21 seconds
13:12:21.003880 [debug] [ThreadPool]: On list_analytics: Close
13:12:21.141730 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
13:12:21.154879 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
13:12:21.155901 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
13:12:21.156736 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:12:22.072765 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1d278-0000-1e52-0000-000298a23e29
13:12:22.074322 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
13:12:22.076096 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
13:12:22.077343 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
13:12:22.078605 [debug] [ThreadPool]: On list_analytics_test: Close
13:12:22.234683 [debug] [MainThread]: Connection 'master' was properly closed.
13:12:22.236135 [debug] [MainThread]: Connection 'list_analytics_test' was properly closed.
13:12:22.238126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e9f9c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e8a29150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e8a29e90>]}


============================== 2022-01-23 13:13:10.711258 | 2addf6c3-26bb-4b40-b3ad-4a9017c223fa ==============================
13:13:10.711258 [info ] [MainThread]: Running with dbt=1.0.1
13:13:10.712442 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:13:10.713771 [debug] [MainThread]: Tracking: tracking
13:13:10.715068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750f289d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750f289a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750f289d10>]}
13:13:10.818282 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:13:10.819716 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
13:13:10.853937 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:13:10.892562 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:13:10.963728 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:13:10.984131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750dd0d350>]}
13:13:11.060253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7511af1dd0>]}
13:13:11.061836 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:13:11.065939 [info ] [MainThread]: 
13:13:11.067931 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:13:11.071329 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:13:11.114999 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:13:11.115973 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:13:11.116547 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:13:12.312550 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.2 seconds
13:13:12.316677 [debug] [ThreadPool]: On list_analytics: Close
13:13:12.488078 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:13:12.512849 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:13:12.513845 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:13:12.514689 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:13:13.364864 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.85 seconds
13:13:13.372027 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:13:13.511711 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:13:13.513948 [info ] [MainThread]: 
13:13:13.521419 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:13:13.522893 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:13:13.524976 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:13:13.527091 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:13:13.528283 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:13:13.535489 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:13:13.546803 [debug] [Thread-1  ]: finished collecting timing info
13:13:13.547921 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:13:13.628248 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:13:13.633672 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:13:13.634562 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:13:13.635458 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:13:15.731213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.1 seconds
13:13:15.774938 [debug] [Thread-1  ]: finished collecting timing info
13:13:15.776072 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:13:15.928844 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c3d2f10>]}
13:13:15.930345 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.40s]
13:13:15.931618 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:13:15.932472 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:13:15.933545 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
13:13:15.935220 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:13:15.935897 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:13:15.936752 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:13:15.964276 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:13:15.968506 [debug] [Thread-1  ]: finished collecting timing info
13:13:15.969403 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:13:16.049237 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:16.050062 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
13:13:16.050617 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:13:17.529978 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
13:13:17.568995 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:17.570033 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:13:17.672781 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:13:17.698646 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:17.699714 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
13:13:17.793979 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:13:17.819656 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:17.820595 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:13:17.903988 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
13:13:17.990083 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:13:18.002996 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:18.003930 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
13:13:18.110224 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
13:13:18.112442 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:18.113664 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:13:18.483840 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.37 seconds
13:13:18.486075 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:13:18.488076 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
13:13:18.651064 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
13:13:18.663514 [debug] [Thread-1  ]: finished collecting timing info
13:13:18.665082 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:13:18.835514 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c8f68d0>]}
13:13:18.838993 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.90s]
13:13:18.841671 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:13:18.843976 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
13:13:18.846145 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:13:18.848399 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
13:13:18.849919 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
13:13:18.850729 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
13:13:18.863592 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
13:13:18.867759 [debug] [Thread-1  ]: finished collecting timing info
13:13:18.868660 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
13:13:18.882095 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:18.883027 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:13:18.883864 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:13:20.444553 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
13:13:20.453809 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:20.454680 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:13:20.566096 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:13:20.586693 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:20.587553 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:13:20.682524 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:13:20.702988 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:20.704132 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:13:20.809654 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:13:20.828127 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
13:13:20.836137 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:20.836957 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
13:13:20.958191 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:13:20.960048 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:20.961157 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:13:21.536255 [debug] [Thread-1  ]: SQL status: SUCCESS 1583 in 0.57 seconds
13:13:21.539114 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:13:21.541033 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
13:13:21.793150 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
13:13:21.803695 [debug] [Thread-1  ]: finished collecting timing info
13:13:21.805616 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
13:13:21.986196 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c85db90>]}
13:13:21.989418 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.14s]
13:13:21.991863 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
13:13:21.993642 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:13:21.995554 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
13:13:21.997873 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:13:21.999015 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:13:21.999927 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:13:22.016312 [debug] [Thread-1  ]: finished collecting timing info
13:13:22.017580 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:13:22.018669 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c3d8690>]}
13:13:22.020007 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
13:13:22.021396 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:13:22.023440 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:13:22.025128 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:13:22.026444 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:13:22.027885 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:13:22.028748 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:13:22.034857 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:13:22.040462 [debug] [Thread-1  ]: finished collecting timing info
13:13:22.041924 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:13:22.047730 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:13:22.053352 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:13:22.054139 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:13:22.054830 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:13:24.140155 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
13:13:24.148956 [debug] [Thread-1  ]: finished collecting timing info
13:13:24.150513 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:13:24.305562 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2addf6c3-26bb-4b40-b3ad-4a9017c223fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c383210>]}
13:13:24.307339 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.28s]
13:13:24.308717 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:13:24.310071 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:13:24.311692 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
13:13:24.313061 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:13:24.367964 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:13:24.369421 [info ] [MainThread]: 
13:13:24.370772 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 13.30s.
13:13:24.371727 [debug] [MainThread]: Connection 'master' was properly closed.
13:13:24.372432 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
13:13:24.396368 [info ] [MainThread]: 
13:13:24.397689 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:13:24.398944 [info ] [MainThread]: 
13:13:24.400162 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
13:13:24.401205 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
13:13:24.402573 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
13:13:24.404110 [error] [MainThread]:   
13:13:24.406975 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:13:24.408304 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:13:24.409660 [info ] [MainThread]: 
13:13:24.410710 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
13:13:24.412255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c3c9190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c3c9990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f750c3c9390>]}


============================== 2022-01-23 13:15:07.796840 | c86bb78f-5bda-4200-9ea0-dbd704e9f89d ==============================
13:15:07.796840 [info ] [MainThread]: Running with dbt=1.0.1
13:15:07.798230 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:15:07.799174 [debug] [MainThread]: Tracking: tracking
13:15:07.800669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9edbade90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9edbadd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9edbade50>]}
13:15:07.911064 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:15:07.912174 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
13:15:07.946695 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:15:07.986034 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:15:08.059699 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:15:08.079769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ed60b290>]}
13:15:08.163018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9eec441d0>]}
13:15:08.164047 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:15:08.168115 [info ] [MainThread]: 
13:15:08.170174 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:15:08.174176 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:15:08.216715 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:15:08.217487 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:15:08.218134 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:15:09.458509 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.24 seconds
13:15:09.462774 [debug] [ThreadPool]: On list_analytics: Close
13:15:09.626176 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:15:09.652190 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:15:09.653358 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:15:09.654333 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:15:10.672085 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.02 seconds
13:15:10.678062 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:15:10.870044 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:15:10.872076 [info ] [MainThread]: 
13:15:10.878130 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:15:10.879338 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:15:10.880763 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:15:10.881453 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:15:10.882667 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:15:10.894044 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:15:10.898176 [debug] [Thread-1  ]: finished collecting timing info
13:15:10.899323 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:15:10.979605 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:15:10.986503 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:15:10.987432 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:15:10.988194 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:15:12.843458 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
13:15:12.891568 [debug] [Thread-1  ]: finished collecting timing info
13:15:12.892486 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:15:13.016861 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec23f9d0>]}
13:15:13.018683 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.14s]
13:15:13.020660 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:15:13.022557 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:15:13.024574 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
13:15:13.026392 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:15:13.027078 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:15:13.028636 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:15:13.061333 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:15:13.066258 [debug] [Thread-1  ]: finished collecting timing info
13:15:13.067519 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:15:13.144170 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:13.145276 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
13:15:13.146155 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:15:14.585660 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
13:15:14.622564 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:14.623417 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:15:14.714039 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:15:14.727765 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:14.728661 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
13:15:14.806621 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
13:15:14.832694 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:14.833811 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:15:14.917765 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
13:15:14.998433 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:15:15.010176 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:15.011081 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
13:15:15.113222 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
13:15:15.114385 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:15.115033 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:15:15.477477 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
13:15:15.479990 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:15:15.481856 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
13:15:15.641269 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
13:15:15.647741 [debug] [Thread-1  ]: finished collecting timing info
13:15:15.649229 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:15:15.794674 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec1a5cd0>]}
13:15:15.798473 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.77s]
13:15:15.801960 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:15:15.805306 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
13:15:15.809427 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:15:15.812241 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
13:15:15.813555 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
13:15:15.815077 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
13:15:15.827730 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
13:15:15.832169 [debug] [Thread-1  ]: finished collecting timing info
13:15:15.833414 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
13:15:15.847399 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:15.848368 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:15:15.849066 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:15:17.365396 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
13:15:17.385293 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:17.386592 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:15:17.489847 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:15:17.498877 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:17.499854 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:15:17.595011 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:15:17.615386 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:17.616564 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:15:17.708403 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:15:17.722663 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
13:15:17.731203 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:17.732277 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
13:15:17.846961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
13:15:17.850078 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:17.852381 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:15:18.414234 [debug] [Thread-1  ]: SQL status: SUCCESS 117 in 0.56 seconds
13:15:18.416934 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:15:18.419219 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
13:15:18.675623 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
13:15:18.685418 [debug] [Thread-1  ]: finished collecting timing info
13:15:18.687678 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
13:15:18.842063 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec05e7d0>]}
13:15:18.843334 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.03s]
13:15:18.844362 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
13:15:18.845124 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:15:18.846435 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
13:15:18.848419 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:15:18.849287 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:15:18.850232 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:15:18.861355 [debug] [Thread-1  ]: finished collecting timing info
13:15:18.862635 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:15:18.863755 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec205090>]}
13:15:18.864794 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
13:15:18.865938 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:15:18.866798 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:15:18.870022 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:15:18.872500 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:15:18.873952 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:15:18.874883 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:15:18.880175 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:15:18.885778 [debug] [Thread-1  ]: finished collecting timing info
13:15:18.887808 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:15:18.895684 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:15:18.902877 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:15:18.903774 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:15:18.904612 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:15:20.971157 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.06 seconds
13:15:20.979886 [debug] [Thread-1  ]: finished collecting timing info
13:15:20.981047 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:15:21.154376 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c86bb78f-5bda-4200-9ea0-dbd704e9f89d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec0e0c10>]}
13:15:21.156885 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.28s]
13:15:21.158831 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:15:21.160358 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:15:21.162320 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
13:15:21.163899 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:15:21.173613 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:15:21.174961 [info ] [MainThread]: 
13:15:21.175922 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 13.01s.
13:15:21.177047 [debug] [MainThread]: Connection 'master' was properly closed.
13:15:21.177846 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
13:15:21.200107 [info ] [MainThread]: 
13:15:21.201871 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:15:21.204142 [info ] [MainThread]: 
13:15:21.206094 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
13:15:21.207616 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
13:15:21.208889 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
13:15:21.210199 [error] [MainThread]:   
13:15:21.211499 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:15:21.212903 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:15:21.214285 [info ] [MainThread]: 
13:15:21.215722 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
13:15:21.218762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9eec44390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec14ed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9ec14e7d0>]}


============================== 2022-01-23 13:18:13.668246 | a155e72c-e9c1-4481-9c73-fd8e1d225fb3 ==============================
13:18:13.668246 [info ] [MainThread]: Running with dbt=1.0.1
13:18:13.669365 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:18:13.670256 [debug] [MainThread]: Tracking: tracking
13:18:13.671772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb5175d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb5175cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb5175d10>]}
13:18:13.730712 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
13:18:13.731905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb5118f50>]}
13:18:13.789408 [debug] [MainThread]: Parsing macros/adapters.sql
13:18:13.946747 [debug] [MainThread]: Parsing macros/catalog.sql
13:18:13.951874 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:18:13.980972 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:18:13.993511 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:18:14.013912 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:18:14.017302 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:18:14.027498 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:18:14.031921 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:18:14.065116 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:18:14.073682 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:18:14.082700 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:18:14.106569 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:18:14.122219 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:18:14.155899 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:18:14.163262 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:18:14.195379 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:18:14.210919 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:18:14.215895 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:18:14.219019 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:18:14.224341 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:18:14.231819 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:18:14.240011 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:18:14.248113 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:18:14.261437 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:18:14.271944 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:18:14.284884 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:18:14.347037 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:18:14.369547 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:18:14.411967 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:18:14.458299 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:18:14.464107 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:18:14.523991 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:18:14.529006 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:18:14.545840 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:18:14.552375 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:18:14.566384 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:18:14.604408 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:18:14.610348 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:18:14.654159 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:18:14.718843 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:18:14.728824 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:18:14.759535 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:18:14.768567 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:18:14.777125 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:18:14.781213 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:18:14.865151 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:18:15.546629 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
13:18:15.580037 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
13:18:15.601660 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
13:18:15.604695 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
13:18:15.615347 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
13:18:15.618501 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:18:15.629395 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:18:15.632636 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:18:15.639809 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
13:18:15.808626 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:18:15.826947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faebc0462d0>]}
13:18:15.847274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb5113510>]}
13:18:15.848542 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:18:15.852692 [info ] [MainThread]: 
13:18:15.855264 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:15.858779 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:18:15.908750 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:18:15.909589 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:18:15.910039 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:18:17.098116 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.19 seconds
13:18:17.102281 [debug] [ThreadPool]: On list_analytics: Close
13:18:17.284993 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:18:17.321554 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:18:17.322642 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:18:17.323171 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:18:18.267892 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.94 seconds
13:18:18.280354 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:18:18.432608 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:18:18.435769 [info ] [MainThread]: 
13:18:18.445164 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:18:18.446723 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:18:18.448623 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:18:18.449949 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:18:18.451027 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:18:18.460928 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:18:18.464166 [debug] [Thread-1  ]: finished collecting timing info
13:18:18.465572 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:18:18.552245 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:18:18.557920 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:18:18.558667 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:18:18.559381 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:20.633148 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
13:18:20.676714 [debug] [Thread-1  ]: finished collecting timing info
13:18:20.677572 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:18:20.857016 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeaf2b6d10>]}
13:18:20.859422 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.41s]
13:18:20.861849 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:18:20.863857 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:18:20.866694 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
13:18:20.868637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:18:20.869952 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:18:20.871543 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:18:20.889221 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:18:20.893652 [debug] [Thread-1  ]: finished collecting timing info
13:18:20.894627 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:18:20.977596 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:20.978476 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
13:18:20.979035 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:22.391907 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
13:18:22.424599 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:22.425544 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:18:22.528084 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:18:22.553558 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:22.554343 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
13:18:22.627664 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.07 seconds
13:18:22.654929 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:22.655714 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:18:22.736144 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
13:18:22.815432 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:18:22.826211 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:22.827195 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
13:18:22.922730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
13:18:22.923781 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:22.924608 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:18:23.276780 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.35 seconds
13:18:23.279236 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:18:23.281146 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
13:18:23.430633 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
13:18:23.441971 [debug] [Thread-1  ]: finished collecting timing info
13:18:23.443449 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:18:23.579052 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeaf7312d0>]}
13:18:23.581735 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.71s]
13:18:23.584567 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:18:23.587161 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
13:18:23.589852 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:18:23.591637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
13:18:23.592774 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
13:18:23.593878 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
13:18:23.606277 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
13:18:23.610795 [debug] [Thread-1  ]: finished collecting timing info
13:18:23.611736 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
13:18:23.624421 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:23.625268 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:18:23.625826 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:25.210590 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
13:18:25.220578 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:25.221494 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:18:25.335451 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:18:25.344079 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:25.344842 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:18:25.437830 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:18:25.458038 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:25.459113 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:18:25.560892 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:18:25.578990 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
13:18:25.587692 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:25.588661 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
13:18:25.704400 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
13:18:25.705907 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:25.706781 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:18:26.264659 [debug] [Thread-1  ]: SQL status: SUCCESS 188 in 0.56 seconds
13:18:26.265671 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:18:26.266384 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
13:18:26.527890 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
13:18:26.538324 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.539581 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
13:18:26.709583 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeaf2d3610>]}
13:18:26.711440 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.12s]
13:18:26.713197 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
13:18:26.714774 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:18:26.717200 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
13:18:26.719434 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:18:26.720563 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:18:26.721715 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:18:26.730642 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.731962 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:18:26.733013 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeada6e2d0>]}
13:18:26.735604 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
13:18:26.737331 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:18:26.738693 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:18:26.740590 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:18:26.741874 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:18:26.742812 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:18:26.743509 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:18:26.748578 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:18:26.753435 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.755208 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:18:26.763003 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:18:26.770237 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:18:26.771443 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:18:26.772134 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:28.764244 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
13:18:28.775956 [debug] [Thread-1  ]: finished collecting timing info
13:18:28.777497 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:18:28.937477 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a155e72c-e9c1-4481-9c73-fd8e1d225fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb40b5650>]}
13:18:28.940393 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.20s]
13:18:28.942643 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:18:28.945001 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:18:28.946807 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
13:18:28.948220 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:18:29.032887 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:29.034728 [info ] [MainThread]: 
13:18:29.035980 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 13.18s.
13:18:29.037384 [debug] [MainThread]: Connection 'master' was properly closed.
13:18:29.038544 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
13:18:29.061492 [info ] [MainThread]: 
13:18:29.062645 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:18:29.063972 [info ] [MainThread]: 
13:18:29.065156 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
13:18:29.067317 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
13:18:29.069834 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
13:18:29.071737 [error] [MainThread]:   
13:18:29.072980 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:18:29.073928 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:18:29.075080 [info ] [MainThread]: 
13:18:29.076304 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
13:18:29.077459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeb508df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeaf727890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faeaf727190>]}


============================== 2022-01-23 13:18:59.255091 | 543e2904-bc6a-4afe-b2dd-7d91bb364c0b ==============================
13:18:59.255091 [info ] [MainThread]: Running with dbt=1.0.1
13:18:59.256302 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:18:59.256806 [debug] [MainThread]: Tracking: tracking
13:18:59.257546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4644d8c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4644d8610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4644d8d10>]}
13:18:59.316870 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
13:18:59.318289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe464442f50>]}
13:18:59.374186 [debug] [MainThread]: Parsing macros/adapters.sql
13:18:59.530626 [debug] [MainThread]: Parsing macros/catalog.sql
13:18:59.536915 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:18:59.567421 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:18:59.581492 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:18:59.599462 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:18:59.603018 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:18:59.613535 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:18:59.617595 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:18:59.652393 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:18:59.661434 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:18:59.669661 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:18:59.695297 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:18:59.710496 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:18:59.744223 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:18:59.750058 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:18:59.779086 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:18:59.794353 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:18:59.798608 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:18:59.800455 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:18:59.803536 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:18:59.806022 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:18:59.810791 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:18:59.815838 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:18:59.824578 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:18:59.831832 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:18:59.844204 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:18:59.907220 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:18:59.927611 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:18:59.972001 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:19:00.020044 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:19:00.026049 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:19:00.088191 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:19:00.094290 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:19:00.110390 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:19:00.116170 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:19:00.130550 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:19:00.166232 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:19:00.171439 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:19:00.212560 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:19:00.276481 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:19:00.285970 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:19:00.314808 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:19:00.323307 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:19:00.330253 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:19:00.334155 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:19:00.419897 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:19:01.079377 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
13:19:01.112404 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
13:19:01.134147 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
13:19:01.138031 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
13:19:01.147880 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
13:19:01.151320 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:19:01.162263 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:19:01.165012 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:19:01.171763 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
13:19:01.374800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe464492d50>]}
13:19:01.391703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe464469810>]}
13:19:01.392928 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:19:01.397047 [info ] [MainThread]: 
13:19:01.399051 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:19:01.403043 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:19:01.455675 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:19:01.456571 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:19:01.457249 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:19:02.554232 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.1 seconds
13:19:02.558968 [debug] [ThreadPool]: On list_analytics: Close
13:19:02.712296 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:19:02.739158 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:19:02.740096 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:19:02.740920 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:19:03.806366 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.07 seconds
13:19:03.823976 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:19:04.032401 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:19:04.033935 [info ] [MainThread]: 
13:19:04.039732 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:19:04.041105 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:19:04.042308 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:19:04.042928 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:19:04.043949 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:19:04.051249 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:19:04.057250 [debug] [Thread-1  ]: finished collecting timing info
13:19:04.058294 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:19:04.144713 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:19:04.151739 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:19:04.152725 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:19:04.153621 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:19:05.662391 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
13:19:05.706005 [debug] [Thread-1  ]: finished collecting timing info
13:19:05.707105 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:19:05.836374 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe46f47f150>]}
13:19:05.838740 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 1.79s]
13:19:05.841081 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:19:05.842484 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:19:05.844893 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
13:19:05.846741 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:19:05.847366 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:19:05.848958 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:19:05.866899 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:19:05.871973 [debug] [Thread-1  ]: finished collecting timing info
13:19:05.873224 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:19:05.954021 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:05.954995 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
13:19:05.955715 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:19:07.192871 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
13:19:07.235218 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:07.236126 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:19:07.349924 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
13:19:07.363039 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:07.363976 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
13:19:07.463366 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:19:07.497045 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:07.497976 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:19:07.593739 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:19:07.676951 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:19:07.687150 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:07.688073 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
13:19:07.807754 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:19:07.815132 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:07.817062 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:19:08.171924 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.35 seconds
13:19:08.174303 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:19:08.175806 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
13:19:08.350137 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
13:19:08.354265 [debug] [Thread-1  ]: finished collecting timing info
13:19:08.355067 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:19:08.540995 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe461b0b050>]}
13:19:08.543403 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.69s]
13:19:08.545809 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:19:08.547743 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
13:19:08.550186 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:19:08.552369 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
13:19:08.553418 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
13:19:08.554649 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
13:19:08.565078 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
13:19:08.570831 [debug] [Thread-1  ]: finished collecting timing info
13:19:08.571751 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
13:19:08.583753 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:08.585128 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:19:08.585760 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:19:09.917453 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
13:19:09.930074 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:09.931200 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:19:10.021063 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:19:10.038544 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:10.039698 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:19:10.119220 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
13:19:10.137033 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:10.137905 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:19:10.221180 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
13:19:10.229214 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
13:19:10.237010 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:10.237855 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
13:19:10.335230 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
13:19:10.336835 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:10.338181 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:19:10.858975 [debug] [Thread-1  ]: SQL status: SUCCESS 45 in 0.52 seconds
13:19:10.861540 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:19:10.863810 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
13:19:11.103382 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
13:19:11.116971 [debug] [Thread-1  ]: finished collecting timing info
13:19:11.118588 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
13:19:11.249118 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe460549690>]}
13:19:11.250326 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.70s]
13:19:11.251866 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
13:19:11.252824 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:19:11.254496 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
13:19:11.256170 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:19:11.256967 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:19:11.257902 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:19:11.269086 [debug] [Thread-1  ]: finished collecting timing info
13:19:11.270133 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:19:11.271085 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4615d3b90>]}
13:19:11.272472 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
13:19:11.273556 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:19:11.274370 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:19:11.275841 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:19:11.277688 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:19:11.278464 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:19:11.279454 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:19:11.287234 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:19:11.291492 [debug] [Thread-1  ]: finished collecting timing info
13:19:11.292329 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:19:11.300230 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:19:11.306089 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:19:11.306921 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:19:11.307627 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:19:12.959717 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:19:12.971029 [debug] [Thread-1  ]: finished collecting timing info
13:19:12.972352 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:19:13.147711 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '543e2904-bc6a-4afe-b2dd-7d91bb364c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe461aed410>]}
13:19:13.151257 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.87s]
13:19:13.153804 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:19:13.155539 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:19:13.157376 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
13:19:13.158706 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:19:13.225040 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:19:13.226505 [info ] [MainThread]: 
13:19:13.227917 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 11.83s.
13:19:13.229209 [debug] [MainThread]: Connection 'master' was properly closed.
13:19:13.230335 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
13:19:13.255512 [info ] [MainThread]: 
13:19:13.260014 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:19:13.261679 [info ] [MainThread]: 
13:19:13.263092 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
13:19:13.265426 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
13:19:13.268005 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
13:19:13.269850 [error] [MainThread]:   
13:19:13.271153 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:19:13.272371 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:19:13.273982 [info ] [MainThread]: 
13:19:13.275282 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
13:19:13.277116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4615d1650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe461b00550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe461b00b90>]}


============================== 2022-01-23 13:20:50.777779 | 90315ab2-54c8-4d33-b481-d01632072b22 ==============================
13:20:50.777779 [info ] [MainThread]: Running with dbt=1.0.1
13:20:50.778862 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:20:50.779448 [debug] [MainThread]: Tracking: tracking
13:20:50.780215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7155fd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7155fad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7155fe10>]}
13:20:50.841880 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
13:20:50.842846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff714c8f50>]}
13:20:50.898478 [debug] [MainThread]: Parsing macros/adapters.sql
13:20:51.054565 [debug] [MainThread]: Parsing macros/catalog.sql
13:20:51.061744 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:20:51.091999 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:20:51.105122 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:20:51.123767 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:20:51.126801 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:20:51.137843 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:20:51.142194 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:20:51.177243 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:20:51.186925 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:20:51.195083 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:20:51.220989 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:20:51.235563 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:20:51.269765 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:20:51.276945 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:20:51.309051 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:20:51.324864 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:20:51.328465 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:20:51.330415 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:20:51.333424 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:20:51.336778 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:20:51.341575 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:20:51.346558 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:20:51.353711 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:20:51.361424 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:20:51.374142 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:20:51.436380 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:20:51.456590 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:20:51.500486 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:20:51.547664 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:20:51.552447 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:20:51.615324 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:20:51.622554 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:20:51.639461 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:20:51.644633 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:20:51.659713 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:20:51.697896 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:20:51.702733 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:20:51.746567 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:20:51.810350 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:20:51.819016 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:20:51.847164 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:20:51.856148 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:20:51.862760 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:20:51.866500 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:20:51.949592 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:20:52.601417 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
13:20:52.635269 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
13:20:52.656795 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
13:20:52.660083 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
13:20:52.670880 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
13:20:52.673557 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:20:52.686077 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:20:52.689339 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:20:52.695680 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
13:20:52.862855 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tests.example.vars

13:20:52.880192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff714b6ad0>]}
13:20:52.899915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff715dec10>]}
13:20:52.901148 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:20:52.906756 [info ] [MainThread]: 
13:20:52.908897 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:20:52.912232 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:20:52.953657 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:20:52.954361 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:20:52.954995 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:20:54.113278 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.16 seconds
13:20:54.118357 [debug] [ThreadPool]: On list_analytics: Close
13:20:54.273169 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:20:54.298990 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:20:54.299905 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:20:54.300482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:20:55.282112 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.98 seconds
13:20:55.289466 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:20:55.454507 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:20:55.457082 [info ] [MainThread]: 
13:20:55.463298 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:20:55.464745 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:20:55.466397 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:20:55.467671 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:20:55.469500 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:20:55.477912 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:20:55.482132 [debug] [Thread-1  ]: finished collecting timing info
13:20:55.483067 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:20:55.569192 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:20:55.574526 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:20:55.575394 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:20:55.576154 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:20:57.423943 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.85 seconds
13:20:57.471659 [debug] [Thread-1  ]: finished collecting timing info
13:20:57.472547 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:20:57.632084 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6a611510>]}
13:20:57.634800 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.17s]
13:20:57.636903 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:20:57.638404 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:20:57.641068 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
13:20:57.643303 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:20:57.644590 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:20:57.645601 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:20:57.662261 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:20:57.667924 [debug] [Thread-1  ]: finished collecting timing info
13:20:57.669223 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:20:57.759321 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:20:57.760328 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
13:20:57.760996 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:20:59.256482 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
13:20:59.298929 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:20:59.299947 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:20:59.395461 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:20:59.412291 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:20:59.413085 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
13:20:59.492771 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
13:20:59.519493 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:20:59.520289 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:20:59.600488 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
13:20:59.671720 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:20:59.681853 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:20:59.682730 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
13:20:59.782735 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
13:20:59.783998 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:20:59.784893 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:21:00.123051 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.34 seconds
13:21:00.123880 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:21:00.124406 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
13:21:00.264381 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
13:21:00.276979 [debug] [Thread-1  ]: finished collecting timing info
13:21:00.278192 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:21:00.421633 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff68ddcd10>]}
13:21:00.425223 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.78s]
13:21:00.428017 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:21:00.430641 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
13:21:00.433345 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:21:00.435514 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
13:21:00.436673 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
13:21:00.437853 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
13:21:00.451077 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
13:21:00.455474 [debug] [Thread-1  ]: finished collecting timing info
13:21:00.456457 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
13:21:00.469117 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:00.469976 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:21:00.470504 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:21:01.925294 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
13:21:01.939724 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:01.940758 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:21:02.032691 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:21:02.046781 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:02.047830 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:21:02.131532 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
13:21:02.153846 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:02.154893 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:21:02.229423 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.07 seconds
13:21:02.240683 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
13:21:02.250427 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:02.251442 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
13:21:02.348366 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
13:21:02.349328 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:02.349778 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:21:03.073072 [debug] [Thread-1  ]: SQL status: SUCCESS 112 in 0.72 seconds
13:21:03.075410 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:21:03.076400 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
13:21:03.314790 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
13:21:03.319007 [debug] [Thread-1  ]: finished collecting timing info
13:21:03.319948 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
13:21:03.470605 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff68dac9d0>]}
13:21:03.472807 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.04s]
13:21:03.474393 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
13:21:03.475896 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:21:03.477813 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
13:21:03.479719 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:21:03.481012 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:21:03.482192 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:21:03.492145 [debug] [Thread-1  ]: finished collecting timing info
13:21:03.493225 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:21:03.494011 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6ab434d0>]}
13:21:03.495056 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
13:21:03.496808 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:21:03.499001 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:21:03.501831 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:21:03.503334 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:21:03.503936 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:21:03.505126 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:21:03.510491 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:21:03.515586 [debug] [Thread-1  ]: finished collecting timing info
13:21:03.516738 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:21:03.523323 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:21:03.528968 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:21:03.530620 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:21:03.531794 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:21:05.274323 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
13:21:05.284800 [debug] [Thread-1  ]: finished collecting timing info
13:21:05.286198 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:21:05.405679 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90315ab2-54c8-4d33-b481-d01632072b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff68d73190>]}
13:21:05.406740 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.90s]
13:21:05.407759 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:21:05.408656 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:21:05.409898 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
13:21:05.410908 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:21:05.418700 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:21:05.422136 [info ] [MainThread]: 
13:21:05.423249 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 12.51s.
13:21:05.424341 [debug] [MainThread]: Connection 'master' was properly closed.
13:21:05.425089 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
13:21:05.447199 [info ] [MainThread]: 
13:21:05.448856 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:21:05.451052 [info ] [MainThread]: 
13:21:05.453723 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
13:21:05.454929 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
13:21:05.456056 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
13:21:05.457117 [error] [MainThread]:   
13:21:05.458390 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:21:05.459635 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:21:05.460940 [info ] [MainThread]: 
13:21:05.462591 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
13:21:05.464995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff700451d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6ab2efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6ab2e910>]}


============================== 2022-01-23 13:58:46.930397 | 2d0918da-bab5-4fba-ac7d-99fc1c12d8f1 ==============================
13:58:46.930397 [info ] [MainThread]: Running with dbt=1.0.1
13:58:46.931796 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:58:46.932585 [debug] [MainThread]: Tracking: tracking
13:58:46.933932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce37b5d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce37b5a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce37b5d10>]}
13:58:46.996951 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
13:58:46.998220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce3757f50>]}
13:58:47.057754 [debug] [MainThread]: Parsing macros/adapters.sql
13:58:47.214325 [debug] [MainThread]: Parsing macros/catalog.sql
13:58:47.221126 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:58:47.251092 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:58:47.262692 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:58:47.282329 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:58:47.284822 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:58:47.295333 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:58:47.300462 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:58:47.335844 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:58:47.343828 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:58:47.352518 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:58:47.375876 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:58:47.391486 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:58:47.422443 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:58:47.429443 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:58:47.462071 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:58:47.477201 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:58:47.482410 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:58:47.483721 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:58:47.486304 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:58:47.488638 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:58:47.493647 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:58:47.498722 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:58:47.507176 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:58:47.516837 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:58:47.530236 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:58:47.591386 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:58:47.614259 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:58:47.658228 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:58:47.708825 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:58:47.713976 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:58:47.773600 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:58:47.780238 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:58:47.795050 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:58:47.801598 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:58:47.816246 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:58:47.851859 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:58:47.857009 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:58:47.900321 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:58:47.964383 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:58:47.973496 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:58:48.001884 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:58:48.011739 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:58:48.019497 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:58:48.023221 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:58:48.106611 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:58:48.772755 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
13:58:48.805927 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
13:58:48.827247 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
13:58:48.831042 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
13:58:48.840406 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
13:58:48.843942 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:58:48.854969 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:58:48.858074 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:58:48.864981 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
13:58:49.054639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce37de7d0>]}
13:58:49.071016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce373f210>]}
13:58:49.072046 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:58:49.075988 [info ] [MainThread]: 
13:58:49.078048 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:58:49.081680 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:58:49.122683 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:58:49.123432 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:58:49.124173 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:58:50.256259 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.13 seconds
13:58:50.260907 [debug] [ThreadPool]: On list_analytics: Close
13:58:50.407755 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:58:50.428298 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:58:50.429308 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:58:50.429860 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:58:51.260268 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.83 seconds
13:58:51.272359 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:58:51.447144 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:58:51.449484 [info ] [MainThread]: 
13:58:51.457065 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
13:58:51.458312 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
13:58:51.460119 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:58:51.468571 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
13:58:51.469394 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
13:58:51.475587 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:58:51.481975 [debug] [Thread-1  ]: finished collecting timing info
13:58:51.483127 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
13:58:51.564594 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
13:58:51.571087 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
13:58:51.572029 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
13:58:51.572795 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:53.747752 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.17 seconds
13:58:53.780732 [debug] [Thread-1  ]: finished collecting timing info
13:58:53.781738 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
13:58:53.955367 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce191b210>]}
13:58:53.960182 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.50s]
13:58:53.964378 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
13:58:53.966285 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
13:58:53.968987 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
13:58:53.971002 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
13:58:53.972374 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
13:58:53.973869 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
13:58:53.991267 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
13:58:53.997005 [debug] [Thread-1  ]: finished collecting timing info
13:58:53.998085 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
13:58:54.077143 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:54.078095 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
13:58:54.078723 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:55.412494 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
13:58:55.448120 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:55.449118 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:58:55.575079 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
13:58:55.600166 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:55.601149 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
13:58:55.708850 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
13:58:55.740702 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:55.741581 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:58:55.910750 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
13:58:55.994242 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
13:58:56.005572 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:56.006354 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
13:58:56.125900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:58:56.127065 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:56.127806 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:58:56.727857 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.6 seconds
13:58:56.728781 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
13:58:56.729630 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
13:58:56.896302 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
13:58:56.908881 [debug] [Thread-1  ]: finished collecting timing info
13:58:56.910814 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
13:58:57.109358 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1920150>]}
13:58:57.113106 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.14s]
13:58:57.115311 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
13:58:57.117384 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
13:58:57.119601 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:58:57.121608 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
13:58:57.122791 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
13:58:57.124067 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
13:58:57.138949 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
13:58:57.143310 [debug] [Thread-1  ]: finished collecting timing info
13:58:57.144702 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
13:58:57.155960 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:58:57.156873 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:58:57.157685 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:58:59.828301 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.67 seconds
13:58:59.843398 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:58:59.844582 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:58:59.951366 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:58:59.961444 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:58:59.962360 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:59:00.058782 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:59:00.074910 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:59:00.075828 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:59:00.169603 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:59:00.177820 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
13:59:00.186469 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:59:00.187570 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
13:59:00.307907 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:59:00.308903 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:59:00.309616 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:59:00.888662 [debug] [Thread-1  ]: SQL status: SUCCESS 2276 in 0.58 seconds
13:59:00.891960 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
13:59:00.893288 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
13:59:01.164577 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
13:59:01.180006 [debug] [Thread-1  ]: finished collecting timing info
13:59:01.181495 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
13:59:01.374323 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1de2550>]}
13:59:01.377822 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.25s]
13:59:01.380121 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
13:59:01.381894 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
13:59:01.384230 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
13:59:01.386175 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
13:59:01.387060 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
13:59:01.388211 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
13:59:01.401548 [debug] [Thread-1  ]: finished collecting timing info
13:59:01.402909 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:59:01.404043 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1de2d10>]}
13:59:01.405032 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
13:59:01.406076 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
13:59:01.407090 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
13:59:01.409175 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:59:01.411135 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:59:01.412276 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
13:59:01.413749 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
13:59:01.422555 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:59:01.427447 [debug] [Thread-1  ]: finished collecting timing info
13:59:01.429071 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
13:59:01.436764 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
13:59:01.443268 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
13:59:01.444322 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:59:01.445986 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:59:03.558864 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.11 seconds
13:59:03.563801 [debug] [Thread-1  ]: finished collecting timing info
13:59:03.565012 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
13:59:03.723542 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d0918da-bab5-4fba-ac7d-99fc1c12d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce0095c10>]}
13:59:03.724879 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.31s]
13:59:03.726266 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
13:59:03.727184 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
13:59:03.728546 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
13:59:03.729865 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
13:59:03.802681 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:59:03.804076 [info ] [MainThread]: 
13:59:03.805103 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 14.73s.
13:59:03.806554 [debug] [MainThread]: Connection 'master' was properly closed.
13:59:03.807682 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
13:59:03.830081 [info ] [MainThread]: 
13:59:03.831747 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:59:03.833832 [info ] [MainThread]: 
13:59:03.835441 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
13:59:03.836672 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
13:59:03.838274 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
13:59:03.841471 [error] [MainThread]:   
13:59:03.843123 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:59:03.844432 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
13:59:03.846855 [info ] [MainThread]: 
13:59:03.849479 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
13:59:03.852107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce36d2ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce19249d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce3789c50>]}


============================== 2022-01-23 14:02:21.012585 | 2614b018-0f54-4a2a-a243-350015dee08b ==============================
14:02:21.012585 [info ] [MainThread]: Running with dbt=1.0.1
14:02:21.014022 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:02:21.014682 [debug] [MainThread]: Tracking: tracking
14:02:21.015994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f015a8dff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f015a8dfed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f015a8dfe90>]}
14:02:21.131036 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:02:21.132235 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:02:21.168600 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:02:21.207954 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:02:21.301962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f015930a390>]}
14:02:21.378108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f015a947250>]}
14:02:21.378942 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:02:21.383255 [info ] [MainThread]: 
14:02:21.385454 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:02:21.389085 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:02:21.436405 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:02:21.437459 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:02:21.438130 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:02:22.557794 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.12 seconds
14:02:22.562704 [debug] [ThreadPool]: On list_analytics: Close
14:02:22.704422 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:02:22.725390 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:02:22.726476 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:02:22.727709 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:02:23.488806 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.76 seconds
14:02:23.494863 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:02:23.634050 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:02:23.635713 [info ] [MainThread]: 
14:02:23.641829 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
14:02:23.643192 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
14:02:23.645114 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
14:02:23.645907 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
14:02:23.648022 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
14:02:23.657131 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
14:02:23.662057 [debug] [Thread-1  ]: finished collecting timing info
14:02:23.663056 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
14:02:23.747160 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
14:02:23.754223 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
14:02:23.755309 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
14:02:23.756091 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:02:25.730817 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.97 seconds
14:02:25.759041 [debug] [Thread-1  ]: finished collecting timing info
14:02:25.760115 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
14:02:25.917383 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f015a965f50>]}
14:02:25.920010 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.27s]
14:02:25.922134 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
14:02:25.923643 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
14:02:25.925880 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
14:02:25.927605 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
14:02:25.928227 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
14:02:25.929605 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
14:02:25.956883 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
14:02:25.961398 [debug] [Thread-1  ]: finished collecting timing info
14:02:25.962275 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
14:02:26.042885 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:26.043822 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
14:02:26.044443 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:02:27.429718 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
14:02:27.476489 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:27.477368 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:02:27.580941 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:02:27.597823 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:27.598760 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
14:02:27.696278 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:02:27.733213 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:27.733976 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:02:27.851555 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
14:02:27.935386 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
14:02:27.946104 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:27.947105 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
14:02:28.058912 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
14:02:28.059878 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:28.060456 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:02:28.619872 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.56 seconds
14:02:28.622163 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
14:02:28.624130 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
14:02:28.793632 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
14:02:28.818157 [debug] [Thread-1  ]: finished collecting timing info
14:02:28.819266 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
14:02:28.988065 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014bf07250>]}
14:02:28.989170 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.06s]
14:02:28.990145 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
14:02:28.991018 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
14:02:28.992535 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
14:02:28.994875 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
14:02:28.996585 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
14:02:28.997978 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
14:02:29.008147 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
14:02:29.012813 [debug] [Thread-1  ]: finished collecting timing info
14:02:29.013924 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
14:02:29.025143 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:29.026108 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:02:29.026731 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:02:30.610229 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
14:02:30.619248 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:30.620067 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:02:30.719652 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:02:30.728571 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:30.729823 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:02:30.819984 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
14:02:30.829237 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:30.830170 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:02:30.918540 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
14:02:30.926535 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
14:02:30.934033 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:30.934767 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
14:02:31.042961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
14:02:31.044043 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:31.044971 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:02:31.663675 [debug] [Thread-1  ]: SQL status: SUCCESS 212 in 0.62 seconds
14:02:31.664578 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
14:02:31.665304 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
14:02:31.912501 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
14:02:31.926567 [debug] [Thread-1  ]: finished collecting timing info
14:02:31.928008 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
14:02:32.088587 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014a181a50>]}
14:02:32.090012 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.09s]
14:02:32.090825 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
14:02:32.091664 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:02:32.092791 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
14:02:32.096283 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:02:32.098649 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:02:32.099508 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:02:32.114871 [debug] [Thread-1  ]: finished collecting timing info
14:02:32.116757 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:02:32.118024 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014befe390>]}
14:02:32.119136 [error] [Thread-1  ]: 4 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
14:02:32.120592 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:02:32.121679 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
14:02:32.123365 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:02:32.126474 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
14:02:32.127755 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
14:02:32.129527 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
14:02:32.141057 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
14:02:32.147963 [debug] [Thread-1  ]: finished collecting timing info
14:02:32.149769 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
14:02:32.158468 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
14:02:32.166406 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
14:02:32.167222 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
14:02:32.167629 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:02:34.307615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.14 seconds
14:02:34.316128 [debug] [Thread-1  ]: finished collecting timing info
14:02:34.317619 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
14:02:34.483019 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2614b018-0f54-4a2a-a243-350015dee08b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014a1b2190>]}
14:02:34.485247 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.36s]
14:02:34.487988 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
14:02:34.490020 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
14:02:34.491749 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
14:02:34.493751 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
14:02:34.591353 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:02:34.592636 [info ] [MainThread]: 
14:02:34.593772 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 13.21s.
14:02:34.595047 [debug] [MainThread]: Connection 'master' was properly closed.
14:02:34.595922 [debug] [MainThread]: Connection 'model.dbt_tests.snowflake_customer_purchases' was properly closed.
14:02:34.617799 [info ] [MainThread]: 
14:02:34.619040 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:02:34.620348 [info ] [MainThread]: 
14:02:34.621670 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:02:34.623082 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
14:02:34.624389 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
14:02:34.626125 [error] [MainThread]:   
14:02:34.629177 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:02:34.630708 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:02:34.632090 [info ] [MainThread]: 
14:02:34.633414 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
14:02:34.634923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014bee66d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014a1a9c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014a1a97d0>]}


============================== 2022-01-23 14:10:28.474387 | 3a900305-9212-4cd5-8119-23dcd1a1e0fe ==============================
14:10:28.474387 [info ] [MainThread]: Running with dbt=1.0.1
14:10:28.475989 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['first_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:10:28.477406 [debug] [MainThread]: Tracking: tracking
14:10:28.478939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea920c4e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea920c4d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea920c4e90>]}
14:10:28.534819 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:10:28.535932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3a900305-9212-4cd5-8119-23dcd1a1e0fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea9202ff50>]}
14:10:28.593634 [debug] [MainThread]: Parsing macros/adapters.sql
14:10:28.759736 [debug] [MainThread]: Parsing macros/catalog.sql
14:10:28.767654 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:10:28.798447 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:10:28.810392 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:10:28.829313 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:10:28.832523 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:10:28.843449 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:10:28.848438 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:10:28.883010 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:10:28.892863 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:10:28.902131 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:10:28.924568 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:10:28.938157 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:10:28.969676 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:10:28.976374 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:10:29.008579 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:10:29.024782 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:10:29.028273 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:10:29.030917 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:10:29.033159 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:10:29.035373 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:10:29.039896 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:10:29.044539 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:10:29.052261 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:10:29.058576 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:10:29.071797 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:10:29.134557 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:10:29.156043 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:10:29.200783 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:10:29.245618 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:10:29.250479 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:10:29.308128 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:10:29.313862 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:10:29.328043 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:10:29.335558 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:10:29.350081 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:10:29.386034 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:10:29.390355 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:10:29.433834 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:10:29.495106 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:10:29.504591 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:10:29.532036 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:10:29.540518 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:10:29.547477 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:10:29.551403 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:10:29.632824 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:10:30.273827 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
14:10:30.308592 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
14:10:30.329348 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
14:10:30.332639 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:10:30.343043 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:10:30.346833 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:10:30.356653 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:10:30.359529 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:10:30.365979 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:10:30.550021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a900305-9212-4cd5-8119-23dcd1a1e0fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea920b0690>]}
14:10:30.567880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a900305-9212-4cd5-8119-23dcd1a1e0fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea9204b710>]}
14:10:30.569059 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:10:30.570692 [warn ] [MainThread]: The selection criterion 'first_model' does not match any nodes
14:10:30.573908 [info ] [MainThread]: 
14:10:30.575059 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
14:10:30.596074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea948b8a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea9204b990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea9204be50>]}


============================== 2022-01-23 14:10:56.189595 | ae9cb9ba-bf57-419d-854a-6c38fd777d47 ==============================
14:10:56.189595 [info ] [MainThread]: Running with dbt=1.0.1
14:10:56.190921 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['dbt.first_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:10:56.191678 [debug] [MainThread]: Tracking: tracking
14:10:56.193036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253c9ae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253c9acd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253c9ae10>]}
14:10:56.302664 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:10:56.303777 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:10:56.321686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ae9cb9ba-bf57-419d-854a-6c38fd777d47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9252b4e550>]}
14:10:56.339345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ae9cb9ba-bf57-419d-854a-6c38fd777d47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253cdff10>]}
14:10:56.340465 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:10:56.342022 [warn ] [MainThread]: The selection criterion 'dbt.first_model' does not match any nodes
14:10:56.345733 [info ] [MainThread]: 
14:10:56.347017 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
14:10:56.364986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253cbab90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253cd7f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9253cd7e90>]}


============================== 2022-01-23 14:11:36.509695 | e0ab1095-57a4-4f17-9a0f-5bfc9b530cbe ==============================
14:11:36.509695 [info ] [MainThread]: Running with dbt=1.0.1
14:11:36.510880 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:11:36.511800 [debug] [MainThread]: Tracking: tracking
14:11:36.513072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8b9afe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8b9afc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8b9afdd0>]}
14:11:36.620410 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:11:36.621309 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:11:36.639263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0ab1095-57a4-4f17-9a0f-5bfc9b530cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8b8ce250>]}
14:11:36.656724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0ab1095-57a4-4f17-9a0f-5bfc9b530cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8ca29650>]}
14:11:36.657838 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:11:36.661098 [info ] [MainThread]: 
14:11:36.662914 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:11:36.666132 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:11:36.722572 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:11:36.723275 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:11:36.723847 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:11:37.927437 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.2 seconds
14:11:37.932792 [debug] [ThreadPool]: On list_analytics: Close
14:11:38.075369 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:11:38.104142 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:11:38.105073 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:11:38.106063 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:11:38.816275 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.71 seconds
14:11:38.821944 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:11:38.960455 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:11:38.964648 [info ] [MainThread]: 
14:11:38.975093 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:11:38.976941 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:11:38.978975 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:11:38.980006 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:11:38.981192 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:11:38.993876 [debug] [Thread-1  ]: finished collecting timing info
14:11:38.995147 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:11:38.996726 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0ab1095-57a4-4f17-9a0f-5bfc9b530cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8a488a90>]}
14:11:38.998195 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
14:11:39.000388 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:11:39.074848 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:11:39.076089 [info ] [MainThread]: 
14:11:39.077003 [info ] [MainThread]: Finished running 1 table model in 2.41s.
14:11:39.078073 [debug] [MainThread]: Connection 'master' was properly closed.
14:11:39.079221 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:11:39.098060 [info ] [MainThread]: 
14:11:39.099969 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:11:39.101884 [info ] [MainThread]: 
14:11:39.103699 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:11:39.104960 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
14:11:39.106194 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
14:11:39.107618 [error] [MainThread]:   
14:11:39.108916 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:11:39.110113 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:11:39.111538 [info ] [MainThread]: 
14:11:39.112821 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
14:11:39.114469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8a47db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8a490c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8a490490>]}


============================== 2022-01-23 14:12:59.762411 | b24bf378-93c6-40ea-9c14-2a43c778c644 ==============================
14:12:59.762411 [info ] [MainThread]: Running with dbt=1.0.1
14:12:59.763879 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:12:59.764773 [debug] [MainThread]: Tracking: tracking
14:12:59.766397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f109507cc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f109507c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f109507cd10>]}
14:12:59.825012 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:12:59.826042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b24bf378-93c6-40ea-9c14-2a43c778c644', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1093fd9f90>]}
14:12:59.885609 [debug] [MainThread]: Parsing macros/adapters.sql
14:13:00.038430 [debug] [MainThread]: Parsing macros/catalog.sql
14:13:00.045601 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:13:00.076452 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:13:00.090769 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:13:00.108377 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:13:00.111689 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:13:00.122587 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:13:00.126420 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:13:00.160946 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:13:00.170609 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:13:00.178497 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:13:00.202931 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:13:00.218225 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:13:00.253236 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:13:00.259491 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:13:00.289488 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:13:00.302876 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:13:00.307897 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:13:00.309370 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:13:00.312527 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:13:00.314557 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:13:00.318402 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:13:00.323971 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:13:00.332543 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:13:00.339563 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:13:00.351539 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:13:00.411885 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:13:00.432024 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:13:00.476057 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:13:00.521885 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:13:00.527091 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:13:00.585142 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:13:00.590099 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:13:00.604293 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:13:00.610327 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:13:00.623813 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:13:00.662120 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:13:00.666367 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:13:00.709579 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:13:00.775066 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:13:00.784776 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:13:00.813751 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:13:00.822429 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:13:00.830029 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:13:00.833829 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:13:00.913308 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:13:01.591010 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
14:13:01.624432 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
14:13:01.646716 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
14:13:01.649481 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:13:01.659792 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:13:01.663614 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:13:01.674564 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:13:01.679455 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:13:01.689905 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:13:01.886346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b24bf378-93c6-40ea-9c14-2a43c778c644', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1093febb50>]}
14:13:01.903998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b24bf378-93c6-40ea-9c14-2a43c778c644', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1095051d50>]}
14:13:01.905034 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:13:01.908293 [info ] [MainThread]: 
14:13:01.910199 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:13:01.912973 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:13:01.958581 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:13:01.959663 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:13:01.960513 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:13:03.738481 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.78 seconds
14:13:03.743475 [debug] [ThreadPool]: On list_analytics: Close
14:13:03.947375 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:13:03.971566 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:13:03.972489 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:13:03.973272 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:13:05.024453 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.05 seconds
14:13:05.033388 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:13:05.203817 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:13:05.211309 [info ] [MainThread]: 
14:13:05.220592 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:13:05.222298 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:13:05.224519 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:13:05.226969 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:13:05.228565 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:13:05.239167 [debug] [Thread-1  ]: finished collecting timing info
14:13:05.240066 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_frist_variable' not found in config:
  Vars supplied to my_first_dbt_model = {
      "my_first_variable": true,
      "my_second_variable": 2020,
      "my_third_variable": 1
  }
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:13:05.240941 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b24bf378-93c6-40ea-9c14-2a43c778c644', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f109247e190>]}
14:13:05.244009 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
14:13:05.245803 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:13:05.353825 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:13:05.359233 [info ] [MainThread]: 
14:13:05.363228 [info ] [MainThread]: Finished running 1 table model in 3.45s.
14:13:05.366121 [debug] [MainThread]: Connection 'master' was properly closed.
14:13:05.368087 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:13:05.395056 [info ] [MainThread]: 
14:13:05.396730 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:13:05.398228 [info ] [MainThread]: 
14:13:05.399284 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:13:05.400371 [error] [MainThread]:   Required var 'my_frist_variable' not found in config:
14:13:05.401573 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {
14:13:05.402807 [error] [MainThread]:       "my_first_variable": true,
14:13:05.404039 [error] [MainThread]:       "my_second_variable": 2020,
14:13:05.405130 [error] [MainThread]:       "my_third_variable": 1
14:13:05.406147 [error] [MainThread]:   }
14:13:05.407411 [error] [MainThread]:   
14:13:05.409011 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:13:05.410817 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:13:05.412879 [info ] [MainThread]: 
14:13:05.414377 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
14:13:05.416342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f109507c350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1092473b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1092473c10>]}


============================== 2022-01-23 14:14:59.909952 | 639b0eba-3e40-4f46-a99b-112b6fbb587c ==============================
14:14:59.909952 [info ] [MainThread]: Running with dbt=1.0.1
14:14:59.911069 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:14:59.911823 [debug] [MainThread]: Tracking: tracking
14:14:59.912971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c3afd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c3afa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c3afd90>]}
14:14:59.968017 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:14:59.968964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '639b0eba-3e40-4f46-a99b-112b6fbb587c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c357f90>]}
14:15:00.028691 [debug] [MainThread]: Parsing macros/adapters.sql
14:15:00.184538 [debug] [MainThread]: Parsing macros/catalog.sql
14:15:00.191702 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:15:00.221191 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:15:00.232431 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:15:00.250664 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:15:00.253673 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:15:00.262713 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:15:00.268044 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:15:00.300348 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:15:00.309163 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:15:00.316806 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:15:00.342398 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:15:00.355476 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:15:00.388798 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:15:00.396474 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:15:00.426038 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:15:00.440699 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:15:00.445798 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:15:00.447965 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:15:00.450163 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:15:00.452420 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:15:00.457151 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:15:00.461798 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:15:00.468660 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:15:00.476010 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:15:00.488579 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:15:00.550895 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:15:00.570068 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:15:00.613253 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:15:00.658932 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:15:00.664742 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:15:00.724767 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:15:00.729827 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:15:00.743945 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:15:00.749714 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:15:00.765739 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:15:00.800501 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:15:00.805667 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:15:00.849294 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:15:00.914723 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:15:00.923846 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:15:00.950386 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:15:00.960380 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:15:00.967239 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:15:00.971170 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:15:01.063577 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:15:01.750459 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
14:15:01.783986 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
14:15:01.805161 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
14:15:01.808578 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:15:01.818434 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:15:01.821855 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:15:01.832922 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:15:01.836061 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:15:01.842760 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:15:02.027679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '639b0eba-3e40-4f46-a99b-112b6fbb587c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c3a6650>]}
14:15:02.045010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '639b0eba-3e40-4f46-a99b-112b6fbb587c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c3a62d0>]}
14:15:02.046289 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:15:02.049658 [info ] [MainThread]: 
14:15:02.051548 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:15:02.054234 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:15:02.097038 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:15:02.097863 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:15:02.098508 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:15:03.321732 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.22 seconds
14:15:03.326599 [debug] [ThreadPool]: On list_analytics: Close
14:15:03.500146 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:15:03.522959 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:15:03.523994 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:15:03.524761 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:15:04.250791 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.73 seconds
14:15:04.261866 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:15:04.393288 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:15:04.407015 [info ] [MainThread]: 
14:15:04.411934 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:15:04.413231 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:15:04.414854 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:15:04.415599 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:15:04.416646 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:15:04.429010 [debug] [Thread-1  ]: finished collecting timing info
14:15:04.430204 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:15:04.431165 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639b0eba-3e40-4f46-a99b-112b6fbb587c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea06a0ac50>]}
14:15:04.432245 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
14:15:04.433243 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:15:04.512507 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:15:04.514116 [info ] [MainThread]: 
14:15:04.515172 [info ] [MainThread]: Finished running 1 table model in 2.46s.
14:15:04.516829 [debug] [MainThread]: Connection 'master' was properly closed.
14:15:04.518112 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:15:04.541325 [info ] [MainThread]: 
14:15:04.542904 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:15:04.544279 [info ] [MainThread]: 
14:15:04.546247 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:15:04.547482 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
14:15:04.548899 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
14:15:04.550241 [error] [MainThread]:   
14:15:04.551451 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:15:04.552744 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:15:04.554071 [info ] [MainThread]: 
14:15:04.555332 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
14:15:04.558258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0c3cad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea069fbb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea069fbc10>]}


============================== 2022-01-23 14:15:51.948109 | 621039aa-9390-4587-a93f-f73d8f028639 ==============================
14:15:51.948109 [info ] [MainThread]: Running with dbt=1.0.1
14:15:51.949304 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:15:51.950391 [debug] [MainThread]: Tracking: tracking
14:15:51.952282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d20666d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d20666d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d20666c90>]}
14:15:52.062546 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:15:52.063504 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:15:52.081546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '621039aa-9390-4587-a93f-f73d8f028639', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d28504450>]}
14:15:52.100180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '621039aa-9390-4587-a93f-f73d8f028639', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d206c3750>]}
14:15:52.101437 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:15:52.105306 [info ] [MainThread]: 
14:15:52.107251 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:15:52.110092 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:15:52.150186 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:15:52.151250 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:15:52.151779 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:15:53.463582 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.31 seconds
14:15:53.468721 [debug] [ThreadPool]: On list_analytics: Close
14:15:53.635892 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:15:53.662911 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:15:53.663948 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:15:53.664727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:15:54.497076 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.83 seconds
14:15:54.508132 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:15:54.682260 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:15:54.685270 [info ] [MainThread]: 
14:15:54.691965 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:15:54.693330 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:15:54.695348 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:15:54.696393 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:15:54.697645 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:15:54.709394 [debug] [Thread-1  ]: finished collecting timing info
14:15:54.710722 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:15:54.711720 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621039aa-9390-4587-a93f-f73d8f028639', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1e108450>]}
14:15:54.712724 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.02s]
14:15:54.713912 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:15:54.792978 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:15:54.794743 [info ] [MainThread]: 
14:15:54.796129 [info ] [MainThread]: Finished running 1 table model in 2.69s.
14:15:54.797916 [debug] [MainThread]: Connection 'master' was properly closed.
14:15:54.799369 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:15:54.823618 [info ] [MainThread]: 
14:15:54.824986 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:15:54.826381 [info ] [MainThread]: 
14:15:54.827904 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:15:54.829246 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
14:15:54.830437 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
14:15:54.831910 [error] [MainThread]:   
14:15:54.833183 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:15:54.835654 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
14:15:54.837474 [info ] [MainThread]: 
14:15:54.839754 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
14:15:54.841139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d20675a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1e113490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1e113890>]}


============================== 2022-01-23 14:16:57.387172 | c954619e-0654-4118-831c-b2fb393cc106 ==============================
14:16:57.387172 [info ] [MainThread]: Running with dbt=1.0.1
14:16:57.388620 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:16:57.389783 [debug] [MainThread]: Tracking: tracking
14:16:57.391314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da0135c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da0135b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da0135d10>]}
14:16:57.445725 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:16:57.446678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c954619e-0654-4118-831c-b2fb393cc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da00d9f50>]}
14:16:57.503276 [debug] [MainThread]: Parsing macros/adapters.sql
14:16:57.659415 [debug] [MainThread]: Parsing macros/catalog.sql
14:16:57.666358 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:16:57.695231 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:16:57.709494 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:16:57.726607 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:16:57.729973 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:16:57.740024 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:16:57.744178 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:16:57.779789 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:16:57.788730 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:16:57.796712 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:16:57.820854 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:16:57.835866 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:16:57.871530 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:16:57.878769 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:16:57.911219 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:16:57.924145 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:16:57.927883 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:16:57.929631 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:16:57.932508 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:16:57.934676 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:16:57.940277 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:16:57.945265 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:16:57.953626 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:16:57.961470 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:16:57.974382 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:16:58.039567 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:16:58.061276 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:16:58.105738 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:16:58.149834 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:16:58.155172 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:16:58.217208 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:16:58.223202 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:16:58.240781 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:16:58.246162 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:16:58.262021 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:16:58.297253 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:16:58.301880 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:16:58.342739 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:16:58.405885 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:16:58.417979 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:16:58.445704 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:16:58.454386 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:16:58.461093 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:16:58.464363 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:16:58.548267 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:16:59.201142 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
14:16:59.234139 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
14:16:59.255602 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
14:16:59.258704 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:16:59.268477 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:16:59.272079 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:16:59.281991 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:16:59.284643 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:16:59.291444 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:16:59.476327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c954619e-0654-4118-831c-b2fb393cc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da011c590>]}
14:16:59.493833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c954619e-0654-4118-831c-b2fb393cc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da00d0090>]}
14:16:59.494774 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:16:59.498122 [info ] [MainThread]: 
14:16:59.500041 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:16:59.503050 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:16:59.555107 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:16:59.555975 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:16:59.556581 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:17:00.662969 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.11 seconds
14:17:00.667508 [debug] [ThreadPool]: On list_analytics: Close
14:17:00.814107 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:17:00.837825 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:17:00.838870 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:17:00.839618 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:17:01.745532 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.91 seconds
14:17:01.751110 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:17:01.908910 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:17:01.911749 [info ] [MainThread]: 
14:17:01.922421 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:17:01.924601 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:17:01.926897 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:17:01.927909 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:17:01.929164 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:17:01.941486 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:17:01.946334 [debug] [Thread-1  ]: finished collecting timing info
14:17:01.947677 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:17:02.028425 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:17:02.033975 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:17:02.035083 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable 
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:17:02.035854 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:17:03.838697 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.8 seconds
14:17:03.874488 [debug] [Thread-1  ]: finished collecting timing info
14:17:03.875440 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:17:04.042396 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c954619e-0654-4118-831c-b2fb393cc106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d98a55150>]}
14:17:04.045324 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.12s]
14:17:04.047985 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:17:04.200257 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:17:04.203285 [info ] [MainThread]: 
14:17:04.205910 [info ] [MainThread]: Finished running 1 table model in 4.70s.
14:17:04.208378 [debug] [MainThread]: Connection 'master' was properly closed.
14:17:04.210238 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:17:04.230922 [info ] [MainThread]: 
14:17:04.232126 [info ] [MainThread]: [32mCompleted successfully[0m
14:17:04.233937 [info ] [MainThread]: 
14:17:04.236938 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:17:04.239070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d9a7896d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d98a557d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d98a55b10>]}


============================== 2022-01-23 14:25:36.760442 | 98b8a3c3-c650-4453-8e2b-32df49d60f6f ==============================
14:25:36.760442 [info ] [MainThread]: Running with dbt=1.0.1
14:25:36.761914 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:25:36.762841 [debug] [MainThread]: Tracking: tracking
14:25:36.764042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bfb07dd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bfb07dad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bfb07de10>]}
14:25:36.873601 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:25:36.875000 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:25:36.908392 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:25:36.949207 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:25:37.039050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '98b8a3c3-c650-4453-8e2b-32df49d60f6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bf9b77610>]}
14:25:37.114156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '98b8a3c3-c650-4453-8e2b-32df49d60f6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bfd8ddf10>]}
14:25:37.115027 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:25:37.118042 [info ] [MainThread]: 
14:25:37.120151 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:25:37.123157 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
14:25:37.171492 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
14:25:37.172205 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
14:25:37.172586 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:25:38.373165 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1d2c1-0000-1e52-0000-000298a23fc9
14:25:38.374616 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
14:25:38.376607 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
14:25:38.377699 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
14:25:38.379125 [debug] [ThreadPool]: On list_analytics_test: Close
14:25:38.542776 [debug] [MainThread]: Connection 'master' was properly closed.
14:25:38.544789 [debug] [MainThread]: Connection 'list_analytics_test' was properly closed.
14:25:38.546749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bfb133890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bf864ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1bf8730c10>]}


============================== 2022-01-23 14:27:39.284103 | 074cdf4f-0bfb-4455-886b-e50d449f9508 ==============================
14:27:39.284103 [info ] [MainThread]: Running with dbt=1.0.1
14:27:39.285580 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:27:39.286280 [debug] [MainThread]: Tracking: tracking
14:27:39.287126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d0e3ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d0e3cd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d0e3ced0>]}
14:27:39.403010 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:27:39.404350 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:27:39.440036 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:27:39.482797 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:27:39.570723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '074cdf4f-0bfb-4455-886b-e50d449f9508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29cfd5d490>]}
14:27:39.644747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '074cdf4f-0bfb-4455-886b-e50d449f9508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d0ede110>]}
14:27:39.645885 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:27:39.650471 [info ] [MainThread]: 
14:27:39.652346 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:27:39.655372 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
14:27:39.694711 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
14:27:39.695490 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
14:27:39.696311 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:27:40.835736 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1d2c3-0000-1e54-0000-000298a24f89
14:27:40.837656 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
14:27:40.839785 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
14:27:40.841100 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
14:27:40.842284 [debug] [ThreadPool]: On list_analytics_test: Close
14:27:41.006404 [debug] [MainThread]: Connection 'master' was properly closed.
14:27:41.008170 [debug] [MainThread]: Connection 'list_analytics_test' was properly closed.
14:27:41.010051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d0edead0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29d772f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29ce4fb810>]}


============================== 2022-01-23 14:28:24.272305 | 9e3b9de8-bd68-400a-88a9-1006a1f09774 ==============================
14:28:24.272305 [info ] [MainThread]: Running with dbt=1.0.1
14:28:24.273450 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:28:24.274406 [debug] [MainThread]: Tracking: tracking
14:28:24.276090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d0d3e9f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d0d3e9dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d0d3e9fd0>]}
14:28:24.390286 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:28:24.391764 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:28:24.426987 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:28:24.468394 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:28:24.559970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e3b9de8-bd68-400a-88a9-1006a1f09774', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d0cef6090>]}
14:28:24.632341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e3b9de8-bd68-400a-88a9-1006a1f09774', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d10c79f90>]}
14:28:24.633146 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:28:24.636123 [info ] [MainThread]: 
14:28:24.637624 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:28:24.640244 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
14:28:24.679434 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
14:28:24.680339 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
14:28:24.680834 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:28:25.874626 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a1d2c4-0000-1e52-0000-000298a23fcd
14:28:25.875743 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
14:28:25.877267 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
14:28:25.878080 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
14:28:25.888990 [debug] [ThreadPool]: On list_analytics_test: Close
14:28:26.062354 [debug] [MainThread]: Connection 'master' was properly closed.
14:28:26.063913 [debug] [MainThread]: Connection 'list_analytics_test' was properly closed.
14:28:26.065163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d0e4ce990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d07aba790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d07a84610>]}


============================== 2022-01-23 14:28:48.148929 | 82bb0104-76bf-44f2-8356-d815f037557d ==============================
14:28:48.148929 [info ] [MainThread]: Running with dbt=1.0.1
14:28:48.150448 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:28:48.151928 [debug] [MainThread]: Tracking: tracking
14:28:48.153262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4beb06ce90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4beb06cd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4beb06ce10>]}
14:28:48.263531 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:28:48.265559 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:28:48.303663 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:28:48.341942 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:28:48.430292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82bb0104-76bf-44f2-8356-d815f037557d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be9acb450>]}
14:28:48.505147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82bb0104-76bf-44f2-8356-d815f037557d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4beb1250d0>]}
14:28:48.506163 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:28:48.509057 [info ] [MainThread]: 
14:28:48.510731 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:28:48.513301 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:28:48.551930 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:28:48.552771 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:28:48.553276 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:28:49.775190 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.22 seconds
14:28:49.781623 [debug] [ThreadPool]: On list_analytics: Close
14:28:49.958911 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:28:49.991812 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:28:49.992819 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:28:49.993276 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:28:51.085788 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.09 seconds
14:28:51.090597 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:28:51.270070 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:28:51.271348 [info ] [MainThread]: 
14:28:51.277334 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:28:51.278839 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:28:51.280792 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:28:51.282607 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:28:51.284719 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:28:51.294449 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:28:51.298528 [debug] [Thread-1  ]: finished collecting timing info
14:28:51.301162 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:28:51.394436 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:28:51.402201 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:28:51.403456 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable 
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:28:51.404459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:28:53.070119 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
14:28:53.105338 [debug] [Thread-1  ]: finished collecting timing info
14:28:53.106132 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:28:53.238076 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82bb0104-76bf-44f2-8356-d815f037557d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be86bd550>]}
14:28:53.239357 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.96s]
14:28:53.240715 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:28:53.336361 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:28:53.340249 [info ] [MainThread]: 
14:28:53.343552 [info ] [MainThread]: Finished running 1 table model in 4.83s.
14:28:53.347172 [debug] [MainThread]: Connection 'master' was properly closed.
14:28:53.350070 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:28:53.374436 [info ] [MainThread]: 
14:28:53.375633 [info ] [MainThread]: [32mCompleted successfully[0m
14:28:53.377187 [info ] [MainThread]: 
14:28:53.378562 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:28:53.380274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be8779990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be86bd210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be86bd390>]}


============================== 2022-01-23 14:32:57.196322 | 52f75788-259a-4fcf-9243-1f322149d2e9 ==============================
14:32:57.196322 [info ] [MainThread]: Running with dbt=1.0.1
14:32:57.197575 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:32:57.198602 [debug] [MainThread]: Tracking: tracking
14:32:57.199880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68dac3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68dac3ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68dac3e10>]}
14:32:57.308949 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:32:57.310469 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:32:57.345331 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:32:57.383381 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:32:57.474103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '52f75788-259a-4fcf-9243-1f322149d2e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68c505f10>]}
14:32:57.548789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '52f75788-259a-4fcf-9243-1f322149d2e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68db28310>]}
14:32:57.549838 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:32:57.553578 [info ] [MainThread]: 
14:32:57.556140 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:32:57.559172 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:32:57.600308 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:32:57.601137 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:32:57.601714 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:32:58.838795 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.24 seconds
14:32:58.843977 [debug] [ThreadPool]: On list_analytics: Close
14:32:58.996024 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:32:59.023275 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:32:59.024062 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:32:59.024604 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:33:00.058424 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.03 seconds
14:33:00.070213 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:33:00.250365 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:33:00.253028 [info ] [MainThread]: 
14:33:00.261545 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:33:00.262919 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:33:00.264691 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:33:00.265894 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:33:00.267011 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:33:00.277904 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:33:00.281694 [debug] [Thread-1  ]: finished collecting timing info
14:33:00.282610 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:33:00.366878 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:33:00.372371 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:33:00.373292 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id

)

select * 
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:33:00.373856 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:33:02.063012 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
14:33:02.118738 [debug] [Thread-1  ]: finished collecting timing info
14:33:02.119654 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:33:02.256844 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52f75788-259a-4fcf-9243-1f322149d2e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb67d3aac50>]}
14:33:02.258239 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.99s]
14:33:02.259419 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:33:02.348189 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:33:02.349855 [info ] [MainThread]: 
14:33:02.351371 [info ] [MainThread]: Finished running 1 table model in 4.79s.
14:33:02.352758 [debug] [MainThread]: Connection 'master' was properly closed.
14:33:02.354209 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:33:02.375068 [info ] [MainThread]: 
14:33:02.376682 [info ] [MainThread]: [32mCompleted successfully[0m
14:33:02.378018 [info ] [MainThread]: 
14:33:02.379227 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:33:02.380902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68db4c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb67f0d1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb67f0d1b90>]}


============================== 2022-01-23 14:33:55.828772 | 585e470a-34dc-4ae9-85fd-cce890400b62 ==============================
14:33:55.828772 [info ] [MainThread]: Running with dbt=1.0.1
14:33:55.830240 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:33:55.831093 [debug] [MainThread]: Tracking: tracking
14:33:55.832451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7bb71ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7bb71e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7bb71dd0>]}
14:33:55.961676 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:33:55.963349 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:33:55.997379 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:33:56.036283 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:33:56.124582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '585e470a-34dc-4ae9-85fd-cce890400b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7b60a110>]}
14:33:56.201965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '585e470a-34dc-4ae9-85fd-cce890400b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7cc51190>]}
14:33:56.202973 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:33:56.208128 [info ] [MainThread]: 
14:33:56.210094 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:33:56.213152 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:33:56.252645 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:33:56.253565 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:33:56.254148 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:33:57.430558 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.18 seconds
14:33:57.435188 [debug] [ThreadPool]: On list_analytics: Close
14:33:57.581923 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:33:57.605187 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:33:57.606140 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:33:57.606974 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:33:58.639170 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.03 seconds
14:33:58.652281 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:33:58.820008 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:33:58.821094 [info ] [MainThread]: 
14:33:58.826470 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:33:58.827979 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:33:58.830396 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:33:58.831951 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:33:58.833332 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:33:58.842504 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:33:58.847895 [debug] [Thread-1  ]: finished collecting timing info
14:33:58.850041 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:33:58.936557 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:33:58.941849 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:33:58.942621 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:33:58.943278 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:34:00.321831 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
14:34:00.366239 [debug] [Thread-1  ]: finished collecting timing info
14:34:00.367296 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:34:00.540018 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585e470a-34dc-4ae9-85fd-cce890400b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7a1f9590>]}
14:34:00.543628 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.71s]
14:34:00.546195 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:34:00.637176 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:34:00.638897 [info ] [MainThread]: 
14:34:00.640117 [info ] [MainThread]: Finished running 1 table model in 4.43s.
14:34:00.641784 [debug] [MainThread]: Connection 'master' was properly closed.
14:34:00.643574 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:34:00.670076 [info ] [MainThread]: 
14:34:00.671696 [info ] [MainThread]: [32mCompleted successfully[0m
14:34:00.673119 [info ] [MainThread]: 
14:34:00.674391 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:34:00.676226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e784cea50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e784ce650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e784cee50>]}


============================== 2022-01-23 14:37:06.419365 | da6618f9-4afb-4813-b0b9-dd9894575bfd ==============================
14:37:06.419365 [info ] [MainThread]: Running with dbt=1.0.1
14:37:06.420632 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:37:06.421691 [debug] [MainThread]: Tracking: tracking
14:37:06.422842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a6a854f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a6a854910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a6a854f90>]}
14:37:06.528559 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:37:06.529582 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:37:06.547626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da6618f9-4afb-4813-b0b9-dd9894575bfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a69746610>]}
14:37:06.565846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da6618f9-4afb-4813-b0b9-dd9894575bfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a6a8ba850>]}
14:37:06.566850 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:37:06.570359 [info ] [MainThread]: 
14:37:06.572539 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:37:06.576999 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:37:06.618460 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:37:06.619482 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:37:06.620323 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:37:07.912727 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.29 seconds
14:37:07.920121 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:37:08.151067 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:37:08.155299 [info ] [MainThread]: 
14:37:08.166100 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:37:08.167387 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
14:37:08.169868 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:37:08.171753 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:37:08.172716 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:37:08.206969 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:37:08.214142 [debug] [Thread-1  ]: finished collecting timing info
14:37:08.215444 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:37:08.266311 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:37:08.272636 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:37:08.273545 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:37:08.274124 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:37:10.109951 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
14:37:10.125928 [debug] [Thread-1  ]: finished collecting timing info
14:37:10.127252 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:37:10.297627 [error] [Thread-1  ]: 1 of 2 FAIL 1 not_null_my_first_dbt_model_id.................................... [[31mFAIL 1[0m in 2.13s]
14:37:10.301430 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:37:10.305076 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:37:10.307956 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
14:37:10.310887 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:37:10.312260 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:37:10.313711 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:37:10.335547 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:37:10.342474 [debug] [Thread-1  ]: finished collecting timing info
14:37:10.343625 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:37:10.348895 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:37:10.354699 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:37:10.355593 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:37:10.356869 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:37:11.164389 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.81 seconds
14:37:11.173309 [debug] [Thread-1  ]: finished collecting timing info
14:37:11.174757 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:37:11.306707 [info ] [Thread-1  ]: 2 of 2 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.00s]
14:37:11.311075 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:37:11.315874 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:37:11.317964 [info ] [MainThread]: 
14:37:11.319750 [info ] [MainThread]: Finished running 2 tests in 4.75s.
14:37:11.321333 [debug] [MainThread]: Connection 'master' was properly closed.
14:37:11.322722 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:37:11.346480 [info ] [MainThread]: 
14:37:11.347847 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:37:11.349400 [info ] [MainThread]: 
14:37:11.350458 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
14:37:11.352069 [error] [MainThread]:   Got 1 result, configured to fail if != 0
14:37:11.354218 [info ] [MainThread]: 
14:37:11.355682 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
14:37:11.359875 [info ] [MainThread]: 
14:37:11.363234 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
14:37:11.365528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a6a8a93d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a62578050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a62578e10>]}


============================== 2022-01-23 14:41:06.503406 | 88102bff-b660-4dd7-9026-03e350525bd3 ==============================
14:41:06.503406 [info ] [MainThread]: Running with dbt=1.0.1
14:41:06.504719 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:41:06.505347 [debug] [MainThread]: Tracking: tracking
14:41:06.506106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa010c4c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa010c4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa010c4d10>]}
14:41:06.613940 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:41:06.615130 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:41:06.649688 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:41:06.688058 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:41:06.776952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '88102bff-b660-4dd7-9026-03e350525bd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9ffb06fd0>]}
14:41:06.850351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '88102bff-b660-4dd7-9026-03e350525bd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa011185d0>]}
14:41:06.851636 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:41:06.854908 [info ] [MainThread]: 
14:41:06.856924 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:41:06.859827 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:41:06.900521 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:41:06.901861 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:41:06.902735 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:41:08.058664 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.16 seconds
14:41:08.063282 [debug] [ThreadPool]: On list_analytics: Close
14:41:08.238024 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:41:08.261246 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:41:08.262225 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:41:08.263047 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:41:09.177765 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.91 seconds
14:41:09.189823 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:41:09.323304 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:41:09.324975 [info ] [MainThread]: 
14:41:09.331936 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:41:09.333838 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:41:09.337168 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:41:09.338850 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:41:09.340352 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:41:09.350220 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:41:09.357416 [debug] [Thread-1  ]: finished collecting timing info
14:41:09.358671 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:41:09.440049 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:41:09.445542 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:41:09.446319 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:41:09.447021 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:41:11.387666 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.94 seconds
14:41:11.430999 [debug] [Thread-1  ]: finished collecting timing info
14:41:11.431830 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:41:11.591920 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88102bff-b660-4dd7-9026-03e350525bd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9fc9d0250>]}
14:41:11.595422 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.26s]
14:41:11.598564 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:41:11.624204 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:41:11.625990 [info ] [MainThread]: 
14:41:11.627229 [info ] [MainThread]: Finished running 1 table model in 4.77s.
14:41:11.628680 [debug] [MainThread]: Connection 'master' was properly closed.
14:41:11.629715 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:41:11.654542 [info ] [MainThread]: 
14:41:11.656044 [info ] [MainThread]: [32mCompleted successfully[0m
14:41:11.657221 [info ] [MainThread]: 
14:41:11.658383 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:41:11.659874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa079a2650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9fc9c5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9fc9c5350>]}


============================== 2022-01-23 14:41:45.518264 | e1159a9f-29a3-4f9c-b8e3-b03c95907095 ==============================
14:41:45.518264 [info ] [MainThread]: Running with dbt=1.0.1
14:41:45.519439 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:41:45.520278 [debug] [MainThread]: Tracking: tracking
14:41:45.521298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7f9f0cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7f9f0a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7f9f0d50>]}
14:41:45.632308 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:41:45.633379 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:41:45.651064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1159a9f-29a3-4f9c-b8e3-b03c95907095', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7f8c6410>]}
14:41:45.669452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1159a9f-29a3-4f9c-b8e3-b03c95907095', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7f991790>]}
14:41:45.670760 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:41:45.674048 [info ] [MainThread]: 
14:41:45.675818 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:41:45.679371 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:41:45.718743 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:41:45.719696 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:41:45.720286 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:41:46.949153 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.23 seconds
14:41:46.954372 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:41:47.103396 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:41:47.104728 [info ] [MainThread]: 
14:41:47.111012 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:41:47.111924 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
14:41:47.113268 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:41:47.114029 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:41:47.115036 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:41:47.148270 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:41:47.152593 [debug] [Thread-1  ]: finished collecting timing info
14:41:47.154004 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:41:47.210405 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:41:47.216045 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:41:47.217071 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:41:47.217905 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:41:48.474981 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.26 seconds
14:41:48.491748 [debug] [Thread-1  ]: finished collecting timing info
14:41:48.493036 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:41:48.656491 [error] [Thread-1  ]: 1 of 2 FAIL 1 not_null_my_first_dbt_model_id.................................... [[31mFAIL 1[0m in 1.54s]
14:41:48.658932 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:41:48.660822 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:41:48.663207 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
14:41:48.665754 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:41:48.667779 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:41:48.669171 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:41:48.689098 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:41:48.692957 [debug] [Thread-1  ]: finished collecting timing info
14:41:48.693682 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:41:48.700470 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:41:48.706796 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:41:48.707616 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:41:48.708913 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:41:49.475828 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
14:41:49.487646 [debug] [Thread-1  ]: finished collecting timing info
14:41:49.488978 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:41:49.626132 [error] [Thread-1  ]: 2 of 2 FAIL 1 unique_my_first_dbt_model_id...................................... [[31mFAIL 1[0m in 0.96s]
14:41:49.627672 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:41:49.692978 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:41:49.694208 [info ] [MainThread]: 
14:41:49.695126 [info ] [MainThread]: Finished running 2 tests in 4.02s.
14:41:49.696269 [debug] [MainThread]: Connection 'master' was properly closed.
14:41:49.698310 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:41:49.718787 [info ] [MainThread]: 
14:41:49.720643 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
14:41:49.722243 [info ] [MainThread]: 
14:41:49.723518 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
14:41:49.725031 [error] [MainThread]:   Got 1 result, configured to fail if != 0
14:41:49.726353 [info ] [MainThread]: 
14:41:49.727569 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
14:41:49.728995 [info ] [MainThread]: 
14:41:49.730296 [error] [MainThread]: [31mFailure in test unique_my_first_dbt_model_id (models/example/schema.yml)[0m
14:41:49.732237 [error] [MainThread]:   Got 1 result, configured to fail if != 0
14:41:49.735297 [info ] [MainThread]: 
14:41:49.737488 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/unique_my_first_dbt_model_id.sql
14:41:49.739384 [info ] [MainThread]: 
14:41:49.741085 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
14:41:49.742251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7f08f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7c711c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7c711c50>]}


============================== 2022-01-23 14:42:48.801138 | a5ceb959-666f-4e45-962d-813ef8f19fb6 ==============================
14:42:48.801138 [info ] [MainThread]: Running with dbt=1.0.1
14:42:48.802231 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:42:48.802958 [debug] [MainThread]: Tracking: tracking
14:42:48.804159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03932cac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03932ca9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03932cad50>]}
14:42:48.912765 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:42:48.914153 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:42:48.948311 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:42:48.984963 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:42:49.074314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5ceb959-666f-4e45-962d-813ef8f19fb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0391d51110>]}
14:42:49.147316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5ceb959-666f-4e45-962d-813ef8f19fb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0393358190>]}
14:42:49.148243 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:42:49.151422 [info ] [MainThread]: 
14:42:49.153287 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:42:49.156178 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:42:49.195570 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:42:49.196221 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:42:49.196674 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:42:50.458168 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.26 seconds
14:42:50.462415 [debug] [ThreadPool]: On list_analytics: Close
14:42:50.639810 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:42:50.663551 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:42:50.664359 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:42:50.665140 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:42:51.486838 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.82 seconds
14:42:51.498101 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:42:51.666862 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:42:51.669234 [info ] [MainThread]: 
14:42:51.680400 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:42:51.681673 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:42:51.682977 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:42:51.683621 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:42:51.684638 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:42:51.694833 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:42:51.699203 [debug] [Thread-1  ]: finished collecting timing info
14:42:51.700279 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:42:51.789529 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:42:51.794745 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:42:51.795531 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    -- union all
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:42:51.796226 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:42:53.075303 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
14:42:53.113868 [debug] [Thread-1  ]: finished collecting timing info
14:42:53.114765 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:42:53.277503 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5ceb959-666f-4e45-962d-813ef8f19fb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03904132d0>]}
14:42:53.279206 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.59s]
14:42:53.280672 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:42:53.332543 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:42:53.333898 [info ] [MainThread]: 
14:42:53.335197 [info ] [MainThread]: Finished running 1 table model in 4.18s.
14:42:53.336586 [debug] [MainThread]: Connection 'master' was properly closed.
14:42:53.337809 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:42:53.356837 [info ] [MainThread]: 
14:42:53.358421 [info ] [MainThread]: [32mCompleted successfully[0m
14:42:53.360008 [info ] [MainThread]: 
14:42:53.361133 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:42:53.362902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0390a02090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0390408910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0390408ad0>]}


============================== 2022-01-23 14:43:14.153350 | ec80d321-764c-4bee-ade6-7a739559098a ==============================
14:43:14.153350 [info ] [MainThread]: Running with dbt=1.0.1
14:43:14.154625 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:43:14.155642 [debug] [MainThread]: Tracking: tracking
14:43:14.156790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b176a0d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b176a0a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b176a0dd0>]}
14:43:14.259980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:43:14.260883 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:43:14.278357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec80d321-764c-4bee-ade6-7a739559098a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b176b0bd0>]}
14:43:14.295740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec80d321-764c-4bee-ade6-7a739559098a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b176fd6d0>]}
14:43:14.296681 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:43:14.300130 [info ] [MainThread]: 
14:43:14.302220 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:43:14.305798 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:43:14.346200 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:43:14.347155 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:43:14.347963 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:43:15.641644 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.29 seconds
14:43:15.647029 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:43:15.823693 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:43:15.826913 [info ] [MainThread]: 
14:43:15.835517 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:43:15.836755 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
14:43:15.838782 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:43:15.839847 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:43:15.840685 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:43:15.875120 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:43:15.878947 [debug] [Thread-1  ]: finished collecting timing info
14:43:15.880328 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:43:15.929913 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:43:15.935654 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:43:15.936436 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:43:15.937018 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:43:16.768131 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
14:43:16.783425 [debug] [Thread-1  ]: finished collecting timing info
14:43:16.784559 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:43:16.903007 [info ] [Thread-1  ]: 1 of 2 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.06s]
14:43:16.904317 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:43:16.905145 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:43:16.906369 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
14:43:16.908056 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:43:16.909119 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:43:16.910091 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:43:16.929736 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:43:16.935036 [debug] [Thread-1  ]: finished collecting timing info
14:43:16.935922 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:43:16.940910 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:43:16.946227 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:43:16.947004 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:43:16.947874 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:43:17.895969 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
14:43:17.901567 [debug] [Thread-1  ]: finished collecting timing info
14:43:17.902687 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:43:18.036085 [info ] [Thread-1  ]: 2 of 2 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.13s]
14:43:18.043091 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:43:18.140703 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:43:18.143239 [info ] [MainThread]: 
14:43:18.145383 [info ] [MainThread]: Finished running 2 tests in 3.84s.
14:43:18.147546 [debug] [MainThread]: Connection 'master' was properly closed.
14:43:18.149438 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:43:18.176965 [info ] [MainThread]: 
14:43:18.179057 [info ] [MainThread]: [32mCompleted successfully[0m
14:43:18.180446 [info ] [MainThread]: 
14:43:18.181863 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
14:43:18.183252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b1518aa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b143cd1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b143cd0d0>]}


============================== 2022-01-23 14:48:00.829480 | fb03ae83-24da-4c34-aa35-b35eb9679625 ==============================
14:48:00.829480 [info ] [MainThread]: Running with dbt=1.0.1
14:48:00.831046 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:48:00.832193 [debug] [MainThread]: Tracking: tracking
14:48:00.833774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee3ce4dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee3ce4b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee3ce4e50>]}
14:48:00.943556 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
14:48:00.945291 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
14:48:00.946362 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:48:00.980761 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:48:01.018981 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:48:01.030081 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:48:01.239148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb03ae83-24da-4c34-aa35-b35eb9679625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8eea5e2750>]}
14:48:01.257302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb03ae83-24da-4c34-aa35-b35eb9679625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee3d0af10>]}
14:48:01.258446 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:48:01.261875 [info ] [MainThread]: 
14:48:01.264158 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:48:01.266940 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:48:01.315435 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:48:01.316518 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:48:01.317436 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:48:02.575967 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.26 seconds
14:48:02.580613 [debug] [ThreadPool]: On list_analytics: Close
14:48:02.754302 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:48:02.778930 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:48:02.779984 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:48:02.780920 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:48:03.545013 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.76 seconds
14:48:03.556598 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:48:03.696555 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:48:03.699972 [info ] [MainThread]: 
14:48:03.713839 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:48:03.716301 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:48:03.718064 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:48:03.718842 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:48:03.719796 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:48:03.729569 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:48:03.736048 [debug] [Thread-1  ]: finished collecting timing info
14:48:03.737713 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:48:03.826705 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:48:03.832312 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:48:03.833256 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    -- union all
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:48:03.834145 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:05.602893 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.77 seconds
14:48:05.650668 [debug] [Thread-1  ]: finished collecting timing info
14:48:05.651641 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:48:05.801249 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb03ae83-24da-4c34-aa35-b35eb9679625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee1345d50>]}
14:48:05.803751 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.08s]
14:48:05.805887 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:48:05.943663 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:48:05.945348 [info ] [MainThread]: 
14:48:05.947278 [info ] [MainThread]: Finished running 1 table model in 4.68s.
14:48:05.949311 [debug] [MainThread]: Connection 'master' was properly closed.
14:48:05.950648 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:48:05.971863 [info ] [MainThread]: 
14:48:05.972929 [info ] [MainThread]: [32mCompleted successfully[0m
14:48:05.974678 [info ] [MainThread]: 
14:48:05.976144 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:48:05.977868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee1345d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee139da10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ee139d710>]}


============================== 2022-01-23 14:49:23.168920 | cca7d528-e3fa-415a-82ef-1744d90fcf91 ==============================
14:49:23.168920 [info ] [MainThread]: Running with dbt=1.0.1
14:49:23.170322 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:49:23.171210 [debug] [MainThread]: Tracking: tracking
14:49:23.172405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89199b3d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89199b3b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89199b3d10>]}
14:49:23.286890 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:49:23.288297 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:49:23.322854 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:49:23.361991 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:49:23.453351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cca7d528-e3fa-415a-82ef-1744d90fcf91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891943d210>]}
14:49:23.525868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cca7d528-e3fa-415a-82ef-1744d90fcf91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891aa78150>]}
14:49:23.526916 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:49:23.530310 [info ] [MainThread]: 
14:49:23.532521 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:49:23.535214 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:49:23.576474 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:49:23.577552 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:49:23.578528 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:49:24.755611 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.18 seconds
14:49:24.760455 [debug] [ThreadPool]: On list_analytics: Close
14:49:24.891002 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:49:24.916861 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:49:24.917707 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:49:24.918487 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:49:25.803915 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.89 seconds
14:49:25.813783 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:49:25.996257 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:49:25.997879 [info ] [MainThread]: 
14:49:26.003704 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:49:26.005031 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:49:26.006968 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:49:26.008769 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:49:26.010043 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:49:26.022340 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:49:26.026257 [debug] [Thread-1  ]: finished collecting timing info
14:49:26.028225 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:49:26.116121 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:49:26.122181 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:49:26.122858 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:49:26.123472 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:49:27.832327 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
14:49:27.870452 [debug] [Thread-1  ]: finished collecting timing info
14:49:27.871436 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:49:28.041703 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cca7d528-e3fa-415a-82ef-1744d90fcf91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89180382d0>]}
14:49:28.044492 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.03s]
14:49:28.046192 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:49:28.054193 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:49:28.055865 [info ] [MainThread]: 
14:49:28.057427 [info ] [MainThread]: Finished running 1 table model in 4.52s.
14:49:28.060977 [debug] [MainThread]: Connection 'master' was properly closed.
14:49:28.062638 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:49:28.083504 [info ] [MainThread]: 
14:49:28.084759 [info ] [MainThread]: [32mCompleted successfully[0m
14:49:28.086229 [info ] [MainThread]: 
14:49:28.087759 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:49:28.089783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8918078a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8918045e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8918045190>]}


============================== 2022-01-23 14:50:00.517911 | f941b6c8-3d29-472d-aec4-d01776e89715 ==============================
14:50:00.517911 [info ] [MainThread]: Running with dbt=1.0.1
14:50:00.519002 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:50:00.519595 [debug] [MainThread]: Tracking: tracking
14:50:00.520339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa368e44e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa368e44dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa368e446d0>]}
14:50:00.623553 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:50:00.624243 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:50:00.641667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f941b6c8-3d29-472d-aec4-d01776e89715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa373928750>]}
14:50:00.659680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f941b6c8-3d29-472d-aec4-d01776e89715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa367df00d0>]}
14:50:00.660868 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:50:00.664772 [info ] [MainThread]: 
14:50:00.666681 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:50:00.670442 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:50:00.716039 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:50:00.716935 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:50:00.717456 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:50:01.963754 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.25 seconds
14:50:01.971014 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:50:02.141361 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:50:02.143338 [info ] [MainThread]: 
14:50:02.149929 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:50:02.150903 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
14:50:02.152177 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:50:02.152778 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:50:02.153834 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:50:02.185775 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:50:02.191039 [debug] [Thread-1  ]: finished collecting timing info
14:50:02.192308 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:50:02.244736 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:50:02.249239 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:50:02.250025 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:50:02.250795 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:03.229882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
14:50:03.235777 [debug] [Thread-1  ]: finished collecting timing info
14:50:03.236899 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:50:03.417943 [error] [Thread-1  ]: 1 of 2 FAIL 1 not_null_my_first_dbt_model_id.................................... [[31mFAIL 1[0m in 1.27s]
14:50:03.422021 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:50:03.424832 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:50:03.428013 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
14:50:03.431015 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:50:03.432761 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:50:03.433873 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:50:03.455291 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:50:03.460771 [debug] [Thread-1  ]: finished collecting timing info
14:50:03.461854 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:50:03.467882 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:50:03.473428 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:50:03.474298 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:50:03.475369 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:04.541015 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
14:50:04.551644 [debug] [Thread-1  ]: finished collecting timing info
14:50:04.552928 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:50:04.714673 [info ] [Thread-1  ]: 2 of 2 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.28s]
14:50:04.719170 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:50:04.755094 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:50:04.756439 [info ] [MainThread]: 
14:50:04.757372 [info ] [MainThread]: Finished running 2 tests in 4.09s.
14:50:04.758771 [debug] [MainThread]: Connection 'master' was properly closed.
14:50:04.760190 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:50:04.779991 [info ] [MainThread]: 
14:50:04.781127 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:50:04.782319 [info ] [MainThread]: 
14:50:04.783533 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
14:50:04.785136 [error] [MainThread]:   Got 1 result, configured to fail if != 0
14:50:04.786516 [info ] [MainThread]: 
14:50:04.788024 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
14:50:04.789318 [info ] [MainThread]: 
14:50:04.790702 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
14:50:04.794399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa367d0b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364b57950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa364b57b10>]}


============================== 2022-01-23 14:51:00.113943 | aab8445b-1874-4ab1-b1c7-ac21103f6a80 ==============================
14:51:00.113943 [info ] [MainThread]: Running with dbt=1.0.1
14:51:00.115203 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:51:00.116157 [debug] [MainThread]: Tracking: tracking
14:51:00.117469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd42d5eedd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd42d5eec50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd42d5eed90>]}
14:51:00.249818 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:51:00.251708 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
14:51:00.290241 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:51:00.329027 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:51:00.426089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aab8445b-1874-4ab1-b1c7-ac21103f6a80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd42d045610>]}
14:51:00.516107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aab8445b-1874-4ab1-b1c7-ac21103f6a80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd42e662290>]}
14:51:00.517411 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:51:00.521306 [info ] [MainThread]: 
14:51:00.523306 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:51:00.526225 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:51:00.577772 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:51:00.578384 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:51:00.578956 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:51:01.764869 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.19 seconds
14:51:01.769782 [debug] [ThreadPool]: On list_analytics: Close
14:51:01.938034 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:51:01.960963 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:51:01.961884 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:51:01.962660 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:51:03.024473 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.06 seconds
14:51:03.028710 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:51:03.204059 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:51:03.206752 [info ] [MainThread]: 
14:51:03.213670 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:51:03.215061 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:51:03.217400 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:51:03.219315 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:51:03.220827 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:51:03.230239 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:51:03.235461 [debug] [Thread-1  ]: finished collecting timing info
14:51:03.236730 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:51:03.325496 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:51:03.334620 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:51:03.335531 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:51:03.336391 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:51:04.621265 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
14:51:04.660898 [debug] [Thread-1  ]: finished collecting timing info
14:51:04.661890 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:51:04.795973 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aab8445b-1874-4ab1-b1c7-ac21103f6a80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd425ef9e10>]}
14:51:04.798915 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.58s]
14:51:04.801180 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:51:04.872463 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:51:04.874112 [info ] [MainThread]: 
14:51:04.875232 [info ] [MainThread]: Finished running 1 table model in 4.35s.
14:51:04.876716 [debug] [MainThread]: Connection 'master' was properly closed.
14:51:04.878300 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:51:04.900921 [info ] [MainThread]: 
14:51:04.902968 [info ] [MainThread]: [32mCompleted successfully[0m
14:51:04.904641 [info ] [MainThread]: 
14:51:04.905981 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:51:04.907335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd42c0f5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43959fc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43959f810>]}


============================== 2022-01-23 14:51:22.477625 | 114c24a8-270e-4ecc-968a-cdcfb69b7cc6 ==============================
14:51:22.477625 [info ] [MainThread]: Running with dbt=1.0.1
14:51:22.479010 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:51:22.479762 [debug] [MainThread]: Tracking: tracking
14:51:22.480882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd08faae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd08faad50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd08faaed0>]}
14:51:22.594254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:51:22.595456 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:51:22.615002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '114c24a8-270e-4ecc-968a-cdcfb69b7cc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd08e896d0>]}
14:51:22.633222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '114c24a8-270e-4ecc-968a-cdcfb69b7cc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd08ff00d0>]}
14:51:22.634170 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:51:22.637766 [info ] [MainThread]: 
14:51:22.639700 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:51:22.643509 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:51:22.683142 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:51:22.684432 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:51:22.685223 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:51:23.925465 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.24 seconds
14:51:23.930202 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:51:24.082941 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:51:24.084312 [info ] [MainThread]: 
14:51:24.091365 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:51:24.092803 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
14:51:24.094924 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:51:24.096667 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:51:24.098033 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:51:24.133889 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:51:24.138226 [debug] [Thread-1  ]: finished collecting timing info
14:51:24.139120 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:51:24.189107 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:51:24.194704 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:51:24.195591 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:51:24.196358 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:51:25.118576 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
14:51:25.135173 [debug] [Thread-1  ]: finished collecting timing info
14:51:25.136670 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:51:25.318206 [info ] [Thread-1  ]: 1 of 2 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.22s]
14:51:25.321089 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:51:25.323482 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:51:25.325452 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
14:51:25.327404 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:51:25.328851 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:51:25.329816 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:51:25.351195 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:51:25.355889 [debug] [Thread-1  ]: finished collecting timing info
14:51:25.357293 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:51:25.362521 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:51:25.368867 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:51:25.369620 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:51:25.370900 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:51:26.447123 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
14:51:26.460419 [debug] [Thread-1  ]: finished collecting timing info
14:51:26.462095 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:51:26.596006 [info ] [Thread-1  ]: 2 of 2 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.27s]
14:51:26.598044 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:51:26.690352 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:51:26.694181 [info ] [MainThread]: 
14:51:26.697180 [info ] [MainThread]: Finished running 2 tests in 4.05s.
14:51:26.700663 [debug] [MainThread]: Connection 'master' was properly closed.
14:51:26.703460 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:51:26.729167 [info ] [MainThread]: 
14:51:26.730352 [info ] [MainThread]: [32mCompleted successfully[0m
14:51:26.731448 [info ] [MainThread]: 
14:51:26.733648 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
14:51:26.735261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd08fc2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd03979d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd03979550>]}


============================== 2022-01-23 14:55:38.424252 | 42e48c18-7d5e-4b47-809b-23ae4a5f46aa ==============================
14:55:38.424252 [info ] [MainThread]: Running with dbt=1.0.1
14:55:38.425985 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:55:38.427005 [debug] [MainThread]: Tracking: tracking
14:55:38.428441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca33becd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca33becc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca33bece10>]}
14:55:38.539002 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:55:38.539870 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:55:38.557568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42e48c18-7d5e-4b47-809b-23ae4a5f46aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca3b3f5b10>]}
14:55:38.576095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42e48c18-7d5e-4b47-809b-23ae4a5f46aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca34c6e1d0>]}
14:55:38.577033 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:55:38.580441 [info ] [MainThread]: 
14:55:38.582666 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:55:38.586256 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:55:38.625630 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:55:38.626711 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:55:38.627683 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:55:39.869525 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.24 seconds
14:55:39.874630 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:55:40.008365 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:55:40.009650 [info ] [MainThread]: 
14:55:40.015057 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:55:40.016009 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
14:55:40.017270 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:55:40.017863 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:55:40.018906 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:55:40.050982 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:55:40.055983 [debug] [Thread-1  ]: finished collecting timing info
14:55:40.057092 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:55:40.110502 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:55:40.115814 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:55:40.116902 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:55:40.117654 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:55:41.192249 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
14:55:41.208530 [debug] [Thread-1  ]: finished collecting timing info
14:55:41.209871 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:55:41.385061 [info ] [Thread-1  ]: 1 of 2 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.37s]
14:55:41.386187 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:55:41.387248 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:55:41.388697 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
14:55:41.390557 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:55:41.394032 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:55:41.394711 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:55:41.419107 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:55:41.423642 [debug] [Thread-1  ]: finished collecting timing info
14:55:41.424807 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:55:41.429837 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:55:41.434602 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:55:41.435497 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:55:41.436494 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:55:42.272394 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
14:55:42.283974 [debug] [Thread-1  ]: finished collecting timing info
14:55:42.285364 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:55:42.457882 [info ] [Thread-1  ]: 2 of 2 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.07s]
14:55:42.459062 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:55:42.527952 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:55:42.529457 [info ] [MainThread]: 
14:55:42.530785 [info ] [MainThread]: Finished running 2 tests in 3.95s.
14:55:42.532589 [debug] [MainThread]: Connection 'master' was properly closed.
14:55:42.534060 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:55:42.562478 [info ] [MainThread]: 
14:55:42.563682 [info ] [MainThread]: [32mCompleted successfully[0m
14:55:42.565158 [info ] [MainThread]: 
14:55:42.567216 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
14:55:42.569047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca326cbd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca3097d510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca30911890>]}


============================== 2022-01-23 14:58:39.783198 | 30d7119e-ba99-4004-b70c-bbf33ddba16d ==============================
14:58:39.783198 [info ] [MainThread]: Running with dbt=1.0.1
14:58:39.784725 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
14:58:39.785585 [debug] [MainThread]: Tracking: tracking
14:58:39.786784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d84fae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d84fad50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d84faed0>]}
14:58:39.903143 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
14:58:39.904819 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
14:58:39.945144 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:58:39.983656 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:58:39.986834 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:58:40.190351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30d7119e-ba99-4004-b70c-bbf33ddba16d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d85b4d90>]}
14:58:40.209454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30d7119e-ba99-4004-b70c-bbf33ddba16d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d8526cd0>]}
14:58:40.210472 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:58:40.214037 [info ] [MainThread]: 
14:58:40.215921 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:58:40.219445 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:58:40.261369 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:58:40.262348 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:58:40.262919 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:58:41.488583 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.23 seconds
14:58:41.494052 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:58:41.670883 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:58:41.673298 [info ] [MainThread]: 
14:58:41.691943 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8
14:58:41.692992 [info ] [Thread-1  ]: 1 of 3 START test accepted_values_my_first_dbt_model_id__False__1__2............ [RUN]
14:58:41.695942 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8"
14:58:41.697347 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8
14:58:41.698615 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8
14:58:41.709148 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8"
14:58:41.718213 [debug] [Thread-1  ]: finished collecting timing info
14:58:41.719145 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8
14:58:41.770105 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8"
14:58:41.777922 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8"
14:58:41.779006 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        id as value_field,
        count(*) as n_records

    from analytics.dbt.first_model
    group by id

)

select *
from all_values
where value_field not in (
    1,2
)



      
    ) dbt_internal_test
14:58:41.779673 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:58:43.034659 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.25 seconds
14:58:43.043962 [debug] [Thread-1  ]: finished collecting timing info
14:58:43.045007 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8: Close
14:58:43.203391 [error] [Thread-1  ]: 1 of 3 FAIL 1 accepted_values_my_first_dbt_model_id__False__1__2................ [[31mFAIL 1[0m in 1.51s]
14:58:43.204790 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8
14:58:43.206047 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:58:43.207488 [info ] [Thread-1  ]: 2 of 3 START test not_null_my_first_dbt_model_id................................ [RUN]
14:58:43.209871 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:58:43.210966 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:58:43.211929 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:58:43.234773 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:58:43.239061 [debug] [Thread-1  ]: finished collecting timing info
14:58:43.240125 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:58:43.246285 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:58:43.252112 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
14:58:43.252833 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
14:58:43.253797 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:58:44.083941 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
14:58:44.087687 [debug] [Thread-1  ]: finished collecting timing info
14:58:44.088619 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
14:58:44.270878 [info ] [Thread-1  ]: 2 of 3 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.06s]
14:58:44.274713 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
14:58:44.277229 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:58:44.279984 [info ] [Thread-1  ]: 3 of 3 START test unique_my_first_dbt_model_id.................................. [RUN]
14:58:44.282424 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:58:44.283791 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:58:44.285157 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:58:44.307465 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:58:44.313905 [debug] [Thread-1  ]: finished collecting timing info
14:58:44.314986 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:58:44.320342 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:58:44.336912 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
14:58:44.337936 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
14:58:44.338717 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:58:45.259056 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
14:58:45.264388 [debug] [Thread-1  ]: finished collecting timing info
14:58:45.265263 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
14:58:45.408818 [info ] [Thread-1  ]: 3 of 3 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.13s]
14:58:45.410940 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
14:58:45.438181 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:58:45.441136 [info ] [MainThread]: 
14:58:45.443822 [info ] [MainThread]: Finished running 3 tests in 5.23s.
14:58:45.446667 [debug] [MainThread]: Connection 'master' was properly closed.
14:58:45.448258 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
14:58:45.471805 [info ] [MainThread]: 
14:58:45.473114 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
14:58:45.474850 [info ] [MainThread]: 
14:58:45.477404 [error] [MainThread]: [31mFailure in test accepted_values_my_first_dbt_model_id__False__1__2 (models/example/schema.yml)[0m
14:58:45.479233 [error] [MainThread]:   Got 1 result, configured to fail if != 0
14:58:45.480450 [info ] [MainThread]: 
14:58:45.481993 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/accepted_values_my_first_dbt_model_id__False__1__2.sql
14:58:45.483164 [info ] [MainThread]: 
14:58:45.484273 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
14:58:45.485883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93dad3e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d5b1f750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93d5b1fdd0>]}


============================== 2022-01-23 15:00:45.490902 | 666f3c58-2811-4552-a66a-14d2e5f1c3ab ==============================
15:00:45.490902 [info ] [MainThread]: Running with dbt=1.0.1
15:00:45.492078 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
15:00:45.492807 [debug] [MainThread]: Tracking: tracking
15:00:45.493481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb3cc3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb3cc3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb3cc3e10>]}
15:00:45.606747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:00:45.608305 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:00:45.642242 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:00:45.680641 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:00:45.769839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '666f3c58-2811-4552-a66a-14d2e5f1c3ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb2755190>]}
15:00:45.852176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '666f3c58-2811-4552-a66a-14d2e5f1c3ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb6524e90>]}
15:00:45.853343 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:00:45.856756 [info ] [MainThread]: 
15:00:45.858815 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:00:45.862362 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:00:45.901107 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:00:45.901935 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:00:45.902442 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:00:47.162402 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.26 seconds
15:00:47.167762 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:00:47.348738 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:00:47.351272 [info ] [MainThread]: 
15:00:47.360100 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:00:47.361394 [info ] [Thread-1  ]: 1 of 2 START test not_null_my_first_dbt_model_id................................ [RUN]
15:00:47.363174 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:00:47.364159 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:00:47.365494 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:00:47.400124 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:00:47.405232 [debug] [Thread-1  ]: finished collecting timing info
15:00:47.406624 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:00:47.455520 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:00:47.460445 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:00:47.461355 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
15:00:47.462034 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:48.437500 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
15:00:48.443318 [debug] [Thread-1  ]: finished collecting timing info
15:00:48.444177 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
15:00:48.588487 [info ] [Thread-1  ]: 1 of 2 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.23s]
15:00:48.591391 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:00:48.593779 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:00:48.596227 [info ] [Thread-1  ]: 2 of 2 START test unique_my_first_dbt_model_id.................................. [RUN]
15:00:48.598196 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:00:48.599419 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:00:48.600766 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:00:48.623529 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:00:48.628364 [debug] [Thread-1  ]: finished collecting timing info
15:00:48.629427 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:00:48.634262 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:00:48.640042 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:00:48.640977 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:00:48.642137 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:49.473807 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
15:00:49.480061 [debug] [Thread-1  ]: finished collecting timing info
15:00:49.481301 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
15:00:49.627413 [info ] [Thread-1  ]: 2 of 2 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.03s]
15:00:49.630449 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:00:49.653966 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:00:49.661680 [info ] [MainThread]: 
15:00:49.665124 [info ] [MainThread]: Finished running 2 tests in 3.80s.
15:00:49.666410 [debug] [MainThread]: Connection 'master' was properly closed.
15:00:49.667255 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
15:00:49.689255 [info ] [MainThread]: 
15:00:49.690918 [info ] [MainThread]: [32mCompleted successfully[0m
15:00:49.693137 [info ] [MainThread]: 
15:00:49.695131 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
15:00:49.696899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb1417490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb05c8b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeb05c8210>]}


============================== 2022-01-23 15:13:31.778403 | bb0f5e64-8028-4f4d-9041-9000dfba8a62 ==============================
15:13:31.778403 [info ] [MainThread]: Running with dbt=1.0.1
15:13:31.779854 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:13:31.780476 [debug] [MainThread]: Tracking: tracking
15:13:31.782134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670d7aed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670d7ae750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670d7aed50>]}
15:13:31.890189 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
15:13:31.892199 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:13:31.893273 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_second_dbt_model.sql
15:13:31.927869 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:13:32.106879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670d204a10>]}
15:13:32.183462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670e846290>]}
15:13:32.184343 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:13:32.188253 [info ] [MainThread]: 
15:13:32.190197 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:13:32.195060 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:13:32.251355 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:13:32.252339 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:13:32.252914 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:13:33.716839 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.46 seconds
15:13:33.721386 [debug] [ThreadPool]: On list_analytics: Close
15:13:33.854726 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:13:33.874504 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:13:33.875547 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:13:33.876350 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:13:34.932507 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.06 seconds
15:13:34.944624 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:13:35.109607 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:13:35.110919 [info ] [MainThread]: 
15:13:35.116241 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:13:35.117373 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:13:35.118777 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:13:35.119436 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:13:35.120195 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:13:35.128897 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:13:35.135030 [debug] [Thread-1  ]: finished collecting timing info
15:13:35.135972 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:13:35.222170 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:13:35.228197 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:13:35.228964 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
15:13:35.229553 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:37.323688 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
15:13:37.367403 [debug] [Thread-1  ]: finished collecting timing info
15:13:37.368422 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:13:37.548319 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67078b8e90>]}
15:13:37.550888 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.43s]
15:13:37.553387 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:13:37.555943 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:13:37.559321 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
15:13:37.561143 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:13:37.562445 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:13:37.563778 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:13:37.594188 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:13:37.598273 [debug] [Thread-1  ]: finished collecting timing info
15:13:37.599306 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:13:37.680917 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:37.681766 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
15:13:37.682323 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:39.270384 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
15:13:39.305775 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:39.306555 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:13:39.422657 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:13:39.447894 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:39.448565 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
15:13:39.557498 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:13:39.593165 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:39.594197 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:13:39.696125 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:13:39.783820 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:13:39.795038 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:39.795934 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
15:13:39.939232 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
15:13:39.941514 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:39.942516 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:13:40.300820 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
15:13:40.302384 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:13:40.303430 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
15:13:40.472288 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
15:13:40.480431 [debug] [Thread-1  ]: finished collecting timing info
15:13:40.481704 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:13:40.660382 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670c0cd590>]}
15:13:40.663433 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.10s]
15:13:40.665592 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:13:40.667420 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:13:40.669766 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
15:13:40.672545 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:13:40.673726 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:13:40.674898 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:13:40.684600 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:13:40.690018 [debug] [Thread-1  ]: finished collecting timing info
15:13:40.691716 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:13:40.704861 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:40.706029 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:13:40.706616 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:42.619168 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
15:13:42.630255 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:42.631272 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:13:42.757255 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
15:13:42.770695 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:42.771741 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:13:42.868443 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:13:42.883862 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:42.884831 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:13:42.979613 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
15:13:42.991284 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:13:42.998504 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:42.999281 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
15:13:43.120227 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
15:13:43.122255 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:43.123844 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:13:43.720366 [debug] [Thread-1  ]: SQL status: SUCCESS 4272 in 0.6 seconds
15:13:43.723001 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:13:43.724666 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
15:13:43.978331 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
15:13:43.986580 [debug] [Thread-1  ]: finished collecting timing info
15:13:43.988085 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:13:44.169859 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6706037c10>]}
15:13:44.171120 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.50s]
15:13:44.172134 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:13:44.173069 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:13:44.174645 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
15:13:44.175870 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:13:44.181564 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:13:44.182201 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:13:44.191903 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:13:44.196093 [debug] [Thread-1  ]: finished collecting timing info
15:13:44.197081 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:13:44.203458 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:13:44.209860 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:13:44.210632 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
where id is not null
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:13:44.211408 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:45.914966 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
15:13:45.925101 [debug] [Thread-1  ]: finished collecting timing info
15:13:45.926460 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:13:46.093731 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6706011c90>]}
15:13:46.095885 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.92s]
15:13:46.098192 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:13:46.099878 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:13:46.102936 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:13:46.104969 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:13:46.106006 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:13:46.107344 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:13:46.114614 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:13:46.118498 [debug] [Thread-1  ]: finished collecting timing info
15:13:46.119955 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:13:46.127327 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:13:46.132895 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:13:46.133669 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:13:46.134349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:48.129674 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
15:13:48.133264 [debug] [Thread-1  ]: finished collecting timing info
15:13:48.133985 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:13:48.386130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670602a250>]}
15:13:48.387257 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.28s]
15:13:48.388293 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:13:48.389323 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:13:48.391072 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
15:13:48.392605 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:13:48.394183 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:13:48.395815 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:13:48.405299 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:13:48.411371 [debug] [Thread-1  ]: finished collecting timing info
15:13:48.412818 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:13:48.420647 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:13:48.427645 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:13:48.428721 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
15:13:48.429623 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:50.078460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
15:13:50.084162 [debug] [Thread-1  ]: finished collecting timing info
15:13:50.085069 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:13:50.206215 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb0f5e64-8028-4f4d-9041-9000dfba8a62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67078dac50>]}
15:13:50.207280 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.81s]
15:13:50.208276 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:13:50.218094 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:13:50.220210 [info ] [MainThread]: 
15:13:50.221906 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 18.03s.
15:13:50.223499 [debug] [MainThread]: Connection 'master' was properly closed.
15:13:50.224425 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:13:50.245722 [info ] [MainThread]: 
15:13:50.246833 [info ] [MainThread]: [32mCompleted successfully[0m
15:13:50.248239 [info ] [MainThread]: 
15:13:50.249955 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
15:13:50.253477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670d7bdf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670604ae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670604aa90>]}


============================== 2022-01-23 15:14:47.266619 | e887fb4a-19d9-496e-add9-58a68ee8c5da ==============================
15:14:47.266619 [info ] [MainThread]: Running with dbt=1.0.1
15:14:47.267924 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
15:14:47.268903 [debug] [MainThread]: Tracking: tracking
15:14:47.270278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e3aef0e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e3aef0c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e3aef0dd0>]}
15:14:47.376724 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:14:47.377487 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:14:47.394759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e887fb4a-19d9-496e-add9-58a68ee8c5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e39dd4190>]}
15:14:47.413210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e887fb4a-19d9-496e-add9-58a68ee8c5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e3ae63a10>]}
15:14:47.414227 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:14:47.418970 [info ] [MainThread]: 
15:14:47.421198 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:14:47.426145 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:14:47.465070 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:14:47.465952 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:14:47.466779 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:14:48.631066 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.16 seconds
15:14:48.636029 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:14:48.785386 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:14:48.787340 [info ] [MainThread]: 
15:14:48.796328 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9
15:14:48.797303 [info ] [Thread-1  ]: 1 of 9 START test not_null_cumulative_orders_by_date_o_orderdate................ [RUN]
15:14:48.798963 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9"
15:14:48.799818 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9
15:14:48.801108 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9
15:14:48.837365 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9"
15:14:48.841693 [debug] [Thread-1  ]: finished collecting timing info
15:14:48.842801 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9
15:14:48.893282 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9"
15:14:48.898202 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9"
15:14:48.898859 [debug] [Thread-1  ]: On test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.cumulative_orders_by_date
where o_orderdate is null



      
    ) dbt_internal_test
15:14:48.899616 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:49.700074 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1d2f2-0000-1e54-0000-000298a260f1
15:14:49.701316 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 12 at position 6
invalid identifier 'O_ORDERDATE'
15:14:49.702856 [debug] [Thread-1  ]: finished collecting timing info
15:14:49.703894 [debug] [Thread-1  ]: On test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9: Close
15:14:49.843389 [debug] [Thread-1  ]: Database Error in test not_null_cumulative_orders_by_date_o_orderdate (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 12 at position 6
  invalid identifier 'O_ORDERDATE'
  compiled SQL at target/run/dbt_tests/models/example/schema.yml/not_null_cumulative_orders_by_date_o_orderdate.sql
15:14:49.845850 [error] [Thread-1  ]: 1 of 9 ERROR not_null_cumulative_orders_by_date_o_orderdate..................... [[31mERROR[0m in 1.05s]
15:14:49.848820 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_cumulative_orders_by_date_o_orderdate.848bc80ab9
15:14:49.851098 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:14:49.854580 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_first_dbt_model_id................................ [RUN]
15:14:49.858701 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:14:49.861427 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:14:49.863353 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:14:49.879288 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:14:49.884636 [debug] [Thread-1  ]: finished collecting timing info
15:14:49.885770 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:14:49.891824 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:14:49.897601 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:14:49.898666 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
15:14:49.899617 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:50.989762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
15:14:51.003465 [debug] [Thread-1  ]: finished collecting timing info
15:14:51.004989 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
15:14:51.171395 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.31s]
15:14:51.172790 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:14:51.173832 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:14:51.175109 [info ] [Thread-1  ]: 3 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
15:14:51.176410 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:14:51.177178 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:14:51.178145 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:14:51.187103 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:14:51.192129 [debug] [Thread-1  ]: finished collecting timing info
15:14:51.193769 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:14:51.199332 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:14:51.204796 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:14:51.205727 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
15:14:51.206578 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:52.128542 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
15:14:52.141347 [debug] [Thread-1  ]: finished collecting timing info
15:14:52.142669 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: Close
15:14:52.309212 [info ] [Thread-1  ]: 3 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.13s]
15:14:52.310457 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:14:52.311466 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:14:52.312918 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
15:14:52.314480 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:14:52.315422 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:14:52.316291 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:14:52.328207 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:14:52.332077 [debug] [Thread-1  ]: finished collecting timing info
15:14:52.332890 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:14:52.338137 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:14:52.343637 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:14:52.344437 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
15:14:52.345178 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:53.200211 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
15:14:53.206749 [debug] [Thread-1  ]: finished collecting timing info
15:14:53.207938 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
15:14:53.343486 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.03s]
15:14:53.344664 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:14:53.345722 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:14:53.347024 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
15:14:53.348337 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:14:53.349217 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:14:53.350201 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:14:53.374809 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:14:53.379589 [debug] [Thread-1  ]: finished collecting timing info
15:14:53.380482 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:14:53.385595 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:14:53.392352 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:14:53.393109 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
15:14:53.393595 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:54.478047 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
15:14:54.483549 [debug] [Thread-1  ]: finished collecting timing info
15:14:54.484757 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
15:14:54.660863 [error] [Thread-1  ]: 5 of 9 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.31s]
15:14:54.663888 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:14:54.665989 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282
15:14:54.668270 [info ] [Thread-1  ]: 6 of 9 START test unique_cumulative_orders_by_date_o_orderdate.................. [RUN]
15:14:54.670620 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282"
15:14:54.672643 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282
15:14:54.673919 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282
15:14:54.694841 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282"
15:14:54.699319 [debug] [Thread-1  ]: finished collecting timing info
15:14:54.700250 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282
15:14:54.705058 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282"
15:14:54.711285 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282"
15:14:54.712153 [debug] [Thread-1  ]: On test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.cumulative_orders_by_date
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
15:14:54.712940 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:55.576848 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1d2f2-0000-1e54-0000-000298a260fd
15:14:55.577951 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 11 at position 4
invalid identifier 'O_ORDERDATE'
15:14:55.578971 [debug] [Thread-1  ]: finished collecting timing info
15:14:55.579992 [debug] [Thread-1  ]: On test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282: Close
15:14:55.748751 [debug] [Thread-1  ]: Database Error in test unique_cumulative_orders_by_date_o_orderdate (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 11 at position 4
  invalid identifier 'O_ORDERDATE'
  compiled SQL at target/run/dbt_tests/models/example/schema.yml/unique_cumulative_orders_by_date_o_orderdate.sql
15:14:55.750483 [error] [Thread-1  ]: 6 of 9 ERROR unique_cumulative_orders_by_date_o_orderdate....................... [[31mERROR[0m in 1.08s]
15:14:55.752773 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_cumulative_orders_by_date_o_orderdate.0cbe7e8282
15:14:55.755271 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:14:55.757228 [info ] [Thread-1  ]: 7 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
15:14:55.758710 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:14:55.760086 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:14:55.760971 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:14:55.772205 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:14:55.777142 [debug] [Thread-1  ]: finished collecting timing info
15:14:55.777985 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:14:55.783303 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:14:55.790591 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:14:55.791416 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:14:55.792334 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:56.723506 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
15:14:56.734818 [debug] [Thread-1  ]: finished collecting timing info
15:14:56.736304 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
15:14:56.901754 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.14s]
15:14:56.904595 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:14:56.906998 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:14:56.908755 [info ] [Thread-1  ]: 8 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
15:14:56.910976 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:14:56.912116 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:14:56.913153 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:14:56.926150 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:14:56.930431 [debug] [Thread-1  ]: finished collecting timing info
15:14:56.931313 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:14:56.935946 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:14:56.941742 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:14:56.943157 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:14:56.943987 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:57.787285 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
15:14:57.798136 [debug] [Thread-1  ]: finished collecting timing info
15:14:57.799537 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
15:14:57.956302 [info ] [Thread-1  ]: 8 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.05s]
15:14:57.957362 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:14:57.958298 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:14:57.959555 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
15:14:57.961205 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:14:57.962150 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:14:57.962989 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:14:57.975060 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:14:57.978566 [debug] [Thread-1  ]: finished collecting timing info
15:14:57.979413 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:14:57.984286 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:14:57.991383 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:14:57.992229 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
15:14:57.992650 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:14:59.088011 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
15:14:59.091760 [debug] [Thread-1  ]: finished collecting timing info
15:14:59.092640 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
15:14:59.252644 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.29s]
15:14:59.255961 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:14:59.263999 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:14:59.265889 [info ] [MainThread]: 
15:14:59.267540 [info ] [MainThread]: Finished running 9 tests in 11.85s.
15:14:59.269439 [debug] [MainThread]: Connection 'master' was properly closed.
15:14:59.271350 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
15:14:59.292050 [info ] [MainThread]: 
15:14:59.293459 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
15:14:59.294885 [info ] [MainThread]: 
15:14:59.296155 [error] [MainThread]: [33mDatabase Error in test not_null_cumulative_orders_by_date_o_orderdate (models/example/schema.yml)[0m
15:14:59.297352 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 12 at position 6
15:14:59.298863 [error] [MainThread]:   invalid identifier 'O_ORDERDATE'
15:14:59.299859 [error] [MainThread]:   compiled SQL at target/run/dbt_tests/models/example/schema.yml/not_null_cumulative_orders_by_date_o_orderdate.sql
15:14:59.301344 [info ] [MainThread]: 
15:14:59.303699 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
15:14:59.305815 [error] [MainThread]:   Got 1 result, configured to fail if != 0
15:14:59.307635 [info ] [MainThread]: 
15:14:59.308818 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
15:14:59.310189 [info ] [MainThread]: 
15:14:59.311422 [error] [MainThread]: [33mDatabase Error in test unique_cumulative_orders_by_date_o_orderdate (models/example/schema.yml)[0m
15:14:59.312689 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 11 at position 4
15:14:59.313980 [error] [MainThread]:   invalid identifier 'O_ORDERDATE'
15:14:59.315191 [error] [MainThread]:   compiled SQL at target/run/dbt_tests/models/example/schema.yml/unique_cumulative_orders_by_date_o_orderdate.sql
15:14:59.316363 [info ] [MainThread]: 
15:14:59.317438 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=3 SKIP=0 TOTAL=9
15:14:59.320569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e3aeb0550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e383754d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e38375c50>]}


============================== 2022-01-23 15:16:07.464366 | ad8b18be-5c2c-497b-8d80-e48b79ecfd8a ==============================
15:16:07.464366 [info ] [MainThread]: Running with dbt=1.0.1
15:16:07.465835 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
15:16:07.466645 [debug] [MainThread]: Tracking: tracking
15:16:07.467853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66ebf1c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66ebf1a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66ebf1cd0>]}
15:16:07.576076 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:16:07.577356 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:16:07.611975 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
15:16:07.694218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad8b18be-5c2c-497b-8d80-e48b79ecfd8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66e6b5310>]}
15:16:07.713708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad8b18be-5c2c-497b-8d80-e48b79ecfd8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66e6d3a90>]}
15:16:07.714738 [info ] [MainThread]: Found 6 models, 7 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:16:07.719124 [info ] [MainThread]: 
15:16:07.721127 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:16:07.724925 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:16:07.824871 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:16:07.825574 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:16:07.826239 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:16:09.080699 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.25 seconds
15:16:09.088201 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:16:09.269374 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:16:09.273222 [info ] [MainThread]: 
15:16:09.283723 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:16:09.285219 [info ] [Thread-1  ]: 1 of 7 START test not_null_my_first_dbt_model_id................................ [RUN]
15:16:09.288224 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:16:09.289774 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:16:09.291133 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:16:09.323486 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:16:09.329031 [debug] [Thread-1  ]: finished collecting timing info
15:16:09.329921 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:16:09.378612 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:16:09.383670 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
15:16:09.384437 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
15:16:09.385311 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:10.138467 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.75 seconds
15:16:10.153305 [debug] [Thread-1  ]: finished collecting timing info
15:16:10.154775 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
15:16:10.297783 [info ] [Thread-1  ]: 1 of 7 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.01s]
15:16:10.301294 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
15:16:10.303371 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:16:10.306196 [info ] [Thread-1  ]: 2 of 7 START test not_null_my_second_dbt_model_id............................... [RUN]
15:16:10.308521 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:16:10.309833 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:16:10.311114 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:16:10.332866 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:16:10.336815 [debug] [Thread-1  ]: finished collecting timing info
15:16:10.338017 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:16:10.345333 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:16:10.350410 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
15:16:10.351484 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
15:16:10.352197 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:11.363815 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
15:16:11.368293 [debug] [Thread-1  ]: finished collecting timing info
15:16:11.369157 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: Close
15:16:11.533331 [info ] [Thread-1  ]: 2 of 7 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.23s]
15:16:11.535897 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
15:16:11.538553 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:16:11.540832 [info ] [Thread-1  ]: 3 of 7 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
15:16:11.542855 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:16:11.544125 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:16:11.545358 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:16:11.556477 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:16:11.561336 [debug] [Thread-1  ]: finished collecting timing info
15:16:11.562410 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:16:11.566881 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:16:11.572562 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:16:11.573356 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
15:16:11.573907 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:12.399824 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
15:16:12.405176 [debug] [Thread-1  ]: finished collecting timing info
15:16:12.406377 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
15:16:12.569300 [info ] [Thread-1  ]: 3 of 7 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.03s]
15:16:12.571438 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:16:12.573261 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:16:12.575560 [info ] [Thread-1  ]: 4 of 7 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
15:16:12.578456 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:16:12.580172 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:16:12.581922 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:16:12.615367 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:16:12.621084 [debug] [Thread-1  ]: finished collecting timing info
15:16:12.622613 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:16:12.627609 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:16:12.635300 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:16:12.636624 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
15:16:12.637695 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:13.708217 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
15:16:13.713287 [debug] [Thread-1  ]: finished collecting timing info
15:16:13.714203 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
15:16:13.890278 [error] [Thread-1  ]: 4 of 7 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.31s]
15:16:13.894395 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:16:13.898536 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:16:13.905629 [info ] [Thread-1  ]: 5 of 7 START test unique_my_first_dbt_model_id.................................. [RUN]
15:16:13.937868 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:16:13.939047 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:16:13.940291 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:16:13.992132 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:16:13.999701 [debug] [Thread-1  ]: finished collecting timing info
15:16:14.001783 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:16:14.008836 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:16:14.013821 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:16:14.014472 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:16:14.014956 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:14.938174 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
15:16:14.943892 [debug] [Thread-1  ]: finished collecting timing info
15:16:14.944915 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
15:16:15.133091 [info ] [Thread-1  ]: 5 of 7 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.21s]
15:16:15.134472 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:16:15.135706 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:16:15.136883 [info ] [Thread-1  ]: 6 of 7 START test unique_my_second_dbt_model_id................................. [RUN]
15:16:15.138457 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:16:15.139333 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:16:15.140252 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:16:15.150221 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:16:15.155194 [debug] [Thread-1  ]: finished collecting timing info
15:16:15.156184 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:16:15.161097 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:16:15.166263 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
15:16:15.167261 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:16:15.168227 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:15.909829 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
15:16:15.921845 [debug] [Thread-1  ]: finished collecting timing info
15:16:15.923719 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
15:16:16.061156 [info ] [Thread-1  ]: 6 of 7 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 0.92s]
15:16:16.063420 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
15:16:16.064979 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:16:16.066578 [info ] [Thread-1  ]: 7 of 7 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
15:16:16.068833 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:16:16.070148 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:16:16.071464 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:16:16.081642 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:16:16.087126 [debug] [Thread-1  ]: finished collecting timing info
15:16:16.088076 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:16:16.093527 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:16:16.099743 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:16:16.100676 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
15:16:16.101673 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:16.949292 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
15:16:16.962376 [debug] [Thread-1  ]: finished collecting timing info
15:16:16.963670 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
15:16:17.102332 [info ] [Thread-1  ]: 7 of 7 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.03s]
15:16:17.104339 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:16:17.155541 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:16:17.157060 [info ] [MainThread]: 
15:16:17.158268 [info ] [MainThread]: Finished running 7 tests in 9.44s.
15:16:17.159683 [debug] [MainThread]: Connection 'master' was properly closed.
15:16:17.160808 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
15:16:17.179705 [info ] [MainThread]: 
15:16:17.180995 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:16:17.182338 [info ] [MainThread]: 
15:16:17.184068 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
15:16:17.186426 [error] [MainThread]:   Got 1 result, configured to fail if != 0
15:16:17.187810 [info ] [MainThread]: 
15:16:17.189222 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
15:16:17.190524 [info ] [MainThread]: 
15:16:17.191945 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
15:16:17.193326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66fcce150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66c51c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff66c51c850>]}


============================== 2022-01-23 15:26:43.714299 | b3c942b2-721d-449d-b9b8-1f192d369f63 ==============================
15:26:43.714299 [info ] [MainThread]: Running with dbt=1.0.1
15:26:43.715442 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
15:26:43.715987 [debug] [MainThread]: Tracking: tracking
15:26:43.716768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b80be8dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b80be8e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b80be8f90>]}
15:26:43.826497 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
15:26:43.827643 [debug] [MainThread]: Partial parsing: added file: dbt_tests://tests/assert_under_10_percent_null.sql
15:26:43.828682 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:26:43.863647 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:26:43.904460 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:26:44.077104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3c942b2-721d-449d-b9b8-1f192d369f63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b81ceaf50>]}
15:26:44.094813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3c942b2-721d-449d-b9b8-1f192d369f63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b81c5d310>]}
15:26:44.095843 [info ] [MainThread]: Found 6 models, 7 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:26:44.099015 [info ] [MainThread]: 
15:26:44.101145 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:26:44.105925 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:26:44.163733 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:26:44.164783 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:26:44.165547 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:26:45.676982 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.51 seconds
15:26:45.681738 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:26:45.815791 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:26:45.818412 [info ] [MainThread]: 
15:26:45.826236 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
15:26:45.827319 [info ] [Thread-1  ]: 1 of 3 START test assert_under_10_percent_null.................................. [RUN]
15:26:45.828820 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
15:26:45.833139 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
15:26:45.834516 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
15:26:45.842648 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
15:26:45.848879 [debug] [Thread-1  ]: finished collecting timing info
15:26:45.850150 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
15:26:45.902582 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
15:26:45.910044 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
15:26:45.911004 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
15:26:45.911882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:26:47.761675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.85 seconds
15:26:47.778394 [debug] [Thread-1  ]: finished collecting timing info
15:26:47.779834 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
15:26:47.904789 [info ] [Thread-1  ]: 1 of 3 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 2.08s]
15:26:47.907741 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
15:26:47.909693 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:26:47.912331 [info ] [Thread-1  ]: 2 of 3 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
15:26:47.914685 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:26:47.916051 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:26:47.917544 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:26:47.953852 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:26:47.959268 [debug] [Thread-1  ]: finished collecting timing info
15:26:47.960454 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:26:47.966434 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:26:47.973168 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:26:47.974269 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
15:26:47.975043 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:26:48.904050 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
15:26:48.909740 [debug] [Thread-1  ]: finished collecting timing info
15:26:48.911020 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
15:26:49.043595 [error] [Thread-1  ]: 2 of 3 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.13s]
15:26:49.045079 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:26:49.046381 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:26:49.047927 [info ] [Thread-1  ]: 3 of 3 START test unique_my_first_dbt_model_id.................................. [RUN]
15:26:49.050068 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:26:49.051003 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:26:49.051857 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:26:49.075614 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:26:49.079884 [debug] [Thread-1  ]: finished collecting timing info
15:26:49.080947 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:26:49.089035 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:26:49.095293 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:26:49.096227 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:26:49.096960 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:26:49.975187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
15:26:49.982930 [debug] [Thread-1  ]: finished collecting timing info
15:26:49.984563 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
15:26:50.168101 [info ] [Thread-1  ]: 3 of 3 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.12s]
15:26:50.169269 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:26:50.250002 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:26:50.251134 [info ] [MainThread]: 
15:26:50.251988 [info ] [MainThread]: Finished running 3 tests in 6.15s.
15:26:50.253247 [debug] [MainThread]: Connection 'master' was properly closed.
15:26:50.254688 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
15:26:50.274475 [info ] [MainThread]: 
15:26:50.275567 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:26:50.277122 [info ] [MainThread]: 
15:26:50.278387 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
15:26:50.279837 [error] [MainThread]:   Got 1 result, configured to fail if != 0
15:26:50.281205 [info ] [MainThread]: 
15:26:50.283985 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
15:26:50.285914 [info ] [MainThread]: 
15:26:50.287678 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
15:26:50.289097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b81c57e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b714fcc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b714fc950>]}


============================== 2022-01-23 15:28:03.994239 | c92caeac-4b7e-4ba7-a679-e7510cd3c041 ==============================
15:28:03.994239 [info ] [MainThread]: Running with dbt=1.0.1
15:28:03.995738 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:28:03.996581 [debug] [MainThread]: Tracking: tracking
15:28:03.998019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb887130dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb887130c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb887130d90>]}
15:28:04.103915 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
15:28:04.105094 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_second_dbt_model.sql
15:28:04.105989 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
15:28:04.140116 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:28:04.173897 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:28:04.185278 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:28:04.374942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8871ad7d0>]}
15:28:04.392831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8870e6410>]}
15:28:04.393978 [info ] [MainThread]: Found 6 models, 7 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:28:04.398494 [info ] [MainThread]: 
15:28:04.401052 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:28:04.404208 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:28:04.445463 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:28:04.446412 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:28:04.446955 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:28:05.759532 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.31 seconds
15:28:05.764387 [debug] [ThreadPool]: On list_analytics: Close
15:28:05.917018 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:28:05.941502 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:28:05.942448 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:28:05.943205 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:28:06.721263 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.78 seconds
15:28:06.733084 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:28:06.981419 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:28:06.984882 [info ] [MainThread]: 
15:28:06.992481 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:28:06.993738 [info ] [Thread-1  ]: 1 of 6 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:28:06.995689 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:28:06.997271 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:28:06.999263 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:28:07.007983 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:28:07.012407 [debug] [Thread-1  ]: finished collecting timing info
15:28:07.013743 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:28:07.099507 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:28:07.105668 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:28:07.106685 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
15:28:07.107361 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:09.097234 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
15:28:09.134353 [debug] [Thread-1  ]: finished collecting timing info
15:28:09.135627 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:28:09.305413 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8846e2bd0>]}
15:28:09.309311 [info ] [Thread-1  ]: 1 of 6 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.31s]
15:28:09.311824 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:28:09.314128 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:28:09.316796 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.dates........................................ [RUN]
15:28:09.318629 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:28:09.319873 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:28:09.320988 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:28:09.351918 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:28:09.355934 [debug] [Thread-1  ]: finished collecting timing info
15:28:09.356705 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:28:09.447771 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:09.448614 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
15:28:09.449149 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:10.808929 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
15:28:10.846876 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:10.847704 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:28:10.959364 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:28:10.987726 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:10.988587 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
15:28:11.117022 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
15:28:11.153126 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:11.153953 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:28:11.256855 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:28:11.342442 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:28:11.353871 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:11.354643 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
15:28:11.470300 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
15:28:11.471606 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:11.472455 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:28:11.853458 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.38 seconds
15:28:11.856126 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:28:11.858289 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
15:28:12.069516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
15:28:12.078241 [debug] [Thread-1  ]: finished collecting timing info
15:28:12.079584 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:28:12.262311 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8841c2ad0>]}
15:28:12.263910 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.94s]
15:28:12.265312 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:28:12.266733 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:28:12.268475 [info ] [Thread-1  ]: 3 of 6 START incremental model dbt.incremental_time............................. [RUN]
15:28:12.269976 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:28:12.271028 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:28:12.271962 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:28:12.282241 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:28:12.286951 [debug] [Thread-1  ]: finished collecting timing info
15:28:12.287994 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:28:12.297038 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:12.298297 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:28:12.299337 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:16.095017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.8 seconds
15:28:16.109993 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:16.111068 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:28:16.197630 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
15:28:16.206421 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:16.207484 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:28:16.287854 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
15:28:16.313062 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:16.314486 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:28:16.395337 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
15:28:16.412186 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:28:16.421249 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:16.422352 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
15:28:16.533219 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
15:28:16.536779 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:16.538562 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:28:17.136990 [debug] [Thread-1  ]: SQL status: SUCCESS 872 in 0.6 seconds
15:28:17.140426 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:28:17.142609 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
15:28:17.385292 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
15:28:17.399425 [debug] [Thread-1  ]: finished collecting timing info
15:28:17.401709 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:28:17.532695 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8841e4350>]}
15:28:17.534701 [info ] [Thread-1  ]: 3 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.26s]
15:28:17.536623 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:28:17.537887 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:28:17.539958 [info ] [Thread-1  ]: 4 of 6 START table model dbt.first_model........................................ [RUN]
15:28:17.541790 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:28:17.543274 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:28:17.544859 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:28:17.553650 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:28:17.557808 [debug] [Thread-1  ]: finished collecting timing info
15:28:17.558892 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:28:17.565657 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:28:17.571845 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:28:17.572773 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:28:17.573643 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:19.085136 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
15:28:19.089813 [debug] [Thread-1  ]: finished collecting timing info
15:28:19.090899 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:28:19.269732 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88414dcd0>]}
15:28:19.272562 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.73s]
15:28:19.275274 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:28:19.277302 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:28:19.279907 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:28:19.281659 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:28:19.282758 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:28:19.283903 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:28:19.290056 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:28:19.294797 [debug] [Thread-1  ]: finished collecting timing info
15:28:19.296370 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:28:19.304848 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:28:19.311484 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:28:19.312563 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:28:19.313300 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:21.448754 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.14 seconds
15:28:21.461984 [debug] [Thread-1  ]: finished collecting timing info
15:28:21.464024 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:28:21.637079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb884175fd0>]}
15:28:21.638918 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.36s]
15:28:21.640692 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:28:21.642155 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:28:21.644002 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
15:28:21.645721 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:28:21.646715 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:28:21.647607 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:28:21.654760 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:28:21.660407 [debug] [Thread-1  ]: finished collecting timing info
15:28:21.661843 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:28:21.668223 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:28:21.673485 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:28:21.674243 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
15:28:21.675636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:23.001957 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
15:28:23.011702 [debug] [Thread-1  ]: finished collecting timing info
15:28:23.013046 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:28:23.166158 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c92caeac-4b7e-4ba7-a679-e7510cd3c041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb884175a90>]}
15:28:23.170017 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.52s]
15:28:23.173681 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:28:23.208354 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:28:23.210999 [info ] [MainThread]: 
15:28:23.212574 [info ] [MainThread]: Finished running 4 table models, 2 incremental models in 18.81s.
15:28:23.213791 [debug] [MainThread]: Connection 'master' was properly closed.
15:28:23.214989 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:28:23.234906 [info ] [MainThread]: 
15:28:23.236132 [info ] [MainThread]: [32mCompleted successfully[0m
15:28:23.237376 [info ] [MainThread]: 
15:28:23.238634 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
15:28:23.241237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb884165490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8841ae150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8841aeed0>]}


============================== 2022-01-23 15:28:39.516738 | 6db0d23b-e50b-46d7-9407-eefd690a1f82 ==============================
15:28:39.516738 [info ] [MainThread]: Running with dbt=1.0.1
15:28:39.518354 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
15:28:39.519376 [debug] [MainThread]: Tracking: tracking
15:28:39.521027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24df464d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24df464a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24df464dd0>]}
15:28:39.635583 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:28:39.636320 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:28:39.653180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6db0d23b-e50b-46d7-9407-eefd690a1f82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24de310490>]}
15:28:39.670377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6db0d23b-e50b-46d7-9407-eefd690a1f82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24de3c44d0>]}
15:28:39.671429 [info ] [MainThread]: Found 6 models, 7 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:28:39.674553 [info ] [MainThread]: 
15:28:39.676366 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:28:39.679892 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:28:39.719563 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:28:39.720406 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:28:39.721060 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:28:41.019815 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.3 seconds
15:28:41.024400 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:28:41.210301 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:28:41.213037 [info ] [MainThread]: 
15:28:41.222967 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
15:28:41.224216 [info ] [Thread-1  ]: 1 of 3 START test assert_under_10_percent_null.................................. [RUN]
15:28:41.226689 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
15:28:41.227793 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
15:28:41.228982 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
15:28:41.240798 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
15:28:41.244222 [debug] [Thread-1  ]: finished collecting timing info
15:28:41.245690 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
15:28:41.302571 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
15:28:41.308153 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
15:28:41.309009 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
15:28:41.309550 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:42.306745 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
15:28:42.312529 [debug] [Thread-1  ]: finished collecting timing info
15:28:42.313376 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
15:28:42.495062 [error] [Thread-1  ]: 1 of 3 FAIL 1 assert_under_10_percent_null...................................... [[31mFAIL 1[0m in 1.27s]
15:28:42.498563 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
15:28:42.501283 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:28:42.503235 [info ] [Thread-1  ]: 2 of 3 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
15:28:42.505323 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:28:42.506560 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:28:42.507729 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:28:42.546271 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:28:42.550611 [debug] [Thread-1  ]: finished collecting timing info
15:28:42.551708 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:28:42.556911 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:28:42.562885 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:28:42.563732 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
15:28:42.564665 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:44.362935 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.8 seconds
15:28:44.375105 [debug] [Thread-1  ]: finished collecting timing info
15:28:44.376831 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
15:28:44.551010 [error] [Thread-1  ]: 2 of 3 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 2.05s]
15:28:44.552675 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:28:44.554276 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:28:44.555881 [info ] [Thread-1  ]: 3 of 3 START test unique_my_first_dbt_model_id.................................. [RUN]
15:28:44.557694 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:28:44.558985 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:28:44.559960 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:28:44.579022 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:28:44.584215 [debug] [Thread-1  ]: finished collecting timing info
15:28:44.584978 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:28:44.589871 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:28:44.595605 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
15:28:44.596419 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:28:44.597329 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:45.382690 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
15:28:45.394136 [debug] [Thread-1  ]: finished collecting timing info
15:28:45.395781 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
15:28:45.530112 [info ] [Thread-1  ]: 3 of 3 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 0.97s]
15:28:45.533353 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
15:28:45.555067 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:28:45.556887 [info ] [MainThread]: 
15:28:45.558273 [info ] [MainThread]: Finished running 3 tests in 5.88s.
15:28:45.559781 [debug] [MainThread]: Connection 'master' was properly closed.
15:28:45.560748 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
15:28:45.580428 [info ] [MainThread]: 
15:28:45.583036 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
15:28:45.585361 [info ] [MainThread]: 
15:28:45.587199 [error] [MainThread]: [31mFailure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)[0m
15:28:45.588873 [error] [MainThread]:   Got 1 result, configured to fail if != 0
15:28:45.590336 [info ] [MainThread]: 
15:28:45.591431 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/tests/assert_under_10_percent_null.sql
15:28:45.593136 [info ] [MainThread]: 
15:28:45.594832 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
15:28:45.597381 [error] [MainThread]:   Got 1 result, configured to fail if != 0
15:28:45.600416 [info ] [MainThread]: 
15:28:45.602971 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
15:28:45.604324 [info ] [MainThread]: 
15:28:45.606115 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=2 SKIP=0 TOTAL=3
15:28:45.608118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24de3db1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24dcf05790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24dcef52d0>]}


============================== 2022-01-23 15:48:16.791946 | a1b87ac3-5dd5-4241-bb55-866c79673254 ==============================
15:48:16.791946 [info ] [MainThread]: Running with dbt=1.0.1
15:48:16.793632 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:48:16.794554 [debug] [MainThread]: Tracking: tracking
15:48:16.795648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f564c534d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f564c534a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f564c534d10>]}
15:48:16.915793 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
15:48:16.917277 [debug] [MainThread]: Partial parsing: added file: dbt_tests://tests/assert_under_100m.sql
15:48:16.918234 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/playing_with_tests.sql
15:48:16.919760 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:48:16.954487 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
15:48:16.992025 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
15:48:17.181090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f563ff9df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f564c5eb6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f564c5ebc10>]}


============================== 2022-01-23 15:51:13.314992 | 7034694f-fb7c-4c05-ae44-f5259bff646a ==============================
15:51:13.314992 [info ] [MainThread]: Running with dbt=1.0.1
15:51:13.316233 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:51:13.317164 [debug] [MainThread]: Tracking: tracking
15:51:13.319641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731b6fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731b6fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731b6fd90>]}
15:51:13.425021 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
15:51:13.425980 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/playing_with_tests.sql
15:51:13.426603 [debug] [MainThread]: Partial parsing: added file: dbt_tests://tests/assert_under_100m.sql
15:51:13.427715 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:51:13.461236 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
15:51:13.499378 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
15:51:13.780706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731b6fb10>]}
15:51:13.801119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731b26910>]}
15:51:13.802147 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
15:51:13.807158 [info ] [MainThread]: 
15:51:13.809341 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:51:13.813266 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:51:13.853480 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:51:13.854431 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:51:13.854862 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:51:15.066410 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.21 seconds
15:51:15.070970 [debug] [ThreadPool]: On list_analytics: Close
15:51:15.243284 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:51:15.267846 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:51:15.268876 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:51:15.269620 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:51:16.297325 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.03 seconds
15:51:16.309013 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:51:16.482778 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:51:16.485161 [info ] [MainThread]: 
15:51:16.492401 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:51:16.493902 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:51:16.495441 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:51:16.496197 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:51:16.497413 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:51:16.504406 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:51:16.510387 [debug] [Thread-1  ]: finished collecting timing info
15:51:16.511567 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:51:16.596084 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:51:16.603259 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:51:16.604131 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
15:51:16.604975 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:51:18.705335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.1 seconds
15:51:18.738264 [debug] [Thread-1  ]: finished collecting timing info
15:51:18.739303 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:51:19.008389 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873008b8d0>]}
15:51:19.010748 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.51s]
15:51:19.012727 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:51:19.013989 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:51:19.016171 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
15:51:19.018734 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:51:19.020729 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:51:19.022683 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:51:19.052883 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:51:19.058233 [debug] [Thread-1  ]: finished collecting timing info
15:51:19.059567 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:51:19.138222 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:19.139271 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
15:51:19.139989 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:51:20.731861 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
15:51:20.771202 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:20.772255 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:51:20.892264 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:51:20.923405 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:20.924486 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
15:51:21.030554 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:51:21.062949 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:21.064172 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:51:21.173217 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:51:21.263664 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:51:21.287093 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:21.288117 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
15:51:21.445399 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
15:51:21.447865 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:21.449803 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:51:21.824080 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.37 seconds
15:51:21.825736 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:51:21.827067 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
15:51:22.037051 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
15:51:22.044674 [debug] [Thread-1  ]: finished collecting timing info
15:51:22.045754 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:51:22.233941 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8730038f90>]}
15:51:22.236093 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.22s]
15:51:22.238507 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:51:22.240094 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:51:22.242117 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:51:22.243854 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:51:22.244979 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:51:22.246073 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:51:22.256589 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:51:22.260767 [debug] [Thread-1  ]: finished collecting timing info
15:51:22.261817 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:51:22.272465 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:22.273311 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:51:22.274126 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:51:23.933201 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
15:51:23.943244 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:23.944299 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:51:24.057333 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:51:24.079854 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:24.081042 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:51:24.178283 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:51:24.193890 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:24.194987 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:51:24.297469 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:51:24.305741 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:51:24.313719 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:24.314587 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
15:51:24.436846 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
15:51:24.439477 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:24.440937 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:51:24.972369 [debug] [Thread-1  ]: SQL status: SUCCESS 1390 in 0.53 seconds
15:51:24.973886 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:51:24.975528 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
15:51:25.236430 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
15:51:25.240196 [debug] [Thread-1  ]: finished collecting timing info
15:51:25.241114 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:51:25.430141 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873013e350>]}
15:51:25.433957 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.19s]
15:51:25.436316 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:51:25.438201 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:51:25.440868 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
15:51:25.443542 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:51:25.444426 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:51:25.445418 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:51:25.457039 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:51:25.461041 [debug] [Thread-1  ]: finished collecting timing info
15:51:25.461972 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:51:25.468349 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:51:25.474698 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:51:25.475676 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:51:25.476604 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:51:26.900386 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
15:51:26.910851 [debug] [Thread-1  ]: finished collecting timing info
15:51:26.912013 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:51:27.031664 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873008aa50>]}
15:51:27.033359 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.59s]
15:51:27.035406 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:51:27.036843 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
15:51:27.038752 [info ] [Thread-1  ]: 5 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:51:27.040850 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
15:51:27.041874 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
15:51:27.042938 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
15:51:27.053445 [debug] [Thread-1  ]: finished collecting timing info
15:51:27.054988 [debug] [Thread-1  ]: Compilation Error in model playing_with_tests (models/example/playing_with_tests.sql)
  'rename_segments' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
15:51:27.055953 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8722395e90>]}
15:51:27.056803 [error] [Thread-1  ]: 5 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.02s]
15:51:27.057665 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
15:51:27.058796 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:51:27.060287 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:51:27.062023 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:51:27.062893 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:51:27.063943 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:51:27.071509 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:51:27.075501 [debug] [Thread-1  ]: finished collecting timing info
15:51:27.076304 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:51:27.082114 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:51:27.088622 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:51:27.089585 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:51:27.090420 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:51:28.889873 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.8 seconds
15:51:28.898264 [debug] [Thread-1  ]: finished collecting timing info
15:51:28.900007 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:51:29.048611 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87223308d0>]}
15:51:29.051417 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.99s]
15:51:29.053568 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:51:29.055244 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:51:29.056528 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:51:29.058686 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:51:29.059599 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:51:29.060906 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:51:29.069236 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:51:29.074141 [debug] [Thread-1  ]: finished collecting timing info
15:51:29.075436 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:51:29.081622 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:51:29.086878 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:51:29.088024 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
15:51:29.088932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:51:30.695698 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.61 seconds
15:51:30.702007 [debug] [Thread-1  ]: finished collecting timing info
15:51:30.703316 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:51:30.859260 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7034694f-fb7c-4c05-ae44-f5259bff646a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873008ca50>]}
15:51:30.860993 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.80s]
15:51:30.862495 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:51:30.950374 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:51:30.952883 [info ] [MainThread]: 
15:51:30.954229 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 17.14s.
15:51:30.956440 [debug] [MainThread]: Connection 'master' was properly closed.
15:51:30.958273 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:51:30.987003 [info ] [MainThread]: 
15:51:30.988201 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:51:30.989768 [info ] [MainThread]: 
15:51:30.991700 [error] [MainThread]: [33mCompilation Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
15:51:30.993239 [error] [MainThread]:   'rename_segments' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
15:51:30.994787 [info ] [MainThread]: 
15:51:30.996274 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
15:51:30.997935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8730095910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873008a490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873008af90>]}


============================== 2022-01-23 15:52:41.939971 | bd28ea48-c6ac-462c-9a2f-441b0f5d784b ==============================
15:52:41.939971 [info ] [MainThread]: Running with dbt=1.0.1
15:52:41.941120 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:52:41.941779 [debug] [MainThread]: Tracking: tracking
15:52:41.942645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6bf73dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6bf73a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6bf73d90>]}
15:52:42.068306 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:52:42.070005 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/playing_with_tests.sql
15:52:42.104607 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
15:52:42.142076 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
15:52:42.334330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6d052410>]}
15:52:42.354140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6bf08090>]}
15:52:42.355003 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
15:52:42.359516 [info ] [MainThread]: 
15:52:42.361084 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:52:42.364829 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:52:42.406377 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:52:42.406989 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:52:42.407577 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:52:43.583871 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.18 seconds
15:52:43.588163 [debug] [ThreadPool]: On list_analytics: Close
15:52:43.770006 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:52:43.793439 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:52:43.794263 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:52:43.794818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:52:44.664744 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.87 seconds
15:52:44.677447 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:52:44.856931 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:52:44.858417 [info ] [MainThread]: 
15:52:44.863709 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:52:44.865053 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:52:44.867088 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:52:44.868351 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:52:44.869854 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:52:44.875979 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:52:44.880022 [debug] [Thread-1  ]: finished collecting timing info
15:52:44.881032 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:52:44.969933 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:52:44.975285 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:52:44.976039 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
15:52:44.976878 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:52:46.848251 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.87 seconds
15:52:46.887794 [debug] [Thread-1  ]: finished collecting timing info
15:52:46.888874 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:52:47.035925 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6a510b10>]}
15:52:47.038440 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.17s]
15:52:47.040416 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:52:47.042025 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:52:47.044197 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
15:52:47.046016 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:52:47.047095 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:52:47.048493 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:52:47.077495 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:52:47.081852 [debug] [Thread-1  ]: finished collecting timing info
15:52:47.082973 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:52:47.167293 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:47.168342 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
15:52:47.169027 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:52:48.406215 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
15:52:48.443959 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:48.444882 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:52:48.548754 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:52:48.561368 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:48.562211 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
15:52:48.656678 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
15:52:48.698012 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:48.699006 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:52:48.786273 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
15:52:48.874740 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:52:48.886151 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:48.887088 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
15:52:48.981109 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
15:52:48.982819 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:48.983845 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:52:49.469287 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.48 seconds
15:52:49.470499 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:52:49.471331 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
15:52:49.610087 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
15:52:49.615878 [debug] [Thread-1  ]: finished collecting timing info
15:52:49.616928 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:52:49.758867 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6884cd50>]}
15:52:49.761181 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.71s]
15:52:49.763553 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:52:49.766043 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:52:49.768296 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:52:49.770936 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:52:49.772217 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:52:49.773420 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:52:49.786617 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:52:49.790522 [debug] [Thread-1  ]: finished collecting timing info
15:52:49.791566 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:52:49.801865 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:49.802806 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:52:49.803471 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:52:51.382870 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
15:52:51.391710 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:51.392738 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:52:51.510021 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
15:52:51.530008 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:51.531164 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:52:51.630782 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:52:51.642348 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:51.643177 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:52:51.750629 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:52:51.771250 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:52:51.781193 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:51.782176 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
15:52:51.906433 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
15:52:51.907422 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:51.908048 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:52:52.416585 [debug] [Thread-1  ]: SQL status: SUCCESS 87 in 0.51 seconds
15:52:52.418102 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:52:52.419300 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
15:52:52.675407 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
15:52:52.686325 [debug] [Thread-1  ]: finished collecting timing info
15:52:52.688073 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:52:52.869169 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6884cc90>]}
15:52:52.870291 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.10s]
15:52:52.871108 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:52:52.872018 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:52:52.873451 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
15:52:52.875259 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:52:52.876135 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:52:52.877013 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:52:52.887361 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:52:52.891604 [debug] [Thread-1  ]: finished collecting timing info
15:52:52.892605 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:52:52.899988 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:52:52.905782 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:52:52.906718 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:52:52.907404 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:52:54.439235 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
15:52:54.452271 [debug] [Thread-1  ]: finished collecting timing info
15:52:54.453935 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:52:54.614205 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6882df90>]}
15:52:54.615525 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.74s]
15:52:54.616866 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:52:54.617815 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
15:52:54.619743 [info ] [Thread-1  ]: 5 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:52:54.621142 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
15:52:54.622168 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
15:52:54.623064 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
15:52:54.633894 [debug] [Thread-1  ]: finished collecting timing info
15:52:54.634959 [debug] [Thread-1  ]: Compilation Error in model playing_with_tests (models/example/playing_with_tests.sql)
  'rename_segments' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
15:52:54.635946 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd687ebe50>]}
15:52:54.636816 [error] [Thread-1  ]: 5 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.02s]
15:52:54.637732 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
15:52:54.638745 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:52:54.639972 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:52:54.641018 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:52:54.642320 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:52:54.643227 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:52:54.651524 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:52:54.655424 [debug] [Thread-1  ]: finished collecting timing info
15:52:54.656372 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:52:54.666046 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:52:54.672208 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:52:54.672998 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:52:54.673715 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:52:56.872910 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.2 seconds
15:52:56.878634 [debug] [Thread-1  ]: finished collecting timing info
15:52:56.879801 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:52:57.226284 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd687d2110>]}
15:52:57.230466 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.58s]
15:52:57.232913 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:52:57.235409 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:52:57.237522 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:52:57.239409 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:52:57.240667 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:52:57.241741 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:52:57.250116 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:52:57.255606 [debug] [Thread-1  ]: finished collecting timing info
15:52:57.256681 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:52:57.271876 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:52:57.277550 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:52:57.278625 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
15:52:57.279448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:52:58.712372 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
15:52:58.717358 [debug] [Thread-1  ]: finished collecting timing info
15:52:58.718582 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:52:58.904106 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd28ea48-c6ac-462c-9a2f-441b0f5d784b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd68852990>]}
15:52:58.905728 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.66s]
15:52:58.907308 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:52:59.022417 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:52:59.025740 [info ] [MainThread]: 
15:52:59.028480 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 16.66s.
15:52:59.031803 [debug] [MainThread]: Connection 'master' was properly closed.
15:52:59.034168 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:52:59.064254 [info ] [MainThread]: 
15:52:59.066040 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:52:59.067742 [info ] [MainThread]: 
15:52:59.069470 [error] [MainThread]: [33mCompilation Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
15:52:59.070925 [error] [MainThread]:   'rename_segments' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
15:52:59.072305 [info ] [MainThread]: 
15:52:59.073764 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
15:52:59.075278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6bebfed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd68892cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd68892a50>]}


============================== 2022-01-23 15:57:57.665857 | e0494c5b-f2af-422c-a94b-7099ba94571f ==============================
15:57:57.665857 [info ] [MainThread]: Running with dbt=1.0.1
15:57:57.667317 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:57:57.668179 [debug] [MainThread]: Tracking: tracking
15:57:57.669087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc7d71cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc7d71550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc7d71c90>]}
15:57:57.792144 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
15:57:57.793888 [debug] [MainThread]: Partial parsing: deleted source source.dbt_tests.sample.customer
15:57:57.794422 [debug] [MainThread]: Partial parsing: deleted source source.dbt_tests.sample.orders
15:57:57.794833 [debug] [MainThread]: Partial parsing: deleted source source.dbt_tests.sample2.customer
15:57:57.795270 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
15:57:57.795935 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://tests/assert_under_100m.sql
15:57:57.796787 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/playing_with_tests.sql
15:57:57.830952 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:57:58.067415 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_tests.assert_under_100m' (tests/assert_under_100m.sql) depends on a node named 'playing_with_test' which was not found
15:57:58.111291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbcf6a9390>]}
15:57:58.130891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc7da2dd0>]}
15:57:58.132354 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:57:58.137029 [info ] [MainThread]: 
15:57:58.138986 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:57:58.143118 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:57:58.188102 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:57:58.188804 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:57:58.189304 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:57:59.436806 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.25 seconds
15:57:59.442206 [debug] [ThreadPool]: On list_analytics: Close
15:57:59.623787 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:57:59.649505 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:57:59.650521 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:57:59.651271 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:58:00.491803 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.84 seconds
15:58:00.496269 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:58:00.673389 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:58:00.676263 [info ] [MainThread]: 
15:58:00.683564 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:58:00.685013 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:58:00.686620 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:58:00.687726 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:58:00.688951 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:58:00.699962 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:58:00.704853 [debug] [Thread-1  ]: finished collecting timing info
15:58:00.705897 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:58:00.790008 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:58:00.797687 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:58:00.798526 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
15:58:00.799157 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:02.778569 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
15:58:02.820093 [debug] [Thread-1  ]: finished collecting timing info
15:58:02.820956 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:58:02.952242 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc63b2550>]}
15:58:02.955502 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.27s]
15:58:02.958416 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:58:02.959918 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:58:02.962157 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
15:58:02.963979 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:58:02.964962 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:58:02.965985 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:58:02.999738 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:58:03.004045 [debug] [Thread-1  ]: finished collecting timing info
15:58:03.005268 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:58:03.083634 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:03.084684 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
15:58:03.085485 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:04.936724 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.85 seconds
15:58:04.973037 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:04.973954 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:58:05.060957 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
15:58:05.076549 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:05.077479 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
15:58:05.159757 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
15:58:05.197675 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:05.198876 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:58:05.283252 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
15:58:05.366251 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:58:05.378234 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:05.379204 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
15:58:05.478329 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
15:58:05.480216 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:05.481302 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:58:05.843458 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
15:58:05.844384 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:58:05.845025 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
15:58:06.001921 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
15:58:06.007662 [debug] [Thread-1  ]: finished collecting timing info
15:58:06.008766 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:58:06.157242 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc63d7650>]}
15:58:06.160736 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.19s]
15:58:06.164245 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:58:06.166596 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:58:06.169419 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:58:06.172332 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:58:06.173825 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:58:06.175056 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:58:06.187267 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:58:06.191499 [debug] [Thread-1  ]: finished collecting timing info
15:58:06.192996 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:58:06.201781 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:06.202610 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:58:06.203358 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:07.647229 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
15:58:07.666697 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:07.667762 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:58:07.760693 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
15:58:07.773316 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:07.774151 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:58:07.869837 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:58:07.880511 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:07.881406 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:58:07.994416 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:58:08.009611 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:58:08.018151 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:08.019062 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
15:58:08.130357 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
15:58:08.133527 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:08.135701 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:58:08.626265 [debug] [Thread-1  ]: SQL status: SUCCESS 316 in 0.49 seconds
15:58:08.628566 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:58:08.630696 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
15:58:08.871405 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
15:58:08.877333 [debug] [Thread-1  ]: finished collecting timing info
15:58:08.878403 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:58:09.025800 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc5e9c910>]}
15:58:09.028133 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.85s]
15:58:09.029921 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:58:09.031831 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:58:09.034069 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
15:58:09.036911 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:58:09.038814 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:58:09.040307 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:58:09.051442 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:58:09.055940 [debug] [Thread-1  ]: finished collecting timing info
15:58:09.057230 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:58:09.062677 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:58:09.068097 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:58:09.068931 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:58:09.069800 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:10.475615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
15:58:10.484977 [debug] [Thread-1  ]: finished collecting timing info
15:58:10.486381 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:58:10.627625 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc46000d0>]}
15:58:10.629532 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.59s]
15:58:10.631298 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:58:10.633394 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
15:58:10.636071 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
15:58:10.638020 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
15:58:10.639268 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
15:58:10.640307 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
15:58:10.648826 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
15:58:10.653989 [debug] [Thread-1  ]: finished collecting timing info
15:58:10.655903 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
15:58:10.664314 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
15:58:10.670246 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
15:58:10.671245 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
15:58:10.672363 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:16.939463 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.27 seconds
15:58:16.945226 [debug] [Thread-1  ]: finished collecting timing info
15:58:16.946351 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
15:58:17.084705 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc5e88e10>]}
15:58:17.131813 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.44s]
15:58:17.139737 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
15:58:17.158967 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:58:17.172321 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:58:17.176227 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:58:17.177961 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:58:17.179102 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:58:17.213372 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:58:17.220340 [debug] [Thread-1  ]: finished collecting timing info
15:58:17.221341 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:58:17.232202 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:58:17.245081 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:58:17.246736 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:58:17.250495 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:19.340826 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
15:58:19.345091 [debug] [Thread-1  ]: finished collecting timing info
15:58:19.345920 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:58:19.469937 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc5e88e90>]}
15:58:19.471045 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.29s]
15:58:19.471995 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:58:19.472877 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:58:19.474605 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:58:19.475751 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:58:19.476973 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:58:19.477942 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:58:19.484981 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:58:19.489480 [debug] [Thread-1  ]: finished collecting timing info
15:58:19.490450 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:58:19.499081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:58:19.504158 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:58:19.505035 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
15:58:19.505759 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:20.904130 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
15:58:20.913529 [debug] [Thread-1  ]: finished collecting timing info
15:58:20.917638 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:58:21.053270 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0494c5b-f2af-422c-a94b-7099ba94571f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc4618290>]}
15:58:21.054390 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
15:58:21.055699 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:58:21.091896 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:58:21.092984 [info ] [MainThread]: 
15:58:21.093921 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 22.95s.
15:58:21.095302 [debug] [MainThread]: Connection 'master' was properly closed.
15:58:21.097126 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:58:21.120759 [info ] [MainThread]: 
15:58:21.121753 [info ] [MainThread]: [32mCompleted successfully[0m
15:58:21.123279 [info ] [MainThread]: 
15:58:21.124758 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:58:21.126696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc63cb590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc4679350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbc4679150>]}


============================== 2022-01-23 15:58:55.404860 | d90168fc-1f43-44be-aff5-6e00ae1acc9a ==============================
15:58:55.404860 [info ] [MainThread]: Running with dbt=1.0.1
15:58:55.406364 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:58:55.407534 [debug] [MainThread]: Tracking: tracking
15:58:55.408696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1f031d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1f031a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1f031dd0>]}
15:58:55.539028 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:58:55.540974 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://tests/assert_under_100m.sql
15:58:55.705282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1deed450>]}
15:58:55.734864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1dfc4b50>]}
15:58:55.736215 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:58:55.743700 [info ] [MainThread]: 
15:58:55.746021 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:58:55.750457 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:58:55.895359 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:58:55.896228 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:58:55.896974 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:58:57.541447 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.64 seconds
15:58:57.545978 [debug] [ThreadPool]: On list_analytics: Close
15:58:57.731435 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:58:57.753602 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:58:57.754584 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:58:57.755366 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:58:58.614624 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.86 seconds
15:58:58.627413 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:58:58.922807 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:58:58.924048 [info ] [MainThread]: 
15:58:58.928909 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:58:58.929903 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:58:58.931866 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:58:58.933264 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:58:58.934884 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:58:58.945467 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:58:58.949377 [debug] [Thread-1  ]: finished collecting timing info
15:58:58.950695 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:58:59.046990 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:58:59.053876 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:58:59.054828 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
15:58:59.055677 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:00.733523 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
15:59:00.767794 [debug] [Thread-1  ]: finished collecting timing info
15:59:00.768767 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:59:00.912069 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1caa9610>]}
15:59:00.914636 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 1.98s]
15:59:00.917111 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:59:00.918977 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:59:00.921657 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
15:59:00.923493 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:59:00.924766 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:59:00.926168 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:59:00.958413 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:59:00.963515 [debug] [Thread-1  ]: finished collecting timing info
15:59:00.964441 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:59:01.043630 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:01.044627 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
15:59:01.045353 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:02.165221 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
15:59:02.203396 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:02.204278 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:59:02.306713 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:59:02.323333 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:02.324171 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
15:59:02.402074 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
15:59:02.428345 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:02.429610 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:59:02.509190 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
15:59:02.590521 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:59:02.601709 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:02.602695 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
15:59:02.702037 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
15:59:02.703540 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:02.704295 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:59:03.062987 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
15:59:03.063993 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:59:03.064959 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
15:59:03.212326 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
15:59:03.220719 [debug] [Thread-1  ]: finished collecting timing info
15:59:03.222123 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:59:03.356489 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1ca934d0>]}
15:59:03.357766 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.43s]
15:59:03.358675 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:59:03.359841 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:59:03.361732 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:59:03.364329 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:59:03.365507 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:59:03.366481 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:59:03.374640 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:59:03.381226 [debug] [Thread-1  ]: finished collecting timing info
15:59:03.382579 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:59:03.393352 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:03.394274 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:59:03.395542 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:04.834579 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
15:59:04.844657 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:04.845815 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:59:04.937919 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
15:59:04.947211 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:04.948242 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:59:05.027011 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
15:59:05.037731 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:05.038597 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:59:05.117080 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
15:59:05.125126 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:59:05.133331 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:05.134145 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
15:59:05.240380 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
15:59:05.241366 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:05.242071 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:59:05.950577 [debug] [Thread-1  ]: SQL status: SUCCESS 58 in 0.71 seconds
15:59:05.951546 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:59:05.952270 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
15:59:06.206704 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
15:59:06.212001 [debug] [Thread-1  ]: finished collecting timing info
15:59:06.213117 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:59:06.352948 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1c4dc8d0>]}
15:59:06.353984 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.99s]
15:59:06.354770 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:59:06.355677 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:59:06.357099 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
15:59:06.359005 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:59:06.360217 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:59:06.361237 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:59:06.371881 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:59:06.375954 [debug] [Thread-1  ]: finished collecting timing info
15:59:06.377605 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:59:06.388330 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:59:06.394925 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:59:06.396014 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:59:06.397130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:07.700050 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
15:59:07.704723 [debug] [Thread-1  ]: finished collecting timing info
15:59:07.705718 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:59:07.850362 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1ca95350>]}
15:59:07.851577 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.49s]
15:59:07.852957 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:59:07.854243 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
15:59:07.856032 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
15:59:07.857367 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
15:59:07.858333 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
15:59:07.859330 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
15:59:07.868071 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
15:59:07.872391 [debug] [Thread-1  ]: finished collecting timing info
15:59:07.873197 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
15:59:07.880418 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
15:59:07.885903 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
15:59:07.886638 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
15:59:07.887685 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:14.163486 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.28 seconds
15:59:14.175638 [debug] [Thread-1  ]: finished collecting timing info
15:59:14.176822 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
15:59:14.352790 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1c4b20d0>]}
15:59:14.354170 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.50s]
15:59:14.355308 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
15:59:14.356704 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:59:14.358747 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:59:14.360437 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:59:14.361763 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:59:14.362748 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:59:14.368671 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:59:14.372904 [debug] [Thread-1  ]: finished collecting timing info
15:59:14.374117 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:59:14.385869 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:59:14.392850 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:59:14.394016 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:59:14.395077 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:16.480587 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
15:59:16.485732 [debug] [Thread-1  ]: finished collecting timing info
15:59:16.486733 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:59:16.620026 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1c4a7d10>]}
15:59:16.621269 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.26s]
15:59:16.622844 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:59:16.626403 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:59:16.627651 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:59:16.629600 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:59:16.630332 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:59:16.631139 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:59:16.636186 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:59:16.642092 [debug] [Thread-1  ]: finished collecting timing info
15:59:16.643770 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:59:16.650693 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:59:16.657286 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:59:16.659011 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
15:59:16.660557 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:59:18.361643 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
15:59:18.370041 [debug] [Thread-1  ]: finished collecting timing info
15:59:18.371612 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:59:18.536285 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd90168fc-1f43-44be-aff5-6e00ae1acc9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1c4a3650>]}
15:59:18.537952 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.91s]
15:59:18.539675 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:59:18.590448 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:59:18.592018 [info ] [MainThread]: 
15:59:18.592958 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 22.85s.
15:59:18.594402 [debug] [MainThread]: Connection 'master' was properly closed.
15:59:18.595792 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:59:18.616721 [info ] [MainThread]: 
15:59:18.617953 [info ] [MainThread]: [32mCompleted successfully[0m
15:59:18.619624 [info ] [MainThread]: 
15:59:18.622178 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:59:18.625815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1df87b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1c55d290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1c55d090>]}


============================== 2022-01-23 16:00:37.509473 | 8eff6933-4fd2-4f6c-9567-d38e9d8f58e3 ==============================
16:00:37.509473 [info ] [MainThread]: Running with dbt=1.0.1
16:00:37.510938 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
16:00:37.511770 [debug] [MainThread]: Tracking: tracking
16:00:37.513013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fb3adc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fb3adb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fb3adc50>]}
16:00:37.633034 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:00:37.634103 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:00:37.652043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8eff6933-4fd2-4f6c-9567-d38e9d8f58e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fb2975d0>]}
16:00:37.672465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8eff6933-4fd2-4f6c-9567-d38e9d8f58e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fb398f10>]}
16:00:37.674012 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
16:00:37.679362 [info ] [MainThread]: 
16:00:37.681333 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:00:37.685759 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:00:37.729123 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:00:37.729979 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:00:37.730465 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:00:39.088023 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.36 seconds
16:00:39.092813 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:00:39.275786 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:00:39.277167 [info ] [MainThread]: 
16:00:39.284814 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:00:39.286095 [info ] [Thread-1  ]: 1 of 11 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
16:00:39.288848 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:00:39.289677 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:00:39.290903 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:00:39.363702 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:00:39.367859 [debug] [Thread-1  ]: finished collecting timing info
16:00:39.368736 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:00:39.418970 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:00:39.424905 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:00:39.425668 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
16:00:39.426243 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:40.570193 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.14 seconds
16:00:40.580486 [debug] [Thread-1  ]: finished collecting timing info
16:00:40.581739 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
16:00:40.710053 [info ] [Thread-1  ]: 1 of 11 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.42s]
16:00:40.713550 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:00:40.715609 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
16:00:40.717892 [info ] [Thread-1  ]: 2 of 11 START test assert_under_100m............................................ [RUN]
16:00:40.720502 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
16:00:40.721927 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
16:00:40.723040 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
16:00:40.732095 [debug] [Thread-1  ]: finished collecting timing info
16:00:40.733929 [debug] [Thread-1  ]: Compilation Error in test assert_under_100m (tests/assert_under_100m.sql)
  Required var 'my_min_acctbal_variable' not found in config:
  Vars supplied to assert_under_100m = {
      "my_first_variable": true,
      "my_second_variable": 2020,
      "my_third_variable": 1
  }
  
  > in test assert_under_100m (tests/assert_under_100m.sql)
  > called by test assert_under_100m (tests/assert_under_100m.sql)
16:00:40.737663 [error] [Thread-1  ]: 2 of 11 ERROR assert_under_100m................................................. [[31mERROR[0m in 0.02s]
16:00:40.739656 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
16:00:40.741101 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
16:00:40.742414 [info ] [Thread-1  ]: 3 of 11 START test assert_under_10_percent_null................................. [RUN]
16:00:40.743843 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:00:40.744706 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
16:00:40.745734 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
16:00:40.753605 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:00:40.758208 [debug] [Thread-1  ]: finished collecting timing info
16:00:40.759774 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
16:00:40.764865 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:00:40.772995 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:00:40.773892 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
16:00:40.774688 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:41.597129 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
16:00:41.607848 [debug] [Thread-1  ]: finished collecting timing info
16:00:41.609284 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
16:00:41.753918 [error] [Thread-1  ]: 3 of 11 FAIL 1 assert_under_10_percent_null..................................... [[31mFAIL 1[0m in 1.01s]
16:00:41.757908 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
16:00:41.759697 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:00:41.761198 [info ] [Thread-1  ]: 4 of 11 START test not_null_my_second_dbt_model_id.............................. [RUN]
16:00:41.763226 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:00:41.764311 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:00:41.765451 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:00:41.787502 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:00:41.792193 [debug] [Thread-1  ]: finished collecting timing info
16:00:41.793190 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:00:41.798391 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:00:41.803842 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:00:41.804714 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
16:00:41.805383 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:42.687034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
16:00:42.706081 [debug] [Thread-1  ]: finished collecting timing info
16:00:42.707253 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: Close
16:00:42.847185 [error] [Thread-1  ]: 4 of 11 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.08s]
16:00:42.848180 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:00:42.848983 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:00:42.850559 [info ] [Thread-1  ]: 5 of 11 START test not_null_playing_with_tests_c_custkey........................ [RUN]
16:00:42.852123 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:00:42.852809 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:00:42.853901 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:00:42.862305 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:00:42.866805 [debug] [Thread-1  ]: finished collecting timing info
16:00:42.868908 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:00:42.875116 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:00:42.880918 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:00:42.881653 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
16:00:42.882452 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:43.671952 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
16:00:43.681743 [debug] [Thread-1  ]: finished collecting timing info
16:00:43.683216 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
16:00:43.818597 [info ] [Thread-1  ]: 5 of 11 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.97s]
16:00:43.820241 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:00:43.821714 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:00:43.823253 [info ] [Thread-1  ]: 6 of 11 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
16:00:43.824920 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:00:43.826091 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:00:43.827383 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:00:43.840867 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:00:43.845049 [debug] [Thread-1  ]: finished collecting timing info
16:00:43.845882 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:00:43.853776 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:00:43.859608 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:00:43.860533 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
16:00:43.861390 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:44.763050 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
16:00:44.775876 [debug] [Thread-1  ]: finished collecting timing info
16:00:44.777592 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
16:00:44.910059 [info ] [Thread-1  ]: 6 of 11 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.09s]
16:00:44.911811 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:00:44.913349 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:00:44.915318 [info ] [Thread-1  ]: 7 of 11 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
16:00:44.918030 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:00:44.919301 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:00:44.920771 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:00:44.948033 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:00:44.952171 [debug] [Thread-1  ]: finished collecting timing info
16:00:44.953349 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:00:44.958224 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:00:44.964198 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:00:44.965195 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
16:00:44.965899 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:46.085436 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
16:00:46.092495 [debug] [Thread-1  ]: finished collecting timing info
16:00:46.093837 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
16:00:46.268757 [error] [Thread-1  ]: 7 of 11 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [[31mFAIL 1[0m in 1.35s]
16:00:46.272293 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:00:46.274229 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:00:46.276614 [info ] [Thread-1  ]: 8 of 11 START test unique_my_first_dbt_model_id................................. [RUN]
16:00:46.278935 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:00:46.280252 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:00:46.281962 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:00:46.303998 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:00:46.308515 [debug] [Thread-1  ]: finished collecting timing info
16:00:46.309424 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:00:46.313944 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:00:46.319225 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:00:46.319985 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:00:46.320657 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:47.110952 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
16:00:47.122469 [debug] [Thread-1  ]: finished collecting timing info
16:00:47.123930 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
16:00:47.255539 [info ] [Thread-1  ]: 8 of 11 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 0.98s]
16:00:47.258802 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:00:47.261906 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:00:47.264794 [info ] [Thread-1  ]: 9 of 11 START test unique_my_second_dbt_model_id................................ [RUN]
16:00:47.268075 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:00:47.269650 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:00:47.270767 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:00:47.285884 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:00:47.290426 [debug] [Thread-1  ]: finished collecting timing info
16:00:47.291446 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:00:47.296335 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:00:47.303232 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:00:47.304122 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:00:47.304852 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:48.190538 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
16:00:48.197957 [debug] [Thread-1  ]: finished collecting timing info
16:00:48.198990 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
16:00:48.331814 [info ] [Thread-1  ]: 9 of 11 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 1.06s]
16:00:48.333064 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:00:48.334005 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:00:48.335041 [info ] [Thread-1  ]: 10 of 11 START test unique_playing_with_tests_c_custkey......................... [RUN]
16:00:48.336498 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:00:48.337313 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:00:48.338470 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:00:48.349009 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:00:48.354271 [debug] [Thread-1  ]: finished collecting timing info
16:00:48.355300 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:00:48.360229 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:00:48.367112 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:00:48.368062 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
16:00:48.368881 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:50.093509 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
16:00:50.100357 [debug] [Thread-1  ]: finished collecting timing info
16:00:50.101429 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
16:00:50.242745 [info ] [Thread-1  ]: 10 of 11 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.91s]
16:00:50.243981 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:00:50.244893 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:00:50.246295 [info ] [Thread-1  ]: 11 of 11 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
16:00:50.248368 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:00:50.249253 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:00:50.250149 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:00:50.261918 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:00:50.267320 [debug] [Thread-1  ]: finished collecting timing info
16:00:50.268983 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:00:50.273996 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:00:50.281487 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:00:50.282872 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
16:00:50.283411 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:51.425730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.14 seconds
16:00:51.430448 [debug] [Thread-1  ]: finished collecting timing info
16:00:51.431468 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
16:00:51.589741 [info ] [Thread-1  ]: 11 of 11 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.34s]
16:00:51.591694 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:00:51.595203 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:00:51.597495 [info ] [MainThread]: 
16:00:51.599362 [info ] [MainThread]: Finished running 11 tests in 13.92s.
16:00:51.601301 [debug] [MainThread]: Connection 'master' was properly closed.
16:00:51.602490 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
16:00:51.625745 [info ] [MainThread]: 
16:00:51.627028 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
16:00:51.628946 [info ] [MainThread]: 
16:00:51.631616 [error] [MainThread]: [33mCompilation Error in test assert_under_100m (tests/assert_under_100m.sql)[0m
16:00:51.633633 [error] [MainThread]:   Required var 'my_min_acctbal_variable' not found in config:
16:00:51.636286 [error] [MainThread]:   Vars supplied to assert_under_100m = {
16:00:51.637872 [error] [MainThread]:       "my_first_variable": true,
16:00:51.639314 [error] [MainThread]:       "my_second_variable": 2020,
16:00:51.640771 [error] [MainThread]:       "my_third_variable": 1
16:00:51.641713 [error] [MainThread]:   }
16:00:51.643136 [error] [MainThread]:   
16:00:51.644402 [error] [MainThread]:   > in test assert_under_100m (tests/assert_under_100m.sql)
16:00:51.646152 [error] [MainThread]:   > called by test assert_under_100m (tests/assert_under_100m.sql)
16:00:51.648901 [info ] [MainThread]: 
16:00:51.650946 [error] [MainThread]: [31mFailure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)[0m
16:00:51.653150 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:00:51.654371 [info ] [MainThread]: 
16:00:51.655761 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/tests/assert_under_10_percent_null.sql
16:00:51.657131 [info ] [MainThread]: 
16:00:51.658412 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
16:00:51.659961 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:00:51.660936 [info ] [MainThread]: 
16:00:51.662079 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
16:00:51.666204 [info ] [MainThread]: 
16:00:51.668235 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
16:00:51.670493 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:00:51.671854 [info ] [MainThread]: 
16:00:51.673048 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
16:00:51.674478 [info ] [MainThread]: 
16:00:51.676152 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=4 SKIP=0 TOTAL=11
16:00:51.677913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fb327190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f9e83350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f9e83990>]}


============================== 2022-01-23 16:03:02.830368 | 7c0916f2-e8cf-448e-818f-2ba2d2756b7f ==============================
16:03:02.830368 [info ] [MainThread]: Running with dbt=1.0.1
16:03:02.831826 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
16:03:02.832715 [debug] [MainThread]: Tracking: tracking
16:03:02.834016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe283bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe283b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe283bbd0>]}
16:03:02.893118 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
16:03:02.894734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe17dff90>]}
16:03:02.958039 [debug] [MainThread]: Parsing macros/adapters.sql
16:03:03.115810 [debug] [MainThread]: Parsing macros/catalog.sql
16:03:03.122666 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
16:03:03.157040 [debug] [MainThread]: Parsing macros/materializations/merge.sql
16:03:03.170722 [debug] [MainThread]: Parsing macros/materializations/seed.sql
16:03:03.190016 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
16:03:03.193330 [debug] [MainThread]: Parsing macros/materializations/table.sql
16:03:03.204627 [debug] [MainThread]: Parsing macros/materializations/view.sql
16:03:03.209657 [debug] [MainThread]: Parsing macros/adapters/columns.sql
16:03:03.257445 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
16:03:03.266545 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
16:03:03.274730 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
16:03:03.301110 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
16:03:03.317129 [debug] [MainThread]: Parsing macros/adapters/relation.sql
16:03:03.364094 [debug] [MainThread]: Parsing macros/adapters/schema.sql
16:03:03.373293 [debug] [MainThread]: Parsing macros/etc/datetime.sql
16:03:03.407255 [debug] [MainThread]: Parsing macros/etc/statement.sql
16:03:03.420739 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
16:03:03.425541 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
16:03:03.427692 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
16:03:03.430053 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
16:03:03.432419 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
16:03:03.437434 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
16:03:03.441520 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
16:03:03.448088 [debug] [MainThread]: Parsing macros/materializations/configs.sql
16:03:03.456222 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
16:03:03.468279 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
16:03:03.536247 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
16:03:03.558300 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
16:03:03.602954 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
16:03:03.649398 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
16:03:03.654830 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
16:03:03.714955 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
16:03:03.720849 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
16:03:03.736203 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
16:03:03.741903 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
16:03:03.755722 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
16:03:03.791708 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
16:03:03.796063 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
16:03:03.838875 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
16:03:03.901397 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
16:03:03.913412 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
16:03:03.943021 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
16:03:03.951155 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
16:03:03.958649 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
16:03:03.962432 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
16:03:04.045415 [debug] [MainThread]: Parsing tests/generic/builtin.sql
16:03:04.697675 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
16:03:04.730677 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
16:03:04.751827 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
16:03:04.755410 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
16:03:04.766400 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
16:03:04.769474 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
16:03:04.780346 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
16:03:04.783606 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
16:03:04.791113 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
16:03:04.796915 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
16:03:05.092793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe9146250>]}
16:03:05.111131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe132f650>]}
16:03:05.112047 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
16:03:05.115996 [info ] [MainThread]: 
16:03:05.117692 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:03:05.121906 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:03:05.163329 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:03:05.164254 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:03:05.164807 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:03:06.242777 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.08 seconds
16:03:06.246861 [debug] [ThreadPool]: On list_analytics: Close
16:03:06.368151 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:03:06.394525 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:03:06.395320 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:03:06.395907 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:03:07.203975 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.81 seconds
16:03:07.216292 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:03:07.391049 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:03:07.394877 [info ] [MainThread]: 
16:03:07.404645 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
16:03:07.406286 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
16:03:07.423308 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:03:07.424376 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
16:03:07.425544 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
16:03:07.432430 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
16:03:07.438314 [debug] [Thread-1  ]: finished collecting timing info
16:03:07.439752 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
16:03:07.521631 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
16:03:07.527222 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:03:07.527960 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
16:03:07.528365 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:09.555281 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.03 seconds
16:03:09.595587 [debug] [Thread-1  ]: finished collecting timing info
16:03:09.596381 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
16:03:09.729946 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe00d3050>]}
16:03:09.731131 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.31s]
16:03:09.732208 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
16:03:09.733196 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
16:03:09.734997 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
16:03:09.736540 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
16:03:09.737275 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
16:03:09.738345 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
16:03:09.753917 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
16:03:09.758598 [debug] [Thread-1  ]: finished collecting timing info
16:03:09.759568 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
16:03:09.841354 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:09.842198 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
16:03:09.842755 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:11.092094 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.25 seconds
16:03:11.130102 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:11.130935 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
16:03:11.233565 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
16:03:11.250859 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:11.251738 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
16:03:11.335804 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
16:03:11.371247 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:11.372048 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
16:03:11.462593 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
16:03:11.553631 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
16:03:11.564327 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:11.565195 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
16:03:11.689898 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
16:03:11.693109 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:11.695339 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
16:03:12.224845 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.53 seconds
16:03:12.227183 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:12.229143 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
16:03:12.387170 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
16:03:12.400666 [debug] [Thread-1  ]: finished collecting timing info
16:03:12.402387 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
16:03:12.542256 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda0fa710>]}
16:03:12.543971 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.81s]
16:03:12.545685 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
16:03:12.547027 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
16:03:12.549191 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
16:03:12.551683 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
16:03:12.552715 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
16:03:12.553851 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
16:03:12.564228 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
16:03:12.569961 [debug] [Thread-1  ]: finished collecting timing info
16:03:12.571043 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
16:03:12.580703 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:12.581436 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
16:03:12.582096 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:14.102010 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
16:03:14.112105 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:14.113026 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
16:03:14.220160 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
16:03:14.240265 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:14.241260 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
16:03:14.319025 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
16:03:14.328711 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:14.329423 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
16:03:14.408250 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
16:03:14.419081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
16:03:14.426122 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:14.426787 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
16:03:14.535970 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
16:03:14.538735 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:14.540636 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
16:03:15.034923 [debug] [Thread-1  ]: SQL status: SUCCESS 249 in 0.49 seconds
16:03:15.035641 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:15.036144 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
16:03:15.267873 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
16:03:15.272125 [debug] [Thread-1  ]: finished collecting timing info
16:03:15.280844 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
16:03:15.418943 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda0acd10>]}
16:03:15.420446 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.87s]
16:03:15.421718 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
16:03:15.422969 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
16:03:15.424250 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
16:03:15.425619 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
16:03:15.426443 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
16:03:15.427408 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
16:03:15.439182 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
16:03:15.443200 [debug] [Thread-1  ]: finished collecting timing info
16:03:15.444248 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
16:03:15.451407 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
16:03:15.456456 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:03:15.457207 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
16:03:15.457890 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:16.713895 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.26 seconds
16:03:16.726387 [debug] [Thread-1  ]: finished collecting timing info
16:03:16.727859 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
16:03:16.861178 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda0d1a10>]}
16:03:16.863998 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.44s]
16:03:16.866222 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
16:03:16.867969 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
16:03:16.870399 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
16:03:16.872522 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
16:03:16.873663 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
16:03:16.874790 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
16:03:16.884210 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
16:03:16.888989 [debug] [Thread-1  ]: finished collecting timing info
16:03:16.889960 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
16:03:16.895463 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
16:03:16.901006 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
16:03:16.902039 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
16:03:16.902750 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:23.296444 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.39 seconds
16:03:23.309709 [debug] [Thread-1  ]: finished collecting timing info
16:03:23.311560 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
16:03:23.441868 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe0099550>]}
16:03:23.444823 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.57s]
16:03:23.447293 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
16:03:23.448970 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
16:03:23.451198 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
16:03:23.453414 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:03:23.454507 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
16:03:23.455514 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
16:03:23.463719 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
16:03:23.467656 [debug] [Thread-1  ]: finished collecting timing info
16:03:23.468811 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
16:03:23.476233 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
16:03:23.482257 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:03:23.483211 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
16:03:23.484076 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:25.425392 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.94 seconds
16:03:25.436813 [debug] [Thread-1  ]: finished collecting timing info
16:03:25.438104 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
16:03:25.588439 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda095650>]}
16:03:25.589689 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.14s]
16:03:25.590976 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
16:03:25.591745 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
16:03:25.593623 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
16:03:25.595435 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
16:03:25.596291 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
16:03:25.597291 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
16:03:25.602891 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
16:03:25.606951 [debug] [Thread-1  ]: finished collecting timing info
16:03:25.608020 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
16:03:25.616694 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
16:03:25.621259 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
16:03:25.622048 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
16:03:25.622738 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:27.174966 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
16:03:27.179012 [debug] [Thread-1  ]: finished collecting timing info
16:03:27.179717 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
16:03:27.318869 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c0916f2-e8cf-448e-818f-2ba2d2756b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda0b13d0>]}
16:03:27.319972 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.72s]
16:03:27.320885 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
16:03:27.340816 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:03:27.342993 [info ] [MainThread]: 
16:03:27.344664 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 22.23s.
16:03:27.346311 [debug] [MainThread]: Connection 'master' was properly closed.
16:03:27.347415 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
16:03:27.374386 [info ] [MainThread]: 
16:03:27.377656 [info ] [MainThread]: [32mCompleted successfully[0m
16:03:27.379857 [info ] [MainThread]: 
16:03:27.384005 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
16:03:27.385869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda1252d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda0c35d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fda0c3e90>]}


============================== 2022-01-23 16:03:38.703941 | 5b5a1434-57da-4e0d-bc6c-99a463323e97 ==============================
16:03:38.703941 [info ] [MainThread]: Running with dbt=1.0.1
16:03:38.705705 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
16:03:38.706578 [debug] [MainThread]: Tracking: tracking
16:03:38.707873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91ae90c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91ae90950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91ae90c90>]}
16:03:38.828007 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:03:38.828848 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:03:38.846109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b5a1434-57da-4e0d-bc6c-99a463323e97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb919d55510>]}
16:03:38.864506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b5a1434-57da-4e0d-bc6c-99a463323e97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91ae4f1d0>]}
16:03:38.865380 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
16:03:38.870964 [info ] [MainThread]: 
16:03:38.873069 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:03:38.876636 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:03:38.915353 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:03:38.916174 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:03:38.916851 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:03:40.163527 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.25 seconds
16:03:40.168713 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:03:40.317368 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:03:40.319165 [info ] [MainThread]: 
16:03:40.327383 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:03:40.328247 [info ] [Thread-1  ]: 1 of 11 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
16:03:40.329874 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:03:40.330825 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:03:40.331886 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:03:40.380045 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:03:40.384461 [debug] [Thread-1  ]: finished collecting timing info
16:03:40.385254 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:03:40.436854 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:03:40.442452 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:03:40.443197 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
16:03:40.443736 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:41.611824 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.17 seconds
16:03:41.623571 [debug] [Thread-1  ]: finished collecting timing info
16:03:41.624678 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
16:03:41.788289 [info ] [Thread-1  ]: 1 of 11 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.46s]
16:03:41.791137 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:03:41.793140 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
16:03:41.795510 [info ] [Thread-1  ]: 2 of 11 START test assert_under_100m............................................ [RUN]
16:03:41.797516 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
16:03:41.798914 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
16:03:41.800176 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
16:03:41.810643 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
16:03:41.813798 [debug] [Thread-1  ]: finished collecting timing info
16:03:41.814591 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
16:03:41.820122 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
16:03:41.826668 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
16:03:41.827510 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
16:03:41.828281 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:42.878890 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1d323-0000-1e52-0000-000298a252ad
16:03:42.879751 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000979 (42601): SQL compilation error:
[SUM(C_ACCTBAL)] is not a valid group by expression
16:03:42.880718 [debug] [Thread-1  ]: finished collecting timing info
16:03:42.881477 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
16:03:43.039049 [debug] [Thread-1  ]: Database Error in test assert_under_100m (tests/assert_under_100m.sql)
  000979 (42601): SQL compilation error:
  [SUM(C_ACCTBAL)] is not a valid group by expression
  compiled SQL at target/run/dbt_tests/tests/assert_under_100m.sql
16:03:43.040954 [error] [Thread-1  ]: 2 of 11 ERROR assert_under_100m................................................. [[31mERROR[0m in 1.24s]
16:03:43.043364 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
16:03:43.045148 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
16:03:43.047097 [info ] [Thread-1  ]: 3 of 11 START test assert_under_10_percent_null................................. [RUN]
16:03:43.049293 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:03:43.050514 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
16:03:43.051541 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
16:03:43.059407 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:03:43.062754 [debug] [Thread-1  ]: finished collecting timing info
16:03:43.063693 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
16:03:43.071205 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:03:43.077158 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:03:43.078037 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
16:03:43.079089 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:43.900721 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
16:03:43.913621 [debug] [Thread-1  ]: finished collecting timing info
16:03:43.915075 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
16:03:44.046296 [error] [Thread-1  ]: 3 of 11 FAIL 1 assert_under_10_percent_null..................................... [[31mFAIL 1[0m in 1.00s]
16:03:44.049494 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
16:03:44.052614 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:03:44.055001 [info ] [Thread-1  ]: 4 of 11 START test not_null_my_second_dbt_model_id.............................. [RUN]
16:03:44.057718 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:03:44.058910 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:03:44.060230 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:03:44.084511 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:03:44.089717 [debug] [Thread-1  ]: finished collecting timing info
16:03:44.091015 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:03:44.095733 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:03:44.100809 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:03:44.101620 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
16:03:44.102556 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:45.074623 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
16:03:45.086021 [debug] [Thread-1  ]: finished collecting timing info
16:03:45.087557 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: Close
16:03:45.259157 [error] [Thread-1  ]: 4 of 11 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.20s]
16:03:45.261456 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:03:45.263688 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:03:45.265622 [info ] [Thread-1  ]: 5 of 11 START test not_null_playing_with_tests_c_custkey........................ [RUN]
16:03:45.268535 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:03:45.270833 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:03:45.271770 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:03:45.284263 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:03:45.290937 [debug] [Thread-1  ]: finished collecting timing info
16:03:45.291849 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:03:45.296447 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:03:45.302485 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:03:45.303669 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
16:03:45.304701 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:46.122937 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
16:03:46.131648 [debug] [Thread-1  ]: finished collecting timing info
16:03:46.133066 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
16:03:46.262086 [info ] [Thread-1  ]: 5 of 11 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.99s]
16:03:46.264258 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:03:46.266669 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:03:46.269426 [info ] [Thread-1  ]: 6 of 11 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
16:03:46.271320 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:03:46.272649 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:03:46.274018 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:03:46.297937 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:03:46.302518 [debug] [Thread-1  ]: finished collecting timing info
16:03:46.303634 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:03:46.309816 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:03:46.315326 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:03:46.316187 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
16:03:46.316942 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:47.143133 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
16:03:47.153984 [debug] [Thread-1  ]: finished collecting timing info
16:03:47.155261 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
16:03:47.293676 [info ] [Thread-1  ]: 6 of 11 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.02s]
16:03:47.295342 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:03:47.297038 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:03:47.298874 [info ] [Thread-1  ]: 7 of 11 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
16:03:47.301497 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:03:47.303676 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:03:47.304919 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:03:47.332234 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:03:47.337633 [debug] [Thread-1  ]: finished collecting timing info
16:03:47.338768 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:03:47.343757 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:03:47.349769 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:03:47.350701 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
16:03:47.351675 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:48.170318 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
16:03:48.178032 [debug] [Thread-1  ]: finished collecting timing info
16:03:48.179323 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
16:03:48.301521 [error] [Thread-1  ]: 7 of 11 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [[31mFAIL 1[0m in 1.00s]
16:03:48.303325 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:03:48.304946 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:03:48.306890 [info ] [Thread-1  ]: 8 of 11 START test unique_my_first_dbt_model_id................................. [RUN]
16:03:48.309006 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:03:48.309942 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:03:48.311297 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:03:48.332798 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:03:48.337572 [debug] [Thread-1  ]: finished collecting timing info
16:03:48.338799 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:03:48.343960 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:03:48.349071 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:03:48.349937 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:03:48.350843 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:49.237317 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
16:03:49.251324 [debug] [Thread-1  ]: finished collecting timing info
16:03:49.252924 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
16:03:49.393334 [info ] [Thread-1  ]: 8 of 11 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.08s]
16:03:49.397228 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:03:49.400017 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:03:49.402758 [info ] [Thread-1  ]: 9 of 11 START test unique_my_second_dbt_model_id................................ [RUN]
16:03:49.404775 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:03:49.406138 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:03:49.407529 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:03:49.422141 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:03:49.426429 [debug] [Thread-1  ]: finished collecting timing info
16:03:49.427431 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:03:49.433919 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:03:49.439666 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:03:49.440292 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:03:49.440883 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:50.240704 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
16:03:50.252701 [debug] [Thread-1  ]: finished collecting timing info
16:03:50.254420 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
16:03:50.393419 [info ] [Thread-1  ]: 9 of 11 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 0.99s]
16:03:50.395074 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:03:50.396290 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:03:50.397422 [info ] [Thread-1  ]: 10 of 11 START test unique_playing_with_tests_c_custkey......................... [RUN]
16:03:50.399469 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:03:50.400628 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:03:50.401575 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:03:50.412599 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:03:50.418440 [debug] [Thread-1  ]: finished collecting timing info
16:03:50.419934 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:03:50.425124 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:03:50.431317 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:03:50.432275 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
16:03:50.433353 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:51.865233 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
16:03:51.877343 [debug] [Thread-1  ]: finished collecting timing info
16:03:51.878917 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
16:03:52.014640 [info ] [Thread-1  ]: 10 of 11 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.62s]
16:03:52.018088 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:03:52.020145 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:03:52.022220 [info ] [Thread-1  ]: 11 of 11 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
16:03:52.024631 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:03:52.025806 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:03:52.026899 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:03:52.038564 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:03:52.043127 [debug] [Thread-1  ]: finished collecting timing info
16:03:52.043945 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:03:52.049705 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:03:52.056591 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:03:52.057511 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
16:03:52.058463 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:52.969117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
16:03:52.975159 [debug] [Thread-1  ]: finished collecting timing info
16:03:52.976289 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
16:03:53.098604 [info ] [Thread-1  ]: 11 of 11 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.07s]
16:03:53.099838 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:03:53.155456 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:03:53.156938 [info ] [MainThread]: 
16:03:53.158141 [info ] [MainThread]: Finished running 11 tests in 14.28s.
16:03:53.159615 [debug] [MainThread]: Connection 'master' was properly closed.
16:03:53.160809 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
16:03:53.183548 [info ] [MainThread]: 
16:03:53.185180 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
16:03:53.186772 [info ] [MainThread]: 
16:03:53.187996 [error] [MainThread]: [33mDatabase Error in test assert_under_100m (tests/assert_under_100m.sql)[0m
16:03:53.189121 [error] [MainThread]:   000979 (42601): SQL compilation error:
16:03:53.190173 [error] [MainThread]:   [SUM(C_ACCTBAL)] is not a valid group by expression
16:03:53.191706 [error] [MainThread]:   compiled SQL at target/run/dbt_tests/tests/assert_under_100m.sql
16:03:53.192761 [info ] [MainThread]: 
16:03:53.194089 [error] [MainThread]: [31mFailure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)[0m
16:03:53.195380 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:03:53.196766 [info ] [MainThread]: 
16:03:53.199013 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/tests/assert_under_10_percent_null.sql
16:03:53.200599 [info ] [MainThread]: 
16:03:53.202641 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
16:03:53.204267 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:03:53.205567 [info ] [MainThread]: 
16:03:53.206684 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
16:03:53.208110 [info ] [MainThread]: 
16:03:53.209333 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
16:03:53.210675 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:03:53.212013 [info ] [MainThread]: 
16:03:53.213411 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
16:03:53.215258 [info ] [MainThread]: 
16:03:53.217483 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=4 SKIP=0 TOTAL=11
16:03:53.220703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91893f1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91826ea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91826e350>]}


============================== 2022-01-23 16:05:51.890165 | 0312c23b-1e12-464b-a314-2243a66e9b96 ==============================
16:05:51.890165 [info ] [MainThread]: Running with dbt=1.0.1
16:05:51.891466 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
16:05:51.892368 [debug] [MainThread]: Tracking: tracking
16:05:51.894254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfc1f1d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfc1f1c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfc1f1d90>]}
16:05:52.003310 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:05:52.004359 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://tests/assert_under_100m.sql
16:05:52.098400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfc0c5110>]}
16:05:52.118331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfc17ad10>]}
16:05:52.119614 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
16:05:52.124405 [info ] [MainThread]: 
16:05:52.126440 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:05:52.130540 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:05:52.233608 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:05:52.234339 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:05:52.234886 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:05:53.368254 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.13 seconds
16:05:53.372736 [debug] [ThreadPool]: On list_analytics: Close
16:05:53.527155 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:05:53.552045 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:05:53.552880 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:05:53.553492 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:05:54.360008 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.81 seconds
16:05:54.372057 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:05:54.531420 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:05:54.533894 [info ] [MainThread]: 
16:05:54.542320 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
16:05:54.544167 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
16:05:54.546857 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:05:54.548130 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
16:05:54.549521 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
16:05:54.556826 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
16:05:54.562142 [debug] [Thread-1  ]: finished collecting timing info
16:05:54.563240 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
16:05:54.645799 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
16:05:54.651616 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:05:54.652406 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
16:05:54.653086 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:56.913225 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.26 seconds
16:05:56.958346 [debug] [Thread-1  ]: finished collecting timing info
16:05:56.959604 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
16:05:57.095171 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfd2a82d0>]}
16:05:57.097329 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.55s]
16:05:57.099566 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
16:05:57.101016 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
16:05:57.103438 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
16:05:57.105603 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
16:05:57.106683 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
16:05:57.108085 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
16:05:57.137944 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
16:05:57.142902 [debug] [Thread-1  ]: finished collecting timing info
16:05:57.144104 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
16:05:57.221545 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:05:57.222625 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
16:05:57.223424 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:59.524529 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.3 seconds
16:05:59.560693 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:05:59.561596 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
16:05:59.653694 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
16:05:59.674323 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:05:59.675365 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
16:05:59.743974 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.07 seconds
16:05:59.782907 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:05:59.783563 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
16:05:59.875175 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
16:05:59.986710 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
16:05:59.997244 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:05:59.998017 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
16:06:00.098588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
16:06:00.100060 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:06:00.100715 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
16:06:00.458920 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
16:06:00.459870 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:06:00.460460 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
16:06:00.591675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
16:06:00.595801 [debug] [Thread-1  ]: finished collecting timing info
16:06:00.596762 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
16:06:00.732033 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf6c25210>]}
16:06:00.734013 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.63s]
16:06:00.735478 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
16:06:00.736883 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
16:06:00.738890 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
16:06:00.741297 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
16:06:00.742366 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
16:06:00.743480 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
16:06:00.752358 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
16:06:00.757033 [debug] [Thread-1  ]: finished collecting timing info
16:06:00.758243 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
16:06:00.768273 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:00.769094 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
16:06:00.769707 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:02.299648 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
16:06:02.307051 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:02.307915 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
16:06:02.414763 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
16:06:02.424096 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:02.424913 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
16:06:02.516605 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
16:06:02.533712 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:02.534628 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
16:06:02.634943 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
16:06:02.655626 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
16:06:02.663960 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:02.664705 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
16:06:02.786345 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
16:06:02.792837 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:02.794454 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
16:06:03.368826 [debug] [Thread-1  ]: SQL status: SUCCESS 168 in 0.57 seconds
16:06:03.369498 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:06:03.370015 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
16:06:03.604673 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
16:06:03.610031 [debug] [Thread-1  ]: finished collecting timing info
16:06:03.611094 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
16:06:03.861737 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf4f265d0>]}
16:06:03.863493 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.12s]
16:06:03.864919 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
16:06:03.866461 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
16:06:03.868319 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
16:06:03.870040 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
16:06:03.871038 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
16:06:03.872224 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
16:06:03.881164 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
16:06:03.884954 [debug] [Thread-1  ]: finished collecting timing info
16:06:03.885923 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
16:06:03.892886 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
16:06:03.898505 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:06:03.899320 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
16:06:03.900091 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:05.446028 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
16:06:05.451702 [debug] [Thread-1  ]: finished collecting timing info
16:06:05.452891 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
16:06:05.630732 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf6b9a4d0>]}
16:06:05.634484 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.76s]
16:06:05.637534 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
16:06:05.640621 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
16:06:05.643378 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
16:06:05.645719 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
16:06:05.646942 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
16:06:05.648030 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
16:06:05.658601 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
16:06:05.662655 [debug] [Thread-1  ]: finished collecting timing info
16:06:05.663654 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
16:06:05.669236 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
16:06:05.675096 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
16:06:05.676087 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
16:06:05.676875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:12.181316 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.5 seconds
16:06:12.196245 [debug] [Thread-1  ]: finished collecting timing info
16:06:12.197663 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
16:06:12.361510 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf4e68b10>]}
16:06:12.363790 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.72s]
16:06:12.366051 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
16:06:12.367523 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
16:06:12.369860 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
16:06:12.372141 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:06:12.373399 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
16:06:12.374611 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
16:06:12.389552 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
16:06:12.393530 [debug] [Thread-1  ]: finished collecting timing info
16:06:12.394641 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
16:06:12.406050 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
16:06:12.411436 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:06:12.412290 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
16:06:12.413079 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:14.123025 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
16:06:14.130130 [debug] [Thread-1  ]: finished collecting timing info
16:06:14.131404 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
16:06:14.276869 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf6c4c250>]}
16:06:14.279763 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.90s]
16:06:14.282271 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
16:06:14.284109 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
16:06:14.286714 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
16:06:14.288493 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
16:06:14.289702 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
16:06:14.290875 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
16:06:14.298581 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
16:06:14.303856 [debug] [Thread-1  ]: finished collecting timing info
16:06:14.304621 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
16:06:14.312710 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
16:06:14.317620 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
16:06:14.318678 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
union all
select 7 as id
      );
16:06:14.319621 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:15.692132 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
16:06:15.696150 [debug] [Thread-1  ]: finished collecting timing info
16:06:15.696826 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
16:06:15.828083 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0312c23b-1e12-464b-a314-2243a66e9b96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf6c652d0>]}
16:06:15.833197 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.54s]
16:06:15.834857 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
16:06:15.938341 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:06:15.942828 [info ] [MainThread]: 
16:06:15.945980 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 23.82s.
16:06:15.951006 [debug] [MainThread]: Connection 'master' was properly closed.
16:06:15.954638 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
16:06:15.987363 [info ] [MainThread]: 
16:06:15.988696 [info ] [MainThread]: [32mCompleted successfully[0m
16:06:15.990179 [info ] [MainThread]: 
16:06:15.991980 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
16:06:15.993313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bfc1d8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf4f11350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf4f115d0>]}


============================== 2022-01-23 16:06:31.734522 | 356b7ae9-8bf8-499e-bb8c-0f98cabe40da ==============================
16:06:31.734522 [info ] [MainThread]: Running with dbt=1.0.1
16:06:31.735929 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
16:06:31.736842 [debug] [MainThread]: Tracking: tracking
16:06:31.738215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41714ecc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41714ecad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41714ecc10>]}
16:06:31.855756 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:06:31.856607 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:06:31.874272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '356b7ae9-8bf8-499e-bb8c-0f98cabe40da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41703d3650>]}
16:06:31.893688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '356b7ae9-8bf8-499e-bb8c-0f98cabe40da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4171553250>]}
16:06:31.894949 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
16:06:31.900053 [info ] [MainThread]: 
16:06:31.901761 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:06:31.905865 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:06:31.951238 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:06:31.951926 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:06:31.952448 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:06:33.252200 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.3 seconds
16:06:33.259362 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:06:33.410842 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:06:33.412415 [info ] [MainThread]: 
16:06:33.419243 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:06:33.419958 [info ] [Thread-1  ]: 1 of 11 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
16:06:33.421292 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:06:33.422328 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:06:33.423414 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:06:33.469395 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:06:33.473540 [debug] [Thread-1  ]: finished collecting timing info
16:06:33.474730 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:06:33.529398 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:06:33.535853 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
16:06:33.536592 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
16:06:33.537350 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:34.831620 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
16:06:34.844257 [debug] [Thread-1  ]: finished collecting timing info
16:06:34.845505 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
16:06:34.994387 [info ] [Thread-1  ]: 1 of 11 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.57s]
16:06:34.995943 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
16:06:34.997230 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
16:06:34.998643 [info ] [Thread-1  ]: 2 of 11 START test assert_under_100m............................................ [RUN]
16:06:35.000878 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
16:06:35.001892 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
16:06:35.002993 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
16:06:35.012206 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
16:06:35.016372 [debug] [Thread-1  ]: finished collecting timing info
16:06:35.017361 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
16:06:35.021955 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
16:06:35.027728 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
16:06:35.028786 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
16:06:35.029665 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:36.682290 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
16:06:36.694292 [debug] [Thread-1  ]: finished collecting timing info
16:06:36.695892 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
16:06:36.873883 [info ] [Thread-1  ]: 2 of 11 PASS assert_under_100m.................................................. [[32mPASS[0m in 1.87s]
16:06:36.875705 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
16:06:36.877430 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
16:06:36.879133 [info ] [Thread-1  ]: 3 of 11 START test assert_under_10_percent_null................................. [RUN]
16:06:36.880567 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:06:36.881558 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
16:06:36.882855 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
16:06:36.889331 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:06:36.893853 [debug] [Thread-1  ]: finished collecting timing info
16:06:36.895368 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
16:06:36.901680 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:06:36.907119 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:06:36.908104 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
16:06:36.908758 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:37.912302 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
16:06:37.917344 [debug] [Thread-1  ]: finished collecting timing info
16:06:37.918130 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
16:06:38.097059 [error] [Thread-1  ]: 3 of 11 FAIL 1 assert_under_10_percent_null..................................... [[31mFAIL 1[0m in 1.22s]
16:06:38.099401 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
16:06:38.101523 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:06:38.103809 [info ] [Thread-1  ]: 4 of 11 START test not_null_my_second_dbt_model_id.............................. [RUN]
16:06:38.105647 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:06:38.107367 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:06:38.108949 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:06:38.129137 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:06:38.133600 [debug] [Thread-1  ]: finished collecting timing info
16:06:38.134611 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:06:38.139708 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:06:38.145207 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"
16:06:38.145946 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
16:06:38.146521 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:39.150991 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
16:06:39.159168 [debug] [Thread-1  ]: finished collecting timing info
16:06:39.160237 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778: Close
16:06:39.332637 [error] [Thread-1  ]: 4 of 11 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.23s]
16:06:39.333508 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_second_dbt_model_id.151b76d778
16:06:39.334615 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:06:39.335666 [info ] [Thread-1  ]: 5 of 11 START test not_null_playing_with_tests_c_custkey........................ [RUN]
16:06:39.337066 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:06:39.337875 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:06:39.338724 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:06:39.352444 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:06:39.357241 [debug] [Thread-1  ]: finished collecting timing info
16:06:39.359025 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:06:39.363910 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:06:39.369132 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
16:06:39.369974 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
16:06:39.370723 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:40.262826 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
16:06:40.272734 [debug] [Thread-1  ]: finished collecting timing info
16:06:40.274343 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
16:06:40.403588 [info ] [Thread-1  ]: 5 of 11 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.07s]
16:06:40.404836 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
16:06:40.406133 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:06:40.407249 [info ] [Thread-1  ]: 6 of 11 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
16:06:40.408287 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:06:40.408997 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:06:40.409843 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:06:40.425453 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:06:40.430296 [debug] [Thread-1  ]: finished collecting timing info
16:06:40.431096 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:06:40.435835 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:06:40.443108 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
16:06:40.443894 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
16:06:40.444516 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:41.340818 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
16:06:41.345793 [debug] [Thread-1  ]: finished collecting timing info
16:06:41.346903 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
16:06:41.483269 [info ] [Thread-1  ]: 6 of 11 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.08s]
16:06:41.484817 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
16:06:41.486216 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:06:41.487902 [info ] [Thread-1  ]: 7 of 11 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
16:06:41.490116 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:06:41.491337 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:06:41.492510 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:06:41.519633 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:06:41.525555 [debug] [Thread-1  ]: finished collecting timing info
16:06:41.526929 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:06:41.532991 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:06:41.540633 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:06:41.541999 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
16:06:41.542691 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:42.807814 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
16:06:42.811766 [debug] [Thread-1  ]: finished collecting timing info
16:06:42.812565 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
16:06:42.979262 [error] [Thread-1  ]: 7 of 11 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [[31mFAIL 1[0m in 1.49s]
16:06:42.980714 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:06:42.981720 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:06:42.982986 [info ] [Thread-1  ]: 8 of 11 START test unique_my_first_dbt_model_id................................. [RUN]
16:06:42.984243 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:06:42.985018 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:06:42.985938 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:06:43.008491 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:06:43.013779 [debug] [Thread-1  ]: finished collecting timing info
16:06:43.014837 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:06:43.019877 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:06:43.025799 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:06:43.026765 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:06:43.027609 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:43.845984 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
16:06:43.854157 [debug] [Thread-1  ]: finished collecting timing info
16:06:43.855710 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
16:06:43.994870 [info ] [Thread-1  ]: 8 of 11 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.01s]
16:06:43.996298 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:06:43.997549 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:06:43.999324 [info ] [Thread-1  ]: 9 of 11 START test unique_my_second_dbt_model_id................................ [RUN]
16:06:44.001211 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:06:44.002297 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:06:44.003130 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:06:44.017445 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:06:44.021311 [debug] [Thread-1  ]: finished collecting timing info
16:06:44.023245 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:06:44.031182 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:06:44.037563 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
16:06:44.038606 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:06:44.039588 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:45.060445 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
16:06:45.064370 [debug] [Thread-1  ]: finished collecting timing info
16:06:45.065180 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
16:06:45.206512 [info ] [Thread-1  ]: 9 of 11 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 1.21s]
16:06:45.208996 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
16:06:45.211802 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:06:45.214165 [info ] [Thread-1  ]: 10 of 11 START test unique_playing_with_tests_c_custkey......................... [RUN]
16:06:45.216175 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:06:45.217931 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:06:45.219433 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:06:45.232804 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:06:45.237755 [debug] [Thread-1  ]: finished collecting timing info
16:06:45.239125 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:06:45.245229 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:06:45.251324 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
16:06:45.252264 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
16:06:45.252923 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:46.782889 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
16:06:46.789830 [debug] [Thread-1  ]: finished collecting timing info
16:06:46.791072 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
16:06:46.945747 [info ] [Thread-1  ]: 10 of 11 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.73s]
16:06:46.947032 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
16:06:46.948474 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:06:46.949977 [info ] [Thread-1  ]: 11 of 11 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
16:06:46.951357 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:06:46.952360 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:06:46.953455 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:06:46.965277 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:06:46.969740 [debug] [Thread-1  ]: finished collecting timing info
16:06:46.970854 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:06:46.977738 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:06:46.983909 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
16:06:46.984846 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
16:06:46.985954 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:47.979135 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
16:06:47.986704 [debug] [Thread-1  ]: finished collecting timing info
16:06:47.988018 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
16:06:48.116349 [info ] [Thread-1  ]: 11 of 11 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.17s]
16:06:48.117506 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
16:06:48.162879 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:06:48.164490 [info ] [MainThread]: 
16:06:48.165298 [info ] [MainThread]: Finished running 11 tests in 16.26s.
16:06:48.166757 [debug] [MainThread]: Connection 'master' was properly closed.
16:06:48.167952 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
16:06:48.192675 [info ] [MainThread]: 
16:06:48.193893 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
16:06:48.196704 [info ] [MainThread]: 
16:06:48.198371 [error] [MainThread]: [31mFailure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)[0m
16:06:48.199989 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:06:48.201419 [info ] [MainThread]: 
16:06:48.204754 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/tests/assert_under_10_percent_null.sql
16:06:48.206455 [info ] [MainThread]: 
16:06:48.211433 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
16:06:48.212550 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:06:48.214212 [info ] [MainThread]: 
16:06:48.215544 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
16:06:48.217139 [info ] [MainThread]: 
16:06:48.218617 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
16:06:48.221335 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:06:48.224063 [info ] [MainThread]: 
16:06:48.226490 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
16:06:48.228085 [info ] [MainThread]: 
16:06:48.229403 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=3 SKIP=0 TOTAL=11
16:06:48.231351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41714f1d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41691a5650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f416af6b510>]}


============================== 2022-01-24 04:39:18.429032 | db137e2f-401b-4fdd-85aa-f45356a11657 ==============================
04:39:18.429032 [info ] [MainThread]: Running with dbt=1.0.1
04:39:18.430966 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['new'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:39:18.431787 [debug] [MainThread]: Tracking: tracking
04:39:18.433044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf27cd1f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf27cd1bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf27cd1ed0>]}
04:39:18.570858 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
04:39:18.571900 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/new/dates.sql
04:39:18.573067 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/new/schema.yml
04:39:18.609219 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
04:39:18.666053 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
04:39:18.667157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf26bdd890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf26beaf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf26beae10>]}


============================== 2022-01-24 04:39:52.617174 | 0ff6cc6a-b012-43af-91ab-79dbf1c78772 ==============================
04:39:52.617174 [info ] [MainThread]: Running with dbt=1.0.1
04:39:52.618592 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['new.dates'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:39:52.619635 [debug] [MainThread]: Tracking: tracking
04:39:52.620824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ac92dfd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ac92dfad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ac92dfe10>]}
04:39:52.743933 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
04:39:52.745553 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/new/dates.sql
04:39:52.747071 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/new/schema.yml
04:39:52.783373 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
04:39:52.836303 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
04:39:52.837364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ac819d790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ac81b3f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ac81a96d0>]}


============================== 2022-01-24 04:40:47.245778 | 504a7c9e-e547-4334-bd99-907a45cbb8e6 ==============================
04:40:47.245778 [info ] [MainThread]: Running with dbt=1.0.1
04:40:47.247257 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['new'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:40:47.248173 [debug] [MainThread]: Tracking: tracking
04:40:47.249604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33474eedd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33474eec50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33474eed90>]}
04:40:47.380580 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 2 files added, 0 files changed.
04:40:47.381714 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/new/dates.sql
04:40:47.382511 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/new/schema.yml
04:40:47.383105 [debug] [MainThread]: Partial parsing: deleted file: dbt_tests://models/example/dates.sql
04:40:47.418288 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
04:40:47.470888 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
04:40:47.528167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '504a7c9e-e547-4334-bd99-907a45cbb8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3346341950>]}
04:40:47.615498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '504a7c9e-e547-4334-bd99-907a45cbb8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3349d548d0>]}
04:40:47.616623 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
04:40:47.621337 [info ] [MainThread]: 
04:40:47.623790 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:40:47.625937 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:40:47.672910 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:40:47.674515 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:40:47.675468 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:40:48.974387 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.3 seconds
04:40:48.979406 [debug] [ThreadPool]: On list_analytics: Close
04:40:49.158674 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:40:49.183127 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:40:49.184019 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:40:49.184816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:40:50.254850 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.07 seconds
04:40:50.266009 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:40:50.443841 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:40:50.445767 [info ] [MainThread]: 
04:40:50.458125 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
04:40:50.459482 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
04:40:50.461268 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
04:40:50.462204 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
04:40:50.463395 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
04:40:50.481928 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
04:40:50.489951 [debug] [Thread-1  ]: finished collecting timing info
04:40:50.491311 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
04:40:50.644450 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:50.645297 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
04:40:50.645869 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:40:53.609333 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.96 seconds
04:40:53.673333 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:53.674303 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
04:40:53.797678 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
04:40:53.850110 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:53.851374 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
04:40:53.955703 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
04:40:54.006998 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:54.007920 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
04:40:54.100409 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
04:40:54.189100 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
04:40:54.202268 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:54.203697 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
04:40:54.315171 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
04:40:54.317630 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:54.319906 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
04:40:54.682007 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.36 seconds
04:40:54.682867 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:40:54.683828 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
04:40:54.847214 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
04:40:54.894377 [debug] [Thread-1  ]: finished collecting timing info
04:40:54.895188 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
04:40:55.049446 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '504a7c9e-e547-4334-bd99-907a45cbb8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3344f51ad0>]}
04:40:55.051592 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.59s]
04:40:55.054327 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
04:40:55.086765 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:40:55.088400 [info ] [MainThread]: 
04:40:55.090097 [info ] [MainThread]: Finished running 1 incremental model in 7.47s.
04:40:55.091756 [debug] [MainThread]: Connection 'master' was properly closed.
04:40:55.093134 [debug] [MainThread]: Connection 'model.dbt_tests.dates' was properly closed.
04:40:55.113667 [info ] [MainThread]: 
04:40:55.114980 [info ] [MainThread]: [32mCompleted successfully[0m
04:40:55.118566 [info ] [MainThread]: 
04:40:55.121059 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:40:55.122902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f334751c250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3344a1ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3344a1b050>]}


============================== 2022-01-24 08:44:43.087375 | f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc ==============================
08:44:43.087375 [info ] [MainThread]: Running with dbt=1.0.1
08:44:43.088969 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
08:44:43.090023 [debug] [MainThread]: Tracking: tracking
08:44:43.091197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa6cf8d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa6cf8a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa6cf8d90>]}
08:44:43.186265 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
08:44:43.187126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa6ca5fd0>]}
08:44:43.284094 [debug] [MainThread]: Parsing macros/adapters.sql
08:44:43.516393 [debug] [MainThread]: Parsing macros/catalog.sql
08:44:43.524397 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
08:44:43.573065 [debug] [MainThread]: Parsing macros/materializations/merge.sql
08:44:43.591222 [debug] [MainThread]: Parsing macros/materializations/seed.sql
08:44:43.628497 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
08:44:43.636571 [debug] [MainThread]: Parsing macros/materializations/table.sql
08:44:43.649881 [debug] [MainThread]: Parsing macros/materializations/view.sql
08:44:43.655713 [debug] [MainThread]: Parsing macros/adapters/columns.sql
08:44:43.707654 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
08:44:43.720145 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
08:44:43.734230 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
08:44:43.771140 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
08:44:43.789384 [debug] [MainThread]: Parsing macros/adapters/relation.sql
08:44:43.868414 [debug] [MainThread]: Parsing macros/adapters/schema.sql
08:44:43.876707 [debug] [MainThread]: Parsing macros/etc/datetime.sql
08:44:43.937466 [debug] [MainThread]: Parsing macros/etc/statement.sql
08:44:43.969046 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
08:44:43.975009 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
08:44:43.979786 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
08:44:43.985133 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
08:44:43.987387 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
08:44:43.992879 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
08:44:44.004678 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
08:44:44.017737 [debug] [MainThread]: Parsing macros/materializations/configs.sql
08:44:44.034830 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
08:44:44.054240 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
08:44:44.167100 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
08:44:44.208059 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
08:44:44.285795 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
08:44:44.381290 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
08:44:44.387962 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
08:44:44.508105 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
08:44:44.519362 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
08:44:44.548790 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
08:44:44.555516 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
08:44:44.586957 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
08:44:44.657268 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
08:44:44.666414 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
08:44:44.746534 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
08:44:44.851935 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
08:44:44.871083 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
08:44:44.918537 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
08:44:44.935850 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
08:44:44.947448 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
08:44:44.951622 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
08:44:45.070950 [debug] [MainThread]: Parsing tests/generic/builtin.sql
08:44:46.151588 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
08:44:46.204345 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
08:44:46.237138 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
08:44:46.240798 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
08:44:46.254772 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
08:44:46.259196 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
08:44:46.271848 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
08:44:46.282641 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
08:44:46.289907 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
08:44:46.305830 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
08:44:46.824018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa9565390>]}
08:44:46.883796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa57d2110>]}
08:44:46.885206 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:44:46.892954 [info ] [MainThread]: 
08:44:46.900741 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:44:46.911191 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:44:47.035102 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:44:47.035915 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:44:47.036312 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:44:48.616686 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.58 seconds
08:44:48.621650 [debug] [ThreadPool]: On list_analytics: Close
08:44:48.813840 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:44:48.859861 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:44:48.867749 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:44:48.868723 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:44:50.038589 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.17 seconds
08:44:50.050261 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:44:50.225452 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:44:50.229218 [info ] [MainThread]: 
08:44:50.239133 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
08:44:50.242661 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
08:44:50.246005 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
08:44:50.247017 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
08:44:50.248156 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
08:44:50.256389 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
08:44:50.265049 [debug] [Thread-1  ]: finished collecting timing info
08:44:50.265821 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
08:44:50.363704 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
08:44:50.369958 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
08:44:50.370762 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
08:44:50.371247 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:44:52.628852 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.26 seconds
08:44:52.670886 [debug] [Thread-1  ]: finished collecting timing info
08:44:52.671920 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
08:44:52.843071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa43063d0>]}
08:44:52.845378 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.60s]
08:44:52.847164 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
08:44:52.848199 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
08:44:52.849194 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
08:44:52.850754 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
08:44:52.852567 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
08:44:52.853693 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
08:44:52.884202 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
08:44:52.887823 [debug] [Thread-1  ]: finished collecting timing info
08:44:52.888833 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
08:44:52.988488 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:52.990224 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
08:44:52.991204 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:44:54.874045 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
08:44:54.914738 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:54.915664 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
08:44:55.007602 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
08:44:55.021574 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:55.023253 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
08:44:55.104711 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
08:44:55.136091 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:55.136995 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
08:44:55.249809 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
08:44:55.357610 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
08:44:55.368439 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:55.369363 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
08:44:55.472705 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
08:44:55.473973 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:55.474851 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
08:44:55.881448 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.41 seconds
08:44:55.882586 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
08:44:55.883362 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
08:44:56.032217 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
08:44:56.039989 [debug] [Thread-1  ]: finished collecting timing info
08:44:56.041764 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
08:44:56.208487 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e5a6210>]}
08:44:56.210167 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.36s]
08:44:56.211544 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
08:44:56.212779 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
08:44:56.214667 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
08:44:56.216566 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
08:44:56.217702 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
08:44:56.218885 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
08:44:56.232996 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
08:44:56.237091 [debug] [Thread-1  ]: finished collecting timing info
08:44:56.240804 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
08:44:56.252131 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:56.253047 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
08:44:56.253933 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:44:57.650393 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
08:44:57.661364 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:57.662105 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
08:44:57.758765 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
08:44:57.767738 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:57.768384 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
08:44:57.855670 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
08:44:57.866830 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:57.867687 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
08:44:57.975336 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
08:44:58.011926 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
08:44:58.020321 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:58.022110 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
08:44:58.132834 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
08:44:58.134867 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:58.137160 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
08:44:58.349035 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.21 seconds
08:44:58.350448 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
08:44:58.351693 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
08:44:58.550388 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
08:44:58.565208 [debug] [Thread-1  ]: finished collecting timing info
08:44:58.566900 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
08:44:58.750441 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e5472d0>]}
08:44:58.751812 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.53s]
08:44:58.754615 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
08:44:58.756598 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
08:44:58.758756 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
08:44:58.761029 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
08:44:58.761633 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
08:44:58.762473 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
08:44:58.772319 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
08:44:58.779353 [debug] [Thread-1  ]: finished collecting timing info
08:44:58.780398 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
08:44:58.789781 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
08:44:58.797453 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
08:44:58.798714 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:44:58.799530 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:45:00.440304 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
08:45:00.444411 [debug] [Thread-1  ]: finished collecting timing info
08:45:00.445195 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
08:45:00.605417 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e58a450>]}
08:45:00.607614 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.84s]
08:45:00.609254 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
08:45:00.610764 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
08:45:00.612832 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
08:45:00.614384 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
08:45:00.615456 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
08:45:00.616249 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
08:45:00.627360 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
08:45:00.631824 [debug] [Thread-1  ]: finished collecting timing info
08:45:00.632693 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
08:45:00.641959 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
08:45:00.648333 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
08:45:00.649233 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
08:45:00.649746 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:45:06.818245 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.17 seconds
08:45:06.834499 [debug] [Thread-1  ]: finished collecting timing info
08:45:06.836212 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
08:45:07.015735 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e503610>]}
08:45:07.020453 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.40s]
08:45:07.022904 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
08:45:07.025293 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
08:45:07.027371 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
08:45:07.029021 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
08:45:07.030284 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
08:45:07.031166 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
08:45:07.041934 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
08:45:07.045385 [debug] [Thread-1  ]: finished collecting timing info
08:45:07.046152 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
08:45:07.059377 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
08:45:07.064541 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
08:45:07.065801 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
08:45:07.066831 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:45:09.347268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.28 seconds
08:45:09.355843 [debug] [Thread-1  ]: finished collecting timing info
08:45:09.357274 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
08:45:09.501940 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e512bd0>]}
08:45:09.504934 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.47s]
08:45:09.506980 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
08:45:09.508901 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
08:45:09.510839 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
08:45:09.512398 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
08:45:09.513395 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
08:45:09.514587 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
08:45:09.525207 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
08:45:09.528330 [debug] [Thread-1  ]: finished collecting timing info
08:45:09.529132 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
08:45:09.540436 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
08:45:09.545256 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
08:45:09.545972 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
08:45:09.546349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:45:11.360682 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
08:45:11.371926 [debug] [Thread-1  ]: finished collecting timing info
08:45:11.373488 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
08:45:11.579001 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0d71d6b-7d3a-48d8-b23c-73a5e7f857cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e4f8390>]}
08:45:11.581627 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.07s]
08:45:11.584619 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
08:45:11.659770 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:45:11.661128 [info ] [MainThread]: 
08:45:11.662713 [info ] [MainThread]: Running 3 on-run-end hooks
08:45:11.665560 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
08:45:11.673634 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
08:45:11.686044 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
08:45:11.689229 [debug] [MainThread]: Using snowflake connection "master"
08:45:11.690393 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:45:11.690981 [debug] [MainThread]: Opening a new connection, currently in state init
08:45:12.815283 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.12 seconds
08:45:12.818972 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.13s]
08:45:12.820819 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
08:45:12.825796 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
08:45:12.829404 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
08:45:12.832138 [debug] [MainThread]: Using snowflake connection "master"
08:45:12.834702 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:45:12.991329 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
08:45:12.994305 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
08:45:12.995744 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
08:45:13.002622 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
08:45:13.009107 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
08:45:13.011711 [debug] [MainThread]: Using snowflake connection "master"
08:45:13.013848 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:45:13.138693 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
08:45:13.141148 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
08:45:13.142154 [info ] [MainThread]: 
08:45:13.143160 [debug] [MainThread]: On master: Close
08:45:13.304641 [info ] [MainThread]: 
08:45:13.305863 [info ] [MainThread]: Finished running 5 table models, 2 incremental models, 3 hooks in 26.41s.
08:45:13.307070 [debug] [MainThread]: Connection 'master' was properly closed.
08:45:13.307986 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
08:45:13.339189 [info ] [MainThread]: 
08:45:13.340984 [info ] [MainThread]: [32mCompleted successfully[0m
08:45:13.342582 [info ] [MainThread]: 
08:45:13.344101 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
08:45:13.347325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fa953c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e588990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f9e588e50>]}


============================== 2022-01-24 11:54:41.468258 | 0b4079ec-3d7c-44d4-b869-ef5f8bc462c8 ==============================
11:54:41.468258 [info ] [MainThread]: Running with dbt=1.0.1
11:54:41.470364 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
11:54:41.471243 [debug] [MainThread]: Tracking: tracking
11:54:41.472270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617ecedd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617ececd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617eced50>]}
11:54:41.553277 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
11:54:41.554898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617e79fd0>]}
11:54:41.644910 [debug] [MainThread]: Parsing macros/adapters.sql
11:54:41.873515 [debug] [MainThread]: Parsing macros/catalog.sql
11:54:41.884246 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
11:54:41.924694 [debug] [MainThread]: Parsing macros/materializations/merge.sql
11:54:41.953190 [debug] [MainThread]: Parsing macros/materializations/seed.sql
11:54:41.981949 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
11:54:41.986306 [debug] [MainThread]: Parsing macros/materializations/table.sql
11:54:42.001097 [debug] [MainThread]: Parsing macros/materializations/view.sql
11:54:42.007382 [debug] [MainThread]: Parsing macros/adapters/columns.sql
11:54:42.055384 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
11:54:42.068207 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
11:54:42.078699 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
11:54:42.116370 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
11:54:42.133283 [debug] [MainThread]: Parsing macros/adapters/relation.sql
11:54:42.179152 [debug] [MainThread]: Parsing macros/adapters/schema.sql
11:54:42.188425 [debug] [MainThread]: Parsing macros/etc/datetime.sql
11:54:42.236969 [debug] [MainThread]: Parsing macros/etc/statement.sql
11:54:42.262879 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
11:54:42.269476 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
11:54:42.271533 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
11:54:42.275553 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
11:54:42.281290 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
11:54:42.292101 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
11:54:42.300005 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
11:54:42.308123 [debug] [MainThread]: Parsing macros/materializations/configs.sql
11:54:42.323699 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
11:54:42.341402 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
11:54:42.434422 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
11:54:42.466610 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
11:54:42.532226 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
11:54:42.595099 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
11:54:42.602398 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
11:54:42.707653 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
11:54:42.722385 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
11:54:42.753641 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
11:54:42.764162 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
11:54:42.783025 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
11:54:42.841035 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
11:54:42.852521 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
11:54:42.913836 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
11:54:43.005710 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
11:54:43.023304 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
11:54:43.068151 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
11:54:43.078933 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
11:54:43.089291 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
11:54:43.096361 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
11:54:43.211448 [debug] [MainThread]: Parsing tests/generic/builtin.sql
11:54:44.270269 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
11:54:44.322635 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
11:54:44.365713 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
11:54:44.369544 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
11:54:44.389898 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
11:54:44.398331 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
11:54:44.415092 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
11:54:44.431746 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
11:54:44.448578 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
11:54:44.463991 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
11:54:45.004586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617e2b850>]}
11:54:45.035080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617ebe190>]}
11:54:45.036169 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:54:45.040849 [info ] [MainThread]: 
11:54:45.045100 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:54:45.051041 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:54:45.132702 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:54:45.133354 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:54:45.133820 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:54:46.928790 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.79 seconds
11:54:46.935395 [debug] [ThreadPool]: On list_analytics: Close
11:54:47.121733 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:54:47.151022 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:54:47.151776 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:54:47.152391 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:54:48.385636 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.23 seconds
11:54:48.404818 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:54:48.604146 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:54:48.606926 [info ] [MainThread]: 
11:54:48.618756 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
11:54:48.619900 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
11:54:48.621395 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
11:54:48.622362 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
11:54:48.623924 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
11:54:48.637158 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
11:54:48.643880 [debug] [Thread-1  ]: finished collecting timing info
11:54:48.645993 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
11:54:48.786893 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
11:54:48.794865 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
11:54:48.796095 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
11:54:48.797360 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:54:51.085101 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.29 seconds
11:54:51.098675 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
11:54:51.099429 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        grant select on analytics.dbt.cumulative_orders_by_date to role analyst
11:54:51.221372 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
11:54:51.257654 [debug] [Thread-1  ]: finished collecting timing info
11:54:51.258631 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
11:54:51.444839 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8614fdcd90>]}
11:54:51.448283 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.82s]
11:54:51.451077 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
11:54:51.453611 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
11:54:51.458245 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
11:54:51.461913 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
11:54:51.463983 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
11:54:51.465489 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
11:54:51.493296 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
11:54:51.497142 [debug] [Thread-1  ]: finished collecting timing info
11:54:51.498054 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
11:54:51.586371 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:51.587211 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
11:54:51.587784 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:54:53.342045 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
11:54:53.377918 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:53.378641 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:54:53.493032 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:54:53.512238 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:53.512971 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
11:54:53.618360 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
11:54:53.661017 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:53.661712 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:54:53.779655 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
11:54:53.883010 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
11:54:53.894842 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:53.895541 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
11:54:54.011484 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
11:54:54.012792 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:54.013514 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:54:54.394891 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.38 seconds
11:54:54.397349 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
11:54:54.399622 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
11:54:54.572811 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
11:54:54.583623 [debug] [Thread-1  ]: finished collecting timing info
11:54:54.584917 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
11:54:54.755876 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86154bb610>]}
11:54:54.759133 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.29s]
11:54:54.761470 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
11:54:54.763758 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
11:54:54.766038 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
11:54:54.767463 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
11:54:54.768467 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
11:54:54.769786 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
11:54:54.782739 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
11:54:54.785982 [debug] [Thread-1  ]: finished collecting timing info
11:54:54.787674 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
11:54:54.799661 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:54.800419 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:54:54.800862 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:54:56.306826 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
11:54:56.319574 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:56.320670 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:54:56.449907 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
11:54:56.465870 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:56.466594 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:54:56.593703 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
11:54:56.610788 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:56.611563 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:54:56.732934 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
11:54:56.747975 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
11:54:56.757483 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:56.758274 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
11:54:56.891009 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:54:56.892267 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:56.893071 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:54:57.235227 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.34 seconds
11:54:57.237289 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:57.239109 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
11:54:57.433300 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
11:54:57.446680 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
11:54:57.447535 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        grant select on analytics.dbt.incremental_time to role analyst
11:54:57.561267 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
11:54:57.568781 [debug] [Thread-1  ]: finished collecting timing info
11:54:57.571006 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
11:54:57.783700 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f861474efd0>]}
11:54:57.785692 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.02s]
11:54:57.787909 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
11:54:57.789955 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
11:54:57.792292 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
11:54:57.795131 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
11:54:57.797399 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
11:54:57.798389 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
11:54:57.809695 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
11:54:57.813223 [debug] [Thread-1  ]: finished collecting timing info
11:54:57.814016 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
11:54:57.822396 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
11:54:57.829502 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
11:54:57.830155 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:54:57.830743 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:54:59.473163 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
11:54:59.478867 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
11:54:59.479829 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
11:54:59.595776 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
11:54:59.605418 [debug] [Thread-1  ]: finished collecting timing info
11:54:59.608659 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
11:54:59.796808 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86155037d0>]}
11:54:59.798787 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.00s]
11:54:59.800951 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
11:54:59.803831 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
11:54:59.806359 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
11:54:59.812270 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
11:54:59.813632 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
11:54:59.814591 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
11:54:59.829185 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
11:54:59.834865 [debug] [Thread-1  ]: finished collecting timing info
11:54:59.836154 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
11:54:59.844463 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
11:54:59.850237 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
11:54:59.851296 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
11:54:59.852293 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:55:06.290292 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.44 seconds
11:55:06.308108 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
11:55:06.319020 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        grant select on analytics.dbt.customer_model to role analyst
11:55:06.436649 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
11:55:06.445451 [debug] [Thread-1  ]: finished collecting timing info
11:55:06.446641 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
11:55:06.642492 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f861471ca90>]}
11:55:06.649122 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.83s]
11:55:06.654143 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
11:55:06.658369 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
11:55:06.661243 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:55:06.664272 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
11:55:06.666259 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
11:55:06.667715 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
11:55:06.687077 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
11:55:06.691930 [debug] [Thread-1  ]: finished collecting timing info
11:55:06.693280 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
11:55:06.702952 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
11:55:06.711660 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
11:55:06.712544 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
11:55:06.713279 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:55:08.689193 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
11:55:08.694947 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
11:55:08.695909 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        grant select on analytics.dbt.snowflake_customer_purchases to role analyst
11:55:08.802759 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
11:55:08.805789 [debug] [Thread-1  ]: finished collecting timing info
11:55:08.806544 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
11:55:08.985296 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617ecea10>]}
11:55:08.987222 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.32s]
11:55:08.988590 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
11:55:08.989552 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
11:55:08.991271 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
11:55:08.992819 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
11:55:08.993695 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
11:55:08.994849 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
11:55:09.007581 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
11:55:09.011737 [debug] [Thread-1  ]: finished collecting timing info
11:55:09.012727 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
11:55:09.022819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
11:55:09.028259 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
11:55:09.029209 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
11:55:09.030008 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:55:10.976104 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
11:55:10.987913 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
11:55:10.988940 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        grant select on analytics.dbt.my_second_dbt_model to role analyst
11:55:11.106338 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
11:55:11.110183 [debug] [Thread-1  ]: finished collecting timing info
11:55:11.110975 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
11:55:11.300660 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b4079ec-3d7c-44d4-b869-ef5f8bc462c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8614724250>]}
11:55:11.302114 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.31s]
11:55:11.303620 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
11:55:11.376929 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:55:11.378205 [info ] [MainThread]: 
11:55:11.379413 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 26.33s.
11:55:11.381274 [debug] [MainThread]: Connection 'master' was properly closed.
11:55:11.382344 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
11:55:11.408343 [info ] [MainThread]: 
11:55:11.409427 [info ] [MainThread]: [32mCompleted successfully[0m
11:55:11.410844 [info ] [MainThread]: 
11:55:11.412254 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
11:55:11.417023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86169406d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8614fd2850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8617e864d0>]}


============================== 2022-01-24 12:01:14.693800 | 8cfa1968-1049-42a7-9ddc-6fce49156952 ==============================
12:01:14.693800 [info ] [MainThread]: Running with dbt=1.0.1
12:01:14.695495 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:01:14.696653 [debug] [MainThread]: Tracking: tracking
12:01:14.698037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf4f6d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf4f6d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf4f6d90>]}
12:01:14.768746 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:01:14.770558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf4a3f90>]}
12:01:14.839362 [debug] [MainThread]: Parsing macros/adapters.sql
12:01:15.024404 [debug] [MainThread]: Parsing macros/catalog.sql
12:01:15.032342 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:01:15.070651 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:01:15.087788 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:01:15.106399 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:01:15.108862 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:01:15.122382 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:01:15.126977 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:01:15.167443 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:01:15.177888 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:01:15.188526 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:01:15.222326 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:01:15.240929 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:01:15.279828 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:01:15.290137 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:01:15.324479 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:01:15.341915 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:01:15.345961 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:01:15.347757 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:01:15.353419 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:01:15.355462 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:01:15.359323 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:01:15.363523 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:01:15.373698 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:01:15.385440 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:01:15.397591 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:01:15.474796 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:01:15.503997 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:01:15.556500 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:01:15.608103 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:01:15.614998 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:01:15.688538 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:01:15.694621 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:01:15.712623 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:01:15.721211 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:01:15.736238 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:01:15.779358 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:01:15.788365 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:01:15.838636 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:01:15.909577 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:01:15.921644 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:01:15.956253 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:01:15.966154 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:01:15.974880 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:01:15.978082 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:01:16.075847 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:01:16.885275 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
12:01:16.924363 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:01:16.950026 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:01:16.955081 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:01:16.972038 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:01:16.975397 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:01:16.982623 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
12:01:16.991013 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:01:16.998598 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:01:17.011650 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:01:17.358863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf56b590>]}
12:01:17.381503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcdfe68d0>]}
12:01:17.383029 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:01:17.388752 [info ] [MainThread]: 
12:01:17.391256 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:01:17.394180 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:01:17.457066 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:01:17.457799 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:01:17.458169 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:01:18.831962 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.37 seconds
12:01:18.838008 [debug] [ThreadPool]: On list_analytics: Close
12:01:19.016981 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:01:19.048751 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:01:19.050836 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:01:19.051791 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:01:20.210644 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.16 seconds
12:01:20.218994 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:01:20.388100 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:01:20.389254 [info ] [MainThread]: 
12:01:20.394231 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:01:20.395420 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:01:20.397828 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:01:20.399875 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:01:20.401333 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:01:20.410070 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:01:20.418213 [debug] [Thread-1  ]: finished collecting timing info
12:01:20.419954 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:01:20.518529 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:01:20.525666 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:01:20.526451 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:01:20.527281 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:22.953572 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.43 seconds
12:01:22.993247 [debug] [Thread-1  ]: finished collecting timing info
12:01:22.994092 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:01:23.170690 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc5d02d0>]}
12:01:23.172219 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.77s]
12:01:23.173581 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:01:23.176991 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:01:23.179648 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
12:01:23.182788 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:01:23.183844 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:01:23.184871 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:01:23.204360 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:01:23.208437 [debug] [Thread-1  ]: finished collecting timing info
12:01:23.209631 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:01:23.301135 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:23.301905 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:01:23.302466 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:24.784630 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
12:01:24.814086 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:24.815007 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:01:24.945785 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:01:24.981932 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:24.983083 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:01:25.108988 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:01:25.154243 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:25.154911 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:01:25.273692 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:01:25.374277 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:01:25.386693 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:25.387526 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:01:25.525765 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:01:25.528133 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:25.529759 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:01:25.925255 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.39 seconds
12:01:25.926482 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:01:25.928537 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:01:26.122378 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
12:01:26.149719 [debug] [Thread-1  ]: finished collecting timing info
12:01:26.150996 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:01:26.391415 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc589950>]}
12:01:26.393406 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.21s]
12:01:26.395748 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:01:26.397747 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:01:26.399616 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
12:01:26.402547 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:01:26.404279 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:01:26.406064 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:01:26.422041 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:01:26.425508 [debug] [Thread-1  ]: finished collecting timing info
12:01:26.426348 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:01:26.439266 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:26.439922 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:01:26.440364 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:27.864837 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
12:01:27.873841 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:27.874550 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:01:27.988246 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:01:28.001824 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:28.002672 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:01:28.103685 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:01:28.119865 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:28.120936 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:01:28.219604 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:01:28.232083 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:01:28.240689 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:28.241768 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
12:01:28.361364 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:01:28.362864 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:28.363887 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:01:28.782790 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.42 seconds
12:01:28.784096 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:01:28.785108 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
12:01:28.949715 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
12:01:28.956109 [debug] [Thread-1  ]: finished collecting timing info
12:01:28.957443 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:01:29.164172 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf5b5210>]}
12:01:29.166155 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.76s]
12:01:29.167959 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:01:29.169218 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:01:29.171011 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
12:01:29.173246 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:01:29.174314 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:01:29.175753 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:01:29.201488 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:01:29.206691 [debug] [Thread-1  ]: finished collecting timing info
12:01:29.207885 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:01:29.218948 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:01:29.224437 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:01:29.225527 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/






with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:01:29.226917 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:30.903853 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
12:01:30.914982 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:01:30.916632 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
12:01:31.044215 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:01:31.056011 [debug] [Thread-1  ]: finished collecting timing info
12:01:31.057731 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:01:31.250712 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc5dc310>]}
12:01:31.252990 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.08s]
12:01:31.254725 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:01:31.256033 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
12:01:31.258829 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
12:01:31.261037 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
12:01:31.262244 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
12:01:31.263512 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
12:01:31.271713 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
12:01:31.277319 [debug] [Thread-1  ]: finished collecting timing info
12:01:31.279728 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
12:01:31.286660 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
12:01:31.291813 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
12:01:31.292857 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
12:01:31.294081 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:38.194205 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.9 seconds
12:01:38.207664 [debug] [Thread-1  ]: finished collecting timing info
12:01:38.209191 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
12:01:38.393962 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc5bd110>]}
12:01:38.397045 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 7.13s]
12:01:38.400323 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
12:01:38.402764 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:01:38.404487 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:01:38.407610 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:01:38.410901 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:01:38.412688 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:01:38.419628 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:01:38.425613 [debug] [Thread-1  ]: finished collecting timing info
12:01:38.426585 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:01:38.433114 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:01:38.438987 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:01:38.440378 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:01:38.442873 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:41.518173 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.08 seconds
12:01:41.535887 [debug] [Thread-1  ]: finished collecting timing info
12:01:41.537322 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:01:41.749229 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc513990>]}
12:01:41.750611 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.34s]
12:01:41.752023 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:01:41.753144 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:01:41.756159 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
12:01:41.759796 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:01:41.760872 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:01:41.761755 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:01:41.776712 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:01:41.782116 [debug] [Thread-1  ]: finished collecting timing info
12:01:41.783296 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:01:41.794300 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:01:41.799860 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:01:41.800540 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
12:01:41.801076 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:43.553937 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
12:01:43.559979 [debug] [Thread-1  ]: finished collecting timing info
12:01:43.560948 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:01:43.737327 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cfa1968-1049-42a7-9ddc-6fce49156952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc5d3510>]}
12:01:43.738969 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.98s]
12:01:43.740493 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:01:43.804496 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:01:43.810162 [info ] [MainThread]: 
12:01:43.815887 [info ] [MainThread]: Finished running 5 table models, 2 incremental models in 26.42s.
12:01:43.819896 [debug] [MainThread]: Connection 'master' was properly closed.
12:01:43.822802 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:01:43.859134 [info ] [MainThread]: 
12:01:43.861060 [info ] [MainThread]: [32mCompleted successfully[0m
12:01:43.862638 [info ] [MainThread]: 
12:01:43.863713 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
12:01:43.865243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcf50e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc5136d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bcc513a90>]}


============================== 2022-01-24 12:06:21.755088 | 9ddcb084-779c-4bbf-9743-43ff6612856e ==============================
12:06:21.755088 [info ] [MainThread]: Running with dbt=1.0.1
12:06:21.757701 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:06:21.761756 [debug] [MainThread]: Tracking: tracking
12:06:21.765043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d7150dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d7150cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d7150e50>]}
12:06:21.857390 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:06:21.858685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d70c1f50>]}
12:06:21.942414 [debug] [MainThread]: Parsing macros/adapters.sql
12:06:22.214076 [debug] [MainThread]: Parsing macros/catalog.sql
12:06:22.222638 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:06:22.267265 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:06:22.287605 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:06:22.319711 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:06:22.323128 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:06:22.338158 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:06:22.344066 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:06:22.396129 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:06:22.422103 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:06:22.440444 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:06:22.472762 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:06:22.493570 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:06:22.549549 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:06:22.557625 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:06:22.605356 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:06:22.623243 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:06:22.629628 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:06:22.633103 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:06:22.637432 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:06:22.639855 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:06:22.647184 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:06:22.654020 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:06:22.663639 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:06:22.675173 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:06:22.696951 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:06:22.788549 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:06:22.819447 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:06:22.905592 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:06:22.977095 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:06:22.985917 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:06:23.076625 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:06:23.086686 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:06:23.108630 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:06:23.121090 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:06:23.153881 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:06:23.208618 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:06:23.217190 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:06:23.273786 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:06:23.358505 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:06:23.374886 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:06:23.428729 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:06:23.450132 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:06:23.458497 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:06:23.467182 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:06:23.589065 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:06:24.650585 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
12:06:24.704960 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:06:24.741189 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:06:24.746613 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:06:24.771554 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:06:24.779213 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:06:24.791488 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
12:06:24.807270 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:06:24.818849 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:06:24.833278 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:06:25.346698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d71d72d0>]}
12:06:25.371263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d7150390>]}
12:06:25.372626 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:06:25.381184 [info ] [MainThread]: 
12:06:25.383815 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:06:25.387383 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:06:25.452259 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:06:25.452928 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:06:25.453563 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:06:27.338728 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.89 seconds
12:06:27.349748 [debug] [ThreadPool]: On list_analytics: Close
12:06:27.531871 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:06:27.590452 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:06:27.592867 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:06:27.595224 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:06:28.876606 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.28 seconds
12:06:28.889219 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:06:29.117560 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:06:29.118643 [info ] [MainThread]: 
12:06:29.132897 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:06:29.134575 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:06:29.136171 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:06:29.136827 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:06:29.137756 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:06:29.150312 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:06:29.154745 [debug] [Thread-1  ]: finished collecting timing info
12:06:29.155441 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:06:29.305679 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:06:29.320299 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:06:29.321044 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:06:29.321540 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:31.731227 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.41 seconds
12:06:31.830609 [debug] [Thread-1  ]: finished collecting timing info
12:06:31.832685 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:06:32.027324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d4702b50>]}
12:06:32.029874 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.89s]
12:06:32.031294 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:06:32.032784 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:06:32.034792 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
12:06:32.035949 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:06:32.036881 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:06:32.037801 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:06:32.072922 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:06:32.078519 [debug] [Thread-1  ]: finished collecting timing info
12:06:32.079708 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:06:32.321271 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:32.322922 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:06:32.323931 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:34.106726 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
12:06:34.144247 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:34.145156 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:06:34.270578 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:06:34.294144 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:34.294886 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:06:34.402191 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:06:34.444626 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:34.445675 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:06:34.551012 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:06:34.659713 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:06:34.672676 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:34.673589 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:06:34.806127 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:06:34.807694 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:34.809194 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:06:35.385657 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.57 seconds
12:06:35.386730 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:06:35.387851 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:06:35.564249 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
12:06:35.570346 [debug] [Thread-1  ]: finished collecting timing info
12:06:35.572456 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:06:35.768191 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d41c9bd0>]}
12:06:35.770245 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.73s]
12:06:35.772049 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:06:35.774319 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:06:35.777324 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
12:06:35.779794 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:06:35.780743 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:06:35.781487 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:06:35.795726 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:06:35.800682 [debug] [Thread-1  ]: finished collecting timing info
12:06:35.802057 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:06:35.816130 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:35.816872 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:06:35.817451 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:37.347486 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
12:06:37.360791 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:37.361913 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:06:37.479031 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:06:37.494502 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:37.496609 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:06:37.595995 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:06:37.611556 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:37.612724 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:06:37.713680 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:06:37.726359 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:06:37.738811 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:37.740638 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
12:06:37.874759 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:06:37.877351 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:37.879901 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:06:38.102966 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.22 seconds
12:06:38.105103 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:06:38.106593 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
12:06:38.266327 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
12:06:38.276860 [debug] [Thread-1  ]: finished collecting timing info
12:06:38.279777 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:06:38.490129 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d5bc7750>]}
12:06:38.494511 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.71s]
12:06:38.498149 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:06:38.501386 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:06:38.504344 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
12:06:38.507471 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:06:38.509572 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:06:38.511196 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:06:38.525222 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:06:38.534628 [debug] [Thread-1  ]: finished collecting timing info
12:06:38.536011 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:06:38.551072 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:06:38.559039 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:06:38.560475 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:06:38.561347 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:40.591932 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.03 seconds
12:06:40.598072 [debug] [Thread-1  ]: finished collecting timing info
12:06:40.599319 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:06:40.778701 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d4702f90>]}
12:06:40.779988 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.27s]
12:06:40.781616 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:06:40.783218 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
12:06:40.785934 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
12:06:40.787659 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
12:06:40.789286 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
12:06:40.791649 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
12:06:40.804452 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
12:06:40.811180 [debug] [Thread-1  ]: finished collecting timing info
12:06:40.812712 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
12:06:40.820758 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
12:06:40.833013 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
12:06:40.833941 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
12:06:40.834647 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:47.968834 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 7.13 seconds
12:06:47.981274 [debug] [Thread-1  ]: finished collecting timing info
12:06:47.983087 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
12:06:48.168317 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d41c8610>]}
12:06:48.170056 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 7.38s]
12:06:48.172297 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
12:06:48.174605 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:06:48.177201 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:06:48.179023 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:06:48.179984 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:06:48.180744 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:06:48.191779 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:06:48.195990 [debug] [Thread-1  ]: finished collecting timing info
12:06:48.196784 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:06:48.209518 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:06:48.215710 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:06:48.218250 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:06:48.220019 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:50.387058 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.17 seconds
12:06:50.394404 [debug] [Thread-1  ]: finished collecting timing info
12:06:50.395383 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:06:50.586069 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d4185190>]}
12:06:50.588568 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.41s]
12:06:50.591881 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:06:50.593701 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:06:50.595581 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
12:06:50.597589 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:06:50.599266 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:06:50.600273 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:06:50.610114 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:06:50.613665 [debug] [Thread-1  ]: finished collecting timing info
12:06:50.615483 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:06:50.625742 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:06:50.630612 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:06:50.632579 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
12:06:50.634228 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:06:52.353867 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
12:06:52.368249 [debug] [Thread-1  ]: finished collecting timing info
12:06:52.369681 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:06:52.557497 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9ddcb084-779c-4bbf-9743-43ff6612856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7d475dad0>]}
12:06:52.560713 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.96s]
12:06:52.565440 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:06:52.590632 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:06:52.591878 [info ] [MainThread]: 
12:06:52.593191 [info ] [MainThread]: Running 3 on-run-end hooks
12:06:52.594782 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:06:52.601889 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:06:52.610285 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:06:52.611978 [debug] [MainThread]: Using snowflake connection "master"
12:06:52.613498 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:06:52.615608 [debug] [MainThread]: Opening a new connection, currently in state init
12:06:53.902120 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.29 seconds
12:06:53.906136 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.29s]
12:06:53.908221 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:06:53.914009 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:06:53.920531 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:06:53.923809 [debug] [MainThread]: Using snowflake connection "master"
12:06:53.926028 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:06:54.085343 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
12:06:54.087153 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
12:06:54.088126 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:06:54.094896 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:06:54.099026 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:06:54.102661 [debug] [MainThread]: Using snowflake connection "master"
12:06:54.105065 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:06:54.214836 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
12:06:54.222003 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
12:06:54.225074 [info ] [MainThread]: 
12:06:54.227465 [debug] [MainThread]: On master: Close
12:06:54.453433 [info ] [MainThread]: 
12:06:54.454630 [info ] [MainThread]: Finished running 5 table models, 2 incremental models, 3 hooks in 29.07s.
12:06:54.456744 [debug] [MainThread]: Connection 'master' was properly closed.
12:06:54.458882 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:06:54.485476 [info ] [MainThread]: 
12:06:54.486738 [info ] [MainThread]: [32mCompleted successfully[0m
12:06:54.488790 [info ] [MainThread]: 
12:06:54.491196 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
12:06:54.493046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7dda14f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e20f1ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e20f1d10>]}


============================== 2022-01-24 12:16:44.043309 | 4b3f9583-42f7-430a-9a8e-6ae1a5ad7478 ==============================
12:16:44.043309 [info ] [MainThread]: Running with dbt=1.0.1
12:16:44.049344 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:16:44.052177 [debug] [MainThread]: Tracking: tracking
12:16:44.054077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d74c6e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d74c6f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d750d050>]}
12:16:44.247666 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:16:44.249610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4b3f9583-42f7-430a-9a8e-6ae1a5ad7478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d7484e10>]}
12:16:44.385579 [debug] [MainThread]: Parsing macros/adapters.sql
12:16:44.965176 [debug] [MainThread]: Parsing macros/catalog.sql
12:16:44.975404 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:16:45.050867 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:16:45.081430 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:16:45.124712 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:16:45.134533 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:16:45.151791 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:16:45.158659 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:16:45.242713 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:16:45.256115 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:16:45.267970 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:16:45.325306 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:16:45.363510 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:16:45.426312 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:16:45.440448 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:16:45.503186 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:16:45.531563 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:16:45.539237 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:16:45.543071 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:16:45.548365 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:16:45.552084 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:16:45.557600 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:16:45.565615 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:16:45.580702 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:16:45.593845 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:16:45.611198 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:16:45.741686 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:16:45.845583 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:16:45.933081 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:16:46.070896 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:16:46.080814 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:16:46.224749 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:16:46.233055 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:16:46.263570 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:16:46.274677 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:16:46.325478 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:16:46.431550 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:16:46.442848 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:16:46.577494 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:16:46.737867 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:16:46.758722 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:16:46.822783 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:16:46.844712 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:16:46.871363 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:16:46.880664 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:16:47.055720 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:16:48.385428 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
12:16:48.446256 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:16:48.487691 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:16:48.493276 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:16:48.515276 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:16:48.522066 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:16:48.531735 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
12:16:48.545149 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:16:48.556115 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:16:48.573259 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:16:49.197498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b3f9583-42f7-430a-9a8e-6ae1a5ad7478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66dd376350>]}
12:16:49.222067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b3f9583-42f7-430a-9a8e-6ae1a5ad7478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d63cc850>]}
12:16:49.223249 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:16:49.228092 [info ] [MainThread]: 
12:16:49.230652 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:16:49.236354 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:16:49.295893 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:16:49.299339 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:16:49.300339 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:16:51.168832 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.87 seconds
12:16:51.178211 [debug] [ThreadPool]: On list_analytics: Close
12:16:51.378212 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:16:51.436243 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:16:51.440090 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:16:51.443045 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:16:52.997835 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.55 seconds
12:16:53.017522 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:16:53.248193 [info ] [MainThread]: 
12:16:53.253436 [info ] [MainThread]: Running 1 on-run-start hook
12:16:53.260703 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:16:53.287145 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:16:53.312339 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:16:53.317103 [debug] [MainThread]: Using snowflake connection "master"
12:16:53.320330 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exist audit (model text, state text, time timestamp_ltz)
12:16:53.321558 [debug] [MainThread]: Opening a new connection, currently in state init
12:16:54.724609 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a1d7e0-0000-1e52-0000-000298a25785
12:16:54.726618 [debug] [MainThread]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 20 unexpected 'exist'.
syntax error line 1 at position 32 unexpected '('.
12:16:54.730467 [info ] [MainThread]: Database error while running on-run-start
12:16:54.736125 [debug] [MainThread]: On master: Close
12:16:54.943659 [debug] [MainThread]: Connection 'master' was properly closed.
12:16:54.947718 [debug] [MainThread]: Connection 'list_analytics_dbt' was properly closed.
12:16:54.951014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d4ab1190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d4ab1d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d4ab1690>]}


============================== 2022-01-24 12:19:14.983351 | 8fb0bcac-2d0e-40ba-a747-a3c97ef0469f ==============================
12:19:14.983351 [info ] [MainThread]: Running with dbt=1.0.1
12:19:14.987289 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:19:14.988882 [debug] [MainThread]: Tracking: tracking
12:19:14.990363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf423be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf423bd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf423bdd0>]}
12:19:15.126874 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:19:15.129102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf31e7e50>]}
12:19:15.246199 [debug] [MainThread]: Parsing macros/adapters.sql
12:19:15.575223 [debug] [MainThread]: Parsing macros/catalog.sql
12:19:15.587599 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:19:15.667816 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:19:15.704404 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:19:15.744133 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:19:15.751804 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:19:15.779898 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:19:15.791839 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:19:15.882399 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:19:15.900085 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:19:15.918852 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:19:15.976126 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:19:16.015766 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:19:16.087084 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:19:16.104256 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:19:16.169059 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:19:16.204915 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:19:16.218796 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:19:16.222446 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:19:16.227978 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:19:16.231907 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:19:16.242653 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:19:16.252022 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:19:16.272575 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:19:16.289394 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:19:16.323168 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:19:16.464714 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:19:16.514340 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:19:16.606468 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:19:16.715615 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:19:16.727483 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:19:16.855606 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:19:16.869393 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:19:16.902088 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:19:16.916736 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:19:16.953844 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:19:17.041088 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:19:17.052872 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:19:17.152022 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:19:17.299748 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:19:17.320700 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:19:17.380704 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:19:17.401763 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:19:17.427964 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:19:17.436432 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:19:17.603771 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:19:19.157578 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
12:19:19.228939 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:19:19.282705 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:19:19.289045 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:19:19.312931 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:19:19.322105 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:19:19.334652 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
12:19:19.348954 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:19:19.363646 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:19:19.385763 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:19:20.151944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcfa125410>]}
12:19:20.191827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf42fabd0>]}
12:19:20.193796 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:19:20.202177 [info ] [MainThread]: 
12:19:20.204602 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:19:20.209404 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:19:20.292526 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:19:20.294026 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:19:20.295118 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:19:22.383383 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.09 seconds
12:19:22.394881 [debug] [ThreadPool]: On list_analytics: Close
12:19:22.592962 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:19:22.675622 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:19:22.677761 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:19:22.679764 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:19:24.088287 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.41 seconds
12:19:24.098007 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:19:24.292562 [info ] [MainThread]: 
12:19:24.296378 [info ] [MainThread]: Running 1 on-run-start hook
12:19:24.302745 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:19:24.314007 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:19:24.342524 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:19:24.346662 [debug] [MainThread]: Using snowflake connection "master"
12:19:24.348252 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
12:19:24.349650 [debug] [MainThread]: Opening a new connection, currently in state init
12:19:26.197625 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.85 seconds
12:19:26.206132 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.86s]
12:19:26.209418 [info ] [MainThread]: 
12:19:26.213877 [debug] [MainThread]: On master: Close
12:19:26.431908 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:19:26.435856 [info ] [MainThread]: 
12:19:26.455056 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:19:26.458454 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:19:26.464730 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:19:26.469639 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:19:26.472573 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:19:26.508265 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:19:26.522621 [debug] [Thread-1  ]: finished collecting timing info
12:19:26.529083 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:19:26.725283 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:19:26.735740 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:19:26.737062 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:19:26.737999 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:29.480801 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.74 seconds
12:19:29.602196 [debug] [Thread-1  ]: finished collecting timing info
12:19:29.603726 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:19:29.796106 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf186ac10>]}
12:19:29.807414 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 3.33s]
12:19:29.812270 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:19:29.816369 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:19:29.825902 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
12:19:29.832919 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:19:29.837427 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:19:29.848840 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:19:29.910942 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:19:29.924860 [debug] [Thread-1  ]: finished collecting timing info
12:19:29.926854 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:19:30.115234 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:30.116529 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:19:30.117759 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:32.205695 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
12:19:32.341946 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:32.343724 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:19:32.481953 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:19:32.543426 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:32.546592 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:19:32.656083 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:19:32.719923 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:32.721349 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:19:32.870903 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:19:33.165378 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:19:33.190698 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:33.192518 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:19:33.318931 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:19:33.321990 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:33.323926 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:19:33.734685 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.41 seconds
12:19:33.744357 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:19:33.749397 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:19:33.979913 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
12:19:34.005267 [debug] [Thread-1  ]: finished collecting timing info
12:19:34.016444 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:19:34.253517 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf02a3b90>]}
12:19:34.256405 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.42s]
12:19:34.258928 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:19:34.261094 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:19:34.263789 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
12:19:34.266181 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:19:34.267488 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:19:34.269230 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:19:34.290896 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:19:34.303073 [debug] [Thread-1  ]: finished collecting timing info
12:19:34.305194 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:19:34.331549 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:34.333116 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:19:34.334614 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:36.567091 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.23 seconds
12:19:36.589877 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:36.592313 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:19:36.720543 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:19:36.751081 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:36.755076 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:19:36.872532 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:19:36.934418 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:36.936613 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:19:37.059789 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:19:37.115643 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:19:37.136026 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:37.137327 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
12:19:37.262023 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:19:37.264171 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:37.265878 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:19:37.709310 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.44 seconds
12:19:37.714857 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:19:37.719554 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
12:19:37.930528 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
12:19:37.935344 [debug] [Thread-1  ]: finished collecting timing info
12:19:37.936174 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:19:38.110986 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf02ea290>]}
12:19:38.113932 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.84s]
12:19:38.116121 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:19:38.118284 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:19:38.121234 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
12:19:38.129257 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:19:38.132783 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:19:38.133944 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:19:38.174027 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:19:38.182632 [debug] [Thread-1  ]: finished collecting timing info
12:19:38.183966 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:19:38.197591 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:19:38.205189 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:19:38.206563 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:19:38.207575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:40.641403 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.43 seconds
12:19:40.661217 [debug] [Thread-1  ]: finished collecting timing info
12:19:40.664443 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:19:40.889599 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf0252e10>]}
12:19:40.891332 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.76s]
12:19:40.892724 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:19:40.893786 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
12:19:40.895755 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
12:19:40.897861 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
12:19:40.898991 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
12:19:40.900673 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
12:19:40.912954 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
12:19:40.917738 [debug] [Thread-1  ]: finished collecting timing info
12:19:40.919168 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
12:19:40.933159 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
12:19:40.937834 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
12:19:40.939135 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
12:19:40.940920 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:48.302875 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 7.36 seconds
12:19:48.329208 [debug] [Thread-1  ]: finished collecting timing info
12:19:48.332880 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
12:19:48.522486 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf0252410>]}
12:19:48.525991 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 7.63s]
12:19:48.528998 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
12:19:48.530969 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:19:48.533424 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:19:48.536797 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:19:48.538228 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:19:48.539704 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:19:48.554986 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:19:48.561724 [debug] [Thread-1  ]: finished collecting timing info
12:19:48.563435 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:19:48.579261 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:19:48.593439 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:19:48.594834 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:19:48.596082 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:51.139714 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.54 seconds
12:19:51.146294 [debug] [Thread-1  ]: finished collecting timing info
12:19:51.147745 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:19:51.324814 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf18639d0>]}
12:19:51.327194 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.79s]
12:19:51.329690 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:19:51.332101 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:19:51.336087 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
12:19:51.340713 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:19:51.343442 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:19:51.344764 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:19:51.364288 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:19:51.368760 [debug] [Thread-1  ]: finished collecting timing info
12:19:51.370139 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:19:51.382150 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:19:51.387139 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:19:51.388080 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
12:19:51.388978 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:19:53.514122 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.13 seconds
12:19:53.527171 [debug] [Thread-1  ]: finished collecting timing info
12:19:53.528980 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:19:53.712059 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8fb0bcac-2d0e-40ba-a747-a3c97ef0469f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf0211d10>]}
12:19:53.719271 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.37s]
12:19:53.726707 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:19:53.750158 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:19:53.756063 [info ] [MainThread]: 
12:19:53.762884 [info ] [MainThread]: Running 3 on-run-end hooks
12:19:53.770157 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:19:53.803163 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:19:53.814267 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:19:53.819399 [debug] [MainThread]: Using snowflake connection "master"
12:19:53.821223 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:19:53.822716 [debug] [MainThread]: Opening a new connection, currently in state closed
12:19:55.173229 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.35 seconds
12:19:55.183622 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.37s]
12:19:55.188618 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:19:55.213986 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:19:55.230324 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:19:55.239304 [debug] [MainThread]: Using snowflake connection "master"
12:19:55.242957 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:19:55.432285 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.19 seconds
12:19:55.442263 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.20s]
12:19:55.448032 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:19:55.470979 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:19:55.488079 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:19:55.495900 [debug] [MainThread]: Using snowflake connection "master"
12:19:55.497717 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:19:55.612953 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
12:19:55.620223 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
12:19:55.624193 [info ] [MainThread]: 
12:19:55.627279 [debug] [MainThread]: On master: Close
12:19:55.789152 [info ] [MainThread]: 
12:19:55.791486 [info ] [MainThread]: Finished running 5 table models, 2 incremental models, 4 hooks in 35.58s.
12:19:55.796002 [debug] [MainThread]: Connection 'master' was properly closed.
12:19:55.799016 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:19:55.838368 [info ] [MainThread]: 
12:19:55.842791 [info ] [MainThread]: [32mCompleted successfully[0m
12:19:55.846305 [info ] [MainThread]: 
12:19:55.849206 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
12:19:55.851658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf18374d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf1822690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcf1822210>]}


============================== 2022-01-24 12:29:03.474729 | b86f9227-cbef-46ee-8fc9-497c6ccedda0 ==============================
12:29:03.474729 [info ] [MainThread]: Running with dbt=1.0.1
12:29:03.477667 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:29:03.479918 [debug] [MainThread]: Tracking: tracking
12:29:03.481858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748bb5b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748bb5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748bb5b50>]}
12:29:03.614711 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:29:03.617114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748b68e50>]}
12:29:03.718872 [debug] [MainThread]: Parsing macros/adapters.sql
12:29:04.098973 [debug] [MainThread]: Parsing macros/catalog.sql
12:29:04.114936 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:29:04.196803 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:29:04.228574 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:29:04.276897 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:29:04.282839 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:29:04.306954 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:29:04.319835 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:29:04.402930 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:29:04.427256 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:29:04.448870 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:29:04.507360 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:29:04.538356 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:29:04.618296 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:29:04.635913 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:29:04.702732 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:29:04.736774 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:29:04.745842 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:29:04.748966 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:29:04.756064 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:29:04.761368 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:29:04.769834 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:29:04.783056 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:29:04.801311 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:29:04.812586 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:29:04.842054 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:29:04.978454 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:29:05.038698 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:29:05.142303 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:29:05.261572 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:29:05.273542 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:29:05.412652 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:29:05.427873 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:29:05.455028 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:29:05.469865 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:29:05.507814 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:29:05.591905 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:29:05.601939 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:29:05.701163 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:29:05.851039 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:29:05.872417 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:29:05.943219 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:29:05.962676 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:29:05.976842 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:29:05.987438 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:29:06.172242 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:29:07.769349 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
12:29:07.865757 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:29:07.914952 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:29:07.923843 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:29:07.949655 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:29:07.954831 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:29:07.978577 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
12:29:08.009915 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:29:08.033051 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:29:08.055384 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:29:08.852965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc749cb1550>]}
12:29:08.889688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748693610>]}
12:29:08.891137 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:29:08.903861 [info ] [MainThread]: 
12:29:08.905961 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:29:08.911388 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:29:08.994559 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:29:08.995713 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:29:08.996560 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:29:11.228861 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.23 seconds
12:29:11.240434 [debug] [ThreadPool]: On list_analytics: Close
12:29:11.450391 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:29:11.553284 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:29:11.554985 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:29:11.556251 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:29:13.146162 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.59 seconds
12:29:13.160011 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:29:13.358654 [info ] [MainThread]: 
12:29:13.362076 [info ] [MainThread]: Running 1 on-run-start hook
12:29:13.365772 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:29:13.382910 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:29:13.405283 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:29:13.408567 [debug] [MainThread]: Using snowflake connection "master"
12:29:13.410236 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
12:29:13.412046 [debug] [MainThread]: Opening a new connection, currently in state init
12:29:14.862786 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.45 seconds
12:29:14.871682 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.46s]
12:29:14.876242 [info ] [MainThread]: 
12:29:14.884350 [debug] [MainThread]: On master: Close
12:29:15.087917 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:29:15.094884 [info ] [MainThread]: 
12:29:15.114340 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
12:29:15.117744 [info ] [Thread-1  ]: 1 of 7 START table model dbt.cumulative_orders_by_date.......................... [RUN]
12:29:15.122774 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:29:15.129911 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
12:29:15.134511 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
12:29:15.168075 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:29:15.174003 [debug] [Thread-1  ]: finished collecting timing info
12:29:15.175245 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
12:29:15.289787 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:29:15.292673 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
12:29:15.294134 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:17.608774 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.31 seconds
12:29:17.752166 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
12:29:17.762365 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
12:29:17.763783 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
12:29:19.285245 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:29:19.392313 [debug] [Thread-1  ]: finished collecting timing info
12:29:19.393601 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
12:29:19.923216 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748028190>]}
12:29:19.930250 [info ] [Thread-1  ]: 1 of 7 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 4.80s]
12:29:19.934393 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
12:29:19.938307 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
12:29:19.948209 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.dates........................................ [RUN]
12:29:19.957810 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
12:29:19.967813 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
12:29:19.973448 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
12:29:20.028736 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
12:29:20.034163 [debug] [Thread-1  ]: finished collecting timing info
12:29:20.035645 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
12:29:20.237815 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:20.239176 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
12:29:20.239969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:22.303282 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.06 seconds
12:29:22.410755 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:22.412226 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:29:22.533393 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:29:22.571625 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:22.572942 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
12:29:22.687111 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:29:22.775602 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:22.777530 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:29:22.899521 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:29:23.150058 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
12:29:23.169692 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:23.171276 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
12:29:23.299951 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:29:23.302170 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:23.303736 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:29:23.689038 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.38 seconds
12:29:23.694145 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
12:29:23.698895 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
12:29:23.920167 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.22 seconds
12:29:23.963290 [debug] [Thread-1  ]: finished collecting timing info
12:29:23.969128 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
12:29:24.188060 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc739469390>]}
12:29:24.199701 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.23s]
12:29:24.207793 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
12:29:24.236708 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
12:29:24.241257 [info ] [Thread-1  ]: 3 of 7 START incremental model dbt.incremental_time............................. [RUN]
12:29:24.253947 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
12:29:24.255870 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
12:29:24.257787 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
12:29:24.281188 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
12:29:24.284439 [debug] [Thread-1  ]: finished collecting timing info
12:29:24.285200 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
12:29:24.299403 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:24.300590 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
12:29:24.301093 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:26.180178 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
12:29:26.215429 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:26.219853 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:29:26.882319 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
12:29:26.951980 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:26.953985 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:29:27.088982 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:29:27.160992 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:27.163663 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:29:27.296769 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:29:27.349740 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:27.350963 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:29:27.460404 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:29:27.496769 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
12:29:27.530194 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:27.533951 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
12:29:27.677932 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:29:27.680565 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:27.683131 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:29:27.946461 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.26 seconds
12:29:27.950975 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
12:29:27.954425 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
12:29:28.166109 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
12:29:28.190786 [debug] [Thread-1  ]: finished collecting timing info
12:29:28.194740 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
12:29:28.426453 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc739443e90>]}
12:29:28.433085 [info ] [Thread-1  ]: 3 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.17s]
12:29:28.444372 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
12:29:28.452756 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:29:28.458733 [info ] [Thread-1  ]: 4 of 7 START table model dbt.first_model........................................ [RUN]
12:29:28.472490 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:29:28.480902 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:29:28.488862 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:29:28.523952 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:29:28.530494 [debug] [Thread-1  ]: finished collecting timing info
12:29:28.531753 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:29:28.552793 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:29:28.553598 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
12:29:28.554340 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:30.671759 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
12:29:30.678743 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:29:30.690003 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:29:30.691740 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:29:31.394220 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
12:29:31.417851 [debug] [Thread-1  ]: finished collecting timing info
12:29:31.423690 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:29:31.662583 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74808ba90>]}
12:29:31.667136 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.19s]
12:29:31.673127 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:29:31.678056 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
12:29:31.684813 [info ] [Thread-1  ]: 5 of 7 START table model dbt.customer_model..................................... [RUN]
12:29:31.691114 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
12:29:31.694646 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
12:29:31.696758 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
12:29:31.721363 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
12:29:31.725118 [debug] [Thread-1  ]: finished collecting timing info
12:29:31.726217 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
12:29:31.742579 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
12:29:31.743893 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
12:29:31.744636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:33.681774 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.94 seconds
12:29:33.699283 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
12:29:33.718439 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
12:29:33.721083 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
12:29:38.996048 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.27 seconds
12:29:39.011391 [debug] [Thread-1  ]: finished collecting timing info
12:29:39.013107 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
12:29:39.220460 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73944b6d0>]}
12:29:39.225775 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 7.53s]
12:29:39.237711 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
12:29:39.244243 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
12:29:39.268179 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:29:39.279709 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:29:39.285122 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
12:29:39.289599 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
12:29:39.312372 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:29:39.319586 [debug] [Thread-1  ]: finished collecting timing info
12:29:39.320707 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
12:29:39.336722 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:29:39.337981 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
12:29:39.338905 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:41.805789 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.47 seconds
12:29:41.835850 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
12:29:41.864434 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
12:29:41.866017 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
12:29:43.051806 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.18 seconds
12:29:43.058233 [debug] [Thread-1  ]: finished collecting timing info
12:29:43.062124 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
12:29:43.253060 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7393eaf50>]}
12:29:43.259812 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.97s]
12:29:43.268687 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
12:29:43.277200 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
12:29:43.284125 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
12:29:43.295670 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
12:29:43.300788 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
12:29:43.305095 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
12:29:43.346126 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
12:29:43.354055 [debug] [Thread-1  ]: finished collecting timing info
12:29:43.356362 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
12:29:43.369319 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:29:43.370746 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
12:29:43.372372 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:29:45.517347 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.14 seconds
12:29:45.546439 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
12:29:45.567943 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
12:29:45.572055 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
12:29:46.321803 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.75 seconds
12:29:46.344117 [debug] [Thread-1  ]: finished collecting timing info
12:29:46.346995 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
12:29:46.918376 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b86f9227-cbef-46ee-8fc9-497c6ccedda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73acd83d0>]}
12:29:46.924699 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 3.63s]
12:29:46.930161 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
12:29:46.979093 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:29:46.985062 [info ] [MainThread]: 
12:29:46.992583 [info ] [MainThread]: Running 3 on-run-end hooks
12:29:46.998236 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:29:47.011690 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:29:47.020450 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:29:47.026406 [debug] [MainThread]: Using snowflake connection "master"
12:29:47.028564 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:29:47.029972 [debug] [MainThread]: Opening a new connection, currently in state closed
12:29:49.107982 [debug] [MainThread]: SQL status: SUCCESS 1 in 2.08 seconds
12:29:49.116917 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 2.09s]
12:29:49.121478 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:29:49.146722 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:29:49.155985 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:29:49.158979 [debug] [MainThread]: Using snowflake connection "master"
12:29:49.160580 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:29:49.333491 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
12:29:49.346417 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
12:29:49.352096 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:29:49.378994 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:29:49.403328 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:29:49.412230 [debug] [MainThread]: Using snowflake connection "master"
12:29:49.417994 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:29:49.721951 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.3 seconds
12:29:49.735156 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.33s]
12:29:49.740817 [info ] [MainThread]: 
12:29:49.746699 [debug] [MainThread]: On master: Close
12:29:50.227170 [info ] [MainThread]: 
12:29:50.230394 [info ] [MainThread]: Finished running 5 table models, 2 incremental models, 4 hooks in 41.32s.
12:29:50.233566 [debug] [MainThread]: Connection 'master' was properly closed.
12:29:50.235457 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
12:29:50.278078 [info ] [MainThread]: 
12:29:50.279096 [info ] [MainThread]: [32mCompleted successfully[0m
12:29:50.280221 [info ] [MainThread]: 
12:29:50.281203 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
12:29:50.282652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74ec2d410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748085550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7480cf7d0>]}


============================== 2022-01-24 12:43:34.216128 | 6c0c4c34-3d97-476d-b335-8acde365660e ==============================
12:43:34.216128 [info ] [MainThread]: Running with dbt=1.0.1
12:43:34.218867 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:43:34.221052 [debug] [MainThread]: Tracking: tracking
12:43:34.223005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabe7b3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabe7b3d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabe7b3dd0>]}
12:43:34.474468 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:43:34.476987 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
12:43:34.583925 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:43:34.684454 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:43:34.900288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c0c4c34-3d97-476d-b335-8acde365660e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabe64a210>]}
12:43:35.096352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c0c4c34-3d97-476d-b335-8acde365660e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabf88d290>]}
12:43:35.098971 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:43:35.110146 [info ] [MainThread]: 
12:43:35.119079 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:43:35.123562 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:43:35.225831 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:43:35.226701 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:43:35.227554 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:43:37.338234 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.11 seconds
12:43:37.347994 [debug] [ThreadPool]: On list_analytics: Close
12:43:37.534882 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:43:37.646089 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:43:37.647988 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:43:37.650086 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:43:39.351890 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.7 seconds
12:43:39.374380 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:43:39.588131 [info ] [MainThread]: 
12:43:39.596827 [info ] [MainThread]: Running 1 on-run-start hook
12:43:39.607324 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:43:39.663674 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:43:39.681144 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:43:39.683178 [debug] [MainThread]: Using snowflake connection "master"
12:43:39.684160 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
12:43:39.685637 [debug] [MainThread]: Opening a new connection, currently in state init
12:43:41.190360 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.5 seconds
12:43:41.201224 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.52s]
12:43:41.205413 [info ] [MainThread]: 
12:43:41.210148 [debug] [MainThread]: On master: Close
12:43:41.428100 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:43:41.433016 [info ] [MainThread]: 
12:43:41.454438 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:43:41.458920 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
12:43:41.465792 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:43:41.471710 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:43:41.474301 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:43:41.496627 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:43:41.503073 [debug] [Thread-1  ]: finished collecting timing info
12:43:41.504969 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:43:41.632575 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:43:41.634063 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
12:43:41.635723 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:43:43.957675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.32 seconds
12:43:44.058386 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:43:44.070191 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:43:44.073224 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'NJ' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:43:44.794825 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
12:43:44.929910 [debug] [Thread-1  ]: finished collecting timing info
12:43:44.931627 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:43:45.167043 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c0c4c34-3d97-476d-b335-8acde365660e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabd259bd0>]}
12:43:45.173210 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.70s]
12:43:45.180464 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:43:45.236693 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:43:45.238703 [info ] [MainThread]: 
12:43:45.241950 [info ] [MainThread]: Running 3 on-run-end hooks
12:43:45.245457 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:43:45.253890 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:43:45.262493 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:43:45.264176 [debug] [MainThread]: Using snowflake connection "master"
12:43:45.265005 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:43:45.265669 [debug] [MainThread]: Opening a new connection, currently in state closed
12:43:46.789764 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.52 seconds
12:43:46.797308 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.53s]
12:43:46.802362 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:43:46.823403 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:43:46.847232 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:43:46.853423 [debug] [MainThread]: Using snowflake connection "master"
12:43:46.855431 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:43:46.999253 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
12:43:47.005615 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
12:43:47.009608 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:43:47.019961 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:43:47.025418 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:43:47.033983 [debug] [MainThread]: Using snowflake connection "master"
12:43:47.037540 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:43:47.154150 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
12:43:47.162184 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
12:43:47.165058 [info ] [MainThread]: 
12:43:47.168365 [debug] [MainThread]: On master: Close
12:43:47.368919 [info ] [MainThread]: 
12:43:47.372886 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 12.25s.
12:43:47.377802 [debug] [MainThread]: Connection 'master' was properly closed.
12:43:47.381445 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
12:43:47.464962 [info ] [MainThread]: 
12:43:47.469474 [info ] [MainThread]: [32mCompleted successfully[0m
12:43:47.473827 [info ] [MainThread]: 
12:43:47.476620 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:43:47.479109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabe781e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabd24b4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbabd24bed0>]}


============================== 2022-01-24 12:50:54.653740 | ef5e93be-be83-4fc2-8a32-7fdadb6485ac ==============================
12:50:54.653740 [info ] [MainThread]: Running with dbt=1.0.1
12:50:54.656224 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.snapshot.SnapshotTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='snapshot', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='snapshot', write_json=None)
12:50:54.658308 [debug] [MainThread]: Tracking: tracking
12:50:54.660288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2249ac4f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2249ac4d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2249ac4ed0>]}
12:50:54.881001 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
12:50:54.883247 [debug] [MainThread]: Partial parsing: added file: dbt_tests://snapshots/first_model_snapshot.sql
12:50:55.141192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ef5e93be-be83-4fc2-8a32-7fdadb6485ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22489a2090>]}
12:50:55.194720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ef5e93be-be83-4fc2-8a32-7fdadb6485ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22489f2ed0>]}
12:50:55.196605 [info ] [MainThread]: Found 7 models, 10 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:50:55.204346 [info ] [MainThread]: 
12:50:55.208950 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:55.214369 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:50:55.425780 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:50:55.426611 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:50:55.427207 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:50:57.497094 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.07 seconds
12:50:57.506927 [debug] [ThreadPool]: On list_analytics: Close
12:50:57.691414 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_snapshots"
12:50:57.694143 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_snapshots"
12:50:57.696074 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='snapshots', identifier=None)"
12:50:57.726001 [debug] [ThreadPool]: Using snowflake connection "create_analytics_snapshots"
12:50:57.732661 [debug] [ThreadPool]: On create_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_snapshots"} */
create schema if not exists analytics.snapshots
12:50:57.734188 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:50:59.347997 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.61 seconds
12:50:59.352193 [debug] [ThreadPool]: On create_analytics_snapshots: Close
12:50:59.580656 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:50:59.617433 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:50:59.618573 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:50:59.619347 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:51:01.238476 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.62 seconds
12:51:01.247188 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:51:01.445829 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
12:51:01.453612 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
12:51:01.454569 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
12:51:01.455454 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:51:02.889591 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.43 seconds
12:51:02.900131 [debug] [ThreadPool]: On list_analytics_snapshots: Close
12:51:03.113180 [info ] [MainThread]: 
12:51:03.117210 [info ] [MainThread]: Running 1 on-run-start hook
12:51:03.122061 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:51:03.136144 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:51:03.156704 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:51:03.162452 [debug] [MainThread]: Using snowflake connection "master"
12:51:03.164828 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
12:51:03.168313 [debug] [MainThread]: Opening a new connection, currently in state init
12:51:04.662252 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.49 seconds
12:51:04.672154 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.51s]
12:51:04.675943 [info ] [MainThread]: 
12:51:04.679955 [debug] [MainThread]: On master: Close
12:51:04.898917 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:51:04.903728 [info ] [MainThread]: 
12:51:04.914281 [debug] [Thread-1  ]: Began running node snapshot.dbt_tests.first_model_snapshot
12:51:04.917138 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.first_model_snapshot............................ [RUN]
12:51:04.922314 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:51:04.924839 [debug] [Thread-1  ]: Began compiling node snapshot.dbt_tests.first_model_snapshot
12:51:04.926812 [debug] [Thread-1  ]: Compiling snapshot.dbt_tests.first_model_snapshot
12:51:04.942501 [debug] [Thread-1  ]: finished collecting timing info
12:51:04.943489 [debug] [Thread-1  ]: Began executing node snapshot.dbt_tests.first_model_snapshot
12:51:05.131676 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:51:05.132918 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snapshots')
            and upper(catalog_name) = upper('analytics')
12:51:05.134238 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:51:09.292225 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 4.16 seconds
12:51:09.565443 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.dbt_tests.first_model_snapshot"
12:51:09.574308 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:51:09.575380 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

      

      create or replace transient table analytics.snapshots.first_model_snapshot  as
      (

    select *,
        md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        



select * from analytics.dbt.first_model

    ) sbq



      );
12:51:10.548915 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
12:51:10.691315 [debug] [Thread-1  ]: finished collecting timing info
12:51:10.693030 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: Close
12:51:10.877640 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef5e93be-be83-4fc2-8a32-7fdadb6485ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2249b85a90>]}
12:51:10.880059 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.first_model_snapshot............................ [[32mSUCCESS 1[0m in 5.96s]
12:51:10.882656 [debug] [Thread-1  ]: Finished running node snapshot.dbt_tests.first_model_snapshot
12:51:10.962266 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:51:10.964030 [info ] [MainThread]: 
12:51:10.966504 [info ] [MainThread]: Running 3 on-run-end hooks
12:51:10.968943 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:51:10.977534 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:51:10.985020 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:51:10.987064 [debug] [MainThread]: Using snowflake connection "master"
12:51:10.988225 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:51:10.989316 [debug] [MainThread]: Opening a new connection, currently in state closed
12:51:12.541882 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.55 seconds
12:51:12.546709 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.56s]
12:51:12.549402 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:51:12.559217 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:51:12.567755 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:51:12.571642 [debug] [MainThread]: Using snowflake connection "master"
12:51:12.573664 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:51:12.713248 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
12:51:12.719009 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
12:51:12.721257 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:51:12.731564 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:51:12.737255 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:51:12.740785 [debug] [MainThread]: Using snowflake connection "master"
12:51:12.742367 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:51:12.859115 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
12:51:12.862670 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
12:51:12.864598 [info ] [MainThread]: 
12:51:12.867349 [debug] [MainThread]: On master: Close
12:51:13.048507 [info ] [MainThread]: 
12:51:13.050257 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 17.84s.
12:51:13.052233 [debug] [MainThread]: Connection 'master' was properly closed.
12:51:13.054298 [debug] [MainThread]: Connection 'snapshot.dbt_tests.first_model_snapshot' was properly closed.
12:51:13.097561 [info ] [MainThread]: 
12:51:13.100101 [info ] [MainThread]: [32mCompleted successfully[0m
12:51:13.103599 [info ] [MainThread]: 
12:51:13.108010 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:51:13.110886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2249b1ac10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224174d450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2249b850d0>]}


============================== 2022-01-24 12:55:23.748768 | ade59cc9-1b64-411b-9bb4-30d9892cea41 ==============================
12:55:23.748768 [info ] [MainThread]: Running with dbt=1.0.1
12:55:23.752016 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
12:55:23.753916 [debug] [MainThread]: Tracking: tracking
12:55:23.756140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a12afe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a12afa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a12afe10>]}
12:55:23.973803 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:55:23.977006 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
12:55:24.041409 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:55:24.123883 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:55:24.361838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ade59cc9-1b64-411b-9bb4-30d9892cea41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a014fdd0>]}
12:55:24.411133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ade59cc9-1b64-411b-9bb4-30d9892cea41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a130ec90>]}
12:55:24.413002 [info ] [MainThread]: Found 7 models, 10 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:55:24.419131 [info ] [MainThread]: 
12:55:24.421278 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:55:24.424227 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:55:24.497548 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:55:24.498544 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:55:24.499338 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:55:26.719068 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.22 seconds
12:55:26.727877 [debug] [ThreadPool]: On list_analytics: Close
12:55:26.977359 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
12:55:27.057182 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
12:55:27.059348 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
12:55:27.061299 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:55:28.495353 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.43 seconds
12:55:28.507952 [debug] [ThreadPool]: On list_analytics_snapshots: Close
12:55:28.754352 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:55:28.772527 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:55:28.774267 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:55:28.775727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:55:30.449855 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.67 seconds
12:55:30.457276 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:55:30.666729 [info ] [MainThread]: 
12:55:30.672823 [info ] [MainThread]: Running 1 on-run-start hook
12:55:30.687090 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:55:30.699797 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:55:30.714352 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:55:30.717134 [debug] [MainThread]: Using snowflake connection "master"
12:55:30.719150 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
12:55:30.721533 [debug] [MainThread]: Opening a new connection, currently in state init
12:55:32.362016 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.64 seconds
12:55:32.371290 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.65s]
12:55:32.373919 [info ] [MainThread]: 
12:55:32.376660 [debug] [MainThread]: On master: Close
12:55:32.567955 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:55:32.571612 [info ] [MainThread]: 
12:55:32.585068 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
12:55:32.587064 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
12:55:32.590824 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
12:55:32.593698 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
12:55:32.599103 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
12:55:32.639503 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
12:55:32.648438 [debug] [Thread-1  ]: finished collecting timing info
12:55:32.651022 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
12:55:32.769620 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:55:32.770509 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
12:55:32.771327 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:55:36.556471 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.78 seconds
12:55:36.691245 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
12:55:36.703042 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
12:55:36.703997 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:55:37.395118 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.69 seconds
12:55:37.464263 [debug] [Thread-1  ]: finished collecting timing info
12:55:37.466147 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
12:55:37.652004 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ade59cc9-1b64-411b-9bb4-30d9892cea41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f009accfa10>]}
12:55:37.663993 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 5.06s]
12:55:37.667508 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
12:55:37.685137 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:55:37.688514 [info ] [MainThread]: 
12:55:37.693072 [info ] [MainThread]: Running 3 on-run-end hooks
12:55:37.700207 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:55:37.719973 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:55:37.735298 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:55:37.743848 [debug] [MainThread]: Using snowflake connection "master"
12:55:37.746539 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:55:37.748677 [debug] [MainThread]: Opening a new connection, currently in state closed
12:55:39.502721 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.75 seconds
12:55:39.506579 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.77s]
12:55:39.511398 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:55:39.520028 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:55:39.526450 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:55:39.530203 [debug] [MainThread]: Using snowflake connection "master"
12:55:39.535495 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:55:39.672186 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
12:55:39.690276 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
12:55:39.694520 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:55:39.713620 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:55:39.725874 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:55:39.730236 [debug] [MainThread]: Using snowflake connection "master"
12:55:39.732101 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:55:39.855680 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
12:55:39.866551 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.14s]
12:55:39.874388 [info ] [MainThread]: 
12:55:39.882228 [debug] [MainThread]: On master: Close
12:55:40.118500 [info ] [MainThread]: 
12:55:40.123506 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 15.70s.
12:55:40.129333 [debug] [MainThread]: Connection 'master' was properly closed.
12:55:40.134015 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
12:55:40.231423 [info ] [MainThread]: 
12:55:40.237908 [info ] [MainThread]: [32mCompleted successfully[0m
12:55:40.245353 [info ] [MainThread]: 
12:55:40.251226 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:55:40.258425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a12ff590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a137c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00a137c290>]}


============================== 2022-01-24 12:56:49.756342 | 34b33d90-7437-49e9-9a0c-c68c6dcd531f ==============================
12:56:49.756342 [info ] [MainThread]: Running with dbt=1.0.1
12:56:49.759615 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.snapshot.SnapshotTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='snapshot', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='snapshot', write_json=None)
12:56:49.761330 [debug] [MainThread]: Tracking: tracking
12:56:49.763676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d1f0de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d1f0db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d1f0ded0>]}
12:56:49.987590 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:56:49.988613 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:56:50.025400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '34b33d90-7437-49e9-9a0c-c68c6dcd531f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d1e45210>]}
12:56:50.066217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '34b33d90-7437-49e9-9a0c-c68c6dcd531f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d1f6c090>]}
12:56:50.067876 [info ] [MainThread]: Found 7 models, 10 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:56:50.075225 [info ] [MainThread]: 
12:56:50.077674 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:56:50.080725 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:56:50.154339 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:56:50.155617 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:56:50.156541 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:56:52.107615 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.95 seconds
12:56:52.116562 [debug] [ThreadPool]: On list_analytics: Close
12:56:52.346786 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:56:52.392753 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:56:52.394058 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:56:52.395016 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:56:53.863053 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.47 seconds
12:56:53.877374 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:56:54.070841 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
12:56:54.086534 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
12:56:54.088025 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
12:56:54.088986 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:56:55.485411 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.4 seconds
12:56:55.497421 [debug] [ThreadPool]: On list_analytics_snapshots: Close
12:56:55.706118 [info ] [MainThread]: 
12:56:55.710028 [info ] [MainThread]: Running 1 on-run-start hook
12:56:55.714373 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
12:56:55.726192 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
12:56:55.741018 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
12:56:55.743432 [debug] [MainThread]: Using snowflake connection "master"
12:56:55.744902 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
12:56:55.746185 [debug] [MainThread]: Opening a new connection, currently in state init
12:56:57.131638 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.39 seconds
12:56:57.139917 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.40s]
12:56:57.143558 [info ] [MainThread]: 
12:56:57.148567 [debug] [MainThread]: On master: Close
12:56:57.345882 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:56:57.348814 [info ] [MainThread]: 
12:56:57.363209 [debug] [Thread-1  ]: Began running node snapshot.dbt_tests.first_model_snapshot
12:56:57.365200 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.first_model_snapshot............................ [RUN]
12:56:57.367470 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:56:57.369155 [debug] [Thread-1  ]: Began compiling node snapshot.dbt_tests.first_model_snapshot
12:56:57.370762 [debug] [Thread-1  ]: Compiling snapshot.dbt_tests.first_model_snapshot
12:56:57.390278 [debug] [Thread-1  ]: finished collecting timing info
12:56:57.391509 [debug] [Thread-1  ]: Began executing node snapshot.dbt_tests.first_model_snapshot
12:56:57.593447 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:56:57.594703 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snapshots')
            and upper(catalog_name) = upper('analytics')
12:56:57.595817 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:56:59.408115 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
12:56:59.626921 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:56:59.628204 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
12:56:59.734961 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.11 seconds
12:56:59.918951 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:56:59.920142 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

        

      create or replace temporary table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"  as
      (with snapshot_query as (

        



select * from analytics.dbt.first_model


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    )

    select * from insertions
    union all
    select * from updates

      );
12:57:00.847861 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
12:57:00.866088 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:00.867267 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
12:57:00.977947 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.11 seconds
12:57:01.007726 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:01.009988 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
12:57:01.115053 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.1 seconds
12:57:01.138564 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:01.139994 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
12:57:01.257390 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.12 seconds
12:57:01.281389 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:01.282792 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
12:57:01.387376 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.1 seconds
12:57:01.439874 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:01.441168 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
12:57:01.545165 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.1 seconds
12:57:01.608485 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.dbt_tests.first_model_snapshot"
12:57:01.619146 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:01.620581 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

      begin;
12:57:01.745512 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:57:01.748723 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:01.751915 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: merge into "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT" as DBT_INTERNAL_DEST
    using "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     and DBT_INTERNAL_DEST.dbt_valid_to is null
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
12:57:02.431807 [debug] [Thread-1  ]: SQL status: SUCCESS 2 in 0.68 seconds
12:57:02.434457 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
12:57:02.437078 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: commit;
12:57:02.703521 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:57:02.786315 [debug] [Thread-1  ]: finished collecting timing info
12:57:02.787894 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: Close
12:57:02.981026 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '34b33d90-7437-49e9-9a0c-c68c6dcd531f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28cb442850>]}
12:57:02.987094 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.first_model_snapshot............................ [[32mSUCCESS 1[0m in 5.61s]
12:57:02.991854 [debug] [Thread-1  ]: Finished running node snapshot.dbt_tests.first_model_snapshot
12:57:03.112163 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:57:03.115165 [info ] [MainThread]: 
12:57:03.118507 [info ] [MainThread]: Running 3 on-run-end hooks
12:57:03.123161 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
12:57:03.142718 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
12:57:03.153648 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
12:57:03.156243 [debug] [MainThread]: Using snowflake connection "master"
12:57:03.157502 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
12:57:03.158605 [debug] [MainThread]: Opening a new connection, currently in state closed
12:57:04.646176 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.49 seconds
12:57:04.653061 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.50s]
12:57:04.656370 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
12:57:04.668147 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
12:57:04.675141 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
12:57:04.678005 [debug] [MainThread]: Using snowflake connection "master"
12:57:04.679425 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
12:57:04.847285 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
12:57:04.857265 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.18s]
12:57:04.861322 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
12:57:04.870240 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
12:57:04.877387 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
12:57:04.880555 [debug] [MainThread]: Using snowflake connection "master"
12:57:04.881673 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
12:57:05.005072 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
12:57:05.015157 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.14s]
12:57:05.021171 [info ] [MainThread]: 
12:57:05.025499 [debug] [MainThread]: On master: Close
12:57:05.201342 [info ] [MainThread]: 
12:57:05.203234 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 15.12s.
12:57:05.205340 [debug] [MainThread]: Connection 'master' was properly closed.
12:57:05.207508 [debug] [MainThread]: Connection 'snapshot.dbt_tests.first_model_snapshot' was properly closed.
12:57:05.242045 [info ] [MainThread]: 
12:57:05.243345 [info ] [MainThread]: [32mCompleted successfully[0m
12:57:05.244730 [info ] [MainThread]: 
12:57:05.246178 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:57:05.247804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d1f54c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28c9bb1b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28c9bb1bd0>]}


============================== 2022-01-24 13:21:28.842028 | 33e6b61a-28ee-4077-8d46-74065edb39fd ==============================
13:21:28.842028 [info ] [MainThread]: Running with dbt=1.0.1
13:21:28.845247 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.sources_customer_orders'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:21:28.847252 [debug] [MainThread]: Tracking: tracking
13:21:28.849582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68bce3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68bce3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68bce3ed0>]}
13:21:29.070227 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
13:21:29.072708 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/sources_customer_orders.sql
13:21:29.075523 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
13:21:29.148781 [debug] [MainThread]: 1699: static parser successfully parsed example/sources_customer_orders.sql
13:21:29.323435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68bc6c610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68a740990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb68a740450>]}


============================== 2022-01-24 13:23:13.525914 | 24a24bab-3d60-42e0-85ef-5c7d6a0256f3 ==============================
13:23:13.525914 [info ] [MainThread]: Running with dbt=1.0.1
13:23:13.528596 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.sources_customer_orders'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
13:23:13.531013 [debug] [MainThread]: Tracking: tracking
13:23:13.533282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5306cdf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5306cdd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5306cded0>]}
13:23:13.762225 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
13:23:13.764985 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/sources_customer_orders.sql
13:23:13.767305 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
13:23:13.839780 [debug] [MainThread]: 1699: static parser successfully parsed example/sources_customer_orders.sql
13:23:14.169159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24a24bab-3d60-42e0-85ef-5c7d6a0256f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff532f38fd0>]}
13:23:14.207242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24a24bab-3d60-42e0-85ef-5c7d6a0256f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5307012d0>]}
13:23:14.208659 [info ] [MainThread]: Found 8 models, 10 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
13:23:14.216847 [info ] [MainThread]: 
13:23:14.219708 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:23:14.223119 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:23:14.302412 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:23:14.303324 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:23:14.304142 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:23:16.204336 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.9 seconds
13:23:16.212424 [debug] [ThreadPool]: On list_analytics: Close
13:23:16.422723 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:23:16.470377 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:23:16.471534 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:23:16.472442 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:23:17.838439 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.37 seconds
13:23:17.853020 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:23:18.040543 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
13:23:18.055435 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
13:23:18.057071 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
13:23:18.058054 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:23:19.505897 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.45 seconds
13:23:19.517300 [debug] [ThreadPool]: On list_analytics_snapshots: Close
13:23:19.698881 [info ] [MainThread]: 
13:23:19.703105 [info ] [MainThread]: Running 1 on-run-start hook
13:23:19.708877 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
13:23:19.724182 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
13:23:19.735432 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
13:23:19.738806 [debug] [MainThread]: Using snowflake connection "master"
13:23:19.740757 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
13:23:19.741919 [debug] [MainThread]: Opening a new connection, currently in state init
13:23:21.139790 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.4 seconds
13:23:21.143670 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.41s]
13:23:21.145232 [info ] [MainThread]: 
13:23:21.147653 [debug] [MainThread]: On master: Close
13:23:21.353605 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:23:21.357314 [info ] [MainThread]: 
13:23:21.371183 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
13:23:21.372865 [info ] [Thread-1  ]: 1 of 1 START table model dbt.sources_customer_orders............................ [RUN]
13:23:21.375686 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
13:23:21.377594 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
13:23:21.378733 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
13:23:21.394389 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
13:23:21.399796 [debug] [Thread-1  ]: finished collecting timing info
13:23:21.401157 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
13:23:21.518857 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
13:23:21.520100 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
13:23:21.520957 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:23:23.746608 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.23 seconds
13:23:23.828408 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
13:23:23.838444 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
13:23:23.839839 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
13:23:25.116533 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
13:23:25.179489 [debug] [Thread-1  ]: finished collecting timing info
13:23:25.180699 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
13:23:25.371892 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24a24bab-3d60-42e0-85ef-5c7d6a0256f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff52dc56290>]}
13:23:25.374988 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 4.00s]
13:23:25.377600 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
13:23:25.438992 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:23:25.440251 [info ] [MainThread]: 
13:23:25.441992 [info ] [MainThread]: Running 3 on-run-end hooks
13:23:25.444610 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
13:23:25.453765 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
13:23:25.461880 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
13:23:25.464407 [debug] [MainThread]: Using snowflake connection "master"
13:23:25.465800 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
13:23:25.467673 [debug] [MainThread]: Opening a new connection, currently in state closed
13:23:26.947814 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.48 seconds
13:23:26.955241 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.49s]
13:23:26.958255 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
13:23:26.974871 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
13:23:26.982710 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
13:23:26.986332 [debug] [MainThread]: Using snowflake connection "master"
13:23:26.988305 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
13:23:27.134072 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
13:23:27.142659 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
13:23:27.144744 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
13:23:27.149957 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
13:23:27.153496 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
13:23:27.155964 [debug] [MainThread]: Using snowflake connection "master"
13:23:27.156910 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
13:23:27.261339 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
13:23:27.268790 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
13:23:27.271817 [info ] [MainThread]: 
13:23:27.276455 [debug] [MainThread]: On master: Close
13:23:27.461859 [info ] [MainThread]: 
13:23:27.464314 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 13.24s.
13:23:27.468136 [debug] [MainThread]: Connection 'master' was properly closed.
13:23:27.469871 [debug] [MainThread]: Connection 'model.dbt_tests.sources_customer_orders' was properly closed.
13:23:27.505541 [info ] [MainThread]: 
13:23:27.507010 [info ] [MainThread]: [32mCompleted successfully[0m
13:23:27.509548 [info ] [MainThread]: 
13:23:27.511333 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
13:23:27.512852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff53078f6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff52d7c8850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff52d7c8950>]}


============================== 2022-01-24 13:32:55.439911 | 37a245d0-000a-4648-a757-070bd08250de ==============================
13:32:55.439911 [info ] [MainThread]: Running with dbt=1.0.1
13:32:55.443019 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
13:32:55.445114 [debug] [MainThread]: Tracking: tracking
13:32:55.447414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c8171e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c8171e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c8171dd0>]}
13:32:55.655797 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:32:55.659702 [debug] [MainThread]: Partial parsing: deleted source source.dbt_tests.sample.customer
13:32:55.661005 [debug] [MainThread]: Partial parsing: deleted source source.dbt_tests.sample.orders
13:32:55.662406 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
13:32:55.724398 [debug] [MainThread]: 1699: static parser successfully parsed example/sources_customer_orders.sql
13:32:56.104444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '37a245d0-000a-4648-a757-070bd08250de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cb9f29d0>]}
13:32:56.142072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '37a245d0-000a-4648-a757-070bd08250de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c81bd7d0>]}
13:32:56.143608 [info ] [MainThread]: Found 8 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
13:32:56.150410 [info ] [MainThread]: 
13:32:56.153024 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:32:56.157530 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:32:56.224825 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:32:56.226255 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:32:56.227355 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:32:57.994390 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 1.77 seconds
13:32:58.009848 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:32:58.184985 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
13:32:58.204575 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
13:32:58.206137 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
13:32:58.207434 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:32:59.630828 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.42 seconds
13:32:59.648835 [debug] [ThreadPool]: On list_analytics_snapshots: Close
13:32:59.827659 [info ] [MainThread]: 
13:32:59.831682 [info ] [MainThread]: Running 1 on-run-start hook
13:32:59.837204 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
13:32:59.847199 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
13:32:59.858778 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
13:32:59.862522 [debug] [MainThread]: Using snowflake connection "master"
13:32:59.863733 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
13:32:59.864794 [debug] [MainThread]: Opening a new connection, currently in state init
13:33:01.150675 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.29 seconds
13:33:01.158828 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.30s]
13:33:01.161422 [info ] [MainThread]: 
13:33:01.164197 [debug] [MainThread]: On master: Close
13:33:01.369343 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:33:01.372648 [info ] [MainThread]: 
13:33:01.391833 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:33:01.393926 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
13:33:01.397737 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:33:01.399306 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:33:01.401193 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:33:01.496218 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:33:01.502242 [debug] [Thread-1  ]: finished collecting timing info
13:33:01.503581 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:33:01.596822 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:33:01.605125 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:33:01.606397 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
13:33:01.607783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:03.730069 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
13:33:03.741370 [debug] [Thread-1  ]: finished collecting timing info
13:33:03.742249 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
13:33:03.910181 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 2.51s]
13:33:03.914742 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:33:03.918420 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
13:33:03.922915 [info ] [Thread-1  ]: 2 of 12 START test assert_under_100m............................................ [RUN]
13:33:03.928737 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
13:33:03.931809 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
13:33:03.934314 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
13:33:03.955850 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
13:33:03.960385 [debug] [Thread-1  ]: finished collecting timing info
13:33:03.961188 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
13:33:03.969038 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
13:33:03.973824 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
13:33:03.974850 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
13:33:03.975679 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:06.162898 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.19 seconds
13:33:06.174404 [debug] [Thread-1  ]: finished collecting timing info
13:33:06.175941 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
13:33:06.354317 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_100m.................................................. [[32mPASS[0m in 2.43s]
13:33:06.359236 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
13:33:06.363649 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
13:33:06.365753 [info ] [Thread-1  ]: 3 of 12 START test assert_under_10_percent_null................................. [RUN]
13:33:06.367849 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
13:33:06.369725 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
13:33:06.371550 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
13:33:06.386149 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
13:33:06.391789 [debug] [Thread-1  ]: finished collecting timing info
13:33:06.397389 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
13:33:06.408011 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
13:33:06.414652 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
13:33:06.415668 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:33:06.416861 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:08.249225 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.83 seconds
13:33:08.262565 [debug] [Thread-1  ]: finished collecting timing info
13:33:08.263899 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
13:33:08.458324 [info ] [Thread-1  ]: 3 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 2.09s]
13:33:08.462243 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
13:33:08.466386 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
13:33:08.469492 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:33:08.473936 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:33:08.477114 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
13:33:08.479443 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
13:33:08.520841 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:33:08.527516 [debug] [Thread-1  ]: finished collecting timing info
13:33:08.529008 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
13:33:08.538412 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:33:08.546849 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:33:08.548098 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
13:33:08.548730 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:09.974680 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
13:33:09.988977 [debug] [Thread-1  ]: finished collecting timing info
13:33:09.991264 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:33:10.180850 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.71s]
13:33:10.183321 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
13:33:10.185624 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:33:10.187455 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:33:10.189313 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:33:10.190837 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:33:10.191823 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:33:10.209036 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:33:10.214388 [debug] [Thread-1  ]: finished collecting timing info
13:33:10.215281 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:33:10.235529 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:33:10.242638 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:33:10.243954 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:33:10.244671 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:11.601059 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
13:33:11.614523 [debug] [Thread-1  ]: finished collecting timing info
13:33:11.616135 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:33:11.784987 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.60s]
13:33:11.788594 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:33:11.792956 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:33:11.797193 [info ] [Thread-1  ]: 6 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:33:11.801486 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:33:11.803418 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:33:11.805238 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:33:11.844354 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:33:11.847971 [debug] [Thread-1  ]: finished collecting timing info
13:33:11.848877 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:33:11.854222 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:33:11.861525 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:33:11.862651 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:33:11.863467 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:13.569966 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
13:33:13.584645 [debug] [Thread-1  ]: finished collecting timing info
13:33:13.587198 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:33:13.778244 [info ] [Thread-1  ]: 6 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 1.98s]
13:33:13.781802 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:33:13.784924 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
13:33:13.787577 [info ] [Thread-1  ]: 7 of 12 START test source_not_null_sample_customer_c_custkey.................... [RUN]
13:33:13.789781 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
13:33:13.792125 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
13:33:13.793488 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
13:33:13.818884 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
13:33:13.828719 [debug] [Thread-1  ]: finished collecting timing info
13:33:13.830008 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
13:33:13.839482 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
13:33:13.844772 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
13:33:13.845925 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
13:33:13.846720 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:15.405867 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
13:33:15.420463 [debug] [Thread-1  ]: finished collecting timing info
13:33:15.422458 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: Close
13:33:15.621369 [info ] [Thread-1  ]: 7 of 12 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 1.83s]
13:33:15.623472 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
13:33:15.625889 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
13:33:15.627971 [info ] [Thread-1  ]: 8 of 12 START test source_unique_sample_customer_c_custkey...................... [RUN]
13:33:15.630147 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
13:33:15.631648 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
13:33:15.632738 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
13:33:15.663826 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
13:33:15.668223 [debug] [Thread-1  ]: finished collecting timing info
13:33:15.669243 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
13:33:15.676719 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
13:33:15.686117 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
13:33:15.687463 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:33:15.688317 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:17.251923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
13:33:17.265865 [debug] [Thread-1  ]: finished collecting timing info
13:33:17.267161 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
13:33:17.470078 [info ] [Thread-1  ]: 8 of 12 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 1.84s]
13:33:17.474343 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
13:33:17.478346 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
13:33:17.482131 [info ] [Thread-1  ]: 9 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
13:33:17.488494 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
13:33:17.491941 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
13:33:17.493781 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
13:33:17.513083 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
13:33:17.519079 [debug] [Thread-1  ]: finished collecting timing info
13:33:17.520433 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
13:33:17.530616 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
13:33:17.538773 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
13:33:17.539939 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:33:17.540648 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:18.855804 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.32 seconds
13:33:18.867272 [debug] [Thread-1  ]: finished collecting timing info
13:33:18.868997 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
13:33:19.050588 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.56s]
13:33:19.053702 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
13:33:19.057330 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
13:33:19.060636 [info ] [Thread-1  ]: 10 of 12 START test unique_my_second_dbt_model_id............................... [RUN]
13:33:19.065131 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
13:33:19.070214 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
13:33:19.072856 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
13:33:19.098785 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
13:33:19.104288 [debug] [Thread-1  ]: finished collecting timing info
13:33:19.105284 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
13:33:19.113080 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
13:33:19.121749 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
13:33:19.123133 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:33:19.124220 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:20.414704 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
13:33:20.426796 [debug] [Thread-1  ]: finished collecting timing info
13:33:20.428393 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
13:33:20.814991 [info ] [Thread-1  ]: 10 of 12 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.75s]
13:33:20.819963 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
13:33:20.823702 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
13:33:20.827379 [info ] [Thread-1  ]: 11 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
13:33:20.832298 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
13:33:20.837917 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
13:33:20.841186 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
13:33:20.870050 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
13:33:20.875854 [debug] [Thread-1  ]: finished collecting timing info
13:33:20.877322 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
13:33:20.886299 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
13:33:20.896071 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
13:33:20.897563 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:33:20.898496 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:23.001067 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.1 seconds
13:33:23.009203 [debug] [Thread-1  ]: finished collecting timing info
13:33:23.010622 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:33:23.208151 [info ] [Thread-1  ]: 11 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 2.38s]
13:33:23.212259 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
13:33:23.215933 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:33:23.218777 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:33:23.221331 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:33:23.222867 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:33:23.224510 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:33:23.243429 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:33:23.249107 [debug] [Thread-1  ]: finished collecting timing info
13:33:23.249877 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:33:23.257645 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:33:23.267364 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:33:23.268875 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:33:23.269686 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:33:24.835399 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
13:33:24.842755 [debug] [Thread-1  ]: finished collecting timing info
13:33:24.844007 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:33:25.003970 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.78s]
13:33:25.005303 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:33:25.055982 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:33:25.056957 [info ] [MainThread]: 
13:33:25.057984 [info ] [MainThread]: Running 3 on-run-end hooks
13:33:25.059261 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
13:33:25.064990 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
13:33:25.070224 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
13:33:25.072812 [debug] [MainThread]: Using snowflake connection "master"
13:33:25.073785 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
13:33:25.074557 [debug] [MainThread]: Opening a new connection, currently in state closed
13:33:26.409494 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.33 seconds
13:33:26.414528 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.34s]
13:33:26.416568 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
13:33:26.423756 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
13:33:26.429901 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
13:33:26.432155 [debug] [MainThread]: Using snowflake connection "master"
13:33:26.433074 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
13:33:26.571654 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
13:33:26.581205 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
13:33:26.584682 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
13:33:26.597192 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
13:33:26.604110 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
13:33:26.611495 [debug] [MainThread]: Using snowflake connection "master"
13:33:26.613189 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
13:33:26.725716 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
13:33:26.728211 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
13:33:26.729520 [info ] [MainThread]: 
13:33:26.731011 [debug] [MainThread]: On master: Close
13:33:26.908129 [info ] [MainThread]: 
13:33:26.911830 [info ] [MainThread]: Finished running 12 tests, 4 hooks in 30.76s.
13:33:26.914196 [debug] [MainThread]: Connection 'master' was properly closed.
13:33:26.915225 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:33:26.962263 [info ] [MainThread]: 
13:33:26.965167 [info ] [MainThread]: [32mCompleted successfully[0m
13:33:26.967354 [info ] [MainThread]: 
13:33:26.968931 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
13:33:26.971075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c09b57d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c0999610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47c0999e50>]}


============================== 2022-01-24 15:01:17.905434 | 40150c5c-1f5b-4910-b3ae-f22258f704fe ==============================
15:01:17.905434 [info ] [MainThread]: Running with dbt=1.0.1
15:01:17.906967 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['sources_customer_orders'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:01:17.908169 [debug] [MainThread]: Tracking: tracking
15:01:17.909760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee43f69e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee43f69d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee43f69e90>]}
15:01:18.042352 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
15:01:18.044145 [debug] [MainThread]: Partial parsing: added file: dbt_tests://macros/group_by.sql
15:01:18.045551 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/sources_customer_orders.sql
15:01:18.046321 [debug] [MainThread]: Parsing macros/group_by.sql
15:01:18.085735 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
15:01:18.131152 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
15:01:18.161608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40150c5c-1f5b-4910-b3ae-f22258f704fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee43de8310>]}
15:01:18.242019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40150c5c-1f5b-4910-b3ae-f22258f704fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee477c1f90>]}
15:01:18.243109 [info ] [MainThread]: Found 8 models, 12 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:01:18.247341 [info ] [MainThread]: 
15:01:18.249537 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:01:18.252646 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:01:18.293512 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:01:18.294527 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:01:18.295640 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:01:19.946916 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.65 seconds
15:01:19.950892 [debug] [ThreadPool]: On list_analytics: Close
15:01:20.137438 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:01:20.160913 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:01:20.161907 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:01:20.162753 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:01:21.051406 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.89 seconds
15:01:21.060292 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:01:21.237335 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:01:21.246725 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:01:21.247844 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:01:21.248656 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:01:22.262910 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.01 seconds
15:01:22.272224 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:01:22.445621 [info ] [MainThread]: 
15:01:22.447788 [info ] [MainThread]: Running 1 on-run-start hook
15:01:22.450735 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:01:22.458045 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:01:22.466961 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:01:22.468892 [debug] [MainThread]: Using snowflake connection "master"
15:01:22.469807 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:01:22.470797 [debug] [MainThread]: Opening a new connection, currently in state init
15:01:23.329870 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.86 seconds
15:01:23.337579 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.87s]
15:01:23.339408 [info ] [MainThread]: 
15:01:23.341981 [debug] [MainThread]: On master: Close
15:01:23.493072 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:01:23.494029 [info ] [MainThread]: 
15:01:23.498715 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
15:01:23.499769 [info ] [Thread-1  ]: 1 of 1 START table model dbt.sources_customer_orders............................ [RUN]
15:01:23.501119 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
15:01:23.501774 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
15:01:23.502773 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
15:01:23.514376 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
15:01:23.519379 [debug] [Thread-1  ]: finished collecting timing info
15:01:23.520266 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
15:01:23.579185 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
15:01:23.579964 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
15:01:23.580512 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:01:25.435756 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
15:01:25.480427 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
15:01:25.486135 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
15:01:25.486852 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
15:01:26.774849 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
15:01:26.806494 [debug] [Thread-1  ]: finished collecting timing info
15:01:26.807539 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
15:01:26.984336 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40150c5c-1f5b-4910-b3ae-f22258f704fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee4233a4d0>]}
15:01:26.987080 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 3.48s]
15:01:26.989638 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
15:01:27.010125 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:01:27.011548 [info ] [MainThread]: 
15:01:27.012878 [info ] [MainThread]: Running 3 on-run-end hooks
15:01:27.014316 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:01:27.018647 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:01:27.024646 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:01:27.027486 [debug] [MainThread]: Using snowflake connection "master"
15:01:27.028720 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:01:27.029602 [debug] [MainThread]: Opening a new connection, currently in state closed
15:01:27.861780 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.83 seconds
15:01:27.863706 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.84s]
15:01:27.864661 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
15:01:27.869010 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
15:01:27.873931 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
15:01:27.876764 [debug] [MainThread]: Using snowflake connection "master"
15:01:27.877989 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:01:28.015940 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
15:01:28.018343 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
15:01:28.019599 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
15:01:28.024676 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
15:01:28.027880 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
15:01:28.029792 [debug] [MainThread]: Using snowflake connection "master"
15:01:28.030789 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:01:28.134487 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
15:01:28.136852 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
15:01:28.138484 [info ] [MainThread]: 
15:01:28.140699 [debug] [MainThread]: On master: Close
15:01:28.307878 [info ] [MainThread]: 
15:01:28.310057 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 10.06s.
15:01:28.312301 [debug] [MainThread]: Connection 'master' was properly closed.
15:01:28.314181 [debug] [MainThread]: Connection 'model.dbt_tests.sources_customer_orders' was properly closed.
15:01:28.337615 [info ] [MainThread]: 
15:01:28.339000 [info ] [MainThread]: [32mCompleted successfully[0m
15:01:28.341121 [info ] [MainThread]: 
15:01:28.343419 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:01:28.346223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee423301d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee4ff3c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee4ff3ce50>]}


============================== 2022-01-24 15:15:54.718736 | 4eed5a80-c4be-4afc-93c6-1bdd71565c21 ==============================
15:15:54.718736 [info ] [MainThread]: Running with dbt=1.0.1
15:15:54.719978 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.rename_segments_macro_test'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:15:54.720696 [debug] [MainThread]: Tracking: tracking
15:15:54.721999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d58169e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d58169bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d58169f10>]}
15:15:54.859105 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
15:15:54.860622 [debug] [MainThread]: Partial parsing: added file: dbt_tests://models/example/rename_segments_macro_test.sql
15:15:54.861599 [debug] [MainThread]: Partial parsing: added file: dbt_tests://macros/renaming_segments.sql
15:15:54.862313 [debug] [MainThread]: Parsing macros/renaming_segments.sql
15:15:54.903818 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
15:15:54.944297 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
15:15:54.975628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4eed5a80-c4be-4afc-93c6-1bdd71565c21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d53bea050>]}
15:15:55.058658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4eed5a80-c4be-4afc-93c6-1bdd71565c21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d5b9f4a10>]}
15:15:55.059802 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:15:55.063954 [info ] [MainThread]: 
15:15:55.066003 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:15:55.068806 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:15:55.108456 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:15:55.109376 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:15:55.110351 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:15:56.335518 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.23 seconds
15:15:56.339692 [debug] [ThreadPool]: On list_analytics: Close
15:15:56.526488 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:15:56.550614 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:15:56.551570 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:15:56.552292 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:15:57.457589 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.91 seconds
15:15:57.464713 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:15:57.632072 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:15:57.642914 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:15:57.644084 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:15:57.645000 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:15:58.548845 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.9 seconds
15:15:58.560967 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:15:58.745374 [info ] [MainThread]: 
15:15:58.747078 [info ] [MainThread]: Running 1 on-run-start hook
15:15:58.748957 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:15:58.755184 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:15:58.764064 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:15:58.767345 [debug] [MainThread]: Using snowflake connection "master"
15:15:58.768866 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:15:58.769942 [debug] [MainThread]: Opening a new connection, currently in state init
15:15:59.614834 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.84 seconds
15:15:59.622052 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.86s]
15:15:59.624158 [info ] [MainThread]: 
15:15:59.626389 [debug] [MainThread]: On master: Close
15:15:59.791440 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:15:59.792747 [info ] [MainThread]: 
15:15:59.797852 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
15:15:59.799165 [info ] [Thread-1  ]: 1 of 1 START table model dbt.rename_segments_macro_test......................... [RUN]
15:15:59.800817 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:15:59.801593 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
15:15:59.802729 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
15:15:59.810518 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
15:15:59.817076 [debug] [Thread-1  ]: finished collecting timing info
15:15:59.818681 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
15:15:59.875123 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:15:59.876142 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
15:15:59.876978 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:01.780834 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
15:16:01.824468 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
15:16:01.831527 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:16:01.832512 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM snowflake_sample_data.tpch_sf1.customer
      );
15:16:02.942549 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.11 seconds
15:16:02.986915 [debug] [Thread-1  ]: finished collecting timing info
15:16:02.987863 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
15:16:03.154565 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eed5a80-c4be-4afc-93c6-1bdd71565c21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d52763510>]}
15:16:03.156726 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 3.35s]
15:16:03.158532 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
15:16:03.259074 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:16:03.262177 [info ] [MainThread]: 
15:16:03.265973 [info ] [MainThread]: Running 3 on-run-end hooks
15:16:03.270707 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:16:03.282053 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:16:03.288329 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:16:03.290409 [debug] [MainThread]: Using snowflake connection "master"
15:16:03.291318 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:16:03.292401 [debug] [MainThread]: Opening a new connection, currently in state closed
15:16:04.123135 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.83 seconds
15:16:04.128699 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.84s]
15:16:04.131334 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
15:16:04.139173 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
15:16:04.145695 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
15:16:04.149924 [debug] [MainThread]: Using snowflake connection "master"
15:16:04.151316 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:16:04.301618 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
15:16:04.309040 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
15:16:04.312014 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
15:16:04.319637 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
15:16:04.323290 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
15:16:04.325175 [debug] [MainThread]: Using snowflake connection "master"
15:16:04.326066 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:16:04.431290 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
15:16:04.433653 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
15:16:04.434728 [info ] [MainThread]: 
15:16:04.435916 [debug] [MainThread]: On master: Close
15:16:04.594605 [info ] [MainThread]: 
15:16:04.596591 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 9.53s.
15:16:04.598519 [debug] [MainThread]: Connection 'master' was properly closed.
15:16:04.600022 [debug] [MainThread]: Connection 'model.dbt_tests.rename_segments_macro_test' was properly closed.
15:16:04.622803 [info ] [MainThread]: 
15:16:04.623880 [info ] [MainThread]: [32mCompleted successfully[0m
15:16:04.625163 [info ] [MainThread]: 
15:16:04.626410 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:16:04.629484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d5b9f4a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d52275b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d52275ad0>]}


============================== 2022-01-24 15:31:01.537179 | 4beb7e26-d7dc-4fab-9112-4392cfc56114 ==============================
15:31:01.537179 [info ] [MainThread]: Running with dbt=1.0.1
15:31:01.538405 [debug] [MainThread]: running dbt with arguments Namespace(args='{warehouse_name: transform_wh}', cls=<class 'dbt.task.run_operation.RunOperationTask'>, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, macro='suspend', partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run-operation', send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run-operation', write_json=None)
15:31:01.539307 [debug] [MainThread]: Tracking: tracking
15:31:01.540202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f2501910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f2501e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f2546050>]}
15:31:01.684263 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
15:31:01.686056 [debug] [MainThread]: Partial parsing: added file: dbt_tests://macros/suspend_warehouse.sql
15:31:01.687055 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
15:31:01.725534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4beb7e26-d7dc-4fab-9112-4392cfc56114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f13e60d0>]}
15:31:01.742375 [debug] [MainThread]: Acquiring new snowflake connection "macro_suspend"
15:31:01.770943 [debug] [MainThread]: Using snowflake connection "macro_suspend"
15:31:01.771877 [debug] [MainThread]: On macro_suspend: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "macro_suspend"} */

    
    alter warehouse transform_wh suspend
15:31:01.772926 [debug] [MainThread]: Opening a new connection, currently in state init
15:31:03.044752 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a1d8a3-0000-1e54-0000-000298a26aa5
15:31:03.045856 [debug] [MainThread]: Snowflake adapter: Snowflake error: 090064 (22000): Invalid state. Warehouse 'TRANSFORM_WH' cannot be suspended.
15:31:03.047286 [debug] [MainThread]: Snowflake adapter: Error running SQL: macro suspend
15:31:03.048141 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
15:31:03.049199 [debug] [MainThread]: On macro_suspend: Close
15:31:03.226352 [error] [MainThread]: Encountered an error while running operation: Database Error
  090064 (22000): Invalid state. Warehouse 'TRANSFORM_WH' cannot be suspended.
15:31:03.227855 [debug] [MainThread]: 
15:31:03.229730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f13df690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f13df410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73f13df110>]}
15:31:04.586468 [debug] [MainThread]: Connection 'macro_suspend' was properly closed.


============================== 2022-01-24 17:02:09.993459 | c65ef226-440e-44a4-aee3-48a9c5ac88ac ==============================
17:02:09.993459 [info ] [MainThread]: Running with dbt=1.0.1
17:02:09.995157 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.rename_segments_macro_test'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
17:02:09.996023 [debug] [MainThread]: Tracking: tracking
17:02:09.996836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febae69fe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febae69fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febae69fe50>]}
17:02:10.147908 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
17:02:10.149140 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/rename_segments_macro_test.sql
17:02:10.149968 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://macros/suspend_warehouse.sql
17:02:10.150604 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
17:02:10.192175 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
17:02:10.274055 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
17:02:10.345814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c65ef226-440e-44a4-aee3-48a9c5ac88ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febad0e1250>]}
17:02:10.441789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c65ef226-440e-44a4-aee3-48a9c5ac88ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febae711310>]}
17:02:10.442831 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
17:02:10.447493 [info ] [MainThread]: 
17:02:10.449700 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:02:10.452666 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
17:02:10.497849 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
17:02:10.498571 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
17:02:10.499345 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:02:11.999174 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.5 seconds
17:02:12.004231 [debug] [ThreadPool]: On list_analytics: Close
17:02:12.196851 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
17:02:12.270585 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
17:02:12.271985 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
17:02:12.272915 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:02:13.158114 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.89 seconds
17:02:13.165367 [debug] [ThreadPool]: On list_analytics_dbt: Close
17:02:13.341220 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
17:02:13.353408 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
17:02:13.354454 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
17:02:13.355281 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:02:14.303427 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.95 seconds
17:02:14.307882 [debug] [ThreadPool]: On list_analytics_snapshots: Close
17:02:14.480609 [info ] [MainThread]: 
17:02:14.481914 [info ] [MainThread]: Running 1 on-run-start hook
17:02:14.483523 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
17:02:14.488229 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
17:02:14.500076 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
17:02:14.502621 [debug] [MainThread]: Using snowflake connection "master"
17:02:14.503954 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
17:02:14.505161 [debug] [MainThread]: Opening a new connection, currently in state init
17:02:15.776421 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.27 seconds
17:02:15.781640 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.28s]
17:02:15.784028 [info ] [MainThread]: 
17:02:15.785931 [debug] [MainThread]: On master: Close
17:02:15.964922 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:02:15.965919 [info ] [MainThread]: 
17:02:15.970430 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
17:02:15.971308 [info ] [Thread-1  ]: 1 of 1 START table model dbt.rename_segments_macro_test......................... [RUN]
17:02:15.973087 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:02:15.974053 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
17:02:15.975189 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
17:02:15.987766 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
17:02:15.993667 [debug] [Thread-1  ]: finished collecting timing info
17:02:15.994914 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
17:02:16.085453 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:02:16.086162 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
17:02:16.086531 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:02:19.270438 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.18 seconds
17:02:19.313737 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
17:02:19.321127 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:02:19.321890 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer(
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
17:02:19.439519 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a1d8fe-0000-1e52-0000-000298a25af5
17:02:19.440466 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 4 at position 4 unexpected 'SELECT'.
syntax error line 13 at position 12 unexpected 'THEN'.
17:02:19.442065 [debug] [Thread-1  ]: finished collecting timing info
17:02:19.443357 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
17:02:19.613894 [debug] [Thread-1  ]: Database Error in model rename_segments_macro_test (models/example/rename_segments_macro_test.sql)
  001003 (42000): SQL compilation error:
  syntax error line 4 at position 4 unexpected 'SELECT'.
  syntax error line 13 at position 12 unexpected 'THEN'.
  compiled SQL at target/run/dbt_tests/models/example/rename_segments_macro_test.sql
17:02:19.615145 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c65ef226-440e-44a4-aee3-48a9c5ac88ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb9fbba190>]}
17:02:19.616304 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt.rename_segments_macro_test................ [[31mERROR[0m in 3.64s]
17:02:19.618304 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
17:02:19.713893 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:02:19.715097 [info ] [MainThread]: 
17:02:19.716270 [info ] [MainThread]: Running 3 on-run-end hooks
17:02:19.717736 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
17:02:19.727300 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
17:02:19.734947 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
17:02:19.737309 [debug] [MainThread]: Using snowflake connection "master"
17:02:19.738707 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
17:02:19.739721 [debug] [MainThread]: Opening a new connection, currently in state closed
17:02:20.784471 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.04 seconds
17:02:20.786725 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.05s]
17:02:20.788050 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
17:02:20.793799 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
17:02:20.799021 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
17:02:20.803764 [debug] [MainThread]: Using snowflake connection "master"
17:02:20.804612 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
17:02:20.945660 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
17:02:20.948174 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
17:02:20.949514 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
17:02:20.954112 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
17:02:20.957771 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
17:02:20.961037 [debug] [MainThread]: Using snowflake connection "master"
17:02:20.962133 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
17:02:21.073044 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
17:02:21.076328 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
17:02:21.078336 [info ] [MainThread]: 
17:02:21.080344 [debug] [MainThread]: On master: Close
17:02:21.250923 [info ] [MainThread]: 
17:02:21.252023 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 10.80s.
17:02:21.253247 [debug] [MainThread]: Connection 'master' was properly closed.
17:02:21.254697 [debug] [MainThread]: Connection 'model.dbt_tests.rename_segments_macro_test' was properly closed.
17:02:21.285043 [info ] [MainThread]: 
17:02:21.286165 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
17:02:21.287261 [info ] [MainThread]: 
17:02:21.289363 [error] [MainThread]: [33mDatabase Error in model rename_segments_macro_test (models/example/rename_segments_macro_test.sql)[0m
17:02:21.291128 [error] [MainThread]:   001003 (42000): SQL compilation error:
17:02:21.293192 [error] [MainThread]:   syntax error line 4 at position 4 unexpected 'SELECT'.
17:02:21.295693 [error] [MainThread]:   syntax error line 13 at position 12 unexpected 'THEN'.
17:02:21.298060 [error] [MainThread]:   compiled SQL at target/run/dbt_tests/models/example/rename_segments_macro_test.sql
17:02:21.301243 [info ] [MainThread]: 
17:02:21.302997 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
17:02:21.304946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febad59da90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb9fcb1ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb9fcb1f50>]}


============================== 2022-01-24 17:10:20.587031 | bd6ab7cb-667d-4f46-b1f2-f23522e003b5 ==============================
17:10:20.587031 [info ] [MainThread]: Running with dbt=1.0.1
17:10:20.588354 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['tag:nightly'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
17:10:20.589152 [debug] [MainThread]: Tracking: tracking
17:10:20.590121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095da8e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095da8b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095da8ed0>]}
17:10:20.660761 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
17:10:20.661812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095d36f90>]}
17:10:20.751671 [debug] [MainThread]: Parsing macros/group_by.sql
17:10:20.755388 [debug] [MainThread]: Parsing macros/renaming_segments.sql
17:10:20.758019 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
17:10:20.761433 [debug] [MainThread]: Parsing macros/adapters.sql
17:10:20.921567 [debug] [MainThread]: Parsing macros/catalog.sql
17:10:20.929380 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
17:10:20.961379 [debug] [MainThread]: Parsing macros/materializations/merge.sql
17:10:20.973473 [debug] [MainThread]: Parsing macros/materializations/seed.sql
17:10:20.993368 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
17:10:20.996652 [debug] [MainThread]: Parsing macros/materializations/table.sql
17:10:21.007243 [debug] [MainThread]: Parsing macros/materializations/view.sql
17:10:21.013066 [debug] [MainThread]: Parsing macros/adapters/columns.sql
17:10:21.048712 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
17:10:21.059660 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
17:10:21.068844 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
17:10:21.096138 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
17:10:21.111926 [debug] [MainThread]: Parsing macros/adapters/relation.sql
17:10:21.146695 [debug] [MainThread]: Parsing macros/adapters/schema.sql
17:10:21.153921 [debug] [MainThread]: Parsing macros/etc/datetime.sql
17:10:21.187966 [debug] [MainThread]: Parsing macros/etc/statement.sql
17:10:21.202944 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
17:10:21.207039 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
17:10:21.209616 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
17:10:21.213119 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
17:10:21.215040 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
17:10:21.219223 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
17:10:21.225198 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
17:10:21.232822 [debug] [MainThread]: Parsing macros/materializations/configs.sql
17:10:21.239588 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
17:10:21.254260 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
17:10:21.317773 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
17:10:21.339013 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
17:10:21.385721 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
17:10:21.441859 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
17:10:21.447786 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
17:10:21.510436 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
17:10:21.515327 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
17:10:21.530608 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
17:10:21.536740 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
17:10:21.553151 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
17:10:21.594971 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
17:10:21.600653 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
17:10:21.645125 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
17:10:21.770712 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
17:10:21.781607 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
17:10:21.813967 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
17:10:21.824000 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
17:10:21.832783 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
17:10:21.836582 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
17:10:21.866481 [debug] [MainThread]: Parsing tests/generic/builtin.sql
17:10:22.550382 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
17:10:22.588584 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
17:10:22.613044 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
17:10:22.617307 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
17:10:22.630166 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
17:10:22.633491 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
17:10:22.645412 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
17:10:22.656747 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
17:10:22.670563 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
17:10:22.674635 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
17:10:22.686323 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
17:10:22.707764 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
17:10:22.711370 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
17:10:22.720771 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
17:10:23.170288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095d206d0>]}
17:10:23.192602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095d13710>]}
17:10:23.193808 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
17:10:23.198190 [info ] [MainThread]: 
17:10:23.200313 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:10:23.204292 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
17:10:23.249778 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
17:10:23.250479 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
17:10:23.250848 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:10:24.485798 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.23 seconds
17:10:24.491023 [debug] [ThreadPool]: On list_analytics: Close
17:10:24.677381 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
17:10:24.705391 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
17:10:24.706134 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
17:10:24.706778 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:10:25.832761 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 1.13 seconds
17:10:25.841439 [debug] [ThreadPool]: On list_analytics_dbt: Close
17:10:26.049394 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
17:10:26.058663 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
17:10:26.059795 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
17:10:26.061951 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:10:26.930309 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.87 seconds
17:10:26.934969 [debug] [ThreadPool]: On list_analytics_snapshots: Close
17:10:27.104744 [info ] [MainThread]: 
17:10:27.105972 [info ] [MainThread]: Running 1 on-run-start hook
17:10:27.107928 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
17:10:27.113930 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
17:10:27.121912 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
17:10:27.123917 [debug] [MainThread]: Using snowflake connection "master"
17:10:27.124688 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
17:10:27.125557 [debug] [MainThread]: Opening a new connection, currently in state init
17:10:28.003752 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.88 seconds
17:10:28.006226 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.88s]
17:10:28.007611 [info ] [MainThread]: 
17:10:28.008673 [debug] [MainThread]: On master: Close
17:10:28.176377 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:10:28.177894 [info ] [MainThread]: 
17:10:28.182851 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
17:10:28.183826 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
17:10:28.184971 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:10:28.185806 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
17:10:28.186780 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
17:10:28.193282 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
17:10:28.198455 [debug] [Thread-1  ]: finished collecting timing info
17:10:28.199917 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
17:10:28.264549 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:10:28.265408 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
17:10:28.265936 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:30.903978 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.64 seconds
17:10:30.942430 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
17:10:30.950031 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:10:30.950936 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
17:10:33.037415 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
17:10:33.102733 [debug] [Thread-1  ]: finished collecting timing info
17:10:33.104724 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
17:10:33.269138 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70942f7450>]}
17:10:33.273694 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 5.08s]
17:10:33.277599 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
17:10:33.281149 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
17:10:33.284561 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_time............................. [RUN]
17:10:33.287370 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
17:10:33.289156 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
17:10:33.290396 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
17:10:33.310199 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
17:10:33.314169 [debug] [Thread-1  ]: finished collecting timing info
17:10:33.315278 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
17:10:33.398087 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:33.399003 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
17:10:33.399404 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:35.023740 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
17:10:35.038106 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:35.048508 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
17:10:35.718007 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
17:10:35.751456 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:35.752717 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
17:10:35.861673 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
17:10:35.875668 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:35.876500 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
17:10:35.986124 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
17:10:36.022412 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:36.023260 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
17:10:36.127773 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
17:10:36.213803 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
17:10:36.222427 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:36.223364 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
17:10:36.345081 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
17:10:36.346247 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:36.347015 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
17:10:36.573272 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.23 seconds
17:10:36.574691 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:10:36.575619 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
17:10:36.754875 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
17:10:36.768014 [debug] [Thread-1  ]: finished collecting timing info
17:10:36.769731 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
17:10:36.947230 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70942a5450>]}
17:10:36.949367 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.66s]
17:10:36.951830 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
17:10:36.952981 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
17:10:36.955307 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
17:10:36.957038 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
17:10:36.958099 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
17:10:36.958929 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
17:10:36.973313 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
17:10:36.978380 [debug] [Thread-1  ]: finished collecting timing info
17:10:36.982288 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
17:10:36.998128 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:10:37.000218 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
17:10:37.001241 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:38.420647 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
17:10:38.425282 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
17:10:38.432659 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:10:38.433609 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
17:10:39.133088 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
17:10:39.142031 [debug] [Thread-1  ]: finished collecting timing info
17:10:39.143044 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
17:10:39.324442 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708fdf0250>]}
17:10:39.326119 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.37s]
17:10:39.327995 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
17:10:39.332818 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
17:10:39.334757 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
17:10:39.337537 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
17:10:39.338466 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
17:10:39.340911 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
17:10:39.355415 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
17:10:39.364437 [debug] [Thread-1  ]: finished collecting timing info
17:10:39.365642 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
17:10:39.382453 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
17:10:39.383699 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
17:10:39.385583 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:41.236157 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.85 seconds
17:10:41.249218 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
17:10:41.255942 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
17:10:41.256779 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
17:10:47.201883 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.94 seconds
17:10:47.205264 [debug] [Thread-1  ]: finished collecting timing info
17:10:47.206816 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
17:10:47.361409 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708e560450>]}
17:10:47.362797 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 8.02s]
17:10:47.363824 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
17:10:47.364576 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
17:10:47.366045 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
17:10:47.367448 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:10:47.368160 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
17:10:47.369135 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
17:10:47.378809 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
17:10:47.383720 [debug] [Thread-1  ]: finished collecting timing info
17:10:47.384634 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
17:10:47.393347 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:10:47.394371 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
17:10:47.395115 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:48.746153 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.35 seconds
17:10:48.750490 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
17:10:48.757767 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:10:48.758671 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
17:10:49.687289 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
17:10:49.692608 [debug] [Thread-1  ]: finished collecting timing info
17:10:49.693831 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
17:10:49.871082 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708e557890>]}
17:10:49.872151 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.50s]
17:10:49.873612 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
17:10:49.874768 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
17:10:49.876313 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
17:10:49.877717 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:10:49.878417 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
17:10:49.879596 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
17:10:49.895514 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
17:10:49.899562 [debug] [Thread-1  ]: finished collecting timing info
17:10:49.900553 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
17:10:49.909822 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:10:49.910580 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
17:10:49.911554 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:51.255473 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
17:10:51.258898 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
17:10:51.273287 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:10:51.274155 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
17:10:52.425788 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.15 seconds
17:10:52.430178 [debug] [Thread-1  ]: finished collecting timing info
17:10:52.431186 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
17:10:52.588784 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708e54ef90>]}
17:10:52.590009 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.71s]
17:10:52.591336 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
17:10:52.592675 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
17:10:52.594581 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
17:10:52.596263 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
17:10:52.597113 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
17:10:52.597784 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
17:10:52.610721 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
17:10:52.614568 [debug] [Thread-1  ]: finished collecting timing info
17:10:52.615627 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
17:10:52.622340 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
17:10:52.623230 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
17:10:52.623751 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:54.041038 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
17:10:54.045088 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
17:10:54.051147 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
17:10:54.051944 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
17:10:55.560598 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
17:10:55.568143 [debug] [Thread-1  ]: finished collecting timing info
17:10:55.569558 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
17:10:55.735110 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708fdcec10>]}
17:10:55.736717 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 3.14s]
17:10:55.738099 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
17:10:55.739095 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
17:10:55.741013 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
17:10:55.743270 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
17:10:55.744344 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
17:10:55.745660 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
17:10:55.756091 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
17:10:55.760683 [debug] [Thread-1  ]: finished collecting timing info
17:10:55.761963 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
17:10:55.769394 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
17:10:55.770495 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
17:10:55.771339 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:10:56.919959 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.15 seconds
17:10:56.923500 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
17:10:56.928953 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
17:10:56.929829 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
17:10:57.649152 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
17:10:57.659552 [debug] [Thread-1  ]: finished collecting timing info
17:10:57.661091 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
17:10:57.837421 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd6ab7cb-667d-4f46-b1f2-f23522e003b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708e587b50>]}
17:10:57.840039 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.09s]
17:10:57.842430 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
17:10:57.933176 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:10:57.934804 [info ] [MainThread]: 
17:10:57.936416 [info ] [MainThread]: Running 3 on-run-end hooks
17:10:57.938835 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
17:10:57.946209 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
17:10:57.952325 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
17:10:57.954141 [debug] [MainThread]: Using snowflake connection "master"
17:10:57.954872 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
17:10:57.955892 [debug] [MainThread]: Opening a new connection, currently in state closed
17:10:58.981365 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.03 seconds
17:10:58.984707 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.03s]
17:10:58.985895 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
17:10:58.991420 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
17:10:58.999020 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
17:10:59.001783 [debug] [MainThread]: Using snowflake connection "master"
17:10:59.002909 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
17:10:59.196906 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.19 seconds
17:10:59.199510 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.20s]
17:10:59.201065 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
17:10:59.206381 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
17:10:59.212081 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
17:10:59.214430 [debug] [MainThread]: Using snowflake connection "master"
17:10:59.215189 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
17:10:59.331334 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
17:10:59.334520 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
17:10:59.336115 [info ] [MainThread]: 
17:10:59.337822 [debug] [MainThread]: On master: Close
17:10:59.564247 [info ] [MainThread]: 
17:10:59.565592 [info ] [MainThread]: Finished running 7 table models, 1 incremental model, 4 hooks in 36.36s.
17:10:59.566976 [debug] [MainThread]: Connection 'master' was properly closed.
17:10:59.567971 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
17:10:59.598498 [info ] [MainThread]: 
17:10:59.599448 [info ] [MainThread]: [32mCompleted successfully[0m
17:10:59.601134 [info ] [MainThread]: 
17:10:59.603111 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
17:10:59.604663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7095cd65d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708e597150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f708e597a10>]}


============================== 2022-01-24 17:14:03.292346 | c1a038f2-6efa-4a57-9220-1fe01e817e00 ==============================
17:14:03.292346 [info ] [MainThread]: Running with dbt=1.0.1
17:14:03.293759 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['tag:nightly'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
17:14:03.294435 [debug] [MainThread]: Tracking: tracking
17:14:03.295184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd61ede50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd61edd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd61eded0>]}
17:14:03.424361 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
17:14:03.426016 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/playing_with_tests.sql
17:14:03.460965 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
17:14:03.683385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd7287090>]}
17:14:03.705981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd6119d90>]}
17:14:03.706978 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
17:14:03.711380 [info ] [MainThread]: 
17:14:03.713412 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:14:03.717211 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
17:14:03.768283 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
17:14:03.769117 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
17:14:03.769679 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:14:05.020386 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.25 seconds
17:14:05.024592 [debug] [ThreadPool]: On list_analytics: Close
17:14:05.200130 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
17:14:05.218587 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
17:14:05.219369 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
17:14:05.219822 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:14:06.104664 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.88 seconds
17:14:06.119725 [debug] [ThreadPool]: On list_analytics_dbt: Close
17:14:06.311278 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
17:14:06.326354 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
17:14:06.327627 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
17:14:06.328881 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:14:07.586976 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.26 seconds
17:14:07.596137 [debug] [ThreadPool]: On list_analytics_snapshots: Close
17:14:07.775123 [info ] [MainThread]: 
17:14:07.778428 [info ] [MainThread]: Running 1 on-run-start hook
17:14:07.781274 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
17:14:07.788550 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
17:14:07.796628 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
17:14:07.798967 [debug] [MainThread]: Using snowflake connection "master"
17:14:07.800853 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
17:14:07.802559 [debug] [MainThread]: Opening a new connection, currently in state init
17:14:08.647778 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.85 seconds
17:14:08.655817 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.86s]
17:14:08.657871 [info ] [MainThread]: 
17:14:08.659305 [debug] [MainThread]: On master: Close
17:14:08.819846 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:14:08.821201 [info ] [MainThread]: 
17:14:08.836360 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
17:14:08.837576 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
17:14:08.838806 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:14:08.839413 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
17:14:08.840370 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
17:14:08.847040 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
17:14:08.853312 [debug] [Thread-1  ]: finished collecting timing info
17:14:08.854556 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
17:14:08.908534 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:14:08.909575 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
17:14:08.910544 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:10.831416 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.92 seconds
17:14:10.923231 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
17:14:10.941933 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:14:10.958258 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
17:14:11.995283 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
17:14:12.027227 [debug] [Thread-1  ]: finished collecting timing info
17:14:12.028292 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
17:14:12.205058 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd47f0450>]}
17:14:12.206426 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 3.37s]
17:14:12.207738 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
17:14:12.208971 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
17:14:12.210404 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_time............................. [RUN]
17:14:12.212434 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
17:14:12.213294 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
17:14:12.214318 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
17:14:12.255435 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
17:14:12.259388 [debug] [Thread-1  ]: finished collecting timing info
17:14:12.260809 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
17:14:12.358517 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:12.359190 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
17:14:12.359661 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:13.553574 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.19 seconds
17:14:13.560028 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:13.560866 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
17:14:14.184458 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
17:14:14.232067 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:14.233056 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
17:14:14.348680 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
17:14:14.370381 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:14.371526 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
17:14:14.476551 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
17:14:14.509872 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:14.510804 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
17:14:14.610625 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
17:14:14.685688 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
17:14:14.694457 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:14.695564 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
17:14:14.826602 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
17:14:14.829468 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:14.831993 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
17:14:15.077896 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.24 seconds
17:14:15.088521 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:14:15.090060 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
17:14:15.257031 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
17:14:15.264526 [debug] [Thread-1  ]: finished collecting timing info
17:14:15.265675 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
17:14:15.447296 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd42cbed0>]}
17:14:15.448725 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.24s]
17:14:15.449978 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
17:14:15.450829 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
17:14:15.452808 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
17:14:15.454420 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
17:14:15.455390 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
17:14:15.456396 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
17:14:15.475662 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
17:14:15.480297 [debug] [Thread-1  ]: finished collecting timing info
17:14:15.481517 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
17:14:15.490783 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:14:15.491775 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
17:14:15.492514 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:16.895363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
17:14:16.899131 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
17:14:16.905130 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:14:16.905976 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
17:14:17.565492 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
17:14:17.575316 [debug] [Thread-1  ]: finished collecting timing info
17:14:17.576738 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
17:14:17.745410 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd425c450>]}
17:14:17.748489 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.29s]
17:14:17.751185 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
17:14:17.753246 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
17:14:17.756099 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
17:14:17.758566 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
17:14:17.759536 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
17:14:17.760672 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
17:14:17.769388 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
17:14:17.774973 [debug] [Thread-1  ]: finished collecting timing info
17:14:17.776579 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
17:14:17.783743 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
17:14:17.784627 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
17:14:17.785372 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:19.124409 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
17:14:19.128538 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
17:14:19.133968 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
17:14:19.134756 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
17:14:24.541910 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.41 seconds
17:14:24.552081 [debug] [Thread-1  ]: finished collecting timing info
17:14:24.553615 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
17:14:24.715991 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd425c9d0>]}
17:14:24.718997 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.96s]
17:14:24.721300 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
17:14:24.723214 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
17:14:24.725788 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
17:14:24.727995 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:14:24.729106 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
17:14:24.730285 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
17:14:24.743094 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
17:14:24.748059 [debug] [Thread-1  ]: finished collecting timing info
17:14:24.749010 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
17:14:24.756296 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:14:24.757671 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
17:14:24.758758 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:26.045066 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
17:14:26.048723 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
17:14:26.054341 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:14:26.055023 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
17:14:26.918404 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
17:14:26.929284 [debug] [Thread-1  ]: finished collecting timing info
17:14:26.930553 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
17:14:27.106247 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd42a5f10>]}
17:14:27.109065 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.38s]
17:14:27.111925 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
17:14:27.113715 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
17:14:27.115877 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
17:14:27.117840 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:14:27.118943 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
17:14:27.119957 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
17:14:27.129349 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
17:14:27.133520 [debug] [Thread-1  ]: finished collecting timing info
17:14:27.134613 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
17:14:27.141289 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:14:27.142533 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
17:14:27.143522 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:28.360162 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
17:14:28.363353 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
17:14:28.369473 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:14:28.370229 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
17:14:29.479330 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.11 seconds
17:14:29.485233 [debug] [Thread-1  ]: finished collecting timing info
17:14:29.486287 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
17:14:29.647804 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd47f5290>]}
17:14:29.649068 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.53s]
17:14:29.650267 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
17:14:29.651287 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
17:14:29.652738 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
17:14:29.654271 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
17:14:29.655193 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
17:14:29.656168 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
17:14:29.676699 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
17:14:29.681907 [debug] [Thread-1  ]: finished collecting timing info
17:14:29.682989 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
17:14:29.692922 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
17:14:29.693837 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
17:14:29.694539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:31.132248 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
17:14:31.135073 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
17:14:31.146088 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
17:14:31.146857 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
17:14:32.170642 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
17:14:32.176310 [debug] [Thread-1  ]: finished collecting timing info
17:14:32.177518 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
17:14:32.361152 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd42a1590>]}
17:14:32.362642 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.71s]
17:14:32.364106 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
17:14:32.365190 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
17:14:32.366943 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
17:14:32.368541 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
17:14:32.369789 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
17:14:32.370709 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
17:14:32.381079 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
17:14:32.386885 [debug] [Thread-1  ]: finished collecting timing info
17:14:32.388001 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
17:14:32.399962 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
17:14:32.400838 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
17:14:32.401731 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:14:33.737669 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
17:14:33.740740 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
17:14:33.744871 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
17:14:33.746297 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
17:14:34.473005 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
17:14:34.477526 [debug] [Thread-1  ]: finished collecting timing info
17:14:34.478478 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
17:14:34.653415 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a038f2-6efa-4a57-9220-1fe01e817e00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd4253310>]}
17:14:34.656782 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.28s]
17:14:34.658848 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
17:14:34.668093 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:14:34.669224 [info ] [MainThread]: 
17:14:34.670271 [info ] [MainThread]: Running 3 on-run-end hooks
17:14:34.672044 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
17:14:34.676537 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
17:14:34.682108 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
17:14:34.684862 [debug] [MainThread]: Using snowflake connection "master"
17:14:34.685922 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
17:14:34.686854 [debug] [MainThread]: Opening a new connection, currently in state closed
17:14:35.495370 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.81 seconds
17:14:35.498755 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.81s]
17:14:35.500149 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
17:14:35.505805 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
17:14:35.511020 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
17:14:35.512971 [debug] [MainThread]: Using snowflake connection "master"
17:14:35.514240 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
17:14:35.700681 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
17:14:35.705494 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
17:14:35.707296 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
17:14:35.713020 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
17:14:35.718371 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
17:14:35.720040 [debug] [MainThread]: Using snowflake connection "master"
17:14:35.720947 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
17:14:35.820709 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
17:14:35.823224 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
17:14:35.824444 [info ] [MainThread]: 
17:14:35.825645 [debug] [MainThread]: On master: Close
17:14:35.995630 [info ] [MainThread]: 
17:14:35.998354 [info ] [MainThread]: Finished running 7 table models, 1 incremental model, 4 hooks in 32.28s.
17:14:36.001151 [debug] [MainThread]: Connection 'master' was properly closed.
17:14:36.002975 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
17:14:36.027595 [info ] [MainThread]: 
17:14:36.028957 [info ] [MainThread]: [32mCompleted successfully[0m
17:14:36.030851 [info ] [MainThread]: 
17:14:36.033317 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
17:14:36.038979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd42eae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd41d3650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdd41d3410>]}


============================== 2022-01-24 17:15:30.192754 | 1a18fea2-c0db-40a3-b2e7-42d94e718d2d ==============================
17:15:30.192754 [info ] [MainThread]: Running with dbt=1.0.1
17:15:30.194865 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['tag:nightly'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
17:15:30.199109 [debug] [MainThread]: Tracking: tracking
17:15:30.200908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91b2aef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91b2aef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91b2aeed0>]}
17:15:30.333123 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
17:15:30.334841 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/playing_with_tests.sql
17:15:30.371508 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
17:15:30.603209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91b369a50>]}
17:15:30.625814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91b30b890>]}
17:15:30.627343 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
17:15:30.632506 [info ] [MainThread]: 
17:15:30.634562 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:15:30.638799 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
17:15:30.679682 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
17:15:30.680553 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
17:15:30.681092 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:15:32.252256 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.57 seconds
17:15:32.257566 [debug] [ThreadPool]: On list_analytics: Close
17:15:32.439333 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
17:15:32.463292 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
17:15:32.465412 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
17:15:32.466916 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:15:33.650692 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 1.18 seconds
17:15:33.657026 [debug] [ThreadPool]: On list_analytics_dbt: Close
17:15:33.821323 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
17:15:33.827241 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
17:15:33.828005 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
17:15:33.828673 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:15:34.832221 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.0 seconds
17:15:34.838941 [debug] [ThreadPool]: On list_analytics_snapshots: Close
17:15:35.009941 [info ] [MainThread]: 
17:15:35.011915 [info ] [MainThread]: Running 1 on-run-start hook
17:15:35.014411 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
17:15:35.022509 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
17:15:35.031007 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
17:15:35.036262 [debug] [MainThread]: Using snowflake connection "master"
17:15:35.037544 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
17:15:35.038512 [debug] [MainThread]: Opening a new connection, currently in state init
17:15:36.075349 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.04 seconds
17:15:36.078804 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.04s]
17:15:36.080615 [info ] [MainThread]: 
17:15:36.082832 [debug] [MainThread]: On master: Close
17:15:36.259521 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:15:36.260943 [info ] [MainThread]: 
17:15:36.268239 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
17:15:36.269329 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
17:15:36.271310 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:15:36.272243 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
17:15:36.273053 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
17:15:36.283171 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
17:15:36.288667 [debug] [Thread-1  ]: finished collecting timing info
17:15:36.289432 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
17:15:36.373079 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:15:36.373905 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
17:15:36.374423 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:37.633156 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.26 seconds
17:15:37.669747 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
17:15:37.675203 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
17:15:37.675957 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

select order_date
      ,total_price
      ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
from (select o_orderdate as order_date
            ,sum(o_totalprice) as total_price
      from snowflake_sample_data.tpch_sf1.orders
      group by 1
      )
order by 1
      );
17:15:38.553669 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
17:15:38.593539 [debug] [Thread-1  ]: finished collecting timing info
17:15:38.594473 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
17:15:38.771266 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9188b2290>]}
17:15:38.772408 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.50s]
17:15:38.773437 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
17:15:38.774178 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
17:15:38.775593 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.incremental_time............................. [RUN]
17:15:38.777100 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
17:15:38.777839 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
17:15:38.778716 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
17:15:38.817994 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
17:15:38.823784 [debug] [Thread-1  ]: finished collecting timing info
17:15:38.824488 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
17:15:38.924477 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:38.925163 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
17:15:38.925801 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:40.151117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
17:15:40.157395 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:40.158428 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
17:15:40.649977 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.49 seconds
17:15:40.677726 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:40.678497 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
17:15:40.804678 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
17:15:40.820032 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:40.820860 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
17:15:40.921397 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
17:15:40.946281 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:40.947062 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
17:15:41.048305 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
17:15:41.125868 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
17:15:41.134311 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:41.135208 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
17:15:41.256871 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
17:15:41.257590 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:41.257991 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
17:15:41.570648 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.31 seconds
17:15:41.572120 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
17:15:41.572840 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
17:15:41.733638 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
17:15:41.738215 [debug] [Thread-1  ]: finished collecting timing info
17:15:41.739093 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
17:15:41.921293 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9183c6bd0>]}
17:15:41.923680 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.14s]
17:15:41.926613 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
17:15:41.928032 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
17:15:41.930219 [info ] [Thread-1  ]: 3 of 8 START table model dbt.first_model........................................ [RUN]
17:15:41.932543 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
17:15:41.933714 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
17:15:41.935322 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
17:15:41.945227 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
17:15:41.949052 [debug] [Thread-1  ]: finished collecting timing info
17:15:41.949963 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
17:15:41.958407 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:15:41.959229 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
17:15:41.959810 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:43.284110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.32 seconds
17:15:43.287313 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
17:15:43.293077 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:15:43.293843 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
17:15:43.946203 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
17:15:43.949340 [debug] [Thread-1  ]: finished collecting timing info
17:15:43.950253 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
17:15:44.116909 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91833ebd0>]}
17:15:44.118302 [info ] [Thread-1  ]: 3 of 8 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.18s]
17:15:44.121097 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
17:15:44.122827 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
17:15:44.124687 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
17:15:44.126137 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
17:15:44.126885 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
17:15:44.127734 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
17:15:44.134552 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
17:15:44.141740 [debug] [Thread-1  ]: finished collecting timing info
17:15:44.143302 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
17:15:44.150112 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
17:15:44.151090 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
17:15:44.152036 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:45.750061 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.6 seconds
17:15:45.753768 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
17:15:45.760006 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
17:15:45.761303 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
17:15:50.709204 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 4.95 seconds
17:15:50.712862 [debug] [Thread-1  ]: finished collecting timing info
17:15:50.713693 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
17:15:50.874556 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb918359ed0>]}
17:15:50.876156 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.75s]
17:15:50.877549 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
17:15:50.878708 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
17:15:50.880769 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
17:15:50.882232 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:15:50.883060 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
17:15:50.884156 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
17:15:50.896966 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
17:15:50.901800 [debug] [Thread-1  ]: finished collecting timing info
17:15:50.902668 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
17:15:50.912714 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:15:50.913653 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
17:15:50.914373 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:52.402642 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
17:15:52.406645 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
17:15:52.422250 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
17:15:52.423346 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
17:15:53.196310 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
17:15:53.202910 [debug] [Thread-1  ]: finished collecting timing info
17:15:53.204602 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
17:15:53.397054 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb918326810>]}
17:15:53.398067 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.51s]
17:15:53.399301 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
17:15:53.400680 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
17:15:53.402143 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
17:15:53.404423 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:15:53.405492 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
17:15:53.406477 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
17:15:53.419025 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
17:15:53.422134 [debug] [Thread-1  ]: finished collecting timing info
17:15:53.423684 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
17:15:53.432461 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:15:53.433221 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
17:15:53.433911 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:54.932110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
17:15:54.935263 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
17:15:54.943802 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
17:15:54.944992 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
17:15:55.936846 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
17:15:55.953856 [debug] [Thread-1  ]: finished collecting timing info
17:15:55.957433 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
17:15:56.139530 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9183012d0>]}
17:15:56.140672 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.74s]
17:15:56.142850 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
17:15:56.144244 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
17:15:56.145885 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
17:15:56.147630 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
17:15:56.148773 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
17:15:56.149637 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
17:15:56.170975 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
17:15:56.174887 [debug] [Thread-1  ]: finished collecting timing info
17:15:56.176187 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
17:15:56.186679 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
17:15:56.187896 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
17:15:56.188917 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:57.434120 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.25 seconds
17:15:57.438783 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
17:15:57.447308 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
17:15:57.448617 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
17:15:58.466907 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
17:15:58.474345 [debug] [Thread-1  ]: finished collecting timing info
17:15:58.476413 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
17:15:58.651193 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91839c5d0>]}
17:15:58.652583 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.50s]
17:15:58.653754 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
17:15:58.654673 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
17:15:58.656362 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
17:15:58.658086 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
17:15:58.659576 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
17:15:58.660461 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
17:15:58.669319 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
17:15:58.673644 [debug] [Thread-1  ]: finished collecting timing info
17:15:58.674658 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
17:15:58.688040 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
17:15:58.689000 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
17:15:58.689833 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:15:59.995162 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
17:15:59.998197 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
17:16:00.003670 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
17:16:00.004566 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
17:16:00.714638 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
17:16:00.720988 [debug] [Thread-1  ]: finished collecting timing info
17:16:00.722523 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
17:16:01.019678 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a18fea2-c0db-40a3-b2e7-42d94e718d2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9188f0b10>]}
17:16:01.021100 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.36s]
17:16:01.022364 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
17:16:01.058886 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:16:01.060252 [info ] [MainThread]: 
17:16:01.061651 [info ] [MainThread]: Running 3 on-run-end hooks
17:16:01.063156 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
17:16:01.067471 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
17:16:01.072737 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
17:16:01.074079 [debug] [MainThread]: Using snowflake connection "master"
17:16:01.074707 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
17:16:01.075970 [debug] [MainThread]: Opening a new connection, currently in state closed
17:16:01.910316 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.83 seconds
17:16:01.913915 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.84s]
17:16:01.915318 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
17:16:01.920366 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
17:16:01.925494 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
17:16:01.928081 [debug] [MainThread]: Using snowflake connection "master"
17:16:01.930328 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
17:16:02.094638 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
17:16:02.097320 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
17:16:02.098816 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
17:16:02.104613 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
17:16:02.108236 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
17:16:02.110718 [debug] [MainThread]: Using snowflake connection "master"
17:16:02.112315 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
17:16:02.220690 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
17:16:02.229822 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
17:16:02.232554 [info ] [MainThread]: 
17:16:02.235102 [debug] [MainThread]: On master: Close
17:16:02.401771 [info ] [MainThread]: 
17:16:02.404255 [info ] [MainThread]: Finished running 7 table models, 1 incremental model, 4 hooks in 31.77s.
17:16:02.407475 [debug] [MainThread]: Connection 'master' was properly closed.
17:16:02.410082 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
17:16:02.440248 [info ] [MainThread]: 
17:16:02.441232 [info ] [MainThread]: [32mCompleted successfully[0m
17:16:02.442837 [info ] [MainThread]: 
17:16:02.444800 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
17:16:02.447078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb91b30b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9182e6450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9182e6510>]}


============================== 2022-01-24 17:17:01.610902 | 5d6803a9-c39b-452f-b954-60c5e20823f8 ==============================
17:17:01.610902 [info ] [MainThread]: Running with dbt=1.0.1
17:17:01.612280 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['tag:nightly'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
17:17:01.613205 [debug] [MainThread]: Tracking: tracking
17:17:01.614537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8da4ebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8da4eed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8da4ef50>]}
17:17:01.674770 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
17:17:01.675855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5d6803a9-c39b-452f-b954-60c5e20823f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8c9f0fd0>]}
17:17:01.754021 [debug] [MainThread]: Parsing macros/group_by.sql
17:17:01.757596 [debug] [MainThread]: Parsing macros/renaming_segments.sql
17:17:01.759482 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
17:17:01.763694 [debug] [MainThread]: Parsing macros/adapters.sql
17:17:02.022969 [debug] [MainThread]: Parsing macros/catalog.sql
17:17:02.037241 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
17:17:02.093906 [debug] [MainThread]: Parsing macros/materializations/merge.sql
17:17:02.120575 [debug] [MainThread]: Parsing macros/materializations/seed.sql
17:17:02.148457 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
17:17:02.152545 [debug] [MainThread]: Parsing macros/materializations/table.sql
17:17:02.162605 [debug] [MainThread]: Parsing macros/materializations/view.sql
17:17:02.169258 [debug] [MainThread]: Parsing macros/adapters/columns.sql
17:17:02.208897 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
17:17:02.223769 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
17:17:02.236040 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
17:17:02.264840 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
17:17:02.284621 [debug] [MainThread]: Parsing macros/adapters/relation.sql
17:17:02.318987 [debug] [MainThread]: Parsing macros/adapters/schema.sql
17:17:02.325240 [debug] [MainThread]: Parsing macros/etc/datetime.sql
17:17:02.359125 [debug] [MainThread]: Parsing macros/etc/statement.sql
17:17:02.374281 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
17:17:02.378353 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
17:17:02.380223 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
17:17:02.382162 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
17:17:02.383999 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
17:17:02.387980 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
17:17:02.393116 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
17:17:02.402240 [debug] [MainThread]: Parsing macros/materializations/configs.sql
17:17:02.410347 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
17:17:02.424606 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
17:17:02.488796 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
17:17:02.510824 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
17:17:02.557016 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
17:17:02.603266 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
17:17:02.608533 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
17:17:02.670176 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
17:17:02.675201 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
17:17:02.690542 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
17:17:02.697540 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
17:17:02.711158 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
17:17:02.747467 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
17:17:02.751760 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
17:17:02.795616 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
17:17:02.918347 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
17:17:02.926282 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
17:17:02.955317 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
17:17:02.965043 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
17:17:02.972877 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
17:17:02.977155 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
17:17:03.005571 [debug] [MainThread]: Parsing tests/generic/builtin.sql
17:17:03.643489 [debug] [MainThread]: 1699: static parser successfully parsed example/cumulative_orders_by_date.sql
17:17:03.681515 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
17:17:03.706152 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
17:17:03.709808 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
17:17:03.731088 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
17:17:03.734965 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
17:17:03.745977 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
17:17:03.756830 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
17:17:03.769315 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
17:17:03.772213 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
17:17:03.783477 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
17:17:03.804008 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
17:17:03.807220 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
17:17:03.817051 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
17:17:04.520696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d6803a9-c39b-452f-b954-60c5e20823f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8db17590>]}
17:17:04.542629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d6803a9-c39b-452f-b954-60c5e20823f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8c96b0d0>]}
17:17:04.543607 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
17:17:04.547642 [info ] [MainThread]: 
17:17:04.550334 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:17:04.553126 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
17:17:04.592584 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
17:17:04.593560 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
17:17:04.594250 [debug] [ThreadPool]: Opening a new connection, currently in state init
17:17:05.936307 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.34 seconds
17:17:05.940367 [debug] [ThreadPool]: On list_analytics: Close
17:17:06.105864 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
17:17:06.128718 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
17:17:06.130949 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
17:17:06.132060 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:17:06.999420 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.87 seconds
17:17:07.004065 [debug] [ThreadPool]: On list_analytics_snapshots: Close
17:17:07.160555 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
17:17:07.169199 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
17:17:07.170425 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
17:17:07.171440 [debug] [ThreadPool]: Opening a new connection, currently in state closed
17:17:08.047976 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.88 seconds
17:17:08.058042 [debug] [ThreadPool]: On list_analytics_dbt: Close
17:17:08.242822 [info ] [MainThread]: 
17:17:08.245634 [info ] [MainThread]: Running 1 on-run-start hook
17:17:08.249680 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
17:17:08.257007 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
17:17:08.269940 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
17:17:08.271755 [debug] [MainThread]: Using snowflake connection "master"
17:17:08.272517 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
17:17:08.273532 [debug] [MainThread]: Opening a new connection, currently in state init
17:17:09.101143 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.83 seconds
17:17:09.107996 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.84s]
17:17:09.110414 [info ] [MainThread]: 
17:17:09.112874 [debug] [MainThread]: On master: Close
17:17:09.276626 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
17:17:09.279188 [info ] [MainThread]: 
17:17:09.292318 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
17:17:09.293392 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
17:17:09.295057 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
17:17:09.295849 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
17:17:09.296820 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
17:17:09.307290 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
17:17:09.311944 [debug] [Thread-1  ]: finished collecting timing info
17:17:09.313100 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
17:17:09.369774 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:17:09.370701 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
17:17:09.371471 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
17:17:10.733867 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
17:17:10.767924 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
17:17:10.774253 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
17:17:10.775090 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
17:17:11.513159 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
17:17:11.551243 [debug] [Thread-1  ]: finished collecting timing info
17:17:11.552351 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
17:17:11.705817 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d6803a9-c39b-452f-b954-60c5e20823f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8c055dd0>]}
17:17:11.708197 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.41s]
17:17:11.709742 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
17:17:11.875497 [debug] [MainThread]: Acquiring new snowflake connection "master"
17:17:11.878357 [info ] [MainThread]: 
17:17:11.882202 [info ] [MainThread]: Running 3 on-run-end hooks
17:17:11.888245 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
17:17:11.898860 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
17:17:11.906699 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
17:17:11.908624 [debug] [MainThread]: Using snowflake connection "master"
17:17:11.909437 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
17:17:11.910379 [debug] [MainThread]: Opening a new connection, currently in state closed
17:17:12.802124 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.89 seconds
17:17:12.806461 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.90s]
17:17:12.808629 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
17:17:12.814278 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
17:17:12.820388 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
17:17:12.822544 [debug] [MainThread]: Using snowflake connection "master"
17:17:12.823428 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
17:17:12.993791 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
17:17:12.999178 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.18s]
17:17:13.001669 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
17:17:13.008361 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
17:17:13.011978 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
17:17:13.014066 [debug] [MainThread]: Using snowflake connection "master"
17:17:13.014999 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
17:17:13.129905 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
17:17:13.135806 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
17:17:13.138095 [info ] [MainThread]: 
17:17:13.140855 [debug] [MainThread]: On master: Close
17:17:13.327386 [info ] [MainThread]: 
17:17:13.330127 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.78s.
17:17:13.333255 [debug] [MainThread]: Connection 'master' was properly closed.
17:17:13.335367 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
17:17:13.362978 [info ] [MainThread]: 
17:17:13.364393 [info ] [MainThread]: [32mCompleted successfully[0m
17:17:13.366022 [info ] [MainThread]: 
17:17:13.369415 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
17:17:13.372693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee8da4eed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee7d231090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee7d231d50>]}


============================== 2022-01-25 05:46:45.268909 | b3c75b2e-c61c-405c-8624-f5e50e54494d ==============================
05:46:45.268909 [info ] [MainThread]: Running with dbt=1.0.1
05:46:45.271022 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.cumulative_orders_by_date'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:46:45.271995 [debug] [MainThread]: Tracking: tracking
05:46:45.273551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5293971e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5293971b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5293971f10>]}
05:46:45.429062 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
05:46:45.430760 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/cumulative_orders_by_date.sql
05:46:45.432265 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
05:46:45.475615 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
05:46:45.527749 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
05:46:45.533098 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
05:46:45.540684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5293842f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f529385b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5293808cd0>]}


============================== 2022-01-25 05:47:16.562528 | b2b999ba-57e1-47c9-bd7a-8bdbbdf30f04 ==============================
05:47:16.562528 [info ] [MainThread]: Running with dbt=1.0.1
05:47:16.563850 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.cumulative_orders_by_date'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:47:16.564656 [debug] [MainThread]: Tracking: tracking
05:47:16.565937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8606f18e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8606f188d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8606f18f10>]}
05:47:16.694969 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
05:47:16.696562 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/cumulative_orders_by_date.sql
05:47:16.697344 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
05:47:16.732360 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
05:47:16.770412 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
05:47:16.774413 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
05:47:16.786419 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
05:47:16.929650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b2b999ba-57e1-47c9-bd7a-8bdbbdf30f04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8606fd6910>]}
05:47:16.952449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b2b999ba-57e1-47c9-bd7a-8bdbbdf30f04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8606f8da50>]}
05:47:16.953748 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:47:16.958825 [info ] [MainThread]: 
05:47:16.960554 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:47:16.963111 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
05:47:17.005549 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
05:47:17.006587 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
05:47:17.007388 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:47:18.236220 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.23 seconds
05:47:18.242222 [debug] [ThreadPool]: On list_analytics: Close
05:47:18.410163 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:47:18.430719 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:47:18.431415 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:47:18.431929 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:47:19.456391 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 1.02 seconds
05:47:19.468646 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:47:19.646382 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:47:19.663332 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:47:19.664391 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:47:19.665276 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:47:20.459105 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.79 seconds
05:47:20.469028 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:47:20.619927 [info ] [MainThread]: 
05:47:20.622940 [info ] [MainThread]: Running 1 on-run-start hook
05:47:20.625021 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:47:20.631610 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:47:20.640945 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:47:20.643228 [debug] [MainThread]: Using snowflake connection "master"
05:47:20.644192 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:47:20.645125 [debug] [MainThread]: Opening a new connection, currently in state init
05:47:21.427833 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.78 seconds
05:47:21.431325 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.79s]
05:47:21.433104 [info ] [MainThread]: 
05:47:21.435193 [debug] [MainThread]: On master: Close
05:47:21.590277 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:47:21.591978 [info ] [MainThread]: 
05:47:21.601983 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
05:47:21.603400 [info ] [Thread-1  ]: 1 of 1 START table model dbt.cumulative_orders_by_date.......................... [RUN]
05:47:21.606053 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:47:21.607095 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
05:47:21.608274 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
05:47:21.617669 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
05:47:21.623260 [debug] [Thread-1  ]: finished collecting timing info
05:47:21.624599 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
05:47:21.681816 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:47:21.682691 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
05:47:21.683590 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:47:25.267965 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.58 seconds
05:47:25.311823 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
05:47:25.317709 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:47:25.318608 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
05:47:26.376699 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.06 seconds
05:47:26.405576 [debug] [Thread-1  ]: finished collecting timing info
05:47:26.406653 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
05:47:26.557437 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b999ba-57e1-47c9-bd7a-8bdbbdf30f04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8604943f50>]}
05:47:26.558766 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 4.95s]
05:47:26.559881 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
05:47:26.654198 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:47:26.654930 [info ] [MainThread]: 
05:47:26.655613 [info ] [MainThread]: Running 3 on-run-end hooks
05:47:26.656886 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:47:26.661400 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:47:26.665314 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:47:26.666724 [debug] [MainThread]: Using snowflake connection "master"
05:47:26.667888 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:47:26.669679 [debug] [MainThread]: Opening a new connection, currently in state closed
05:47:27.506305 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.84 seconds
05:47:27.513425 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.85s]
05:47:27.515659 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:47:27.523440 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:47:27.528740 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:47:27.530538 [debug] [MainThread]: Using snowflake connection "master"
05:47:27.531600 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:47:27.669430 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
05:47:27.673230 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
05:47:27.675362 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:47:27.681122 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:47:27.685069 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:47:27.687921 [debug] [MainThread]: Using snowflake connection "master"
05:47:27.689098 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:47:27.803036 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
05:47:27.809259 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
05:47:27.812576 [info ] [MainThread]: 
05:47:27.816784 [debug] [MainThread]: On master: Close
05:47:27.982907 [info ] [MainThread]: 
05:47:27.984151 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 11.02s.
05:47:27.985203 [debug] [MainThread]: Connection 'master' was properly closed.
05:47:27.986230 [debug] [MainThread]: Connection 'model.dbt_tests.cumulative_orders_by_date' was properly closed.
05:47:28.012811 [info ] [MainThread]: 
05:47:28.014138 [info ] [MainThread]: [32mCompleted successfully[0m
05:47:28.015556 [info ] [MainThread]: 
05:47:28.018505 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
05:47:28.021497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8606e4a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f860443a350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f860443aa10>]}


============================== 2022-01-27 04:38:14.060355 | d12f05aa-7b69-482b-af0f-7fd489829de9 ==============================
04:38:14.060355 [info ] [MainThread]: Running with dbt=1.0.1
04:38:14.065010 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
04:38:14.066026 [debug] [MainThread]: Tracking: tracking
04:38:14.067158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332a5253d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332a525390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332a525490>]}
04:38:14.193905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
04:38:14.195142 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
04:38:14.196145 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/cumulative_orders_by_date.sql
04:38:14.197376 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/sources_customer_orders.sql
04:38:14.214636 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
04:38:14.309514 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
04:38:14.312386 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
04:38:14.324163 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
04:38:14.328763 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
04:38:14.345097 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
04:38:14.394738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd12f05aa-7b69-482b-af0f-7fd489829de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3330432310>]}
04:38:14.410955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd12f05aa-7b69-482b-af0f-7fd489829de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332a4373d0>]}
04:38:14.412089 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:38:14.416899 [info ] [MainThread]: 
04:38:14.418002 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:38:14.420594 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:38:14.452842 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:38:14.453557 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:38:14.454283 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:38:25.923240 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 11.47 seconds
04:38:25.927504 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:38:26.053034 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:38:26.058178 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:38:26.058861 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:38:26.059624 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:38:31.909528 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 5.85 seconds
04:38:31.914547 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:38:32.055039 [info ] [MainThread]: 
04:38:32.056997 [info ] [MainThread]: Running 1 on-run-start hook
04:38:32.065610 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:38:32.069479 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:38:32.076013 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:38:32.077592 [debug] [MainThread]: Using snowflake connection "master"
04:38:32.078207 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:38:32.078728 [debug] [MainThread]: Opening a new connection, currently in state init
04:38:37.735830 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.66 seconds
04:38:37.740908 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 5.66s]
04:38:37.741954 [info ] [MainThread]: 
04:38:37.743662 [debug] [MainThread]: On master: Close
04:38:37.871965 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:38:37.872933 [info ] [MainThread]: 
04:38:37.876868 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
04:38:37.877837 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
04:38:37.880122 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
04:38:37.880938 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
04:38:37.881669 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
04:38:37.917966 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
04:38:37.921338 [debug] [Thread-1  ]: finished collecting timing info
04:38:37.922103 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
04:38:37.963752 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
04:38:37.968028 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
04:38:37.968605 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
04:38:37.974041 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:38:45.770015 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 7.8 seconds
04:38:45.782164 [debug] [Thread-1  ]: finished collecting timing info
04:38:45.783147 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
04:38:45.939999 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 8.06s]
04:38:45.941361 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
04:38:45.942753 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
04:38:45.946427 [info ] [Thread-1  ]: 2 of 12 START test assert_under_100m............................................ [RUN]
04:38:45.950501 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
04:38:45.954283 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
04:38:45.956419 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
04:38:45.966404 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
04:38:45.976523 [debug] [Thread-1  ]: finished collecting timing info
04:38:45.977742 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
04:38:45.987173 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
04:38:45.991946 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
04:38:45.993255 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
04:38:45.994336 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:38:52.511074 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.52 seconds
04:38:52.514245 [debug] [Thread-1  ]: finished collecting timing info
04:38:52.515023 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
04:38:52.653383 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_100m.................................................. [[32mPASS[0m in 6.70s]
04:38:52.654341 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
04:38:52.655411 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
04:38:52.656259 [info ] [Thread-1  ]: 3 of 12 START test assert_under_10_percent_null................................. [RUN]
04:38:52.657568 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
04:38:52.659144 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
04:38:52.660069 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
04:38:52.665091 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
04:38:52.669300 [debug] [Thread-1  ]: finished collecting timing info
04:38:52.670076 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
04:38:52.673706 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
04:38:52.677660 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
04:38:52.678326 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
04:38:52.679085 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:38:59.851672 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 7.17 seconds
04:38:59.863728 [debug] [Thread-1  ]: finished collecting timing info
04:38:59.865414 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
04:39:00.019380 [info ] [Thread-1  ]: 3 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 7.36s]
04:39:00.022727 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
04:39:00.025653 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
04:39:00.027855 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
04:39:00.030825 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
04:39:00.032150 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
04:39:00.034556 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
04:39:00.049703 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
04:39:00.054027 [debug] [Thread-1  ]: finished collecting timing info
04:39:00.054781 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
04:39:00.058090 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
04:39:00.062892 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
04:39:00.063511 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
04:39:00.064135 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:05.714816 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.65 seconds
04:39:05.718528 [debug] [Thread-1  ]: finished collecting timing info
04:39:05.719620 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
04:39:05.900777 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 5.87s]
04:39:05.902700 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
04:39:05.903769 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
04:39:05.904639 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
04:39:05.906958 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
04:39:05.908754 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
04:39:05.909579 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
04:39:05.917906 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
04:39:05.922183 [debug] [Thread-1  ]: finished collecting timing info
04:39:05.923107 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
04:39:05.926050 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
04:39:05.930729 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
04:39:05.931612 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
04:39:05.932344 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:11.841630 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.91 seconds
04:39:11.844757 [debug] [Thread-1  ]: finished collecting timing info
04:39:11.845582 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
04:39:11.996436 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 6.09s]
04:39:11.997852 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
04:39:11.998725 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
04:39:11.999859 [info ] [Thread-1  ]: 6 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
04:39:12.003944 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
04:39:12.006065 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
04:39:12.007665 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
04:39:12.023265 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
04:39:12.027907 [debug] [Thread-1  ]: finished collecting timing info
04:39:12.028841 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
04:39:12.031846 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
04:39:12.037145 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
04:39:12.038009 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
04:39:12.038867 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:18.309758 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.27 seconds
04:39:18.321819 [debug] [Thread-1  ]: finished collecting timing info
04:39:18.323506 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
04:39:18.466236 [info ] [Thread-1  ]: 6 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 6.46s]
04:39:18.470052 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
04:39:18.473036 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
04:39:18.476311 [info ] [Thread-1  ]: 7 of 12 START test source_not_null_sample_customer_c_custkey.................... [RUN]
04:39:18.480121 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
04:39:18.481872 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
04:39:18.483589 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
04:39:18.495690 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
04:39:18.503363 [debug] [Thread-1  ]: finished collecting timing info
04:39:18.504362 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
04:39:18.507563 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
04:39:18.512617 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
04:39:18.513576 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
04:39:18.514207 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:24.430665 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.92 seconds
04:39:24.434230 [debug] [Thread-1  ]: finished collecting timing info
04:39:24.435293 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: Close
04:39:24.571798 [info ] [Thread-1  ]: 7 of 12 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 6.09s]
04:39:24.572744 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
04:39:24.573669 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
04:39:24.574806 [info ] [Thread-1  ]: 8 of 12 START test source_unique_sample_customer_c_custkey...................... [RUN]
04:39:24.579290 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
04:39:24.581178 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
04:39:24.582801 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
04:39:24.601661 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
04:39:24.604718 [debug] [Thread-1  ]: finished collecting timing info
04:39:24.605340 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
04:39:24.608804 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
04:39:24.614128 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
04:39:24.614774 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
04:39:24.615249 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:30.508730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.89 seconds
04:39:30.511569 [debug] [Thread-1  ]: finished collecting timing info
04:39:30.512211 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
04:39:30.643525 [info ] [Thread-1  ]: 8 of 12 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 6.07s]
04:39:30.644717 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
04:39:30.646393 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
04:39:30.648038 [info ] [Thread-1  ]: 9 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
04:39:30.649870 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
04:39:30.651606 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
04:39:30.652825 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
04:39:30.662394 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
04:39:30.667467 [debug] [Thread-1  ]: finished collecting timing info
04:39:30.668350 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
04:39:30.671705 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
04:39:30.676800 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
04:39:30.677426 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
04:39:30.678042 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:36.750129 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.07 seconds
04:39:36.762389 [debug] [Thread-1  ]: finished collecting timing info
04:39:36.763423 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
04:39:36.912052 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 6.26s]
04:39:36.913718 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
04:39:36.915017 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
04:39:36.917061 [info ] [Thread-1  ]: 10 of 12 START test unique_my_second_dbt_model_id............................... [RUN]
04:39:36.921829 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
04:39:36.923401 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
04:39:36.926271 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
04:39:36.946097 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
04:39:36.957108 [debug] [Thread-1  ]: finished collecting timing info
04:39:36.958767 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
04:39:36.970853 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
04:39:36.977453 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
04:39:36.978266 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
04:39:36.979051 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:42.788149 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.81 seconds
04:39:42.791212 [debug] [Thread-1  ]: finished collecting timing info
04:39:42.792129 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
04:39:42.922664 [info ] [Thread-1  ]: 10 of 12 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 6.00s]
04:39:42.923918 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
04:39:42.924603 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
04:39:42.925253 [info ] [Thread-1  ]: 11 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
04:39:42.926626 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
04:39:42.927748 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
04:39:42.928885 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
04:39:42.936694 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
04:39:42.940915 [debug] [Thread-1  ]: finished collecting timing info
04:39:42.941650 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
04:39:42.944858 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
04:39:42.950785 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
04:39:42.951498 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
04:39:42.952468 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:49.373691 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.42 seconds
04:39:49.378275 [debug] [Thread-1  ]: finished collecting timing info
04:39:49.379074 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
04:39:49.509877 [info ] [Thread-1  ]: 11 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 6.58s]
04:39:49.511171 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
04:39:49.512759 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
04:39:49.513715 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
04:39:49.516317 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
04:39:49.517861 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
04:39:49.518818 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
04:39:49.530580 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
04:39:49.534679 [debug] [Thread-1  ]: finished collecting timing info
04:39:49.535611 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
04:39:49.540082 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
04:39:49.548333 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
04:39:49.549273 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
04:39:49.550303 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:39:55.745292 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.19 seconds
04:39:55.752646 [debug] [Thread-1  ]: finished collecting timing info
04:39:55.753473 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
04:39:55.886235 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 6.37s]
04:39:55.887337 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
04:39:55.933702 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:39:55.935688 [info ] [MainThread]: 
04:39:55.938360 [info ] [MainThread]: Running 3 on-run-end hooks
04:39:55.940264 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:39:55.944498 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:39:55.955357 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:39:55.957098 [debug] [MainThread]: Using snowflake connection "master"
04:39:55.957669 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:39:55.958163 [debug] [MainThread]: Opening a new connection, currently in state closed
04:40:01.704553 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.75 seconds
04:40:01.706512 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 5.75s]
04:40:01.708078 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:40:01.712955 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:40:01.717573 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:40:01.719260 [debug] [MainThread]: Using snowflake connection "master"
04:40:01.719831 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:40:01.851911 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
04:40:01.853598 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
04:40:01.854617 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:40:01.856817 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:40:01.863968 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:40:01.865648 [debug] [MainThread]: Using snowflake connection "master"
04:40:01.866394 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:40:01.964068 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
04:40:01.966899 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
04:40:01.967847 [info ] [MainThread]: 
04:40:01.968852 [debug] [MainThread]: On master: Close
04:40:02.112032 [info ] [MainThread]: 
04:40:02.113215 [info ] [MainThread]: Finished running 12 tests, 4 hooks in 107.69s.
04:40:02.114589 [debug] [MainThread]: Connection 'master' was properly closed.
04:40:02.115412 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
04:40:02.133951 [info ] [MainThread]: 
04:40:02.135117 [info ] [MainThread]: [32mCompleted successfully[0m
04:40:02.136441 [info ] [MainThread]: 
04:40:02.137267 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
04:40:02.138765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3322040310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332203c5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332203ccd0>]}


============================== 2022-01-27 05:03:09.247370 | e282e12c-79e9-4fa2-b354-a08118f503a2 ==============================
05:03:09.247370 [info ] [MainThread]: Running with dbt=1.0.1
05:03:09.249086 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
05:03:09.249796 [debug] [MainThread]: Tracking: tracking
05:03:09.250632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fb8bc710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fb8bc6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fb8bc590>]}
05:03:09.294282 [info ] [MainThread]: Unable to do partial parsing because profile has changed
05:03:09.295213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e282e12c-79e9-4fa2-b354-a08118f503a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fb839f50>]}
05:03:09.345676 [debug] [MainThread]: Parsing macros/group_by.sql
05:03:09.348508 [debug] [MainThread]: Parsing macros/renaming_segments.sql
05:03:09.349892 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
05:03:09.351981 [debug] [MainThread]: Parsing macros/adapters.sql
05:03:09.409586 [debug] [MainThread]: Parsing macros/catalog.sql
05:03:09.414980 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
05:03:09.428974 [debug] [MainThread]: Parsing macros/materializations/merge.sql
05:03:09.436234 [debug] [MainThread]: Parsing macros/materializations/seed.sql
05:03:09.446059 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
05:03:09.448986 [debug] [MainThread]: Parsing macros/materializations/table.sql
05:03:09.454787 [debug] [MainThread]: Parsing macros/materializations/view.sql
05:03:09.457396 [debug] [MainThread]: Parsing macros/adapters/columns.sql
05:03:09.472429 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
05:03:09.477558 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
05:03:09.483292 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
05:03:09.495755 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
05:03:09.503899 [debug] [MainThread]: Parsing macros/adapters/relation.sql
05:03:09.519011 [debug] [MainThread]: Parsing macros/adapters/schema.sql
05:03:09.522995 [debug] [MainThread]: Parsing macros/etc/datetime.sql
05:03:09.586520 [debug] [MainThread]: Parsing macros/etc/statement.sql
05:03:09.600510 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
05:03:09.605078 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
05:03:09.607076 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
05:03:09.609873 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
05:03:09.612298 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
05:03:09.616571 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
05:03:09.619865 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
05:03:09.624168 [debug] [MainThread]: Parsing macros/materializations/configs.sql
05:03:09.628861 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
05:03:09.635682 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
05:03:09.661048 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
05:03:09.671593 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
05:03:09.689244 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
05:03:09.707865 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
05:03:09.726047 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
05:03:09.754504 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
05:03:09.757802 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
05:03:09.765672 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
05:03:09.769472 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
05:03:09.777035 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
05:03:09.793793 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
05:03:09.796968 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
05:03:09.814522 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
05:03:09.838622 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
05:03:09.843648 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
05:03:09.854796 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
05:03:09.859518 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
05:03:09.863906 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
05:03:09.866866 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
05:03:09.877927 [debug] [MainThread]: Parsing tests/generic/builtin.sql
05:03:10.243290 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
05:03:10.265816 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
05:03:10.268520 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
05:03:10.282807 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
05:03:10.285539 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
05:03:10.293409 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
05:03:10.297074 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
05:03:10.303922 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
05:03:10.311719 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
05:03:10.320128 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
05:03:10.322796 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
05:03:10.329479 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
05:03:10.340810 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
05:03:10.343011 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
05:03:10.349294 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
05:03:10.588595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e282e12c-79e9-4fa2-b354-a08118f503a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fb8e6610>]}
05:03:10.603446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e282e12c-79e9-4fa2-b354-a08118f503a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9017c4290>]}
05:03:10.604454 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:03:10.608246 [info ] [MainThread]: 
05:03:10.609667 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:03:10.612136 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:03:10.632448 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:03:10.633260 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:03:10.634003 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:03:16.667266 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 6.03 seconds
05:03:16.671106 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:03:16.938483 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:03:16.943504 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:03:16.944262 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:03:16.947047 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:03:22.543732 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 5.6 seconds
05:03:22.551705 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:03:22.708647 [info ] [MainThread]: 
05:03:22.710321 [info ] [MainThread]: Running 1 on-run-start hook
05:03:22.711557 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:03:22.715030 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:03:22.720817 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:03:22.722217 [debug] [MainThread]: Using snowflake connection "master"
05:03:22.722699 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:03:22.723095 [debug] [MainThread]: Opening a new connection, currently in state init
05:03:28.439333 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.72 seconds
05:03:28.445927 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 5.72s]
05:03:28.448951 [info ] [MainThread]: 
05:03:28.450900 [debug] [MainThread]: On master: Close
05:03:28.595988 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:03:28.598833 [info ] [MainThread]: 
05:03:28.609144 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
05:03:28.610864 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
05:03:28.613042 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
05:03:28.614303 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
05:03:28.615345 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
05:03:28.637313 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
05:03:28.642307 [debug] [Thread-1  ]: finished collecting timing info
05:03:28.643405 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
05:03:28.668993 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
05:03:28.674301 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
05:03:28.675217 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
05:03:28.676049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:03:34.308733 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.63 seconds
05:03:34.319596 [debug] [Thread-1  ]: finished collecting timing info
05:03:34.321535 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
05:03:34.491433 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 5.88s]
05:03:34.492720 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
05:03:34.493528 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
05:03:34.494463 [info ] [Thread-1  ]: 2 of 12 START test assert_under_100m............................................ [RUN]
05:03:34.495832 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
05:03:34.496588 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
05:03:34.497376 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
05:03:34.506447 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
05:03:34.510433 [debug] [Thread-1  ]: finished collecting timing info
05:03:34.511346 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
05:03:34.514557 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
05:03:34.518360 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
05:03:34.519209 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
05:03:34.519951 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:03:40.256983 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.74 seconds
05:03:40.267739 [debug] [Thread-1  ]: finished collecting timing info
05:03:40.270608 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
05:03:40.573320 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_100m.................................................. [[32mPASS[0m in 6.08s]
05:03:40.575337 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
05:03:40.576297 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
05:03:40.577308 [info ] [Thread-1  ]: 3 of 12 START test assert_under_10_percent_null................................. [RUN]
05:03:40.578996 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
05:03:40.579916 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
05:03:40.580741 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
05:03:40.584996 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
05:03:40.589146 [debug] [Thread-1  ]: finished collecting timing info
05:03:40.593460 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
05:03:40.596838 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
05:03:40.603341 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
05:03:40.607530 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
05:03:40.608238 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:03:46.189146 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.58 seconds
05:03:46.198836 [debug] [Thread-1  ]: finished collecting timing info
05:03:46.200586 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
05:03:46.330490 [info ] [Thread-1  ]: 3 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 5.75s]
05:03:46.331960 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
05:03:46.332679 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
05:03:46.333479 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
05:03:46.334786 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
05:03:46.335373 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
05:03:46.336029 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
05:03:46.346072 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
05:03:46.349707 [debug] [Thread-1  ]: finished collecting timing info
05:03:46.350509 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
05:03:46.353347 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
05:03:46.357702 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
05:03:46.358377 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
05:03:46.359004 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:03:52.198368 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.84 seconds
05:03:52.208097 [debug] [Thread-1  ]: finished collecting timing info
05:03:52.209761 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
05:03:52.369082 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 6.03s]
05:03:52.371531 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
05:03:52.372586 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
05:03:52.374147 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
05:03:52.376298 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
05:03:52.377276 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
05:03:52.378266 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
05:03:52.386119 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
05:03:52.390290 [debug] [Thread-1  ]: finished collecting timing info
05:03:52.391151 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
05:03:52.394069 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
05:03:52.398112 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
05:03:52.398974 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
05:03:52.399683 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:03:58.444770 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.05 seconds
05:03:58.451591 [debug] [Thread-1  ]: finished collecting timing info
05:03:58.452997 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
05:03:58.600951 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 6.23s]
05:03:58.605019 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
05:03:58.607164 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
05:03:58.609768 [info ] [Thread-1  ]: 6 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
05:03:58.612557 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
05:03:58.613912 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
05:03:58.615249 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
05:03:58.627534 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
05:03:58.631456 [debug] [Thread-1  ]: finished collecting timing info
05:03:58.632342 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
05:03:58.635392 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
05:03:58.640712 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
05:03:58.641275 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
05:03:58.641798 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:04.448920 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.81 seconds
05:04:04.452609 [debug] [Thread-1  ]: finished collecting timing info
05:04:04.453667 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
05:04:04.597466 [info ] [Thread-1  ]: 6 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 5.99s]
05:04:04.605580 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
05:04:04.608545 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
05:04:04.610946 [info ] [Thread-1  ]: 7 of 12 START test source_not_null_sample_customer_c_custkey.................... [RUN]
05:04:04.613626 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
05:04:04.615054 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
05:04:04.616497 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
05:04:04.625538 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
05:04:04.630309 [debug] [Thread-1  ]: finished collecting timing info
05:04:04.631211 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
05:04:04.637188 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
05:04:04.641991 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
05:04:04.642833 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
05:04:04.643542 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:10.453686 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.81 seconds
05:04:10.456974 [debug] [Thread-1  ]: finished collecting timing info
05:04:10.457979 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: Close
05:04:10.581476 [info ] [Thread-1  ]: 7 of 12 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 5.97s]
05:04:10.584753 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
05:04:10.588159 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
05:04:10.590659 [info ] [Thread-1  ]: 8 of 12 START test source_unique_sample_customer_c_custkey...................... [RUN]
05:04:10.593785 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
05:04:10.595404 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
05:04:10.597040 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
05:04:10.622175 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
05:04:10.626768 [debug] [Thread-1  ]: finished collecting timing info
05:04:10.627748 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
05:04:10.631411 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
05:04:10.636735 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
05:04:10.637817 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
05:04:10.638634 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:16.240081 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.6 seconds
05:04:16.249752 [debug] [Thread-1  ]: finished collecting timing info
05:04:16.251450 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
05:04:16.378679 [info ] [Thread-1  ]: 8 of 12 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 5.79s]
05:04:16.380059 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
05:04:16.380757 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
05:04:16.381657 [info ] [Thread-1  ]: 9 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
05:04:16.383086 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
05:04:16.383759 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
05:04:16.384578 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
05:04:16.391484 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
05:04:16.395149 [debug] [Thread-1  ]: finished collecting timing info
05:04:16.396025 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
05:04:16.398875 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
05:04:16.403043 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
05:04:16.403769 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
05:04:16.404338 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:22.187865 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.78 seconds
05:04:22.201295 [debug] [Thread-1  ]: finished collecting timing info
05:04:22.202706 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
05:04:22.329999 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 5.95s]
05:04:22.333036 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
05:04:22.334514 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
05:04:22.335388 [info ] [Thread-1  ]: 10 of 12 START test unique_my_second_dbt_model_id............................... [RUN]
05:04:22.337273 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
05:04:22.338835 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
05:04:22.340220 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
05:04:22.353532 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
05:04:22.357474 [debug] [Thread-1  ]: finished collecting timing info
05:04:22.358255 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
05:04:22.362968 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
05:04:22.367349 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
05:04:22.368251 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
05:04:22.368853 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:27.952488 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.58 seconds
05:04:27.957472 [debug] [Thread-1  ]: finished collecting timing info
05:04:27.958415 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
05:04:28.077955 [info ] [Thread-1  ]: 10 of 12 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 5.74s]
05:04:28.079927 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
05:04:28.080998 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
05:04:28.082149 [info ] [Thread-1  ]: 11 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
05:04:28.084018 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
05:04:28.084854 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
05:04:28.085735 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
05:04:28.094407 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
05:04:28.098638 [debug] [Thread-1  ]: finished collecting timing info
05:04:28.099393 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
05:04:28.102462 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
05:04:28.109990 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
05:04:28.111243 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
05:04:28.111805 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:33.884516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.77 seconds
05:04:33.893487 [debug] [Thread-1  ]: finished collecting timing info
05:04:33.894893 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
05:04:34.017095 [info ] [Thread-1  ]: 11 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 5.93s]
05:04:34.018281 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
05:04:34.019034 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
05:04:34.019897 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
05:04:34.021120 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
05:04:34.021801 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
05:04:34.022547 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
05:04:34.028899 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
05:04:34.032898 [debug] [Thread-1  ]: finished collecting timing info
05:04:34.033540 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
05:04:34.036583 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
05:04:34.041013 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
05:04:34.041728 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
05:04:34.042351 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:04:39.988129 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.95 seconds
05:04:39.991599 [debug] [Thread-1  ]: finished collecting timing info
05:04:39.992343 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
05:04:40.114847 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 6.09s]
05:04:40.119362 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
05:04:40.211643 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:04:40.213924 [info ] [MainThread]: 
05:04:40.217389 [info ] [MainThread]: Running 3 on-run-end hooks
05:04:40.219492 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:04:40.224884 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:04:40.230577 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:04:40.232399 [debug] [MainThread]: Using snowflake connection "master"
05:04:40.233207 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:04:40.234033 [debug] [MainThread]: Opening a new connection, currently in state closed
05:04:45.820684 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.59 seconds
05:04:45.826532 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 5.59s]
05:04:45.829620 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:04:45.834665 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:04:45.840754 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:04:45.842432 [debug] [MainThread]: Using snowflake connection "master"
05:04:45.843032 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:04:45.961251 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
05:04:45.964347 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
05:04:45.966183 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:04:45.970912 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:04:45.974751 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:04:45.975901 [debug] [MainThread]: Using snowflake connection "master"
05:04:45.976277 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:04:46.057829 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
05:04:46.059578 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.08s]
05:04:46.060897 [info ] [MainThread]: 
05:04:46.061977 [debug] [MainThread]: On master: Close
05:04:46.173169 [info ] [MainThread]: 
05:04:46.174664 [info ] [MainThread]: Finished running 12 tests, 4 hooks in 95.56s.
05:04:46.176630 [debug] [MainThread]: Connection 'master' was properly closed.
05:04:46.177435 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
05:04:46.198816 [info ] [MainThread]: 
05:04:46.199827 [info ] [MainThread]: [32mCompleted successfully[0m
05:04:46.200861 [info ] [MainThread]: 
05:04:46.201770 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
05:04:46.202753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fb8e6c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8f8e97410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8fa337c50>]}


============================== 2022-01-27 05:11:59.976692 | 836026ee-1dda-4cc0-b8dd-6169bdb07fda ==============================
05:11:59.976692 [info ] [MainThread]: Running with dbt=1.0.1
05:11:59.978453 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:11:59.979126 [debug] [MainThread]: Tracking: tracking
05:11:59.980089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18eb0947d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18eb094750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18eb094810>]}
05:12:00.084882 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:12:00.085767 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:12:00.097054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '836026ee-1dda-4cc0-b8dd-6169bdb07fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18e9fa2190>]}
05:12:00.112853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '836026ee-1dda-4cc0-b8dd-6169bdb07fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18eb0f5ad0>]}
05:12:00.113994 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:12:00.117063 [info ] [MainThread]: 
05:12:00.118647 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:12:00.120657 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
05:12:00.188374 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
05:12:00.189610 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
05:12:00.190516 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:12:06.016946 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 5.83 seconds
05:12:06.020527 [debug] [ThreadPool]: On list_analytics: Close
05:12:06.142633 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:12:06.158752 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:12:06.159764 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:12:06.160509 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:12:12.194423 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 6.03 seconds
05:12:12.205720 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:12:12.339698 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:12:12.344957 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:12:12.346362 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:12:12.347439 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:12:17.920115 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 5.57 seconds
05:12:17.924715 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:12:18.068549 [info ] [MainThread]: 
05:12:18.069936 [info ] [MainThread]: Running 1 on-run-start hook
05:12:18.070972 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:12:18.073756 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:12:18.080587 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:12:18.082131 [debug] [MainThread]: Using snowflake connection "master"
05:12:18.082981 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:12:18.083769 [debug] [MainThread]: Opening a new connection, currently in state init
05:12:23.824595 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.74 seconds
05:12:23.830311 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 5.75s]
05:12:23.833553 [info ] [MainThread]: 
05:12:23.835243 [debug] [MainThread]: On master: Close
05:12:23.982042 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:12:23.984630 [info ] [MainThread]: 
05:12:23.990416 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:12:23.991619 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
05:12:23.993495 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:12:23.994291 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:12:23.994928 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:12:24.002064 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:12:24.005939 [debug] [Thread-1  ]: finished collecting timing info
05:12:24.006747 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
05:12:24.038502 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
05:12:24.039364 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
05:12:24.039851 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:12:30.801194 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.76 seconds
05:12:30.832082 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
05:12:30.838064 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
05:12:30.839018 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
05:12:31.746532 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
05:12:31.766633 [debug] [Thread-1  ]: finished collecting timing info
05:12:31.767568 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
05:12:31.931069 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '836026ee-1dda-4cc0-b8dd-6169bdb07fda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18e8610a50>]}
05:12:31.932447 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 7.94s]
05:12:31.933685 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:12:31.947177 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:12:31.948205 [info ] [MainThread]: 
05:12:31.949103 [info ] [MainThread]: Running 3 on-run-end hooks
05:12:31.950096 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:12:31.952342 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:12:31.957071 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:12:31.958532 [debug] [MainThread]: Using snowflake connection "master"
05:12:31.959272 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:12:31.960048 [debug] [MainThread]: Opening a new connection, currently in state closed
05:12:37.706240 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.75 seconds
05:12:37.707927 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 5.75s]
05:12:37.709160 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:12:37.711633 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:12:37.716133 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:12:37.717770 [debug] [MainThread]: Using snowflake connection "master"
05:12:37.718659 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:12:37.835367 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
05:12:37.839057 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
05:12:37.841285 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:12:37.845506 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:12:37.850702 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:12:37.852488 [debug] [MainThread]: Using snowflake connection "master"
05:12:37.853415 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:12:37.951247 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
05:12:37.956805 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
05:12:37.959507 [info ] [MainThread]: 
05:12:37.960921 [debug] [MainThread]: On master: Close
05:12:38.093920 [info ] [MainThread]: 
05:12:38.095923 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 37.98s.
05:12:38.097729 [debug] [MainThread]: Connection 'master' was properly closed.
05:12:38.098833 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
05:12:38.119189 [info ] [MainThread]: 
05:12:38.120538 [info ] [MainThread]: [32mCompleted successfully[0m
05:12:38.122160 [info ] [MainThread]: 
05:12:38.123649 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
05:12:38.125053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18e8b9afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18e8b34ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18e8b34a50>]}


============================== 2022-01-27 06:12:21.767874 | 0818ac5a-6244-424f-91bf-9f4dd324126b ==============================
06:12:21.767874 [info ] [MainThread]: Running with dbt=1.0.1
06:12:21.769159 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
06:12:21.769793 [debug] [MainThread]: Tracking: tracking
06:12:21.770477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd710990910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd710990950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd710990810>]}
06:12:21.878022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:12:21.878908 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:12:21.889349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0818ac5a-6244-424f-91bf-9f4dd324126b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7108a0450>]}
06:12:21.904765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0818ac5a-6244-424f-91bf-9f4dd324126b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7109f1750>]}
06:12:21.906051 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
06:12:21.909105 [info ] [MainThread]: 
06:12:21.910624 [debug] [MainThread]: Acquiring new snowflake connection "master"
06:12:21.912423 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
06:12:21.993096 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
06:12:21.994174 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
06:12:21.995108 [debug] [ThreadPool]: Opening a new connection, currently in state init
06:12:27.807983 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 5.81 seconds
06:12:27.811504 [debug] [ThreadPool]: On list_analytics: Close
06:12:27.945858 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
06:12:27.974260 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
06:12:27.974873 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
06:12:27.975368 [debug] [ThreadPool]: Opening a new connection, currently in state closed
06:12:33.688912 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 5.71 seconds
06:12:33.698794 [debug] [ThreadPool]: On list_analytics_snapshots: Close
06:12:33.837997 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
06:12:33.845317 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
06:12:33.846438 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
06:12:33.847419 [debug] [ThreadPool]: Opening a new connection, currently in state closed
06:12:39.424369 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 5.58 seconds
06:12:39.440667 [debug] [ThreadPool]: On list_analytics_dbt: Close
06:12:39.565472 [info ] [MainThread]: 
06:12:39.567119 [info ] [MainThread]: Running 1 on-run-start hook
06:12:39.568785 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
06:12:39.572774 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
06:12:39.581440 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
06:12:39.583169 [debug] [MainThread]: Using snowflake connection "master"
06:12:39.583952 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
06:12:39.584773 [debug] [MainThread]: Opening a new connection, currently in state init
06:12:45.459732 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.87 seconds
06:12:45.465286 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 5.88s]
06:12:45.468089 [info ] [MainThread]: 
06:12:45.470298 [debug] [MainThread]: On master: Close
06:12:45.634300 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
06:12:45.637444 [info ] [MainThread]: 
06:12:45.644724 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
06:12:45.646000 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
06:12:45.647734 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
06:12:45.648635 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
06:12:45.649602 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
06:12:45.657348 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
06:12:45.661275 [debug] [Thread-1  ]: finished collecting timing info
06:12:45.661882 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
06:12:45.689773 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
06:12:45.690524 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
06:12:45.691459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
06:12:52.467347 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.78 seconds
06:12:52.491856 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
06:12:52.496616 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
06:12:52.497279 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
06:12:53.321455 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
06:12:53.348533 [debug] [Thread-1  ]: finished collecting timing info
06:12:53.349347 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
06:12:53.480131 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0818ac5a-6244-424f-91bf-9f4dd324126b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd70b3f4610>]}
06:12:53.482541 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 7.83s]
06:12:53.485762 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
06:12:53.521462 [debug] [MainThread]: Acquiring new snowflake connection "master"
06:12:53.522319 [info ] [MainThread]: 
06:12:53.522986 [info ] [MainThread]: Running 3 on-run-end hooks
06:12:53.523949 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
06:12:53.526068 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
06:12:53.531004 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
06:12:53.532618 [debug] [MainThread]: Using snowflake connection "master"
06:12:53.533279 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
06:12:53.534057 [debug] [MainThread]: Opening a new connection, currently in state closed
06:12:59.324010 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.79 seconds
06:12:59.325790 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 5.79s]
06:12:59.327100 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
06:12:59.329562 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
06:12:59.336781 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
06:12:59.338441 [debug] [MainThread]: Using snowflake connection "master"
06:12:59.339194 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
06:12:59.469810 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
06:12:59.471947 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
06:12:59.473401 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
06:12:59.475710 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
06:12:59.478811 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
06:12:59.480212 [debug] [MainThread]: Using snowflake connection "master"
06:12:59.481051 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
06:12:59.575754 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
06:12:59.577722 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
06:12:59.579004 [info ] [MainThread]: 
06:12:59.580082 [debug] [MainThread]: On master: Close
06:12:59.730066 [info ] [MainThread]: 
06:12:59.733286 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 37.82s.
06:12:59.736261 [debug] [MainThread]: Connection 'master' was properly closed.
06:12:59.738031 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
06:12:59.758888 [info ] [MainThread]: 
06:12:59.760115 [info ] [MainThread]: [32mCompleted successfully[0m
06:12:59.761447 [info ] [MainThread]: 
06:12:59.762444 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
06:12:59.763650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7197e7110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd70b3e91d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd70b3e9390>]}


============================== 2022-01-27 06:14:50.619287 | e9fa0af7-fac1-4dd5-b275-4e9d7f818cf3 ==============================
06:14:50.619287 [info ] [MainThread]: Running with dbt=1.0.1
06:14:50.620597 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
06:14:50.621151 [debug] [MainThread]: Tracking: tracking
06:14:50.621792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e3b41ea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e3b41e710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e3b41e990>]}
06:14:50.722021 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
06:14:50.722710 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
06:14:50.733532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9fa0af7-fac1-4dd5-b275-4e9d7f818cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e3a321690>]}
06:14:50.748596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9fa0af7-fac1-4dd5-b275-4e9d7f818cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e3a3c1b90>]}
06:14:50.749647 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
06:14:50.752875 [info ] [MainThread]: 
06:14:50.754522 [debug] [MainThread]: Acquiring new snowflake connection "master"
06:14:50.756354 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
06:14:50.824838 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
06:14:50.825541 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
06:14:50.826108 [debug] [ThreadPool]: Opening a new connection, currently in state init
06:14:56.665555 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 5.84 seconds
06:14:56.669182 [debug] [ThreadPool]: On list_analytics: Close
06:14:56.786133 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
06:14:56.799208 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
06:14:56.800082 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
06:14:56.800808 [debug] [ThreadPool]: Opening a new connection, currently in state closed
06:15:02.422583 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 5.62 seconds
06:15:02.432486 [debug] [ThreadPool]: On list_analytics_dbt: Close
06:15:02.572814 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
06:15:02.578781 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
06:15:02.579636 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
06:15:02.580471 [debug] [ThreadPool]: Opening a new connection, currently in state closed
06:15:08.407124 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 5.83 seconds
06:15:08.414150 [debug] [ThreadPool]: On list_analytics_snapshots: Close
06:15:08.550714 [info ] [MainThread]: 
06:15:08.551997 [info ] [MainThread]: Running 1 on-run-start hook
06:15:08.553086 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
06:15:08.556090 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
06:15:08.562109 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
06:15:08.563668 [debug] [MainThread]: Using snowflake connection "master"
06:15:08.564220 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
06:15:08.564741 [debug] [MainThread]: Opening a new connection, currently in state init
06:15:14.610451 [debug] [MainThread]: SQL status: SUCCESS 1 in 6.05 seconds
06:15:14.612877 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 6.05s]
06:15:14.614523 [info ] [MainThread]: 
06:15:14.616231 [debug] [MainThread]: On master: Close
06:15:14.759879 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
06:15:14.761520 [info ] [MainThread]: 
06:15:14.766363 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
06:15:14.767646 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
06:15:14.769460 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
06:15:14.770387 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
06:15:14.771434 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
06:15:14.781454 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
06:15:14.785944 [debug] [Thread-1  ]: finished collecting timing info
06:15:14.786853 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
06:15:14.815856 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
06:15:14.816575 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
06:15:14.817124 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
06:15:21.408725 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 6.59 seconds
06:15:21.431430 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
06:15:21.437560 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
06:15:21.438267 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
06:15:22.279715 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
06:15:22.310965 [debug] [Thread-1  ]: finished collecting timing info
06:15:22.311715 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
06:15:22.424722 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e9fa0af7-fac1-4dd5-b275-4e9d7f818cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e389975d0>]}
06:15:22.426608 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 7.66s]
06:15:22.428575 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
06:15:22.441300 [debug] [MainThread]: Acquiring new snowflake connection "master"
06:15:22.442520 [info ] [MainThread]: 
06:15:22.443719 [info ] [MainThread]: Running 3 on-run-end hooks
06:15:22.445022 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
06:15:22.448568 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
06:15:22.454303 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
06:15:22.455804 [debug] [MainThread]: Using snowflake connection "master"
06:15:22.456631 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
06:15:22.457220 [debug] [MainThread]: Opening a new connection, currently in state closed
06:15:28.171159 [debug] [MainThread]: SQL status: SUCCESS 1 in 5.71 seconds
06:15:28.173988 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 5.72s]
06:15:28.175101 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
06:15:28.177570 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
06:15:28.182797 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
06:15:28.184996 [debug] [MainThread]: Using snowflake connection "master"
06:15:28.185979 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
06:15:28.298265 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
06:15:28.300500 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
06:15:28.301851 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
06:15:28.304176 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
06:15:28.307389 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
06:15:28.308989 [debug] [MainThread]: Using snowflake connection "master"
06:15:28.309770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
06:15:28.379065 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.07 seconds
06:15:28.381421 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.07s]
06:15:28.382719 [info ] [MainThread]: 
06:15:28.383987 [debug] [MainThread]: On master: Close
06:15:28.523806 [info ] [MainThread]: 
06:15:28.525645 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 37.77s.
06:15:28.527455 [debug] [MainThread]: Connection 'master' was properly closed.
06:15:28.528415 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
06:15:28.545548 [info ] [MainThread]: 
06:15:28.547097 [info ] [MainThread]: [32mCompleted successfully[0m
06:15:28.548682 [info ] [MainThread]: 
06:15:28.549789 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
06:15:28.551018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e3b465f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e38eb8ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e38eb8490>]}


============================== 2022-01-27 09:24:36.611212 | 3eab79c2-c551-4136-92ae-61aa2d84914a ==============================
09:24:36.611212 [info ] [MainThread]: Running with dbt=1.0.1
09:24:36.614730 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
09:24:36.616113 [debug] [MainThread]: Tracking: tracking
09:24:36.617956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2638c77a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2638c77550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2638c77a90>]}
09:24:36.809847 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:24:36.811133 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:24:36.832537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3eab79c2-c551-4136-92ae-61aa2d84914a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2637b61650>]}
09:24:36.858408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3eab79c2-c551-4136-92ae-61aa2d84914a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2638c27990>]}
09:24:36.859845 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:24:36.863396 [info ] [MainThread]: 
09:24:36.864978 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:24:36.866743 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:24:36.964452 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:24:36.965575 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:24:36.966460 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:24:38.291754 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.33 seconds
09:24:38.297024 [debug] [ThreadPool]: On list_analytics: Close
09:24:38.443463 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:24:38.478145 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:24:38.479229 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:24:38.480353 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:24:39.207153 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.73 seconds
09:24:39.217457 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:24:39.387164 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
09:24:39.400172 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
09:24:39.402055 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
09:24:39.404012 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:24:40.333963 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.93 seconds
09:24:40.338688 [debug] [ThreadPool]: On list_analytics_snapshots: Close
09:24:40.490243 [info ] [MainThread]: 
09:24:40.494057 [info ] [MainThread]: Running 1 on-run-start hook
09:24:40.498403 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
09:24:40.506447 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
09:24:40.537927 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
09:24:40.540597 [debug] [MainThread]: Using snowflake connection "master"
09:24:40.541441 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:24:40.542263 [debug] [MainThread]: Opening a new connection, currently in state init
09:24:41.300021 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.76 seconds
09:24:41.303402 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.76s]
09:24:41.305550 [info ] [MainThread]: 
09:24:41.307253 [debug] [MainThread]: On master: Close
09:24:41.444149 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:24:41.448190 [info ] [MainThread]: 
09:24:41.458703 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
09:24:41.461409 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
09:24:41.469685 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
09:24:41.471926 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
09:24:41.474188 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
09:24:41.496113 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
09:24:41.500700 [debug] [Thread-1  ]: finished collecting timing info
09:24:41.501761 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
09:24:41.564093 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
09:24:41.565112 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:24:41.566092 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:44.578183 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.01 seconds
09:24:44.626848 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
09:24:44.632645 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
09:24:44.633372 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:24:46.479213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
09:24:46.526023 [debug] [Thread-1  ]: finished collecting timing info
09:24:46.527600 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
09:24:46.689768 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3eab79c2-c551-4136-92ae-61aa2d84914a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2636705990>]}
09:24:46.693464 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 5.22s]
09:24:46.697387 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
09:24:46.767504 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:24:46.770997 [info ] [MainThread]: 
09:24:46.775660 [info ] [MainThread]: Running 3 on-run-end hooks
09:24:46.781328 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
09:24:46.792395 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
09:24:46.803320 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
09:24:46.806874 [debug] [MainThread]: Using snowflake connection "master"
09:24:46.807981 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:24:46.808812 [debug] [MainThread]: Opening a new connection, currently in state closed
09:24:47.689176 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.88 seconds
09:24:47.694968 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.89s]
09:24:47.699058 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
09:24:47.705303 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
09:24:47.711415 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
09:24:47.713527 [debug] [MainThread]: Using snowflake connection "master"
09:24:47.714488 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:24:47.841932 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
09:24:47.847575 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
09:24:47.851407 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
09:24:47.858302 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
09:24:47.862599 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
09:24:47.865962 [debug] [MainThread]: Using snowflake connection "master"
09:24:47.867062 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:24:47.961337 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
09:24:47.964378 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
09:24:47.966810 [info ] [MainThread]: 
09:24:47.968529 [debug] [MainThread]: On master: Close
09:24:48.168549 [info ] [MainThread]: 
09:24:48.170100 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 11.30s.
09:24:48.173121 [debug] [MainThread]: Connection 'master' was properly closed.
09:24:48.174888 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
09:24:48.219665 [info ] [MainThread]: 
09:24:48.220832 [info ] [MainThread]: [32mCompleted successfully[0m
09:24:48.222318 [info ] [MainThread]: 
09:24:48.223471 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:24:48.224614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2638cc5d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26361e37d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26361e3690>]}


============================== 2022-01-27 09:27:53.082669 | 7982f8c4-7b95-439e-a050-3df82adf8df8 ==============================
09:27:53.082669 [info ] [MainThread]: Running with dbt=1.0.1
09:27:53.084434 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
09:27:53.085538 [debug] [MainThread]: Tracking: tracking
09:27:53.086685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a717a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a717a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a717a90>]}
09:27:53.233581 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:27:53.234432 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:27:53.265886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7982f8c4-7b95-439e-a050-3df82adf8df8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a626290>]}
09:27:53.286727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7982f8c4-7b95-439e-a050-3df82adf8df8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a6c6c10>]}
09:27:53.287736 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:27:53.294271 [info ] [MainThread]: 
09:27:53.296601 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:27:53.300427 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:27:53.440867 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:27:53.441981 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:27:53.443208 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:27:54.741244 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.3 seconds
09:27:54.747401 [debug] [ThreadPool]: On list_analytics: Close
09:27:54.944764 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:27:54.980084 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:27:54.980769 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:27:54.981464 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:27:55.758582 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.78 seconds
09:27:55.768313 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:27:55.914672 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
09:27:55.943317 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
09:27:55.944665 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
09:27:55.945708 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:27:56.790446 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.84 seconds
09:27:56.797006 [debug] [ThreadPool]: On list_analytics_snapshots: Close
09:27:56.930904 [info ] [MainThread]: 
09:27:56.932929 [info ] [MainThread]: Running 1 on-run-start hook
09:27:56.935116 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
09:27:56.940049 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
09:27:56.949406 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
09:27:56.951550 [debug] [MainThread]: Using snowflake connection "master"
09:27:56.952369 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:27:56.952876 [debug] [MainThread]: Opening a new connection, currently in state init
09:27:57.837715 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.88 seconds
09:27:57.841673 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.89s]
09:27:57.843967 [info ] [MainThread]: 
09:27:57.845357 [debug] [MainThread]: On master: Close
09:27:57.984167 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:27:57.985407 [info ] [MainThread]: 
09:27:57.989357 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
09:27:57.990415 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
09:27:57.992260 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
09:27:57.993023 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
09:27:57.993781 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
09:27:58.004662 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
09:27:58.008142 [debug] [Thread-1  ]: finished collecting timing info
09:27:58.009008 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
09:27:58.077814 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
09:27:58.079052 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:27:58.080427 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:28:00.116060 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
09:28:00.148430 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
09:28:00.154445 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
09:28:00.155164 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:28:00.786878 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.63 seconds
09:28:00.841113 [debug] [Thread-1  ]: finished collecting timing info
09:28:00.842348 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
09:28:00.993975 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7982f8c4-7b95-439e-a050-3df82adf8df8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a717f90>]}
09:28:00.996400 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.00s]
09:28:00.998113 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
09:28:01.003849 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:28:01.004878 [info ] [MainThread]: 
09:28:01.006018 [info ] [MainThread]: Running 3 on-run-end hooks
09:28:01.007266 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
09:28:01.010870 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
09:28:01.016434 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
09:28:01.018626 [debug] [MainThread]: Using snowflake connection "master"
09:28:01.019669 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:28:01.020667 [debug] [MainThread]: Opening a new connection, currently in state closed
09:28:01.876045 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.86 seconds
09:28:01.882037 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.86s]
09:28:01.885700 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
09:28:01.893403 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
09:28:01.904232 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
09:28:01.908492 [debug] [MainThread]: Using snowflake connection "master"
09:28:01.910694 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:28:02.052199 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:28:02.055738 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
09:28:02.057806 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
09:28:02.061663 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
09:28:02.066667 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
09:28:02.069063 [debug] [MainThread]: Using snowflake connection "master"
09:28:02.070134 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:28:02.200068 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
09:28:02.205430 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:28:02.209292 [info ] [MainThread]: 
09:28:02.212460 [debug] [MainThread]: On master: Close
09:28:02.376148 [info ] [MainThread]: 
09:28:02.378333 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 9.08s.
09:28:02.380374 [debug] [MainThread]: Connection 'master' was properly closed.
09:28:02.381721 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
09:28:02.407363 [info ] [MainThread]: 
09:28:02.409423 [info ] [MainThread]: [32mCompleted successfully[0m
09:28:02.411434 [info ] [MainThread]: 
09:28:02.413136 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:28:02.415114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc28a758f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2880c0c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2880c0250>]}


============================== 2022-01-27 09:28:12.016703 | 4ef97981-9e33-48b5-8362-68eba54f775c ==============================
09:28:12.016703 [info ] [MainThread]: Running with dbt=1.0.1
09:28:12.019349 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
09:28:12.020679 [debug] [MainThread]: Tracking: tracking
09:28:12.021568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55ff61f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55ff61fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55ff61f950>]}
09:28:12.167656 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:28:12.168911 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:28:12.188694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ef97981-9e33-48b5-8362-68eba54f775c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55fe523410>]}
09:28:12.213323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ef97981-9e33-48b5-8362-68eba54f775c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55ff681910>]}
09:28:12.214596 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:28:12.219255 [info ] [MainThread]: 
09:28:12.221009 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:28:12.223064 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:28:12.323877 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:28:12.325045 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:28:12.326113 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:28:13.404178 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.08 seconds
09:28:13.410203 [debug] [ThreadPool]: On list_analytics: Close
09:28:13.550431 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:28:13.574793 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:28:13.575672 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:28:13.576439 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:28:14.653423 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 1.08 seconds
09:28:14.658679 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:28:14.797101 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
09:28:14.806597 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
09:28:14.807706 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
09:28:14.809443 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:28:15.638987 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.83 seconds
09:28:15.645220 [debug] [ThreadPool]: On list_analytics_snapshots: Close
09:28:15.809856 [info ] [MainThread]: 
09:28:15.812411 [info ] [MainThread]: Running 1 on-run-start hook
09:28:15.814312 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
09:28:15.819874 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
09:28:15.829836 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
09:28:15.832289 [debug] [MainThread]: Using snowflake connection "master"
09:28:15.833205 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:28:15.834125 [debug] [MainThread]: Opening a new connection, currently in state init
09:28:16.743272 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.91 seconds
09:28:16.749498 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.92s]
09:28:16.753108 [info ] [MainThread]: 
09:28:16.756352 [debug] [MainThread]: On master: Close
09:28:16.930682 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:28:16.932431 [info ] [MainThread]: 
09:28:16.937520 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
09:28:16.939083 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
09:28:16.941122 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
09:28:16.942226 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
09:28:16.943775 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
09:28:16.960527 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
09:28:16.965210 [debug] [Thread-1  ]: finished collecting timing info
09:28:16.965927 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
09:28:17.048177 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
09:28:17.049495 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:28:17.050223 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:28:18.199983 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.15 seconds
09:28:18.230785 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
09:28:18.237084 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
09:28:18.238932 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:28:19.142028 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
09:28:19.167977 [debug] [Thread-1  ]: finished collecting timing info
09:28:19.169168 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
09:28:19.316539 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ef97981-9e33-48b5-8362-68eba54f775c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55fcb926d0>]}
09:28:19.319579 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.38s]
09:28:19.322392 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
09:28:19.423453 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:28:19.424784 [info ] [MainThread]: 
09:28:19.427343 [info ] [MainThread]: Running 3 on-run-end hooks
09:28:19.429332 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
09:28:19.434961 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
09:28:19.440895 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
09:28:19.443004 [debug] [MainThread]: Using snowflake connection "master"
09:28:19.444166 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:28:19.445811 [debug] [MainThread]: Opening a new connection, currently in state closed
09:28:20.208059 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.76 seconds
09:28:20.211357 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.77s]
09:28:20.213544 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
09:28:20.221847 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
09:28:20.228086 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
09:28:20.230593 [debug] [MainThread]: Using snowflake connection "master"
09:28:20.231723 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:28:20.368365 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:28:20.374159 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:28:20.378029 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
09:28:20.384951 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
09:28:20.391878 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
09:28:20.396020 [debug] [MainThread]: Using snowflake connection "master"
09:28:20.397788 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:28:20.511276 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
09:28:20.517909 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
09:28:20.522363 [info ] [MainThread]: 
09:28:20.527981 [debug] [MainThread]: On master: Close
09:28:20.686650 [info ] [MainThread]: 
09:28:20.690127 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.47s.
09:28:20.694404 [debug] [MainThread]: Connection 'master' was properly closed.
09:28:20.697328 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
09:28:20.733179 [info ] [MainThread]: 
09:28:20.734680 [info ] [MainThread]: [32mCompleted successfully[0m
09:28:20.736751 [info ] [MainThread]: 
09:28:20.738236 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:28:20.739761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55fe5c3810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55fcb8dd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55fcb8d4d0>]}


============================== 2022-01-31 04:46:41.994128 | 50db9d08-79ec-4c1c-afac-d566cd8b4b7f ==============================
04:46:41.994128 [info ] [MainThread]: Running with dbt=1.0.1
04:46:42.000535 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:46:42.004466 [debug] [MainThread]: Tracking: tracking
04:46:42.005476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3285caea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3285caea50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3285cae9d0>]}
04:46:42.157271 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
04:46:42.158549 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
04:46:42.179300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '50db9d08-79ec-4c1c-afac-d566cd8b4b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3284ba21d0>]}
04:46:42.200384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '50db9d08-79ec-4c1c-afac-d566cd8b4b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3285d0cf50>]}
04:46:42.201567 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:46:42.205466 [info ] [MainThread]: 
04:46:42.207050 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:46:42.208931 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:46:42.318245 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:46:42.319451 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:46:42.320452 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:46:44.011442 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.69 seconds
04:46:44.018428 [debug] [ThreadPool]: On list_analytics: Close
04:46:44.200277 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:46:44.277095 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:46:44.278035 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:46:44.279241 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:46:45.317106 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.04 seconds
04:46:45.324222 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:46:45.482673 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:46:45.493883 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:46:45.495394 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:46:45.496849 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:46:46.238860 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.74 seconds
04:46:46.244254 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:46:46.382178 [info ] [MainThread]: 
04:46:46.385010 [info ] [MainThread]: Running 1 on-run-start hook
04:46:46.387225 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:46:46.399276 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:46:46.413121 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:46:46.416152 [debug] [MainThread]: Using snowflake connection "master"
04:46:46.417186 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:46:46.418364 [debug] [MainThread]: Opening a new connection, currently in state init
04:46:47.199572 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.78 seconds
04:46:47.203514 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.79s]
04:46:47.206358 [info ] [MainThread]: 
04:46:47.209096 [debug] [MainThread]: On master: Close
04:46:47.364828 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:46:47.366645 [info ] [MainThread]: 
04:46:47.372263 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:46:47.373827 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
04:46:47.375876 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:46:47.377061 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:46:47.378142 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:46:47.389976 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:46:47.401121 [debug] [Thread-1  ]: finished collecting timing info
04:46:47.402531 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:46:47.485634 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:46:47.486377 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
04:46:47.487534 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:46:50.085439 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.6 seconds
04:46:50.137021 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
04:46:50.150045 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:46:50.151477 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
04:46:51.926419 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.77 seconds
04:46:51.956391 [debug] [Thread-1  ]: finished collecting timing info
04:46:51.957149 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
04:46:52.098273 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50db9d08-79ec-4c1c-afac-d566cd8b4b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f327f067e50>]}
04:46:52.100503 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 4.72s]
04:46:52.102451 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:46:52.134074 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:46:52.136458 [info ] [MainThread]: 
04:46:52.140419 [info ] [MainThread]: Running 3 on-run-end hooks
04:46:52.142131 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:46:52.148905 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:46:52.159967 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:46:52.162441 [debug] [MainThread]: Using snowflake connection "master"
04:46:52.163726 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:46:52.164715 [debug] [MainThread]: Opening a new connection, currently in state closed
04:46:53.052885 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.89 seconds
04:46:53.056854 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.89s]
04:46:53.060928 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:46:53.066807 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:46:53.073116 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:46:53.075734 [debug] [MainThread]: Using snowflake connection "master"
04:46:53.076548 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:46:53.214379 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
04:46:53.220423 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
04:46:53.224021 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:46:53.229504 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:46:53.234438 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:46:53.237289 [debug] [MainThread]: Using snowflake connection "master"
04:46:53.238464 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:46:53.334516 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
04:46:53.340787 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
04:46:53.347019 [info ] [MainThread]: 
04:46:53.349194 [debug] [MainThread]: On master: Close
04:46:53.498529 [info ] [MainThread]: 
04:46:53.500956 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 11.29s.
04:46:53.502922 [debug] [MainThread]: Connection 'master' was properly closed.
04:46:53.505700 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:46:53.542100 [info ] [MainThread]: 
04:46:53.548328 [info ] [MainThread]: [32mCompleted successfully[0m
04:46:53.551301 [info ] [MainThread]: 
04:46:53.553316 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:46:53.556400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3285cf0f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f327f060910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f327f0608d0>]}


============================== 2022-01-31 04:47:02.123493 | 412e5b09-1122-408e-9881-779afb506ca1 ==============================
04:47:02.123493 [info ] [MainThread]: Running with dbt=1.0.1
04:47:02.125405 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:47:02.126201 [debug] [MainThread]: Tracking: tracking
04:47:02.127318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705edd09d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705edd0b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705edd0ad0>]}
04:47:02.272254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
04:47:02.272996 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
04:47:02.286119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '412e5b09-1122-408e-9881-779afb506ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705ece2290>]}
04:47:02.319012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '412e5b09-1122-408e-9881-779afb506ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705ed81b50>]}
04:47:02.320974 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:47:02.327326 [info ] [MainThread]: 
04:47:02.330415 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:47:02.333885 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:47:02.471648 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:47:02.472626 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:47:02.473693 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:47:03.772510 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.3 seconds
04:47:03.781219 [debug] [ThreadPool]: On list_analytics: Close
04:47:03.929037 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:47:03.951318 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:47:03.952191 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:47:03.953061 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:47:04.799356 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.85 seconds
04:47:04.806057 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:47:04.967406 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:47:04.985364 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:47:04.995013 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:47:04.998389 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:47:05.956698 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.96 seconds
04:47:05.962279 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:47:06.118133 [info ] [MainThread]: 
04:47:06.120087 [info ] [MainThread]: Running 1 on-run-start hook
04:47:06.122168 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:47:06.127246 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:47:06.138797 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:47:06.141389 [debug] [MainThread]: Using snowflake connection "master"
04:47:06.142628 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:47:06.143771 [debug] [MainThread]: Opening a new connection, currently in state init
04:47:07.163939 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.02 seconds
04:47:07.168417 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.03s]
04:47:07.171381 [info ] [MainThread]: 
04:47:07.174005 [debug] [MainThread]: On master: Close
04:47:07.341792 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:47:07.344474 [info ] [MainThread]: 
04:47:07.349910 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:47:07.351868 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
04:47:07.354633 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:07.356077 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:47:07.357168 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:47:07.373163 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:47:07.377287 [debug] [Thread-1  ]: finished collecting timing info
04:47:07.378358 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:47:07.454166 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:07.454991 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
04:47:07.455620 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:47:08.910878 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
04:47:08.960252 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
04:47:08.966052 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:08.967009 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
04:47:09.613833 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
04:47:09.689511 [debug] [Thread-1  ]: finished collecting timing info
04:47:09.693991 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
04:47:09.848194 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '412e5b09-1122-408e-9881-779afb506ca1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705fe8e5d0>]}
04:47:09.850683 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.49s]
04:47:09.853011 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:47:09.893702 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:47:09.894750 [info ] [MainThread]: 
04:47:09.895956 [info ] [MainThread]: Running 3 on-run-end hooks
04:47:09.897929 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:47:09.902780 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:47:09.913195 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:47:09.915501 [debug] [MainThread]: Using snowflake connection "master"
04:47:09.917093 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:47:09.918023 [debug] [MainThread]: Opening a new connection, currently in state closed
04:47:10.915258 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.0 seconds
04:47:10.918880 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.00s]
04:47:10.920885 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:47:10.927175 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:47:10.934898 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:47:10.938006 [debug] [MainThread]: Using snowflake connection "master"
04:47:10.939238 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:47:11.063557 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
04:47:11.067754 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
04:47:11.069723 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:47:11.080405 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:47:11.086265 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:47:11.089079 [debug] [MainThread]: Using snowflake connection "master"
04:47:11.090782 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:47:11.206221 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
04:47:11.210673 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
04:47:11.214556 [info ] [MainThread]: 
04:47:11.218994 [debug] [MainThread]: On master: Close
04:47:11.398118 [info ] [MainThread]: 
04:47:11.399603 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 9.07s.
04:47:11.401882 [debug] [MainThread]: Connection 'master' was properly closed.
04:47:11.402911 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:47:11.475327 [info ] [MainThread]: 
04:47:11.477277 [info ] [MainThread]: [32mCompleted successfully[0m
04:47:11.479378 [info ] [MainThread]: 
04:47:11.486782 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:47:11.490414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705fe39fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705d367190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705d367410>]}


============================== 2022-01-31 04:47:23.588796 | 382bf565-a3b1-4b3a-984c-06bcac8bcbc4 ==============================
04:47:23.588796 [info ] [MainThread]: Running with dbt=1.0.1
04:47:23.591847 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:47:23.593067 [debug] [MainThread]: Tracking: tracking
04:47:23.594808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fdf7ce950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fdf7ce190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fdf7ce990>]}
04:47:23.805117 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
04:47:23.807816 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
04:47:23.836437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '382bf565-a3b1-4b3a-984c-06bcac8bcbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fdf6e2590>]}
04:47:23.872273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '382bf565-a3b1-4b3a-984c-06bcac8bcbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe0866f50>]}
04:47:23.874400 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:47:23.882242 [info ] [MainThread]: 
04:47:23.884320 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:47:23.886933 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:47:24.007517 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:47:24.008567 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:47:24.009907 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:47:25.171307 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.16 seconds
04:47:25.177339 [debug] [ThreadPool]: On list_analytics: Close
04:47:25.329888 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:47:25.350048 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:47:25.351130 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:47:25.351791 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:47:26.337720 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.99 seconds
04:47:26.349136 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:47:26.514133 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:47:26.521776 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:47:26.523129 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:47:26.524557 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:47:27.409171 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.88 seconds
04:47:27.438856 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:47:27.636417 [info ] [MainThread]: 
04:47:27.641428 [info ] [MainThread]: Running 1 on-run-start hook
04:47:27.645081 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:47:27.652393 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:47:27.665349 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:47:27.668118 [debug] [MainThread]: Using snowflake connection "master"
04:47:27.668819 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:47:27.669801 [debug] [MainThread]: Opening a new connection, currently in state init
04:47:28.594909 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.93 seconds
04:47:28.600038 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.93s]
04:47:28.604361 [info ] [MainThread]: 
04:47:28.606468 [debug] [MainThread]: On master: Close
04:47:28.763317 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:47:28.766328 [info ] [MainThread]: 
04:47:28.776715 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:47:28.778174 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
04:47:28.783729 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:28.785793 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:47:28.787382 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:47:28.814108 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:47:28.821259 [debug] [Thread-1  ]: finished collecting timing info
04:47:28.822792 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:47:28.907899 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:28.908539 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
04:47:28.909364 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:47:30.146080 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
04:47:30.220863 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
04:47:30.228808 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:30.229995 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
04:47:30.979785 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.75 seconds
04:47:31.060227 [debug] [Thread-1  ]: finished collecting timing info
04:47:31.061128 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
04:47:31.202776 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '382bf565-a3b1-4b3a-984c-06bcac8bcbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fddd64e50>]}
04:47:31.206531 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.42s]
04:47:31.210565 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:47:31.283773 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:47:31.286979 [info ] [MainThread]: 
04:47:31.290093 [info ] [MainThread]: Running 3 on-run-end hooks
04:47:31.293557 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:47:31.302117 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:47:31.313090 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:47:31.317816 [debug] [MainThread]: Using snowflake connection "master"
04:47:31.320161 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:47:31.322029 [debug] [MainThread]: Opening a new connection, currently in state closed
04:47:32.179708 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.86 seconds
04:47:32.183180 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.87s]
04:47:32.185718 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:47:32.190479 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:47:32.198797 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:47:32.201332 [debug] [MainThread]: Using snowflake connection "master"
04:47:32.202407 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:47:32.328781 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
04:47:32.332717 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
04:47:32.335391 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:47:32.340803 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:47:32.345901 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:47:32.349276 [debug] [MainThread]: Using snowflake connection "master"
04:47:32.350780 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:47:32.449535 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
04:47:32.452577 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
04:47:32.454860 [info ] [MainThread]: 
04:47:32.457149 [debug] [MainThread]: On master: Close
04:47:32.616042 [info ] [MainThread]: 
04:47:32.618529 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.73s.
04:47:32.620529 [debug] [MainThread]: Connection 'master' was properly closed.
04:47:32.622011 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:47:32.649331 [info ] [MainThread]: 
04:47:32.651490 [info ] [MainThread]: [32mCompleted successfully[0m
04:47:32.654979 [info ] [MainThread]: 
04:47:32.658146 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:47:32.660184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe0848f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fde271d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fde271390>]}


============================== 2022-01-31 04:47:43.547822 | 84227e75-986e-4234-a5bb-9243f3769687 ==============================
04:47:43.547822 [info ] [MainThread]: Running with dbt=1.0.1
04:47:43.549443 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:47:43.550445 [debug] [MainThread]: Tracking: tracking
04:47:43.551375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88209d2ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88209d2b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88209d2a90>]}
04:47:43.696582 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
04:47:43.697504 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
04:47:43.738413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '84227e75-986e-4234-a5bb-9243f3769687', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8829950f90>]}
04:47:43.779278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '84227e75-986e-4234-a5bb-9243f3769687', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8821a4a090>]}
04:47:43.781358 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:47:43.789851 [info ] [MainThread]: 
04:47:43.793186 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:47:43.796253 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:47:43.938518 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:47:43.939333 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:47:43.939932 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:47:45.260182 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.32 seconds
04:47:45.266406 [debug] [ThreadPool]: On list_analytics: Close
04:47:45.412146 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:47:45.435312 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:47:45.436921 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:47:45.437754 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:47:46.574582 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 1.14 seconds
04:47:46.587382 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:47:46.757581 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:47:46.763101 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:47:46.764709 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:47:46.765614 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:47:47.601300 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.84 seconds
04:47:47.606841 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:47:47.758813 [info ] [MainThread]: 
04:47:47.761260 [info ] [MainThread]: Running 1 on-run-start hook
04:47:47.764414 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:47:47.770756 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:47:47.783941 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:47:47.787828 [debug] [MainThread]: Using snowflake connection "master"
04:47:47.788907 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:47:47.790808 [debug] [MainThread]: Opening a new connection, currently in state init
04:47:48.842328 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.05 seconds
04:47:48.856808 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.07s]
04:47:48.864632 [info ] [MainThread]: 
04:47:48.925823 [debug] [MainThread]: On master: Close
04:47:49.136769 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:47:49.138415 [info ] [MainThread]: 
04:47:49.147791 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:47:49.149929 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
04:47:49.152313 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:49.155227 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:47:49.156512 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:47:49.170968 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:47:49.175241 [debug] [Thread-1  ]: finished collecting timing info
04:47:49.176290 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:47:49.260841 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:49.261998 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
04:47:49.262927 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:47:50.383570 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
04:47:50.445487 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
04:47:50.473407 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:47:50.476221 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
04:47:51.124751 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
04:47:51.209474 [debug] [Thread-1  ]: finished collecting timing info
04:47:51.210678 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
04:47:51.392406 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84227e75-986e-4234-a5bb-9243f3769687', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8821a6d4d0>]}
04:47:51.397853 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.24s]
04:47:51.401853 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:47:51.439490 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:47:51.446624 [info ] [MainThread]: 
04:47:51.451773 [info ] [MainThread]: Running 3 on-run-end hooks
04:47:51.459325 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:47:51.467694 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:47:51.477385 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:47:51.481044 [debug] [MainThread]: Using snowflake connection "master"
04:47:51.482833 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:47:51.484214 [debug] [MainThread]: Opening a new connection, currently in state closed
04:47:52.328182 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.84 seconds
04:47:52.332216 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.85s]
04:47:52.334760 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:47:52.340744 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:47:52.349200 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:47:52.352335 [debug] [MainThread]: Using snowflake connection "master"
04:47:52.353510 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:47:52.489833 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
04:47:52.493450 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
04:47:52.495683 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:47:52.502761 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:47:52.507893 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:47:52.510805 [debug] [MainThread]: Using snowflake connection "master"
04:47:52.511990 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:47:52.617944 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
04:47:52.628518 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
04:47:52.634245 [info ] [MainThread]: 
04:47:52.638091 [debug] [MainThread]: On master: Close
04:47:52.832086 [info ] [MainThread]: 
04:47:52.834124 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 9.04s.
04:47:52.836250 [debug] [MainThread]: Connection 'master' was properly closed.
04:47:52.837270 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:47:52.870276 [info ] [MainThread]: 
04:47:52.872736 [info ] [MainThread]: [32mCompleted successfully[0m
04:47:52.875049 [info ] [MainThread]: 
04:47:52.876741 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:47:52.879686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8821a2dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f881b498650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f881af213d0>]}


============================== 2022-02-01 03:56:15.580915 | 95a37f2f-08ca-4e94-ad95-0d0a71d0d8b4 ==============================
03:56:15.580915 [info ] [MainThread]: Running with dbt=1.0.1
03:56:15.582452 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
03:56:15.583513 [debug] [MainThread]: Tracking: tracking
03:56:15.584544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb86ad9b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb86ad9b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb86ad9a10>]}
03:56:15.683404 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
03:56:15.684203 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
03:56:15.694984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95a37f2f-08ca-4e94-ad95-0d0a71d0d8b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb8d32dd90>]}
03:56:15.710831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95a37f2f-08ca-4e94-ad95-0d0a71d0d8b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb86b38c10>]}
03:56:15.712000 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
03:56:15.715098 [info ] [MainThread]: 
03:56:15.716450 [debug] [MainThread]: Acquiring new snowflake connection "master"
03:56:15.718227 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
03:56:15.786309 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
03:56:15.787175 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
03:56:15.788154 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:56:16.582277 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.79 seconds
03:56:16.586102 [debug] [ThreadPool]: On list_analytics: Close
03:56:16.709330 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
03:56:16.724068 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
03:56:16.724838 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
03:56:16.725530 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:56:17.366805 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.64 seconds
03:56:17.377201 [debug] [ThreadPool]: On list_analytics_dbt: Close
03:56:17.517939 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
03:56:17.529320 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
03:56:17.532411 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
03:56:17.537505 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:56:18.061598 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.52 seconds
03:56:18.069400 [debug] [ThreadPool]: On list_analytics_snapshots: Close
03:56:18.196607 [info ] [MainThread]: 
03:56:18.198427 [info ] [MainThread]: Running 1 on-run-start hook
03:56:18.200072 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
03:56:18.203850 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
03:56:18.210706 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
03:56:18.212189 [debug] [MainThread]: Using snowflake connection "master"
03:56:18.212788 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
03:56:18.213639 [debug] [MainThread]: Opening a new connection, currently in state init
03:56:19.006597 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.79 seconds
03:56:19.009256 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.80s]
03:56:19.010518 [info ] [MainThread]: 
03:56:19.011868 [debug] [MainThread]: On master: Close
03:56:19.173543 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
03:56:19.177371 [info ] [MainThread]: 
03:56:19.187303 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
03:56:19.189041 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
03:56:19.191260 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
03:56:19.192088 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
03:56:19.192803 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
03:56:19.201461 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
03:56:19.205500 [debug] [Thread-1  ]: finished collecting timing info
03:56:19.206341 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
03:56:19.248740 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
03:56:19.249535 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
03:56:19.250165 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
03:56:21.717693 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.47 seconds
03:56:21.733928 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
03:56:21.739028 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
03:56:21.739718 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2020-03-01 00:03:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
03:56:22.344465 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
03:56:22.371541 [debug] [Thread-1  ]: finished collecting timing info
03:56:22.372263 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
03:56:22.504994 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95a37f2f-08ca-4e94-ad95-0d0a71d0d8b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb84052a50>]}
03:56:22.508286 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.31s]
03:56:22.513104 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
03:56:22.527211 [debug] [MainThread]: Acquiring new snowflake connection "master"
03:56:22.528193 [info ] [MainThread]: 
03:56:22.529233 [info ] [MainThread]: Running 3 on-run-end hooks
03:56:22.530291 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
03:56:22.532973 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
03:56:22.537859 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
03:56:22.539487 [debug] [MainThread]: Using snowflake connection "master"
03:56:22.540327 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
03:56:22.541081 [debug] [MainThread]: Opening a new connection, currently in state closed
03:56:23.094790 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.55 seconds
03:56:23.100386 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.56s]
03:56:23.103797 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
03:56:23.108467 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
03:56:23.114799 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
03:56:23.116541 [debug] [MainThread]: Using snowflake connection "master"
03:56:23.117284 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
03:56:23.240513 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
03:56:23.242480 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
03:56:23.243810 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
03:56:23.246112 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
03:56:23.248926 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
03:56:23.250344 [debug] [MainThread]: Using snowflake connection "master"
03:56:23.251076 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
03:56:23.341519 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
03:56:23.343298 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
03:56:23.344465 [info ] [MainThread]: 
03:56:23.345905 [debug] [MainThread]: On master: Close
03:56:23.486436 [info ] [MainThread]: 
03:56:23.487669 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.77s.
03:56:23.488708 [debug] [MainThread]: Connection 'master' was properly closed.
03:56:23.489501 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
03:56:23.511160 [info ] [MainThread]: 
03:56:23.512529 [info ] [MainThread]: [32mCompleted successfully[0m
03:56:23.513354 [info ] [MainThread]: 
03:56:23.513980 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
03:56:23.514728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb86b1df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb8405d410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb8405d7d0>]}


============================== 2022-02-07 10:48:30.102507 | 0a9a799c-05ef-4d3f-b285-dd849683a93e ==============================
10:48:30.102507 [info ] [MainThread]: Running with dbt=1.0.1
10:48:30.104805 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
10:48:30.114602 [debug] [MainThread]: Tracking: tracking
10:48:30.116297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03a08c4590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03a08c4810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03a08c4290>]}
10:48:30.390294 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:48:30.392281 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
10:48:30.433641 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
10:48:30.477680 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
10:48:30.564854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039f753190>]}
10:48:30.587519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03a090a510>]}
10:48:30.588698 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:48:30.594439 [info ] [MainThread]: 
10:48:30.598360 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:48:30.603443 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:48:30.649423 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:48:30.650683 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:48:30.651431 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:48:32.049467 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.4 seconds
10:48:32.053408 [debug] [ThreadPool]: On list_analytics: Close
10:48:32.168938 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:48:32.187566 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:48:32.188522 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:48:32.189305 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:48:33.030307 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.84 seconds
10:48:33.034456 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:48:33.157557 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
10:48:33.162323 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
10:48:33.163002 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
10:48:33.163641 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:48:33.795394 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.63 seconds
10:48:33.799402 [debug] [ThreadPool]: On list_analytics_snapshots: Close
10:48:33.917050 [info ] [MainThread]: 
10:48:33.918306 [info ] [MainThread]: Running 1 on-run-start hook
10:48:33.920514 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
10:48:33.924416 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
10:48:33.935283 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
10:48:33.936924 [debug] [MainThread]: Using snowflake connection "master"
10:48:33.937706 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
10:48:33.938651 [debug] [MainThread]: Opening a new connection, currently in state init
10:48:34.617342 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.68 seconds
10:48:34.619543 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.68s]
10:48:34.620820 [info ] [MainThread]: 
10:48:34.622077 [debug] [MainThread]: On master: Close
10:48:34.741416 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:48:34.742908 [info ] [MainThread]: 
10:48:34.746776 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
10:48:34.747921 [info ] [Thread-1  ]: 1 of 9 START table model dbt.cumulative_orders_by_date.......................... [RUN]
10:48:34.750322 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
10:48:34.752226 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
10:48:34.754157 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
10:48:34.764028 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
10:48:34.771784 [debug] [Thread-1  ]: finished collecting timing info
10:48:34.772488 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
10:48:34.810217 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
10:48:34.810896 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
10:48:34.811413 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:36.044822 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
10:48:36.090024 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
10:48:36.100421 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
10:48:36.101521 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
10:48:37.634618 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
10:48:37.667469 [debug] [Thread-1  ]: finished collecting timing info
10:48:37.668426 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
10:48:37.790332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039dd58cd0>]}
10:48:37.791475 [info ] [Thread-1  ]: 1 of 9 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 3.04s]
10:48:37.792377 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
10:48:37.793384 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
10:48:37.795638 [info ] [Thread-1  ]: 2 of 9 START incremental model dbt.dates........................................ [RUN]
10:48:37.797115 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
10:48:37.798104 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
10:48:37.799004 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
10:48:37.830378 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
10:48:37.834022 [debug] [Thread-1  ]: finished collecting timing info
10:48:37.834732 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
10:48:37.902851 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:37.903545 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



    and d_date > (SELECT MAX(d_date) FROM analytics.dbt.dates)

      );
10:48:37.904251 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:39.493006 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
10:48:39.511268 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:39.512248 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:48:39.603698 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
10:48:39.613172 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:39.613713 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table analytics.dbt.dates
10:48:39.692029 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
10:48:39.716336 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:39.717059 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:48:39.794348 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.08 seconds
10:48:39.857690 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
10:48:39.870724 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:39.871657 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */
begin;
10:48:39.968552 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
10:48:39.969880 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:39.970884 [debug] [Thread-1  ]: On model.dbt_tests.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:48:40.525400 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.55 seconds
10:48:40.526552 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
10:48:40.527467 [debug] [Thread-1  ]: On model.dbt_tests.dates: commit;
10:48:40.751204 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.22 seconds
10:48:40.754380 [debug] [Thread-1  ]: finished collecting timing info
10:48:40.755276 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
10:48:40.890842 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039e29d890>]}
10:48:40.891954 [info ] [Thread-1  ]: 2 of 9 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.09s]
10:48:40.892893 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
10:48:40.893537 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
10:48:40.895688 [info ] [Thread-1  ]: 3 of 9 START incremental model dbt.incremental_time............................. [RUN]
10:48:40.900274 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
10:48:40.901109 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
10:48:40.901943 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
10:48:40.907444 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
10:48:40.912530 [debug] [Thread-1  ]: finished collecting timing info
10:48:40.914084 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
10:48:40.921792 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:40.922720 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
10:48:40.923537 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:41.777739 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
10:48:41.783080 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:41.784091 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
10:48:42.495648 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
10:48:42.505359 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:42.506226 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
10:48:42.585516 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
10:48:42.591027 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:42.592045 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table analytics.dbt.incremental_time
10:48:42.671034 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.08 seconds
10:48:42.676762 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:42.677703 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
10:48:42.752941 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.07 seconds
10:48:42.761233 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
10:48:42.766455 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:42.767490 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */
begin;
10:48:42.855263 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
10:48:42.856007 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:42.856619 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
10:48:43.046568 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.19 seconds
10:48:43.049852 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
10:48:43.050427 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: commit;
10:48:43.190254 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:48:43.196251 [debug] [Thread-1  ]: finished collecting timing info
10:48:43.197278 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
10:48:43.322686 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039c4a2350>]}
10:48:43.324007 [info ] [Thread-1  ]: 3 of 9 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.43s]
10:48:43.325042 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
10:48:43.325760 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
10:48:43.326961 [info ] [Thread-1  ]: 4 of 9 START table model dbt.first_model........................................ [RUN]
10:48:43.328921 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
10:48:43.329686 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
10:48:43.330709 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
10:48:43.335948 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
10:48:43.340295 [debug] [Thread-1  ]: finished collecting timing info
10:48:43.341349 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
10:48:43.347224 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
10:48:43.348314 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
10:48:43.349159 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:44.347072 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
10:48:44.350916 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
10:48:44.362105 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
10:48:44.363052 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:48:45.120820 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
10:48:45.123891 [debug] [Thread-1  ]: finished collecting timing info
10:48:45.124684 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
10:48:45.241352 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039c4fbd90>]}
10:48:45.242375 [info ] [Thread-1  ]: 4 of 9 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.91s]
10:48:45.243421 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
10:48:45.244236 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
10:48:45.245829 [info ] [Thread-1  ]: 5 of 9 START table model dbt.customer_model..................................... [RUN]
10:48:45.246992 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
10:48:45.247592 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
10:48:45.248408 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
10:48:45.252880 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
10:48:45.256545 [debug] [Thread-1  ]: finished collecting timing info
10:48:45.257285 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
10:48:45.264312 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
10:48:45.265412 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
10:48:45.266267 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:46.484507 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
10:48:46.486908 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
10:48:46.494537 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
10:48:46.495248 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
10:48:52.058976 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.56 seconds
10:48:52.062211 [debug] [Thread-1  ]: finished collecting timing info
10:48:52.062872 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
10:48:52.180670 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039c447510>]}
10:48:52.181917 [info ] [Thread-1  ]: 5 of 9 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.93s]
10:48:52.182989 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
10:48:52.183836 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
10:48:52.185590 [info ] [Thread-1  ]: 6 of 9 START table model dbt.rename_segments_macro_test......................... [RUN]
10:48:52.187199 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
10:48:52.187868 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
10:48:52.188947 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
10:48:52.197148 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
10:48:52.201779 [debug] [Thread-1  ]: finished collecting timing info
10:48:52.202743 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
10:48:52.207924 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
10:48:52.209294 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
10:48:52.211429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:53.074452 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
10:48:53.078234 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
10:48:53.084608 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
10:48:53.085669 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
10:48:53.968686 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
10:48:53.971905 [debug] [Thread-1  ]: finished collecting timing info
10:48:53.972869 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
10:48:54.094214 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039f714910>]}
10:48:54.095396 [info ] [Thread-1  ]: 6 of 9 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 1.91s]
10:48:54.096472 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
10:48:54.097388 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
10:48:54.098462 [info ] [Thread-1  ]: 7 of 9 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:48:54.100157 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
10:48:54.100705 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
10:48:54.101809 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
10:48:54.109024 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
10:48:54.114160 [debug] [Thread-1  ]: finished collecting timing info
10:48:54.115262 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
10:48:54.120549 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
10:48:54.121496 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
10:48:54.122324 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:55.059679 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
10:48:55.062352 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
10:48:55.068371 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
10:48:55.069185 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
10:48:56.170072 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
10:48:56.173970 [debug] [Thread-1  ]: finished collecting timing info
10:48:56.175024 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
10:48:56.301190 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03a29620d0>]}
10:48:56.302242 [info ] [Thread-1  ]: 7 of 9 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.20s]
10:48:56.303114 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
10:48:56.303910 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
10:48:56.304985 [info ] [Thread-1  ]: 8 of 9 START table model dbt.sources_customer_orders............................ [RUN]
10:48:56.306495 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
10:48:56.307395 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
10:48:56.308405 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
10:48:56.327570 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
10:48:56.332733 [debug] [Thread-1  ]: finished collecting timing info
10:48:56.333736 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
10:48:56.344692 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
10:48:56.345737 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
10:48:56.346653 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:57.385742 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
10:48:57.388519 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
10:48:57.397949 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
10:48:57.398800 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
10:48:58.367375 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
10:48:58.372506 [debug] [Thread-1  ]: finished collecting timing info
10:48:58.373730 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
10:48:58.484351 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039e28f6d0>]}
10:48:58.485343 [info ] [Thread-1  ]: 8 of 9 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.18s]
10:48:58.486253 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
10:48:58.487017 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
10:48:58.488510 [info ] [Thread-1  ]: 9 of 9 START table model dbt.my_second_dbt_model................................ [RUN]
10:48:58.490156 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
10:48:58.490727 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
10:48:58.491815 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
10:48:58.496152 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
10:48:58.500946 [debug] [Thread-1  ]: finished collecting timing info
10:48:58.501730 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
10:48:58.507967 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
10:48:58.508846 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
10:48:58.509515 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:48:59.537372 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
10:48:59.541262 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
10:48:59.551076 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
10:48:59.551956 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
10:49:00.155037 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
10:49:00.158275 [debug] [Thread-1  ]: finished collecting timing info
10:49:00.159170 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
10:49:00.265317 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9a799c-05ef-4d3f-b285-dd849683a93e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039dd42110>]}
10:49:00.266372 [info ] [Thread-1  ]: 9 of 9 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.78s]
10:49:00.267440 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
10:49:00.305981 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:49:00.307250 [info ] [MainThread]: 
10:49:00.308371 [info ] [MainThread]: Running 3 on-run-end hooks
10:49:00.310072 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
10:49:00.313196 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
10:49:00.325476 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
10:49:00.327444 [debug] [MainThread]: Using snowflake connection "master"
10:49:00.328438 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
10:49:00.329283 [debug] [MainThread]: Opening a new connection, currently in state closed
10:49:00.868701 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.54 seconds
10:49:00.870940 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.54s]
10:49:00.872126 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
10:49:00.874901 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
10:49:00.880317 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
10:49:00.881735 [debug] [MainThread]: Using snowflake connection "master"
10:49:00.882417 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
10:49:01.017605 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
10:49:01.020907 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
10:49:01.022090 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
10:49:01.024718 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
10:49:01.031753 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
10:49:01.033066 [debug] [MainThread]: Using snowflake connection "master"
10:49:01.033722 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
10:49:01.111193 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
10:49:01.113959 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.08s]
10:49:01.115295 [info ] [MainThread]: 
10:49:01.116809 [debug] [MainThread]: On master: Close
10:49:01.226184 [info ] [MainThread]: 
10:49:01.227058 [info ] [MainThread]: Finished running 7 table models, 2 incremental models, 4 hooks in 30.63s.
10:49:01.227963 [debug] [MainThread]: Connection 'master' was properly closed.
10:49:01.229006 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
10:49:01.248841 [info ] [MainThread]: 
10:49:01.249872 [info ] [MainThread]: [32mCompleted successfully[0m
10:49:01.250960 [info ] [MainThread]: 
10:49:01.251949 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
10:49:01.257590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039dd7ed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039c4cbdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f039c4cb710>]}


============================== 2022-02-07 10:49:57.523162 | 655822d4-917a-46c8-8a25-6f627c641213 ==============================
10:49:57.523162 [info ] [MainThread]: Running with dbt=1.0.1
10:49:57.524737 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.snapshot.SnapshotTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='snapshot', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='snapshot', write_json=None)
10:49:57.525583 [debug] [MainThread]: Tracking: tracking
10:49:57.527039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558efddd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558efdd310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558efdd7d0>]}
10:49:57.656020 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:49:57.656712 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:49:57.672991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '655822d4-917a-46c8-8a25-6f627c641213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558eeef150>]}
10:49:57.694768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '655822d4-917a-46c8-8a25-6f627c641213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558efd5950>]}
10:49:57.696014 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:49:57.700740 [info ] [MainThread]: 
10:49:57.703426 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:49:57.706310 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:49:57.748030 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:49:57.748963 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:49:57.750007 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:49:58.608787 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.86 seconds
10:49:58.613168 [debug] [ThreadPool]: On list_analytics: Close
10:49:58.738180 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:49:58.755966 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:49:58.756718 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:49:58.757266 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:49:59.622894 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.87 seconds
10:49:59.628026 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:49:59.757773 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
10:49:59.763950 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
10:49:59.764908 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
10:49:59.765868 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:50:00.297694 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.53 seconds
10:50:00.300324 [debug] [ThreadPool]: On list_analytics_snapshots: Close
10:50:00.410870 [info ] [MainThread]: 
10:50:00.411728 [info ] [MainThread]: Running 1 on-run-start hook
10:50:00.413022 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
10:50:00.416100 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
10:50:00.421510 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
10:50:00.423042 [debug] [MainThread]: Using snowflake connection "master"
10:50:00.423855 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
10:50:00.424737 [debug] [MainThread]: Opening a new connection, currently in state init
10:50:01.051108 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.63 seconds
10:50:01.056910 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.63s]
10:50:01.061364 [info ] [MainThread]: 
10:50:01.065050 [debug] [MainThread]: On master: Close
10:50:01.204601 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:50:01.206498 [info ] [MainThread]: 
10:50:01.213470 [debug] [Thread-1  ]: Began running node snapshot.dbt_tests.first_model_snapshot
10:50:01.214952 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.first_model_snapshot............................ [RUN]
10:50:01.217501 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:50:01.218996 [debug] [Thread-1  ]: Began compiling node snapshot.dbt_tests.first_model_snapshot
10:50:01.221075 [debug] [Thread-1  ]: Compiling snapshot.dbt_tests.first_model_snapshot
10:50:01.232156 [debug] [Thread-1  ]: finished collecting timing info
10:50:01.233426 [debug] [Thread-1  ]: Began executing node snapshot.dbt_tests.first_model_snapshot
10:50:01.306538 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:50:01.307292 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snapshots')
            and upper(catalog_name) = upper('analytics')
10:50:01.308118 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:50:03.175108 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.87 seconds
10:50:03.251235 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.dbt_tests.first_model_snapshot"
10:50:03.261329 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:50:03.262222 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

      

      create or replace transient table analytics.snapshots.first_model_snapshot  as
      (

    select *,
        md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        



select * from analytics.dbt.first_model

    ) sbq



      );
10:50:03.953559 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.69 seconds
10:50:03.992935 [debug] [Thread-1  ]: finished collecting timing info
10:50:03.993853 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: Close
10:50:04.119726 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655822d4-917a-46c8-8a25-6f627c641213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558da5bfd0>]}
10:50:04.121123 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.first_model_snapshot............................ [[32mSUCCESS 1[0m in 2.90s]
10:50:04.122225 [debug] [Thread-1  ]: Finished running node snapshot.dbt_tests.first_model_snapshot
10:50:04.125175 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:50:04.125941 [info ] [MainThread]: 
10:50:04.126833 [info ] [MainThread]: Running 3 on-run-end hooks
10:50:04.128017 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
10:50:04.130409 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
10:50:04.134113 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
10:50:04.135286 [debug] [MainThread]: Using snowflake connection "master"
10:50:04.135836 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
10:50:04.136737 [debug] [MainThread]: Opening a new connection, currently in state closed
10:50:04.747005 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.61 seconds
10:50:04.748946 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.61s]
10:50:04.749861 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
10:50:04.753153 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
10:50:04.757295 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
10:50:04.758877 [debug] [MainThread]: Using snowflake connection "master"
10:50:04.759415 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
10:50:04.884315 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
10:50:04.886316 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
10:50:04.887323 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
10:50:04.891251 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
10:50:04.895699 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
10:50:04.897285 [debug] [MainThread]: Using snowflake connection "master"
10:50:04.898201 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
10:50:04.988963 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
10:50:04.991038 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
10:50:04.992016 [info ] [MainThread]: 
10:50:04.993081 [debug] [MainThread]: On master: Close
10:50:05.168430 [info ] [MainThread]: 
10:50:05.170276 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 7.47s.
10:50:05.171479 [debug] [MainThread]: Connection 'master' was properly closed.
10:50:05.172449 [debug] [MainThread]: Connection 'snapshot.dbt_tests.first_model_snapshot' was properly closed.
10:50:05.188159 [info ] [MainThread]: 
10:50:05.189213 [info ] [MainThread]: [32mCompleted successfully[0m
10:50:05.190929 [info ] [MainThread]: 
10:50:05.194352 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
10:50:05.196814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f559002ded0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558da4c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558da4c090>]}


============================== 2022-02-07 10:53:56.397169 | 300b928d-452f-439f-8b37-f12823509f44 ==============================
10:53:56.397169 [info ] [MainThread]: Running with dbt=1.0.1
10:53:56.398269 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model.sql'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
10:53:56.399328 [debug] [MainThread]: Tracking: tracking
10:53:56.401800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90bac49110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90bac49050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90bac33610>]}
10:53:56.512770 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:53:56.514590 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
10:53:56.536166 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
10:53:56.567730 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
10:53:56.624921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '300b928d-452f-439f-8b37-f12823509f44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90b9ae1250>]}
10:53:56.641355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '300b928d-452f-439f-8b37-f12823509f44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90b9b4aa90>]}
10:53:56.642433 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:53:56.643936 [warn ] [MainThread]: The selection criterion 'example.my_first_dbt_model.sql' does not match any nodes
10:53:56.647084 [info ] [MainThread]: 
10:53:56.648399 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
10:53:56.664813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90bac73fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90bac73cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90bac73f50>]}


============================== 2022-02-07 10:56:09.501393 | b3292697-044e-441a-a39d-6afdd6321b78 ==============================
10:56:09.501393 [info ] [MainThread]: Running with dbt=1.0.1
10:56:09.502700 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model.sql'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
10:56:09.503368 [debug] [MainThread]: Tracking: tracking
10:56:09.504631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a00818d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a0081c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a0081790>]}
10:56:09.603780 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:56:09.604642 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:56:09.617843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3292697-044e-441a-a39d-6afdd6321b78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc29ef70690>]}
10:56:09.634951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3292697-044e-441a-a39d-6afdd6321b78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a0079950>]}
10:56:09.635945 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:56:09.637222 [warn ] [MainThread]: The selection criterion 'example.my_first_dbt_model.sql' does not match any nodes
10:56:09.640503 [info ] [MainThread]: 
10:56:09.641571 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
10:56:09.654327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a006e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a00d2f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2a00d2d10>]}


============================== 2022-02-07 10:56:42.280478 | 7a501e7a-6723-402a-abef-1e9a8074637a ==============================
10:56:42.280478 [info ] [MainThread]: Running with dbt=1.0.1
10:56:42.281818 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model.sql'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
10:56:42.282736 [debug] [MainThread]: Tracking: tracking
10:56:42.284174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb899150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb884650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb884790>]}
10:56:42.383769 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:56:42.384451 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:56:42.397174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a501e7a-6723-402a-abef-1e9a8074637a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58ca771210>]}
10:56:42.412033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a501e7a-6723-402a-abef-1e9a8074637a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb8351d0>]}
10:56:42.412881 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:56:42.414209 [warn ] [MainThread]: The selection criterion 'example.my_first_dbt_model.sql' does not match any nodes
10:56:42.417523 [info ] [MainThread]: 
10:56:42.418827 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
10:56:42.433387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb8c5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb884790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58cb872b10>]}


============================== 2022-02-07 10:57:13.285304 | 06e70e89-8f82-44f5-a2f2-66a7a75a7f9f ==============================
10:57:13.285304 [info ] [MainThread]: Running with dbt=1.0.1
10:57:13.286908 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
10:57:13.287972 [debug] [MainThread]: Tracking: tracking
10:57:13.289248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff204c4b210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff204c4b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff204c4b1d0>]}
10:57:13.391602 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:57:13.392397 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:57:13.404193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06e70e89-8f82-44f5-a2f2-66a7a75a7f9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff203b316d0>]}
10:57:13.424005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06e70e89-8f82-44f5-a2f2-66a7a75a7f9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff204c25a50>]}
10:57:13.425259 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:57:13.428579 [info ] [MainThread]: 
10:57:13.430455 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:57:13.433524 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:57:13.459398 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:57:13.460316 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:57:13.461243 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:57:14.362329 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.9 seconds
10:57:14.366265 [debug] [ThreadPool]: On list_analytics: Close
10:57:14.507556 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:57:14.524151 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:57:14.525008 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:57:14.525683 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:57:15.416426 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.89 seconds
10:57:15.424870 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:57:15.573227 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
10:57:15.578241 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
10:57:15.579170 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
10:57:15.580092 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:57:16.140092 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.56 seconds
10:57:16.142560 [debug] [ThreadPool]: On list_analytics_snapshots: Close
10:57:16.261833 [info ] [MainThread]: 
10:57:16.263005 [info ] [MainThread]: Running 1 on-run-start hook
10:57:16.264308 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
10:57:16.267942 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
10:57:16.273757 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
10:57:16.274996 [debug] [MainThread]: Using snowflake connection "master"
10:57:16.275745 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
10:57:16.276540 [debug] [MainThread]: Opening a new connection, currently in state init
10:57:16.807704 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
10:57:16.809633 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.53s]
10:57:16.810742 [info ] [MainThread]: 
10:57:16.811713 [debug] [MainThread]: On master: Close
10:57:16.942241 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:57:16.943311 [info ] [MainThread]: 
10:57:16.947026 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
10:57:16.948009 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
10:57:16.949168 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
10:57:16.950032 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
10:57:16.950765 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
10:57:16.957874 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
10:57:16.968704 [debug] [Thread-1  ]: finished collecting timing info
10:57:16.969728 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
10:57:17.006893 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
10:57:17.007437 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
10:57:17.007996 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:57:18.426430 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
10:57:18.457585 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
10:57:18.463301 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
10:57:18.464250 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-02-01 13:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:57:19.065289 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
10:57:19.090311 [debug] [Thread-1  ]: finished collecting timing info
10:57:19.090979 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
10:57:19.211063 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e70e89-8f82-44f5-a2f2-66a7a75a7f9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2021631d0>]}
10:57:19.212098 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.26s]
10:57:19.213033 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
10:57:19.292957 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:57:19.293974 [info ] [MainThread]: 
10:57:19.294771 [info ] [MainThread]: Running 3 on-run-end hooks
10:57:19.296089 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
10:57:19.299134 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
10:57:19.303831 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
10:57:19.305268 [debug] [MainThread]: Using snowflake connection "master"
10:57:19.305978 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
10:57:19.307104 [debug] [MainThread]: Opening a new connection, currently in state closed
10:57:19.848249 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.54 seconds
10:57:19.857372 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.55s]
10:57:19.859162 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
10:57:19.863455 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
10:57:19.868533 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
10:57:19.869896 [debug] [MainThread]: Using snowflake connection "master"
10:57:19.870509 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
10:57:19.999143 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
10:57:20.001906 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
10:57:20.003132 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
10:57:20.006395 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
10:57:20.009522 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
10:57:20.011065 [debug] [MainThread]: Using snowflake connection "master"
10:57:20.011681 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
10:57:20.095273 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
10:57:20.097133 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
10:57:20.099026 [info ] [MainThread]: 
10:57:20.100395 [debug] [MainThread]: On master: Close
10:57:20.215367 [info ] [MainThread]: 
10:57:20.216387 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.79s.
10:57:20.217911 [debug] [MainThread]: Connection 'master' was properly closed.
10:57:20.219371 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
10:57:20.236231 [info ] [MainThread]: 
10:57:20.237324 [info ] [MainThread]: [32mCompleted successfully[0m
10:57:20.238924 [info ] [MainThread]: 
10:57:20.240062 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
10:57:20.241483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff204c70350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff202155050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff202155f10>]}


============================== 2022-02-07 10:57:49.769265 | a99c6856-a2da-4d0f-8681-065418f84a52 ==============================
10:57:49.769265 [info ] [MainThread]: Running with dbt=1.0.1
10:57:49.770860 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.snapshot.SnapshotTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='snapshot', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='snapshot', write_json=None)
10:57:49.772762 [debug] [MainThread]: Tracking: tracking
10:57:49.773911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ee54bf690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ee54bfd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ee54bf550>]}
10:57:49.901262 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:57:49.902001 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:57:49.916104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a99c6856-a2da-4d0f-8681-065418f84a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ee43af650>]}
10:57:49.937875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a99c6856-a2da-4d0f-8681-065418f84a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ee54f67d0>]}
10:57:49.938807 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:57:49.942685 [info ] [MainThread]: 
10:57:49.944533 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:57:49.947659 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:57:49.981930 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:57:49.982776 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:57:49.983553 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:57:50.919509 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.94 seconds
10:57:50.924980 [debug] [ThreadPool]: On list_analytics: Close
10:57:51.041383 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
10:57:51.067545 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
10:57:51.068707 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
10:57:51.069570 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:57:51.831937 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.76 seconds
10:57:51.834940 [debug] [ThreadPool]: On list_analytics_snapshots: Close
10:57:51.949402 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:57:51.953846 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:57:51.954444 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:57:51.955283 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:57:52.968008 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 1.01 seconds
10:57:52.972795 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:57:53.109180 [info ] [MainThread]: 
10:57:53.110171 [info ] [MainThread]: Running 1 on-run-start hook
10:57:53.111382 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
10:57:53.115000 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
10:57:53.122036 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
10:57:53.123920 [debug] [MainThread]: Using snowflake connection "master"
10:57:53.124618 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
10:57:53.125380 [debug] [MainThread]: Opening a new connection, currently in state init
10:57:53.720944 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.6 seconds
10:57:53.722851 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.60s]
10:57:53.723766 [info ] [MainThread]: 
10:57:53.724780 [debug] [MainThread]: On master: Close
10:57:53.853995 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:57:53.855027 [info ] [MainThread]: 
10:57:53.858783 [debug] [Thread-1  ]: Began running node snapshot.dbt_tests.first_model_snapshot
10:57:53.859854 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.first_model_snapshot............................ [RUN]
10:57:53.861127 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:53.861834 [debug] [Thread-1  ]: Began compiling node snapshot.dbt_tests.first_model_snapshot
10:57:53.862751 [debug] [Thread-1  ]: Compiling snapshot.dbt_tests.first_model_snapshot
10:57:53.871441 [debug] [Thread-1  ]: finished collecting timing info
10:57:53.872414 [debug] [Thread-1  ]: Began executing node snapshot.dbt_tests.first_model_snapshot
10:57:53.934239 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:53.935072 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snapshots')
            and upper(catalog_name) = upper('analytics')
10:57:53.935675 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:57:54.792503 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
10:57:54.851705 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:54.852513 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
10:57:54.947547 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.09 seconds
10:57:55.014972 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:55.016586 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

        

      create or replace temporary table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"  as
      (with snapshot_query as (

        



select * from analytics.dbt.first_model


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    )

    select * from insertions
    union all
    select * from updates

      );
10:57:56.118335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
10:57:56.123247 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.124287 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
10:57:56.221003 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.1 seconds
10:57:56.229173 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.229935 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
10:57:56.307511 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.08 seconds
10:57:56.314945 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.315746 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
10:57:56.398649 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.08 seconds
10:57:56.405533 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.406301 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT"
10:57:56.484315 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.08 seconds
10:57:56.502437 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.503731 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
10:57:56.595051 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.09 seconds
10:57:56.613210 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.dbt_tests.first_model_snapshot"
10:57:56.618858 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.619747 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.dbt_tests.first_model_snapshot"} */

      begin;
10:57:56.722732 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
10:57:56.723739 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:56.724456 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: merge into "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT" as DBT_INTERNAL_DEST
    using "ANALYTICS"."SNAPSHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     and DBT_INTERNAL_DEST.dbt_valid_to is null
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
10:57:57.289405 [debug] [Thread-1  ]: SQL status: SUCCESS 2 in 0.56 seconds
10:57:57.290551 [debug] [Thread-1  ]: Using snowflake connection "snapshot.dbt_tests.first_model_snapshot"
10:57:57.291767 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: commit;
10:57:57.537689 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
10:57:57.568188 [debug] [Thread-1  ]: finished collecting timing info
10:57:57.569363 [debug] [Thread-1  ]: On snapshot.dbt_tests.first_model_snapshot: Close
10:57:57.714386 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a99c6856-a2da-4d0f-8681-065418f84a52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7edd0f16d0>]}
10:57:57.715755 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.first_model_snapshot............................ [[32mSUCCESS 1[0m in 3.85s]
10:57:57.716997 [debug] [Thread-1  ]: Finished running node snapshot.dbt_tests.first_model_snapshot
10:57:57.792563 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:57:57.793232 [info ] [MainThread]: 
10:57:57.794382 [info ] [MainThread]: Running 3 on-run-end hooks
10:57:57.796337 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
10:57:57.801203 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
10:57:57.806480 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
10:57:57.808679 [debug] [MainThread]: Using snowflake connection "master"
10:57:57.809488 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
10:57:57.810327 [debug] [MainThread]: Opening a new connection, currently in state closed
10:57:58.405856 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.6 seconds
10:57:58.407800 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.60s]
10:57:58.409008 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
10:57:58.413213 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
10:57:58.417102 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
10:57:58.418537 [debug] [MainThread]: Using snowflake connection "master"
10:57:58.419438 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
10:57:58.531066 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
10:57:58.532591 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.11s]
10:57:58.534162 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
10:57:58.537266 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
10:57:58.540093 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
10:57:58.542191 [debug] [MainThread]: Using snowflake connection "master"
10:57:58.542897 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
10:57:58.626858 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
10:57:58.629196 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
10:57:58.630695 [info ] [MainThread]: 
10:57:58.632038 [debug] [MainThread]: On master: Close
10:57:58.757709 [info ] [MainThread]: 
10:57:58.758848 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 8.81s.
10:57:58.759839 [debug] [MainThread]: Connection 'master' was properly closed.
10:57:58.761467 [debug] [MainThread]: Connection 'snapshot.dbt_tests.first_model_snapshot' was properly closed.
10:57:58.781534 [info ] [MainThread]: 
10:57:58.783743 [info ] [MainThread]: [32mCompleted successfully[0m
10:57:58.785349 [info ] [MainThread]: 
10:57:58.786485 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
10:57:58.787937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ee54ac850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7edd15a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7edd15a350>]}


============================== 2022-02-07 11:14:29.556652 | aeee0425-7ce0-4f5f-b2c8-5043a81c5373 ==============================
11:14:29.556652 [info ] [MainThread]: Running with dbt=1.0.1
11:14:29.557688 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
11:14:29.558985 [debug] [MainThread]: Tracking: tracking
11:14:29.560565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a1549850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a1549c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a15495d0>]}
11:14:29.711177 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:14:29.712853 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
11:14:29.736652 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
11:14:29.770027 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
11:14:29.826843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aeee0425-7ce0-4f5f-b2c8-5043a81c5373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a1468f10>]}
11:14:29.846146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aeee0425-7ce0-4f5f-b2c8-5043a81c5373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a1582090>]}
11:14:29.847105 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
11:14:29.852275 [info ] [MainThread]: 
11:14:29.854089 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:14:29.858011 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:14:29.893819 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:14:29.894388 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:14:29.895145 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:14:30.993115 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 1.1 seconds
11:14:30.997477 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:14:31.134492 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
11:14:31.142193 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
11:14:31.143518 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
11:14:31.144643 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:14:31.863508 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.72 seconds
11:14:31.881829 [debug] [ThreadPool]: On list_analytics_snapshots: Close
11:14:32.042180 [info ] [MainThread]: 
11:14:32.045998 [info ] [MainThread]: Running 1 on-run-start hook
11:14:32.051024 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
11:14:32.060813 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
11:14:32.068451 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
11:14:32.070504 [debug] [MainThread]: Using snowflake connection "master"
11:14:32.071200 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
11:14:32.071914 [debug] [MainThread]: Opening a new connection, currently in state init
11:14:32.873211 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.8 seconds
11:14:32.876531 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.81s]
11:14:32.877730 [info ] [MainThread]: 
11:14:32.879269 [debug] [MainThread]: On master: Close
11:14:32.992929 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:14:32.994060 [info ] [MainThread]: 
11:14:32.999214 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
11:14:33.000980 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
11:14:33.002249 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
11:14:33.003291 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
11:14:33.004466 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
11:14:33.044595 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
11:14:33.053055 [debug] [Thread-1  ]: finished collecting timing info
11:14:33.053862 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
11:14:33.105548 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
11:14:33.113339 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
11:14:33.114400 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
11:14:33.115299 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:34.531065 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
11:14:34.537119 [debug] [Thread-1  ]: finished collecting timing info
11:14:34.537734 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
11:14:34.653659 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.65s]
11:14:34.655173 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
11:14:34.656767 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
11:14:34.657808 [info ] [Thread-1  ]: 2 of 12 START test assert_under_100m............................................ [RUN]
11:14:34.659066 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
11:14:34.659910 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
11:14:34.660774 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
11:14:34.670549 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
11:14:34.677773 [debug] [Thread-1  ]: finished collecting timing info
11:14:34.678556 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
11:14:34.688739 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
11:14:34.693526 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
11:14:34.694414 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
11:14:34.695336 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:36.604744 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
11:14:36.614665 [debug] [Thread-1  ]: finished collecting timing info
11:14:36.619311 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
11:14:36.799196 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_100m.................................................. [[32mPASS[0m in 2.14s]
11:14:36.806453 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
11:14:36.809097 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
11:14:36.816919 [info ] [Thread-1  ]: 3 of 12 START test assert_under_10_percent_null................................. [RUN]
11:14:36.821686 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
11:14:36.823171 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
11:14:36.824390 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
11:14:36.832505 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
11:14:36.836683 [debug] [Thread-1  ]: finished collecting timing info
11:14:36.837293 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
11:14:36.840802 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
11:14:36.848135 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
11:14:36.851021 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
11:14:36.852753 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:37.610882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
11:14:37.615529 [debug] [Thread-1  ]: finished collecting timing info
11:14:37.616745 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
11:14:37.793392 [info ] [Thread-1  ]: 3 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.97s]
11:14:37.799989 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
11:14:37.801512 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
11:14:37.803470 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
11:14:37.806031 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
11:14:37.806855 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
11:14:37.807847 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
11:14:37.830115 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
11:14:37.837158 [debug] [Thread-1  ]: finished collecting timing info
11:14:37.838109 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
11:14:37.840991 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
11:14:37.849196 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
11:14:37.853092 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
11:14:37.855345 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:38.555502 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
11:14:38.562874 [debug] [Thread-1  ]: finished collecting timing info
11:14:38.563766 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
11:14:38.702072 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.90s]
11:14:38.703300 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
11:14:38.704355 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
11:14:38.706400 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
11:14:38.708453 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
11:14:38.710186 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
11:14:38.713137 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
11:14:38.728935 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
11:14:38.734441 [debug] [Thread-1  ]: finished collecting timing info
11:14:38.736045 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
11:14:38.739088 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
11:14:38.746205 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
11:14:38.748365 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
11:14:38.750967 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:39.551356 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
11:14:39.561788 [debug] [Thread-1  ]: finished collecting timing info
11:14:39.563277 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
11:14:39.706173 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.00s]
11:14:39.708402 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
11:14:39.710784 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
11:14:39.713028 [info ] [Thread-1  ]: 6 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
11:14:39.715721 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
11:14:39.717262 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
11:14:39.718987 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
11:14:39.738736 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
11:14:39.748117 [debug] [Thread-1  ]: finished collecting timing info
11:14:39.749758 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
11:14:39.756065 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
11:14:39.761117 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
11:14:39.761804 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
11:14:39.762397 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:40.643410 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.88 seconds
11:14:40.652444 [debug] [Thread-1  ]: finished collecting timing info
11:14:40.654286 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
11:14:40.782806 [info ] [Thread-1  ]: 6 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 1.07s]
11:14:40.784560 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
11:14:40.785875 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
11:14:40.787111 [info ] [Thread-1  ]: 7 of 12 START test source_not_null_sample_customer_c_custkey.................... [RUN]
11:14:40.789238 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
11:14:40.790737 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
11:14:40.792280 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
11:14:40.802264 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
11:14:40.807060 [debug] [Thread-1  ]: finished collecting timing info
11:14:40.808018 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
11:14:40.818539 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
11:14:40.824333 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
11:14:40.825151 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
11:14:40.825890 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:41.525438 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
11:14:41.531518 [debug] [Thread-1  ]: finished collecting timing info
11:14:41.532822 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: Close
11:14:41.670175 [info ] [Thread-1  ]: 7 of 12 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 0.88s]
11:14:41.671768 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
11:14:41.672857 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
11:14:41.675001 [info ] [Thread-1  ]: 8 of 12 START test source_unique_sample_customer_c_custkey...................... [RUN]
11:14:41.679066 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
11:14:41.682515 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
11:14:41.684575 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
11:14:41.702613 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
11:14:41.706234 [debug] [Thread-1  ]: finished collecting timing info
11:14:41.707031 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
11:14:41.714643 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
11:14:41.720417 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
11:14:41.721195 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
11:14:41.721637 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:42.420581 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
11:14:42.425140 [debug] [Thread-1  ]: finished collecting timing info
11:14:42.426304 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
11:14:42.586363 [info ] [Thread-1  ]: 8 of 12 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 0.91s]
11:14:42.588008 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
11:14:42.589057 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
11:14:42.590929 [info ] [Thread-1  ]: 9 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
11:14:42.595073 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
11:14:42.596592 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
11:14:42.598285 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
11:14:42.730499 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
11:14:42.737438 [debug] [Thread-1  ]: finished collecting timing info
11:14:42.738396 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
11:14:42.746024 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
11:14:42.752322 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
11:14:42.753089 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
11:14:42.753676 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:43.807410 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
11:14:43.813493 [debug] [Thread-1  ]: finished collecting timing info
11:14:43.814846 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
11:14:43.947744 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.35s]
11:14:43.948908 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
11:14:43.949796 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
11:14:43.950933 [info ] [Thread-1  ]: 10 of 12 START test unique_my_second_dbt_model_id............................... [RUN]
11:14:43.953317 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
11:14:43.954652 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
11:14:43.955559 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
11:14:43.969144 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
11:14:43.979222 [debug] [Thread-1  ]: finished collecting timing info
11:14:43.980816 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
11:14:43.989113 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
11:14:43.995338 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
11:14:43.996301 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
11:14:43.997333 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:44.774508 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.78 seconds
11:14:44.781471 [debug] [Thread-1  ]: finished collecting timing info
11:14:44.782494 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
11:14:44.906360 [info ] [Thread-1  ]: 10 of 12 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.95s]
11:14:44.907581 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
11:14:44.908815 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
11:14:44.910260 [info ] [Thread-1  ]: 11 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
11:14:44.914320 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
11:14:44.915369 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
11:14:44.916357 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
11:14:44.923975 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
11:14:44.933279 [debug] [Thread-1  ]: finished collecting timing info
11:14:44.934843 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
11:14:44.939096 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
11:14:44.949183 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
11:14:44.950915 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
11:14:44.951939 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:46.415122 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
11:14:46.417961 [debug] [Thread-1  ]: finished collecting timing info
11:14:46.418643 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
11:14:46.527204 [info ] [Thread-1  ]: 11 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.61s]
11:14:46.528193 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
11:14:46.528905 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
11:14:46.530117 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
11:14:46.532108 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
11:14:46.532942 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
11:14:46.533703 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
11:14:46.547091 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
11:14:46.553794 [debug] [Thread-1  ]: finished collecting timing info
11:14:46.554789 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
11:14:46.559157 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
11:14:46.568377 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
11:14:46.569224 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
11:14:46.569835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:14:47.428505 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
11:14:47.432403 [debug] [Thread-1  ]: finished collecting timing info
11:14:47.433267 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
11:14:47.567169 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.04s]
11:14:47.568449 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
11:14:47.605956 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:14:47.607096 [info ] [MainThread]: 
11:14:47.608454 [info ] [MainThread]: Running 3 on-run-end hooks
11:14:47.610353 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
11:14:47.618070 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
11:14:47.623602 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
11:14:47.626720 [debug] [MainThread]: Using snowflake connection "master"
11:14:47.627892 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
11:14:47.628846 [debug] [MainThread]: Opening a new connection, currently in state closed
11:14:48.698539 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.07 seconds
11:14:48.701382 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 1.08s]
11:14:48.703074 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
11:14:48.707738 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
11:14:48.712401 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
11:14:48.714353 [debug] [MainThread]: Using snowflake connection "master"
11:14:48.715387 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
11:14:48.844251 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
11:14:48.847523 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
11:14:48.848999 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
11:14:48.853535 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
11:14:48.858554 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
11:14:48.860920 [debug] [MainThread]: Using snowflake connection "master"
11:14:48.862242 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
11:14:48.950685 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
11:14:48.954088 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
11:14:48.956374 [info ] [MainThread]: 
11:14:48.958128 [debug] [MainThread]: On master: Close
11:14:49.084058 [info ] [MainThread]: 
11:14:49.088417 [info ] [MainThread]: Finished running 12 tests, 4 hooks in 19.23s.
11:14:49.091131 [debug] [MainThread]: Connection 'master' was properly closed.
11:14:49.092105 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
11:14:49.133168 [info ] [MainThread]: 
11:14:49.134525 [info ] [MainThread]: [32mCompleted successfully[0m
11:14:49.136238 [info ] [MainThread]: 
11:14:49.137950 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
11:14:49.140146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a157f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a03c0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3a159fd50>]}


============================== 2022-02-07 15:58:31.660435 | 5fb1cb6b-a527-4769-9d64-d1178db8229e ==============================
15:58:31.660435 [info ] [MainThread]: Running with dbt=1.0.1
15:58:31.664784 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:58:31.665878 [debug] [MainThread]: Tracking: tracking
15:58:31.668443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb304422550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb304422690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb304422b50>]}
15:58:31.799913 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:58:31.800835 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:58:31.813268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fb1cb6b-a527-4769-9d64-d1178db8229e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb303332650>]}
15:58:31.833532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fb1cb6b-a527-4769-9d64-d1178db8229e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb304472e50>]}
15:58:31.835032 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:58:31.838729 [info ] [MainThread]: 
15:58:31.840161 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:58:31.842512 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:58:31.869021 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:58:31.869646 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:58:31.870416 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:58:32.769461 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.9 seconds
15:58:32.773244 [debug] [ThreadPool]: On list_analytics: Close
15:58:32.889862 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
15:58:32.890957 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
15:58:32.891818 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
15:58:32.902555 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
15:58:32.903217 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
15:58:32.904025 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:58:33.830174 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.93 seconds
15:58:33.837228 [debug] [ThreadPool]: On create_analytics_dbt: Close
15:58:33.982122 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:58:34.003931 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:58:34.004861 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:58:34.005449 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:58:34.620862 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.62 seconds
15:58:34.624053 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:58:34.748048 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:58:34.751342 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:58:34.752205 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:58:34.753006 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:58:35.365949 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.61 seconds
15:58:35.368876 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:58:35.500514 [info ] [MainThread]: 
15:58:35.501465 [info ] [MainThread]: Running 1 on-run-start hook
15:58:35.502507 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:58:35.506851 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:58:35.513985 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:58:35.515645 [debug] [MainThread]: Using snowflake connection "master"
15:58:35.516500 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:58:35.517372 [debug] [MainThread]: Opening a new connection, currently in state init
15:58:36.163586 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
15:58:36.165715 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.65s]
15:58:36.166967 [info ] [MainThread]: 
15:58:36.168295 [debug] [MainThread]: On master: Close
15:58:36.304718 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:58:36.307231 [info ] [MainThread]: 
15:58:36.312775 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:58:36.314057 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
15:58:36.316196 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:58:36.316994 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:58:36.318004 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:58:36.328373 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:58:36.331973 [debug] [Thread-1  ]: finished collecting timing info
15:58:36.332886 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:58:36.363521 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:58:36.364418 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:58:36.365231 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:58:38.688024 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.32 seconds
15:58:38.713439 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:58:38.721991 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:58:38.723042 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:58:39.385729 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
15:58:39.428543 [debug] [Thread-1  ]: finished collecting timing info
15:58:39.429581 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:58:39.569571 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fb1cb6b-a527-4769-9d64-d1178db8229e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb301958f50>]}
15:58:39.571664 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.25s]
15:58:39.573659 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:58:39.640325 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:58:39.641814 [info ] [MainThread]: 
15:58:39.643474 [info ] [MainThread]: Running 3 on-run-end hooks
15:58:39.647105 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:58:39.654752 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:58:39.662826 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:58:39.667244 [debug] [MainThread]: Using snowflake connection "master"
15:58:39.669975 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:58:39.671337 [debug] [MainThread]: Opening a new connection, currently in state closed
15:58:40.238025 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.57 seconds
15:58:40.239564 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.57s]
15:58:40.240672 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
15:58:40.243953 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
15:58:40.248188 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
15:58:40.249558 [debug] [MainThread]: Using snowflake connection "master"
15:58:40.250139 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:58:40.348712 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
15:58:40.353907 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.10s]
15:58:40.355337 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
15:58:40.365994 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
15:58:40.370482 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
15:58:40.372109 [debug] [MainThread]: Using snowflake connection "master"
15:58:40.373135 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:58:40.452566 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
15:58:40.454534 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.08s]
15:58:40.455733 [info ] [MainThread]: 
15:58:40.457180 [debug] [MainThread]: On master: Close
15:58:40.570813 [info ] [MainThread]: 
15:58:40.571936 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.73s.
15:58:40.573404 [debug] [MainThread]: Connection 'master' was properly closed.
15:58:40.574930 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
15:58:40.594814 [info ] [MainThread]: 
15:58:40.595867 [info ] [MainThread]: [32mCompleted successfully[0m
15:58:40.597590 [info ] [MainThread]: 
15:58:40.598836 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:58:40.600261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb30445e910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb301967250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb301967490>]}


============================== 2022-02-07 16:02:56.590092 | b6217400-734f-4ed8-9b07-91faa30b7c34 ==============================
16:02:56.590092 [info ] [MainThread]: Running with dbt=1.0.1
16:02:56.591345 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
16:02:56.591984 [debug] [MainThread]: Tracking: tracking
16:02:56.592993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414ba48790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414ba48b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414ba48510>]}
16:02:56.710827 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:02:56.712311 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
16:02:56.733105 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
16:02:56.761697 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
16:02:56.812806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414a869090>]}
16:02:56.830598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414ba92b90>]}
16:02:56.831797 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:02:56.836346 [info ] [MainThread]: 
16:02:56.838040 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:02:56.841327 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:02:56.867451 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:02:56.868568 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:02:56.869679 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:02:57.764191 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.89 seconds
16:02:57.767952 [debug] [ThreadPool]: On list_analytics: Close
16:02:57.889906 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:02:57.901484 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:02:57.902526 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:02:57.903475 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:02:58.575273 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.67 seconds
16:02:58.585211 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:02:58.730715 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
16:02:58.733970 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
16:02:58.734739 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
16:02:58.735394 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:02:59.479044 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.74 seconds
16:02:59.483999 [debug] [ThreadPool]: On list_analytics_snapshots: Close
16:02:59.609593 [info ] [MainThread]: 
16:02:59.610503 [info ] [MainThread]: Running 1 on-run-start hook
16:02:59.611600 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
16:02:59.614859 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
16:02:59.621921 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
16:02:59.623344 [debug] [MainThread]: Using snowflake connection "master"
16:02:59.623784 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:02:59.624806 [debug] [MainThread]: Opening a new connection, currently in state init
16:03:00.165118 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.54 seconds
16:03:00.168143 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.54s]
16:03:00.169757 [info ] [MainThread]: 
16:03:00.171157 [debug] [MainThread]: On master: Close
16:03:00.285309 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:03:00.286698 [info ] [MainThread]: 
16:03:00.290724 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
16:03:00.291835 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
16:03:00.293127 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:03:00.293802 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
16:03:00.294685 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
16:03:00.301109 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
16:03:00.306011 [debug] [Thread-1  ]: finished collecting timing info
16:03:00.306947 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
16:03:00.343497 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:03:00.344288 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
16:03:00.345049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:01.662695 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.32 seconds
16:03:01.690388 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
16:03:01.695858 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
16:03:01.696364 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
16:03:02.787050 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
16:03:02.809619 [debug] [Thread-1  ]: finished collecting timing info
16:03:02.810524 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
16:03:02.917055 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4149409990>]}
16:03:02.918181 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.62s]
16:03:02.919047 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
16:03:02.919751 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
16:03:02.920861 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.dates........................................ [RUN]
16:03:02.922206 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
16:03:02.922679 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
16:03:02.923521 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
16:03:02.944669 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
16:03:02.949010 [debug] [Thread-1  ]: finished collecting timing info
16:03:02.951081 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
16:03:03.046703 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
16:03:03.050977 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
16:03:03.051734 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
16:03:03.052485 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:04.637263 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
16:03:04.641803 [debug] [Thread-1  ]: finished collecting timing info
16:03:04.642915 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
16:03:04.768559 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4149415690>]}
16:03:04.769862 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 1.85s]
16:03:04.771008 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
16:03:04.771776 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
16:03:04.773525 [info ] [Thread-1  ]: 3 of 8 START incremental model dbt.incremental_time............................. [RUN]
16:03:04.775282 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
16:03:04.775942 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
16:03:04.776796 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
16:03:04.788959 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
16:03:04.793643 [debug] [Thread-1  ]: finished collecting timing info
16:03:04.794667 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
16:03:04.802171 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:04.807246 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
16:03:04.814383 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:05.946526 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.13 seconds
16:03:05.949244 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
16:03:05.952904 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
16:03:05.953451 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
16:03:06.876408 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
16:03:06.880201 [debug] [Thread-1  ]: finished collecting timing info
16:03:06.881034 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
16:03:06.995074 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414940de90>]}
16:03:06.996467 [info ] [Thread-1  ]: 3 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.22s]
16:03:06.997739 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
16:03:07.000651 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
16:03:07.001835 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
16:03:07.002553 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
16:03:07.003155 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
16:03:07.009197 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
16:03:07.012805 [debug] [Thread-1  ]: finished collecting timing info
16:03:07.013967 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
16:03:07.014908 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
16:03:07.016290 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
16:03:07.017917 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
16:03:07.018914 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
16:03:07.019731 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
16:03:07.024091 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
16:03:07.026824 [debug] [Thread-1  ]: finished collecting timing info
16:03:07.027812 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
16:03:07.035876 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
16:03:07.036742 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
16:03:07.037432 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:07.966862 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
16:03:07.970750 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
16:03:07.978125 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
16:03:07.981471 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
16:03:13.514615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.53 seconds
16:03:13.521010 [debug] [Thread-1  ]: finished collecting timing info
16:03:13.522092 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
16:03:13.645058 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414866cb50>]}
16:03:13.646033 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.63s]
16:03:13.646862 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
16:03:13.647722 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
16:03:13.648805 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
16:03:13.650161 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
16:03:13.651369 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
16:03:13.652185 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
16:03:13.659779 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
16:03:13.663777 [debug] [Thread-1  ]: finished collecting timing info
16:03:13.665415 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
16:03:13.671724 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
16:03:13.672667 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
16:03:13.673324 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:14.920776 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.25 seconds
16:03:14.924428 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
16:03:14.930279 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
16:03:14.931238 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
16:03:15.864499 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
16:03:15.867592 [debug] [Thread-1  ]: finished collecting timing info
16:03:15.869001 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
16:03:15.984163 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41486a5190>]}
16:03:15.985269 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.33s]
16:03:15.986447 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
16:03:15.987470 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
16:03:15.989531 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
16:03:15.991338 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:03:15.991964 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
16:03:15.993112 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
16:03:15.999837 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
16:03:16.003983 [debug] [Thread-1  ]: finished collecting timing info
16:03:16.004895 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
16:03:16.009964 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:03:16.011018 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
16:03:16.011889 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:16.903057 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
16:03:16.905547 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
16:03:16.910486 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
16:03:16.911216 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
16:03:17.977743 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
16:03:17.980782 [debug] [Thread-1  ]: finished collecting timing info
16:03:17.981496 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
16:03:18.098238 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41494056d0>]}
16:03:18.101454 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.11s]
16:03:18.102774 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
16:03:18.103694 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
16:03:18.104849 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
16:03:18.106481 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
16:03:18.107566 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
16:03:18.108110 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
16:03:18.124703 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
16:03:18.128994 [debug] [Thread-1  ]: finished collecting timing info
16:03:18.129912 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
16:03:18.138925 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
16:03:18.139874 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
16:03:18.140860 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:19.413504 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
16:03:19.417295 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
16:03:19.423031 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
16:03:19.423900 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
16:03:20.470220 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
16:03:20.474340 [debug] [Thread-1  ]: finished collecting timing info
16:03:20.475264 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
16:03:20.611652 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414bab1e10>]}
16:03:20.612554 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.51s]
16:03:20.613745 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
16:03:20.614774 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
16:03:20.616250 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
16:03:20.617789 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
16:03:20.618609 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
16:03:20.619763 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
16:03:20.636688 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
16:03:20.639698 [debug] [Thread-1  ]: finished collecting timing info
16:03:20.640456 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
16:03:20.647108 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
16:03:20.648018 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
16:03:20.648625 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:03:21.610494 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
16:03:21.613386 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
16:03:21.620828 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
16:03:21.621748 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
-- where id = 1
-- union all
-- select 7 as id
      );
16:03:22.265416 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
16:03:22.274587 [debug] [Thread-1  ]: finished collecting timing info
16:03:22.275812 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
16:03:22.414182 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6217400-734f-4ed8-9b07-91faa30b7c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4148ed4e50>]}
16:03:22.415223 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.80s]
16:03:22.416748 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
16:03:22.454230 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:03:22.455087 [info ] [MainThread]: 
16:03:22.456268 [info ] [MainThread]: Running 3 on-run-end hooks
16:03:22.458345 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
16:03:22.461339 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
16:03:22.466309 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
16:03:22.467737 [debug] [MainThread]: Using snowflake connection "master"
16:03:22.468527 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:03:22.469411 [debug] [MainThread]: Opening a new connection, currently in state closed
16:03:23.282302 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.81 seconds
16:03:23.283795 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.82s]
16:03:23.284879 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
16:03:23.287948 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
16:03:23.292363 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
16:03:23.293988 [debug] [MainThread]: Using snowflake connection "master"
16:03:23.294721 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:03:23.453180 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
16:03:23.455109 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
16:03:23.456233 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
16:03:23.460573 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
16:03:23.464170 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
16:03:23.465397 [debug] [MainThread]: Using snowflake connection "master"
16:03:23.466094 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:03:23.551330 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
16:03:23.553763 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
16:03:23.555289 [info ] [MainThread]: 
16:03:23.556288 [debug] [MainThread]: On master: Close
16:03:23.686410 [info ] [MainThread]: 
16:03:23.687348 [info ] [MainThread]: Finished running 6 table models, 2 incremental models, 4 hooks in 26.85s.
16:03:23.688459 [debug] [MainThread]: Connection 'master' was properly closed.
16:03:23.689952 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
16:03:23.705288 [info ] [MainThread]: 
16:03:23.706438 [info ] [MainThread]: [32mCompleted successfully[0m
16:03:23.709301 [info ] [MainThread]: 
16:03:23.710753 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
16:03:23.712113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414ba8db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414bacf4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414bacf690>]}


============================== 2022-02-07 16:08:59.537784 | 2aa2191b-ffc0-4f58-94b8-3b1142a149d6 ==============================
16:08:59.537784 [info ] [MainThread]: Running with dbt=1.0.1
16:08:59.539266 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
16:08:59.539924 [debug] [MainThread]: Tracking: tracking
16:08:59.541046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f981789f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f981789fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f981789f790>]}
16:08:59.652366 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
16:08:59.654031 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
16:08:59.654885 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
16:08:59.674493 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
16:08:59.701315 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
16:08:59.752733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2aa2191b-ffc0-4f58-94b8-3b1142a149d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98166eb0d0>]}
16:08:59.769539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2aa2191b-ffc0-4f58-94b8-3b1142a149d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98178a1790>]}
16:08:59.770723 [info ] [MainThread]: Found 9 models, 13 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:08:59.774764 [info ] [MainThread]: 
16:08:59.776287 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:08:59.779117 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:08:59.805255 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:08:59.806868 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:08:59.807781 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:09:00.708279 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.9 seconds
16:09:00.711921 [debug] [ThreadPool]: On list_analytics: Close
16:09:00.843795 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:09:00.860308 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:09:00.861016 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:09:00.861768 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:09:01.523804 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.66 seconds
16:09:01.527401 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:09:01.668429 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
16:09:01.672816 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
16:09:01.673639 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
16:09:01.674483 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:09:02.401218 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.73 seconds
16:09:02.406801 [debug] [ThreadPool]: On list_analytics_snapshots: Close
16:09:02.519396 [info ] [MainThread]: 
16:09:02.520812 [info ] [MainThread]: Running 1 on-run-start hook
16:09:02.522330 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
16:09:02.526432 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
16:09:02.533103 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
16:09:02.534808 [debug] [MainThread]: Using snowflake connection "master"
16:09:02.535483 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:09:02.536685 [debug] [MainThread]: Opening a new connection, currently in state init
16:09:03.123164 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
16:09:03.126801 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.59s]
16:09:03.128757 [info ] [MainThread]: 
16:09:03.130817 [debug] [MainThread]: On master: Close
16:09:03.265626 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:09:03.266720 [info ] [MainThread]: 
16:09:03.270388 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
16:09:03.271517 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
16:09:03.273112 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
16:09:03.274466 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
16:09:03.275516 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
16:09:03.282130 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
16:09:03.286412 [debug] [Thread-1  ]: finished collecting timing info
16:09:03.287088 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
16:09:03.322914 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:09:03.324234 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
16:09:03.325226 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:09:04.659514 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
16:09:04.681660 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
16:09:04.686085 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:09:04.686736 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
16:09:05.353179 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
16:09:05.379080 [debug] [Thread-1  ]: finished collecting timing info
16:09:05.380008 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
16:09:05.507215 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa2191b-ffc0-4f58-94b8-3b1142a149d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f981529b610>]}
16:09:05.508384 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.23s]
16:09:05.509500 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
16:09:05.586765 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:09:05.587681 [info ] [MainThread]: 
16:09:05.588979 [info ] [MainThread]: Running 3 on-run-end hooks
16:09:05.590225 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
16:09:05.593494 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
16:09:05.597865 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
16:09:05.599176 [debug] [MainThread]: Using snowflake connection "master"
16:09:05.599933 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:09:05.600704 [debug] [MainThread]: Opening a new connection, currently in state closed
16:09:06.165606 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.56 seconds
16:09:06.168235 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.57s]
16:09:06.169852 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
16:09:06.174120 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
16:09:06.179297 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
16:09:06.182146 [debug] [MainThread]: Using snowflake connection "master"
16:09:06.183210 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:09:06.314276 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
16:09:06.316339 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
16:09:06.317375 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
16:09:06.320380 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
16:09:06.323539 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
16:09:06.324839 [debug] [MainThread]: Using snowflake connection "master"
16:09:06.325365 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:09:06.410381 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
16:09:06.418157 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
16:09:06.419670 [info ] [MainThread]: 
16:09:06.421174 [debug] [MainThread]: On master: Close
16:09:06.544957 [info ] [MainThread]: 
16:09:06.545971 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.77s.
16:09:06.547058 [debug] [MainThread]: Connection 'master' was properly closed.
16:09:06.548256 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
16:09:06.564104 [info ] [MainThread]: 
16:09:06.565359 [info ] [MainThread]: [32mCompleted successfully[0m
16:09:06.566545 [info ] [MainThread]: 
16:09:06.567655 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
16:09:06.568838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98167cab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f981529bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f981529b210>]}


============================== 2022-02-07 16:10:10.973505 | a617662d-912f-4266-8003-ca448abe7b78 ==============================
16:10:10.973505 [info ] [MainThread]: Running with dbt=1.0.1
16:10:10.975095 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
16:10:10.975675 [debug] [MainThread]: Tracking: tracking
16:10:10.977055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc36f8110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc36f80d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc36de610>]}
16:10:11.100452 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:10:11.101653 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:10:11.113524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a617662d-912f-4266-8003-ca448abe7b78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc25f25d0>]}
16:10:11.130057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a617662d-912f-4266-8003-ca448abe7b78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc3667750>]}
16:10:11.131288 [info ] [MainThread]: Found 9 models, 13 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:10:11.134919 [info ] [MainThread]: 
16:10:11.136635 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:10:11.140221 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
16:10:11.166735 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
16:10:11.167571 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
16:10:11.168150 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:10:12.031242 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.86 seconds
16:10:12.036304 [debug] [ThreadPool]: On list_analytics_snapshots: Close
16:10:12.157327 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:10:12.161782 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:10:12.162691 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:10:12.163686 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:10:13.028061 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.86 seconds
16:10:13.032496 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:10:13.146542 [info ] [MainThread]: 
16:10:13.147993 [info ] [MainThread]: Running 1 on-run-start hook
16:10:13.149729 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
16:10:13.153772 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
16:10:13.165471 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
16:10:13.167382 [debug] [MainThread]: Using snowflake connection "master"
16:10:13.168452 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:10:13.169394 [debug] [MainThread]: Opening a new connection, currently in state init
16:10:13.717125 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.55 seconds
16:10:13.719398 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.55s]
16:10:13.720707 [info ] [MainThread]: 
16:10:13.721816 [debug] [MainThread]: On master: Close
16:10:13.849116 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:10:13.850257 [info ] [MainThread]: 
16:10:13.853699 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
16:10:13.854334 [info ] [Thread-1  ]: 1 of 4 START test assert_under_10_percent_null.................................. [RUN]
16:10:13.855516 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:10:13.856588 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
16:10:13.857516 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
16:10:13.863303 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:10:13.866861 [debug] [Thread-1  ]: finished collecting timing info
16:10:13.867798 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
16:10:13.901281 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:10:13.906091 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:10:13.906913 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
16:10:13.907652 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:10:14.579621 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
16:10:14.587248 [debug] [Thread-1  ]: finished collecting timing info
16:10:14.588191 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
16:10:14.713639 [info ] [Thread-1  ]: 1 of 4 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 0.86s]
16:10:14.715077 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
16:10:14.716012 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
16:10:14.717581 [info ] [Thread-1  ]: 2 of 4 START test not_null_my_first_dbt_model_id................................ [RUN]
16:10:14.719131 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
16:10:14.720042 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
16:10:14.721066 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
16:10:14.742535 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
16:10:14.748036 [debug] [Thread-1  ]: finished collecting timing info
16:10:14.748740 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
16:10:14.752999 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
16:10:14.758092 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"
16:10:14.759415 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
16:10:14.760419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:10:15.340380 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.58 seconds
16:10:15.344214 [debug] [Thread-1  ]: finished collecting timing info
16:10:15.345001 [debug] [Thread-1  ]: On test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710: Close
16:10:15.454527 [error] [Thread-1  ]: 2 of 4 FAIL 1 not_null_my_first_dbt_model_id.................................... [[31mFAIL 1[0m in 0.74s]
16:10:15.455719 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_my_first_dbt_model_id.5fb22c2710
16:10:15.456706 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:10:15.457972 [info ] [Thread-1  ]: 3 of 4 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
16:10:15.459416 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:10:15.460008 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:10:15.461051 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:10:15.479890 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:10:15.484829 [debug] [Thread-1  ]: finished collecting timing info
16:10:15.485747 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:10:15.491570 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:10:15.498418 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:10:15.499297 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
16:10:15.500069 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:10:16.410486 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
16:10:16.414810 [debug] [Thread-1  ]: finished collecting timing info
16:10:16.415564 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
16:10:16.552661 [info ] [Thread-1  ]: 3 of 4 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.09s]
16:10:16.553631 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:10:16.554399 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:10:16.555570 [info ] [Thread-1  ]: 4 of 4 START test unique_my_first_dbt_model_id.................................. [RUN]
16:10:16.557008 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:10:16.557730 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:10:16.558650 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:10:16.570113 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:10:16.575334 [debug] [Thread-1  ]: finished collecting timing info
16:10:16.576785 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:10:16.580083 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:10:16.584712 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:10:16.585536 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:10:16.586463 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:10:17.207216 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
16:10:17.211590 [debug] [Thread-1  ]: finished collecting timing info
16:10:17.212726 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
16:10:17.349011 [info ] [Thread-1  ]: 4 of 4 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 0.79s]
16:10:17.350684 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:10:17.379968 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:10:17.380967 [info ] [MainThread]: 
16:10:17.382119 [info ] [MainThread]: Running 3 on-run-end hooks
16:10:17.388918 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
16:10:17.391982 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
16:10:17.396785 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
16:10:17.398476 [debug] [MainThread]: Using snowflake connection "master"
16:10:17.399385 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:10:17.400435 [debug] [MainThread]: Opening a new connection, currently in state closed
16:10:17.928273 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
16:10:17.930254 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.53s]
16:10:17.931472 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
16:10:17.934394 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
16:10:17.939168 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
16:10:17.941077 [debug] [MainThread]: Using snowflake connection "master"
16:10:17.942010 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:10:18.051104 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
16:10:18.054134 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.11s]
16:10:18.055572 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
16:10:18.059330 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
16:10:18.063239 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
16:10:18.064507 [debug] [MainThread]: Using snowflake connection "master"
16:10:18.065145 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:10:18.143211 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
16:10:18.146017 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.08s]
16:10:18.147539 [info ] [MainThread]: 
16:10:18.149129 [debug] [MainThread]: On master: Close
16:10:18.268543 [info ] [MainThread]: 
16:10:18.269681 [info ] [MainThread]: Finished running 4 tests, 4 hooks in 7.13s.
16:10:18.271271 [debug] [MainThread]: Connection 'master' was properly closed.
16:10:18.272697 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
16:10:18.286421 [info ] [MainThread]: 
16:10:18.287767 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
16:10:18.291571 [info ] [MainThread]: 
16:10:18.293521 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
16:10:18.294914 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:10:18.296327 [info ] [MainThread]: 
16:10:18.297552 [info ] [MainThread]:   compiled SQL at target/compiled/dbt_tests/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
16:10:18.298579 [info ] [MainThread]: 
16:10:18.299806 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
16:10:18.301075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc25e0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc03b9d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4cc03b9810>]}


============================== 2022-02-07 16:10:49.012951 | d333c4c8-75d2-42dc-b4b6-889b0617e781 ==============================
16:10:49.012951 [info ] [MainThread]: Running with dbt=1.0.1
16:10:49.014212 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
16:10:49.015170 [debug] [MainThread]: Tracking: tracking
16:10:49.017023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b923f090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b923f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b81e4550>]}
16:10:49.138111 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:10:49.140172 [debug] [MainThread]: Partial parsing: update schema file: dbt_tests://models/example/schema.yml
16:10:49.160407 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
16:10:49.187881 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
16:10:49.234000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd333c4c8-75d2-42dc-b4b6-889b0617e781', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b3f9a190>]}
16:10:49.253023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd333c4c8-75d2-42dc-b4b6-889b0617e781', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b9257590>]}
16:10:49.254503 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:10:49.258115 [info ] [MainThread]: 
16:10:49.259823 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:10:49.262683 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:10:49.290941 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:10:49.291796 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:10:49.292666 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:10:50.151885 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.86 seconds
16:10:50.155555 [debug] [ThreadPool]: On list_analytics: Close
16:10:50.280822 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
16:10:50.293702 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
16:10:50.294693 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
16:10:50.295510 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:10:50.927421 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.63 seconds
16:10:50.937434 [debug] [ThreadPool]: On list_analytics_snapshots: Close
16:10:51.057281 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:10:51.063064 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:10:51.064369 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:10:51.065848 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:10:51.866378 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.8 seconds
16:10:51.871102 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:10:52.023294 [info ] [MainThread]: 
16:10:52.024977 [info ] [MainThread]: Running 1 on-run-start hook
16:10:52.026839 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
16:10:52.031519 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
16:10:52.037737 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
16:10:52.039358 [debug] [MainThread]: Using snowflake connection "master"
16:10:52.041146 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:10:52.042118 [debug] [MainThread]: Opening a new connection, currently in state init
16:10:52.627817 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
16:10:52.630878 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.59s]
16:10:52.631946 [info ] [MainThread]: 
16:10:52.633050 [debug] [MainThread]: On master: Close
16:10:52.753202 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:10:52.754352 [info ] [MainThread]: 
16:10:52.757820 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
16:10:52.758743 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
16:10:52.759745 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
16:10:52.760392 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
16:10:52.760984 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
16:10:52.767051 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
16:10:52.771891 [debug] [Thread-1  ]: finished collecting timing info
16:10:52.773290 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
16:10:52.810303 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:10:52.811161 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
16:10:52.811970 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:10:53.660424 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
16:10:53.689153 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
16:10:53.694769 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:10:53.695759 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
16:10:54.352094 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
16:10:54.378717 [debug] [Thread-1  ]: finished collecting timing info
16:10:54.379645 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
16:10:54.490186 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd333c4c8-75d2-42dc-b4b6-889b0617e781', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b0e3a550>]}
16:10:54.491232 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.73s]
16:10:54.492148 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
16:10:54.538242 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:10:54.539180 [info ] [MainThread]: 
16:10:54.540138 [info ] [MainThread]: Running 3 on-run-end hooks
16:10:54.541174 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
16:10:54.545027 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
16:10:54.549410 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
16:10:54.551188 [debug] [MainThread]: Using snowflake connection "master"
16:10:54.551997 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:10:54.552663 [debug] [MainThread]: Opening a new connection, currently in state closed
16:10:55.075003 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.52 seconds
16:10:55.076770 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.53s]
16:10:55.077918 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
16:10:55.081535 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
16:10:55.086115 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
16:10:55.087844 [debug] [MainThread]: Using snowflake connection "master"
16:10:55.089360 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:10:55.204752 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
16:10:55.206942 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
16:10:55.208047 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
16:10:55.210645 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
16:10:55.213911 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
16:10:55.215387 [debug] [MainThread]: Using snowflake connection "master"
16:10:55.215853 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:10:55.297018 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.08 seconds
16:10:55.299414 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.08s]
16:10:55.300593 [info ] [MainThread]: 
16:10:55.301767 [debug] [MainThread]: On master: Close
16:10:55.409365 [info ] [MainThread]: 
16:10:55.410730 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.15s.
16:10:55.411727 [debug] [MainThread]: Connection 'master' was properly closed.
16:10:55.412663 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
16:10:55.428679 [info ] [MainThread]: 
16:10:55.430000 [info ] [MainThread]: [32mCompleted successfully[0m
16:10:55.431287 [info ] [MainThread]: 
16:10:55.432193 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
16:10:55.433426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b8115110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b0e3af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b0e3a190>]}


============================== 2022-02-07 16:11:02.945753 | f42999c6-78e8-4662-8253-3e4714d29af2 ==============================
16:11:02.945753 [info ] [MainThread]: Running with dbt=1.0.1
16:11:02.946822 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
16:11:02.947734 [debug] [MainThread]: Tracking: tracking
16:11:02.949027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27028de090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27028de0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27028de110>]}
16:11:03.067104 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:11:03.068191 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:11:03.079552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f42999c6-78e8-4662-8253-3e4714d29af2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27017b3390>]}
16:11:03.100488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f42999c6-78e8-4662-8253-3e4714d29af2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27028de490>]}
16:11:03.101614 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:11:03.104961 [info ] [MainThread]: 
16:11:03.106441 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:11:03.110039 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
16:11:03.137021 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
16:11:03.137916 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
16:11:03.139181 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:11:04.051462 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.91 seconds
16:11:04.055087 [debug] [ThreadPool]: On list_analytics_snapshots: Close
16:11:04.191384 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:11:04.196669 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:11:04.197558 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:11:04.198444 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:11:04.826694 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.63 seconds
16:11:04.841382 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:11:04.962972 [info ] [MainThread]: 
16:11:04.964408 [info ] [MainThread]: Running 1 on-run-start hook
16:11:04.966320 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
16:11:04.971417 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
16:11:04.980039 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
16:11:04.981570 [debug] [MainThread]: Using snowflake connection "master"
16:11:04.982183 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:11:04.983419 [debug] [MainThread]: Opening a new connection, currently in state init
16:11:05.537916 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.55 seconds
16:11:05.539837 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.56s]
16:11:05.540867 [info ] [MainThread]: 
16:11:05.541772 [debug] [MainThread]: On master: Close
16:11:05.658624 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:11:05.659756 [info ] [MainThread]: 
16:11:05.662732 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
16:11:05.663539 [info ] [Thread-1  ]: 1 of 3 START test assert_under_10_percent_null.................................. [RUN]
16:11:05.665010 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:11:05.666306 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
16:11:05.666879 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
16:11:05.673313 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:11:05.677280 [debug] [Thread-1  ]: finished collecting timing info
16:11:05.678016 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
16:11:05.713198 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
16:11:05.717833 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
16:11:05.718728 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM analytics.dbt.first_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
16:11:05.719728 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:11:06.583234 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
16:11:06.590184 [debug] [Thread-1  ]: finished collecting timing info
16:11:06.591241 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
16:11:06.716493 [info ] [Thread-1  ]: 1 of 3 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 1.05s]
16:11:06.717846 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
16:11:06.719119 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:11:06.720319 [info ] [Thread-1  ]: 2 of 3 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
16:11:06.722089 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:11:06.723071 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:11:06.724064 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:11:06.751072 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:11:06.756017 [debug] [Thread-1  ]: finished collecting timing info
16:11:06.756864 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:11:06.761105 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:11:06.766342 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
16:11:06.767421 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
16:11:06.768894 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:11:07.482054 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
16:11:07.486843 [debug] [Thread-1  ]: finished collecting timing info
16:11:07.488091 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
16:11:07.599518 [info ] [Thread-1  ]: 2 of 3 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 0.88s]
16:11:07.600837 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
16:11:07.601998 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:11:07.603322 [info ] [Thread-1  ]: 3 of 3 START test unique_my_first_dbt_model_id.................................. [RUN]
16:11:07.605281 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:11:07.606189 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:11:07.607099 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:11:07.621934 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:11:07.626217 [debug] [Thread-1  ]: finished collecting timing info
16:11:07.627204 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:11:07.635786 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:11:07.641049 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
16:11:07.641958 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:11:07.642840 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:11:08.273181 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.63 seconds
16:11:08.279114 [debug] [Thread-1  ]: finished collecting timing info
16:11:08.280427 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
16:11:08.395130 [info ] [Thread-1  ]: 3 of 3 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 0.79s]
16:11:08.396197 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
16:11:08.464396 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:11:08.465666 [info ] [MainThread]: 
16:11:08.466882 [info ] [MainThread]: Running 3 on-run-end hooks
16:11:08.468172 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
16:11:08.471843 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
16:11:08.476408 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
16:11:08.477978 [debug] [MainThread]: Using snowflake connection "master"
16:11:08.478689 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:11:08.479667 [debug] [MainThread]: Opening a new connection, currently in state closed
16:11:09.069457 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
16:11:09.071759 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.59s]
16:11:09.073333 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
16:11:09.077254 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
16:11:09.083456 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
16:11:09.087050 [debug] [MainThread]: Using snowflake connection "master"
16:11:09.088209 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:11:09.217424 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
16:11:09.219846 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
16:11:09.220718 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
16:11:09.224231 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
16:11:09.227756 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
16:11:09.229035 [debug] [MainThread]: Using snowflake connection "master"
16:11:09.229995 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:11:09.324151 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
16:11:09.326075 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
16:11:09.327136 [info ] [MainThread]: 
16:11:09.328158 [debug] [MainThread]: On master: Close
16:11:09.470620 [info ] [MainThread]: 
16:11:09.472078 [info ] [MainThread]: Finished running 3 tests, 4 hooks in 6.36s.
16:11:09.474299 [debug] [MainThread]: Connection 'master' was properly closed.
16:11:09.476006 [debug] [MainThread]: Connection 'test.dbt_tests.unique_my_first_dbt_model_id.16e066b321' was properly closed.
16:11:09.494112 [info ] [MainThread]: 
16:11:09.495516 [info ] [MainThread]: [32mCompleted successfully[0m
16:11:09.497160 [info ] [MainThread]: 
16:11:09.500023 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
16:11:09.503041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f270037a950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2702871c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27002c1ed0>]}


============================== 2022-02-08 04:38:04.388555 | cdf6f2ff-a389-4642-88c4-c37666268f52 ==============================
04:38:04.388555 [info ] [MainThread]: Running with dbt=1.0.1
04:38:04.393284 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:38:04.394759 [debug] [MainThread]: Tracking: tracking
04:38:04.396110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3734897610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3734897d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3734897110>]}
04:38:04.540210 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
04:38:04.541190 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
04:38:04.553111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdf6f2ff-a389-4642-88c4-c37666268f52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3733771390>]}
04:38:04.570816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdf6f2ff-a389-4642-88c4-c37666268f52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37348cf110>]}
04:38:04.571914 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:38:04.576103 [info ] [MainThread]: 
04:38:04.577966 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:38:04.580697 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:38:04.627889 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:38:04.628874 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:38:04.629965 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:38:05.817998 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.19 seconds
04:38:05.822722 [debug] [ThreadPool]: On list_analytics: Close
04:38:05.941460 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
04:38:05.942703 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
04:38:05.943643 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
04:38:05.963485 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
04:38:05.964242 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
04:38:05.965229 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:38:06.825838 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.86 seconds
04:38:06.833554 [debug] [ThreadPool]: On create_analytics_dbt: Close
04:38:07.078292 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:38:07.146562 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:38:07.149816 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:38:07.153117 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:38:08.356098 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.2 seconds
04:38:08.366773 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:38:08.529563 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:38:08.539253 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:38:08.540883 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:38:08.542245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:38:09.461688 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.92 seconds
04:38:09.465975 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:38:09.603560 [info ] [MainThread]: 
04:38:09.605308 [info ] [MainThread]: Running 1 on-run-start hook
04:38:09.608451 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:38:09.615218 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:38:09.628005 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:38:09.632443 [debug] [MainThread]: Using snowflake connection "master"
04:38:09.633885 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:38:09.635700 [debug] [MainThread]: Opening a new connection, currently in state init
04:38:10.426637 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.79 seconds
04:38:10.431132 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.80s]
04:38:10.432840 [info ] [MainThread]: 
04:38:10.435319 [debug] [MainThread]: On master: Close
04:38:10.562698 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:38:10.564766 [info ] [MainThread]: 
04:38:10.570731 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:38:10.572453 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
04:38:10.575106 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:10.577690 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:38:10.579297 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:38:10.607108 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:38:10.618500 [debug] [Thread-1  ]: finished collecting timing info
04:38:10.620068 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:38:10.693879 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:10.694757 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
04:38:10.695512 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:38:13.008370 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.31 seconds
04:38:13.042806 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
04:38:13.048670 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:13.049438 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
04:38:14.784882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
04:38:14.820708 [debug] [Thread-1  ]: finished collecting timing info
04:38:14.821723 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
04:38:14.966202 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdf6f2ff-a389-4642-88c4-c37666268f52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3731dbcc10>]}
04:38:14.968089 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 4.39s]
04:38:14.970433 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:38:15.030554 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:38:15.032529 [info ] [MainThread]: 
04:38:15.035755 [info ] [MainThread]: Running 3 on-run-end hooks
04:38:15.038538 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:38:15.045258 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:38:15.052534 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:38:15.055355 [debug] [MainThread]: Using snowflake connection "master"
04:38:15.062160 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:38:15.064037 [debug] [MainThread]: Opening a new connection, currently in state closed
04:38:15.766326 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.7 seconds
04:38:15.769495 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.71s]
04:38:15.771153 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:38:15.776974 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:38:15.782746 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:38:15.784877 [debug] [MainThread]: Using snowflake connection "master"
04:38:15.787032 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:38:15.896311 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
04:38:15.899705 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
04:38:15.901774 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:38:15.906740 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:38:15.911554 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:38:15.915282 [debug] [MainThread]: Using snowflake connection "master"
04:38:15.916566 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:38:16.008407 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
04:38:16.012130 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
04:38:16.014968 [info ] [MainThread]: 
04:38:16.018476 [debug] [MainThread]: On master: Close
04:38:16.181016 [info ] [MainThread]: 
04:38:16.182473 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 11.60s.
04:38:16.187095 [debug] [MainThread]: Connection 'master' was properly closed.
04:38:16.191990 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:38:16.238162 [info ] [MainThread]: 
04:38:16.239698 [info ] [MainThread]: [32mCompleted successfully[0m
04:38:16.241364 [info ] [MainThread]: 
04:38:16.242570 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:38:16.244438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f373233ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3731daf710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3731daf0d0>]}


============================== 2022-02-08 04:42:57.541039 | 143011b2-68f6-49f8-b487-95c9eb8b90e6 ==============================
04:42:57.541039 [info ] [MainThread]: Running with dbt=1.0.1
04:42:57.542296 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:42:57.542933 [debug] [MainThread]: Tracking: tracking
04:42:57.544024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4d3fe090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4d3fe0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4d3da590>]}
04:42:57.682950 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
04:42:57.684231 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
04:42:57.708632 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
04:42:57.741021 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
04:42:57.802367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4d22ef90>]}
04:42:57.819808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4e462290>]}
04:42:57.820843 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:42:57.825332 [info ] [MainThread]: 
04:42:57.827015 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:42:57.830487 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:42:57.866660 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:42:57.868706 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:42:57.869400 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:42:58.963291 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.09 seconds
04:42:58.972577 [debug] [ThreadPool]: On list_analytics: Close
04:42:59.118712 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
04:42:59.141783 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
04:42:59.142509 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
04:42:59.143151 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:42:59.863472 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.72 seconds
04:42:59.878376 [debug] [ThreadPool]: On list_analytics_dbt: Close
04:43:00.048558 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:43:00.065794 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:43:00.067916 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:43:00.070454 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:43:00.926303 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.86 seconds
04:43:00.930260 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:43:01.053230 [info ] [MainThread]: 
04:43:01.054421 [info ] [MainThread]: Running 1 on-run-start hook
04:43:01.055859 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:43:01.059163 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:43:01.065300 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:43:01.066889 [debug] [MainThread]: Using snowflake connection "master"
04:43:01.067558 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:43:01.068441 [debug] [MainThread]: Opening a new connection, currently in state init
04:43:01.814291 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.75 seconds
04:43:01.818630 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.75s]
04:43:01.820251 [info ] [MainThread]: 
04:43:01.821950 [debug] [MainThread]: On master: Close
04:43:01.981239 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:43:01.983160 [info ] [MainThread]: 
04:43:01.989568 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
04:43:01.991497 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
04:43:01.995176 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
04:43:01.997036 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
04:43:01.998176 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
04:43:02.023712 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
04:43:02.036397 [debug] [Thread-1  ]: finished collecting timing info
04:43:02.039872 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
04:43:02.147028 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
04:43:02.147856 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
04:43:02.148822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:03.918967 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.77 seconds
04:43:03.962104 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
04:43:03.968538 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
04:43:03.969451 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
04:43:04.938071 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
04:43:05.009281 [debug] [Thread-1  ]: finished collecting timing info
04:43:05.010927 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
04:43:05.132132 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4788cb90>]}
04:43:05.134213 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 3.14s]
04:43:05.136469 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
04:43:05.138179 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
04:43:05.140831 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.dates........................................ [RUN]
04:43:05.142660 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
04:43:05.143869 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
04:43:05.145092 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
04:43:05.199108 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
04:43:05.208686 [debug] [Thread-1  ]: finished collecting timing info
04:43:05.209968 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
04:43:05.287817 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
04:43:05.291838 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
04:43:05.292700 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
04:43:05.293354 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:07.097370 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.8 seconds
04:43:07.109167 [debug] [Thread-1  ]: finished collecting timing info
04:43:07.112040 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
04:43:07.270501 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4c079690>]}
04:43:07.273082 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.13s]
04:43:07.276880 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
04:43:07.278586 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
04:43:07.282156 [info ] [Thread-1  ]: 3 of 8 START incremental model dbt.incremental_time............................. [RUN]
04:43:07.285087 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
04:43:07.286526 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
04:43:07.288787 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
04:43:07.315334 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
04:43:07.323585 [debug] [Thread-1  ]: finished collecting timing info
04:43:07.326036 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
04:43:07.351587 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
04:43:07.353196 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
04:43:07.355566 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:08.475101 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
04:43:08.477441 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
04:43:08.482144 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
04:43:08.482690 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
04:43:09.685663 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.2 seconds
04:43:09.700915 [debug] [Thread-1  ]: finished collecting timing info
04:43:09.704044 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
04:43:09.859507 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4c040e90>]}
04:43:09.860937 [info ] [Thread-1  ]: 3 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.57s]
04:43:09.861892 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
04:43:09.862816 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:43:09.864386 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:43:09.865796 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:43:09.866531 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:43:09.877998 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:43:09.884154 [debug] [Thread-1  ]: finished collecting timing info
04:43:09.887520 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:43:09.891072 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
04:43:09.893506 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
04:43:09.895522 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
04:43:09.896469 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
04:43:09.899783 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
04:43:09.913200 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
04:43:09.916566 [debug] [Thread-1  ]: finished collecting timing info
04:43:09.917519 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
04:43:09.928749 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
04:43:09.931000 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
04:43:09.932125 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:11.329873 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
04:43:11.334011 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
04:43:11.338927 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
04:43:11.339844 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
04:43:16.566989 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.23 seconds
04:43:16.577522 [debug] [Thread-1  ]: finished collecting timing info
04:43:16.580014 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
04:43:16.731260 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e46006650>]}
04:43:16.742875 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.84s]
04:43:16.746045 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
04:43:16.749967 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
04:43:16.756279 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
04:43:16.768007 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
04:43:16.770389 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
04:43:16.781937 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
04:43:16.814101 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
04:43:16.819156 [debug] [Thread-1  ]: finished collecting timing info
04:43:16.820906 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
04:43:16.829618 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
04:43:16.830301 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
04:43:16.830970 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:17.885641 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
04:43:17.890222 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
04:43:17.900011 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
04:43:17.901206 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
04:43:18.697110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
04:43:18.703205 [debug] [Thread-1  ]: finished collecting timing info
04:43:18.704816 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
04:43:18.842138 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e46023c50>]}
04:43:18.844401 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.08s]
04:43:18.846447 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
04:43:18.848416 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
04:43:18.851892 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
04:43:18.855161 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
04:43:18.856609 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
04:43:18.858854 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
04:43:18.873888 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
04:43:18.883357 [debug] [Thread-1  ]: finished collecting timing info
04:43:18.885396 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
04:43:18.898168 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
04:43:18.900521 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
04:43:18.901988 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:20.161136 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.26 seconds
04:43:20.167897 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
04:43:20.174935 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
04:43:20.175912 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
04:43:21.260254 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
04:43:21.267937 [debug] [Thread-1  ]: finished collecting timing info
04:43:21.269817 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
04:43:21.401542 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e46047a90>]}
04:43:21.402831 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.55s]
04:43:21.404002 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
04:43:21.404869 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
04:43:21.406236 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
04:43:21.407765 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
04:43:21.408666 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
04:43:21.409489 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
04:43:21.441047 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
04:43:21.449244 [debug] [Thread-1  ]: finished collecting timing info
04:43:21.450756 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
04:43:21.467003 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
04:43:21.468521 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
04:43:21.469759 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:22.782501 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
04:43:22.787196 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
04:43:22.793955 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
04:43:22.795118 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
04:43:23.745413 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
04:43:23.750744 [debug] [Thread-1  ]: finished collecting timing info
04:43:23.752205 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
04:43:23.898501 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4602ca90>]}
04:43:23.900836 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.49s]
04:43:23.904361 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
04:43:23.906478 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
04:43:23.909380 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
04:43:23.918463 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
04:43:23.923082 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
04:43:23.926063 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
04:43:23.959088 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
04:43:23.963395 [debug] [Thread-1  ]: finished collecting timing info
04:43:23.964326 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
04:43:23.976181 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
04:43:23.976874 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
04:43:23.977499 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:43:24.996865 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
04:43:25.003576 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
04:43:25.016387 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
04:43:25.017358 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
-- where id = 1
-- union all
-- select 7 as id
      );
04:43:25.657784 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
04:43:25.668029 [debug] [Thread-1  ]: finished collecting timing info
04:43:25.671567 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
04:43:25.845364 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143011b2-68f6-49f8-b487-95c9eb8b90e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4c0aaa50>]}
04:43:25.848786 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.93s]
04:43:25.852114 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
04:43:25.934192 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:43:25.937085 [info ] [MainThread]: 
04:43:25.941359 [info ] [MainThread]: Running 3 on-run-end hooks
04:43:25.945045 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
04:43:25.957291 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
04:43:25.979435 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
04:43:25.984960 [debug] [MainThread]: Using snowflake connection "master"
04:43:25.987708 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
04:43:25.991853 [debug] [MainThread]: Opening a new connection, currently in state closed
04:43:26.803450 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.81 seconds
04:43:26.807173 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.82s]
04:43:26.809071 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
04:43:26.817050 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
04:43:26.827160 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
04:43:26.831578 [debug] [MainThread]: Using snowflake connection "master"
04:43:26.833265 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
04:43:26.997899 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
04:43:27.004102 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
04:43:27.005869 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
04:43:27.011500 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
04:43:27.018571 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
04:43:27.021985 [debug] [MainThread]: Using snowflake connection "master"
04:43:27.025211 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
04:43:27.130866 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
04:43:27.133916 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
04:43:27.136373 [info ] [MainThread]: 
04:43:27.138446 [debug] [MainThread]: On master: Close
04:43:27.291132 [info ] [MainThread]: 
04:43:27.294061 [info ] [MainThread]: Finished running 6 table models, 2 incremental models, 4 hooks in 29.46s.
04:43:27.300537 [debug] [MainThread]: Connection 'master' was properly closed.
04:43:27.303303 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
04:43:27.391014 [info ] [MainThread]: 
04:43:27.393421 [info ] [MainThread]: [32mCompleted successfully[0m
04:43:27.397637 [info ] [MainThread]: 
04:43:27.401589 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
04:43:27.404322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e55249310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4e488d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e4e488790>]}


============================== 2022-02-11 09:12:22.675677 | d48ff10f-b37a-4a4d-867c-9ecc47b0ad72 ==============================
09:12:22.675677 [info ] [MainThread]: Running with dbt=1.0.1
09:12:22.677092 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
09:12:22.677746 [debug] [MainThread]: Tracking: tracking
09:12:22.678752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19eac26610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19eac26510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19eac26250>]}
09:12:22.811401 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:12:22.812378 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:12:22.823236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd48ff10f-b37a-4a4d-867c-9ecc47b0ad72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19e9b3af90>]}
09:12:22.840663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd48ff10f-b37a-4a4d-867c-9ecc47b0ad72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19eac6bf10>]}
09:12:22.841701 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:12:22.845304 [info ] [MainThread]: 
09:12:22.846635 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:12:22.849877 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
09:12:22.872093 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
09:12:22.872772 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
09:12:22.873267 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:12:24.107404 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.23 seconds
09:12:24.111859 [debug] [ThreadPool]: On list_analytics_snapshots: Close
09:12:24.259718 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:12:24.265036 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:12:24.265787 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:12:24.266500 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:12:24.869760 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.6 seconds
09:12:24.874966 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:12:25.015968 [info ] [MainThread]: 
09:12:25.018704 [info ] [MainThread]: Running 1 on-run-start hook
09:12:25.021333 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
09:12:25.026356 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
09:12:25.036117 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
09:12:25.037978 [debug] [MainThread]: Using snowflake connection "master"
09:12:25.038642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:12:25.039378 [debug] [MainThread]: Opening a new connection, currently in state init
09:12:25.801911 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.76 seconds
09:12:25.804012 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.77s]
09:12:25.805057 [info ] [MainThread]: 
09:12:25.805938 [debug] [MainThread]: On master: Close
09:12:25.929037 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:12:25.931985 [info ] [MainThread]: 
09:12:25.945955 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:12:25.947398 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
09:12:25.949629 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:12:25.951091 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:12:25.952527 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:12:25.981026 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:12:25.985621 [debug] [Thread-1  ]: finished collecting timing info
09:12:25.986415 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:12:26.013069 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:12:26.018645 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:12:26.019284 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
09:12:26.020073 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:26.505642 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.49 seconds
09:12:26.517896 [debug] [Thread-1  ]: finished collecting timing info
09:12:26.519983 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
09:12:26.646400 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 0.70s]
09:12:26.649792 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:12:26.651786 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
09:12:26.654841 [info ] [Thread-1  ]: 2 of 12 START test assert_under_100m............................................ [RUN]
09:12:26.658145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
09:12:26.659535 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
09:12:26.660650 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
09:12:26.668063 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
09:12:26.675441 [debug] [Thread-1  ]: finished collecting timing info
09:12:26.675955 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
09:12:26.678642 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
09:12:26.683282 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
09:12:26.684002 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
09:12:26.684498 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:27.162888 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.48 seconds
09:12:27.166179 [debug] [Thread-1  ]: finished collecting timing info
09:12:27.167142 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
09:12:27.281628 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_100m.................................................. [[32mPASS[0m in 0.62s]
09:12:27.284413 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
09:12:27.286737 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
09:12:27.289142 [info ] [Thread-1  ]: 3 of 12 START test assert_under_10_percent_null................................. [RUN]
09:12:27.292802 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
09:12:27.294658 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
09:12:27.296105 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
09:12:27.303517 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
09:12:27.311346 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
09:12:27.333250 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
09:12:27.337137 [debug] [Thread-1  ]: finished collecting timing info
09:12:27.337928 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
09:12:27.340921 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
09:12:27.346288 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
09:12:27.346932 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM __dbt__cte__my_first_dbt_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
09:12:27.347578 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:28.018474 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
09:12:28.025923 [debug] [Thread-1  ]: finished collecting timing info
09:12:28.027378 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
09:12:28.197131 [info ] [Thread-1  ]: 3 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.91s]
09:12:28.200120 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
09:12:28.202276 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:12:28.205424 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
09:12:28.209284 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:12:28.210242 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:12:28.211735 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:12:28.226257 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:12:28.234706 [debug] [Thread-1  ]: finished collecting timing info
09:12:28.235882 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:12:28.239324 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:12:28.244753 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:12:28.245341 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
09:12:28.245812 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:28.770812 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
09:12:28.776680 [debug] [Thread-1  ]: finished collecting timing info
09:12:28.778215 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
09:12:28.928612 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.72s]
09:12:28.931476 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:12:28.933996 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:12:28.936775 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
09:12:28.940316 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:12:28.941469 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:12:28.943196 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:12:28.956336 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:12:28.964330 [debug] [Thread-1  ]: finished collecting timing info
09:12:28.965034 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:12:28.968324 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:12:28.973227 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:12:28.973843 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
09:12:28.974555 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:29.485487 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
09:12:29.490921 [debug] [Thread-1  ]: finished collecting timing info
09:12:29.492224 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
09:12:29.606882 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 0.67s]
09:12:29.609694 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:12:29.611734 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:12:29.614749 [info ] [Thread-1  ]: 6 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
09:12:29.617179 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:12:29.618388 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:12:29.619869 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:12:29.652639 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:12:29.659880 [debug] [Thread-1  ]: finished collecting timing info
09:12:29.660479 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:12:29.664082 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:12:29.670954 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:12:29.671718 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with  __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
),child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from __dbt__cte__my_first_dbt_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
09:12:29.672369 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:30.283758 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.61 seconds
09:12:30.288980 [debug] [Thread-1  ]: finished collecting timing info
09:12:30.290369 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
09:12:30.432998 [info ] [Thread-1  ]: 6 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 0.82s]
09:12:30.435734 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:12:30.437959 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:12:30.440716 [info ] [Thread-1  ]: 7 of 12 START test source_not_null_sample_customer_c_custkey.................... [RUN]
09:12:30.443119 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:12:30.444341 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:12:30.445121 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:12:30.455693 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:12:30.464057 [debug] [Thread-1  ]: finished collecting timing info
09:12:30.464825 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:12:30.468156 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:12:30.473800 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:12:30.474571 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
09:12:30.475251 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:31.382781 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
09:12:31.391859 [debug] [Thread-1  ]: finished collecting timing info
09:12:31.393998 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: Close
09:12:31.561249 [info ] [Thread-1  ]: 7 of 12 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 1.12s]
09:12:31.564202 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:12:31.566631 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:12:31.569688 [info ] [Thread-1  ]: 8 of 12 START test source_unique_sample_customer_c_custkey...................... [RUN]
09:12:31.572871 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:12:31.574453 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:12:31.575746 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:12:31.645532 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:12:31.649306 [debug] [Thread-1  ]: finished collecting timing info
09:12:31.649943 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:12:31.652970 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:12:31.660264 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:12:31.661023 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
09:12:31.661644 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:32.272700 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.61 seconds
09:12:32.280898 [debug] [Thread-1  ]: finished collecting timing info
09:12:32.282501 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
09:12:32.434269 [info ] [Thread-1  ]: 8 of 12 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 0.86s]
09:12:32.437003 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:12:32.440028 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:12:32.441972 [info ] [Thread-1  ]: 9 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
09:12:32.444177 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:12:32.445492 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:12:32.446755 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:12:32.460621 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:12:32.467940 [debug] [Thread-1  ]: finished collecting timing info
09:12:32.468566 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:12:32.471283 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:12:32.476983 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:12:32.477643 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)select
    id as unique_field,
    count(*) as n_records

from __dbt__cte__my_first_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
09:12:32.478206 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:33.056580 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.58 seconds
09:12:33.065005 [debug] [Thread-1  ]: finished collecting timing info
09:12:33.066514 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
09:12:33.187043 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 0.74s]
09:12:33.189768 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:12:33.192083 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:12:33.194835 [info ] [Thread-1  ]: 10 of 12 START test unique_my_second_dbt_model_id............................... [RUN]
09:12:33.197739 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:12:33.199247 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:12:33.200581 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:12:33.209510 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:12:33.217893 [debug] [Thread-1  ]: finished collecting timing info
09:12:33.218896 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:12:33.221619 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:12:33.225903 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:12:33.226636 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
09:12:33.227072 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:33.729089 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.5 seconds
09:12:33.736855 [debug] [Thread-1  ]: finished collecting timing info
09:12:33.738483 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
09:12:33.871046 [info ] [Thread-1  ]: 10 of 12 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.67s]
09:12:33.872559 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:12:33.873926 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:12:33.875342 [info ] [Thread-1  ]: 11 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
09:12:33.877278 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:12:33.878289 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:12:33.879158 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:12:33.887246 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:12:33.894313 [debug] [Thread-1  ]: finished collecting timing info
09:12:33.894876 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:12:33.898659 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:12:33.903240 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:12:33.903902 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
09:12:33.904405 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:34.641986 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
09:12:34.645559 [debug] [Thread-1  ]: finished collecting timing info
09:12:34.646670 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
09:12:34.777823 [info ] [Thread-1  ]: 11 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 0.90s]
09:12:34.780790 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:12:34.782874 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:12:34.785023 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
09:12:34.788386 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:12:34.789863 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:12:34.792149 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:12:34.810105 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:12:34.814766 [debug] [Thread-1  ]: finished collecting timing info
09:12:34.815845 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:12:34.819250 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:12:34.826798 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:12:34.827824 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
09:12:34.828337 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:12:35.372156 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.54 seconds
09:12:35.380389 [debug] [Thread-1  ]: finished collecting timing info
09:12:35.381764 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
09:12:35.519938 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 0.73s]
09:12:35.522416 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:12:35.601373 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:12:35.602920 [info ] [MainThread]: 
09:12:35.604706 [info ] [MainThread]: Running 3 on-run-end hooks
09:12:35.606349 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
09:12:35.611642 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
09:12:35.620908 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
09:12:35.622178 [debug] [MainThread]: Using snowflake connection "master"
09:12:35.622783 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:12:35.623668 [debug] [MainThread]: Opening a new connection, currently in state closed
09:12:36.342189 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.72 seconds
09:12:36.347000 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.72s]
09:12:36.349764 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
09:12:36.356172 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
09:12:36.365929 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
09:12:36.367741 [debug] [MainThread]: Using snowflake connection "master"
09:12:36.368351 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:12:36.478791 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
09:12:36.482317 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.11s]
09:12:36.484217 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
09:12:36.489407 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
09:12:36.494120 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
09:12:36.495717 [debug] [MainThread]: Using snowflake connection "master"
09:12:36.497095 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:12:36.583819 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
09:12:36.585755 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
09:12:36.586897 [info ] [MainThread]: 
09:12:36.588001 [debug] [MainThread]: On master: Close
09:12:36.735373 [info ] [MainThread]: 
09:12:36.738253 [info ] [MainThread]: Finished running 12 tests, 4 hooks in 13.89s.
09:12:36.741112 [debug] [MainThread]: Connection 'master' was properly closed.
09:12:36.742936 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
09:12:36.765567 [info ] [MainThread]: 
09:12:36.766456 [info ] [MainThread]: [32mCompleted successfully[0m
09:12:36.767483 [info ] [MainThread]: 
09:12:36.769097 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
09:12:36.770274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19eacb4c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19e9b29310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19e9b29250>]}


============================== 2022-02-11 09:22:03.849786 | aa6867a0-80f9-4aa0-8e5b-b1894507ccc6 ==============================
09:22:03.849786 [info ] [MainThread]: Running with dbt=1.0.1
09:22:03.850937 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.debug.DebugTask'>, config_dir=True, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='debug', write_json=None)
09:22:03.851588 [debug] [MainThread]: Tracking: tracking
09:22:03.859604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52e6f39150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52e6f394d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ef11c910>]}
09:22:03.860901 [info ] [MainThread]: To view your profiles.yml file, run:

xdg-open /home/vagrant/.dbt
09:22:03.864064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52ef11c910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52e6f394d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52e6f39e50>]}


============================== 2022-02-11 09:23:16.749602 | 14e62e71-db11-455e-85e4-d0d4eabba261 ==============================
09:23:16.749602 [info ] [MainThread]: Running with dbt=1.0.1
09:23:16.750640 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
09:23:16.751157 [debug] [MainThread]: Tracking: tracking
09:23:16.751737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855fc7850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855fc74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855fc7710>]}
09:23:16.854392 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:23:16.855277 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:23:16.865822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14e62e71-db11-455e-85e4-d0d4eabba261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855feec10>]}
09:23:16.882061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14e62e71-db11-455e-85e4-d0d4eabba261', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f085703c050>]}
09:23:16.883173 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:23:16.886174 [info ] [MainThread]: 
09:23:16.887464 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:23:16.889715 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:23:16.909258 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:23:16.910208 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:23:16.911166 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:23:17.739409 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.83 seconds
09:23:17.743407 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:23:17.852576 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
09:23:17.858436 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
09:23:17.859444 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
09:23:17.860352 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:23:18.460134 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.6 seconds
09:23:18.466852 [debug] [ThreadPool]: On list_analytics_snapshots: Close
09:23:18.609712 [info ] [MainThread]: 
09:23:18.612808 [info ] [MainThread]: Running 1 on-run-start hook
09:23:18.615855 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
09:23:18.623819 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
09:23:18.634046 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
09:23:18.635982 [debug] [MainThread]: Using snowflake connection "master"
09:23:18.636789 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:23:18.637488 [debug] [MainThread]: Opening a new connection, currently in state init
09:23:19.452153 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.81 seconds
09:23:19.457389 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.82s]
09:23:19.459122 [info ] [MainThread]: 
09:23:19.460259 [debug] [MainThread]: On master: Close
09:23:19.610544 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:23:19.611813 [info ] [MainThread]: 
09:23:19.616249 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
09:23:19.617387 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
09:23:19.618261 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
09:23:19.618986 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
09:23:19.626705 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
09:23:19.630661 [debug] [Thread-1  ]: finished collecting timing info
09:23:19.631911 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
09:23:19.748870 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:23:19.749764 [info ] [MainThread]: 
09:23:19.750762 [info ] [MainThread]: Running 3 on-run-end hooks
09:23:19.751816 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
09:23:19.754266 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
09:23:19.758170 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
09:23:19.759482 [debug] [MainThread]: Using snowflake connection "master"
09:23:19.760247 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:23:19.760907 [debug] [MainThread]: Opening a new connection, currently in state closed
09:23:20.415778 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
09:23:20.418892 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.66s]
09:23:20.420695 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
09:23:20.423919 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
09:23:20.429644 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
09:23:20.431254 [debug] [MainThread]: Using snowflake connection "master"
09:23:20.432014 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:23:20.550596 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
09:23:20.554200 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
09:23:20.556574 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
09:23:20.560798 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
09:23:20.564345 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
09:23:20.565937 [debug] [MainThread]: Using snowflake connection "master"
09:23:20.566658 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:23:20.675338 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
09:23:20.679330 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
09:23:20.681191 [info ] [MainThread]: 
09:23:20.683034 [debug] [MainThread]: On master: Close
09:23:20.837646 [info ] [MainThread]: 
09:23:20.840844 [info ] [MainThread]: Finished running 4 hooks in 3.95s.
09:23:20.843421 [debug] [MainThread]: Connection 'master' was properly closed.
09:23:20.849842 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
09:23:20.871208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855fe4d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855ebb0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0855ebb110>]}


============================== 2022-02-11 09:52:00.527067 | 49f8b516-64ca-4742-af10-bf704687e28a ==============================
09:52:00.527067 [info ] [MainThread]: Running with dbt=1.0.1
09:52:00.528295 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
09:52:00.529040 [debug] [MainThread]: Tracking: tracking
09:52:00.529704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874bfcb210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874bfcb4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874bfcb510>]}
09:52:00.617067 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:52:00.617996 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:52:00.628930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49f8b516-64ca-4742-af10-bf704687e28a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f875390ba50>]}
09:52:00.643996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49f8b516-64ca-4742-af10-bf704687e28a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874d01fc90>]}
09:52:00.644780 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:52:00.648101 [info ] [MainThread]: 
09:52:00.649463 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:52:00.652721 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:52:00.680982 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:52:00.681631 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:52:00.682107 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:52:01.807898 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 1.13 seconds
09:52:01.813084 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:52:02.032652 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
09:52:02.036597 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
09:52:02.037100 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
09:52:02.037555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:52:02.726769 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.69 seconds
09:52:02.730867 [debug] [ThreadPool]: On list_analytics_snapshots: Close
09:52:02.995765 [info ] [MainThread]: 
09:52:02.997218 [info ] [MainThread]: Running 1 on-run-start hook
09:52:02.999406 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
09:52:03.007024 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
09:52:03.014088 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
09:52:03.015621 [debug] [MainThread]: Using snowflake connection "master"
09:52:03.016448 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:52:03.017160 [debug] [MainThread]: Opening a new connection, currently in state init
09:52:03.611009 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
09:52:03.615689 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.60s]
09:52:03.618824 [info ] [MainThread]: 
09:52:03.622164 [debug] [MainThread]: On master: Close
09:52:04.290186 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:52:04.291586 [info ] [MainThread]: 
09:52:04.298736 [debug] [Thread-1  ]: Began running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:52:04.299568 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
09:52:04.301309 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:52:04.302161 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:52:04.303079 [debug] [Thread-1  ]: Compiling test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:52:04.343034 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:52:04.345934 [debug] [Thread-1  ]: finished collecting timing info
09:52:04.346647 [debug] [Thread-1  ]: Began executing node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:52:04.382654 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:52:04.386664 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
09:52:04.387224 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.customer_model
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
09:52:04.387825 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:04.941868 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.55 seconds
09:52:04.949691 [debug] [Thread-1  ]: finished collecting timing info
09:52:04.950423 [debug] [Thread-1  ]: On test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
09:52:05.111041 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 0.81s]
09:52:05.112039 [debug] [Thread-1  ]: Finished running node test.dbt_tests.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
09:52:05.112669 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_100m
09:52:05.113475 [info ] [Thread-1  ]: 2 of 12 START test assert_under_100m............................................ [RUN]
09:52:05.115101 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_100m"
09:52:05.115743 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_100m
09:52:05.116584 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_100m
09:52:05.120701 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_100m"
09:52:05.124532 [debug] [Thread-1  ]: finished collecting timing info
09:52:05.125479 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_100m
09:52:05.128671 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_100m"
09:52:05.132780 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_100m"
09:52:05.133354 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT 
   c_custkey, c_acctbal, SUM(c_acctbal)
FROM analytics.dbt.customer_model
GROUP BY 1, 2
HAVING SUM(c_acctbal) > 100000000
      
    ) dbt_internal_test
09:52:05.134042 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:05.796731 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
09:52:05.800919 [debug] [Thread-1  ]: finished collecting timing info
09:52:05.801937 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_100m: Close
09:52:05.964991 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_100m.................................................. [[32mPASS[0m in 0.85s]
09:52:05.974424 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_100m
09:52:05.976158 [debug] [Thread-1  ]: Began running node test.dbt_tests.assert_under_10_percent_null
09:52:05.978402 [info ] [Thread-1  ]: 3 of 12 START test assert_under_10_percent_null................................. [RUN]
09:52:05.980991 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.assert_under_10_percent_null"
09:52:05.982196 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.assert_under_10_percent_null
09:52:05.983470 [debug] [Thread-1  ]: Compiling test.dbt_tests.assert_under_10_percent_null
09:52:05.992959 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
09:52:06.000679 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
09:52:06.021367 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.assert_under_10_percent_null"
09:52:06.024069 [debug] [Thread-1  ]: finished collecting timing info
09:52:06.024690 [debug] [Thread-1  ]: Began executing node test.dbt_tests.assert_under_10_percent_null
09:52:06.027762 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.assert_under_10_percent_null"
09:52:06.032366 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.assert_under_10_percent_null"
09:52:06.033102 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)SELECT
  SUM(case when id is null then 1 else 0 end) / count(*) as total_nulls
FROM __dbt__cte__my_first_dbt_model
HAVING SUM(case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
09:52:06.033705 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:06.635918 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
09:52:06.640764 [debug] [Thread-1  ]: finished collecting timing info
09:52:06.641905 [debug] [Thread-1  ]: On test.dbt_tests.assert_under_10_percent_null: Close
09:52:06.794839 [info ] [Thread-1  ]: 3 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 0.81s]
09:52:06.795841 [debug] [Thread-1  ]: Finished running node test.dbt_tests.assert_under_10_percent_null
09:52:06.796719 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:52:06.797793 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
09:52:06.799127 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:52:06.799889 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:52:06.800664 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:52:06.820307 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:52:06.823358 [debug] [Thread-1  ]: finished collecting timing info
09:52:06.824336 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:52:06.827900 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:52:06.832149 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"
09:52:06.832930 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.customer_model
where c_custkey is null



      
    ) dbt_internal_test
09:52:06.833397 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:07.386923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.55 seconds
09:52:07.392449 [debug] [Thread-1  ]: finished collecting timing info
09:52:07.393257 [debug] [Thread-1  ]: On test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
09:52:07.501689 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.70s]
09:52:07.505104 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_playing_with_tests_c_custkey.8de0306ae4
09:52:07.507681 [debug] [Thread-1  ]: Began running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:52:07.509015 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
09:52:07.511134 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:52:07.511804 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:52:07.512965 [debug] [Thread-1  ]: Compiling test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:52:07.520198 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:52:07.525343 [debug] [Thread-1  ]: finished collecting timing info
09:52:07.526707 [debug] [Thread-1  ]: Began executing node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:52:07.530105 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:52:07.535154 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"
09:52:07.536015 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
09:52:07.536681 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:08.505861 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
09:52:08.510435 [debug] [Thread-1  ]: finished collecting timing info
09:52:08.511301 [debug] [Thread-1  ]: On test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
09:52:08.677742 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.17s]
09:52:08.678648 [debug] [Thread-1  ]: Finished running node test.dbt_tests.not_null_snowflake_customer_purchases_c_custkey.482188c502
09:52:08.679711 [debug] [Thread-1  ]: Began running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:52:08.680592 [info ] [Thread-1  ]: 6 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
09:52:08.682652 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:52:08.687060 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:52:08.687887 [debug] [Thread-1  ]: Compiling test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:52:08.717855 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:52:08.720697 [debug] [Thread-1  ]: finished collecting timing info
09:52:08.721406 [debug] [Thread-1  ]: Began executing node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:52:08.725383 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:52:08.730480 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
09:52:08.730984 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with  __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
),child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from __dbt__cte__my_first_dbt_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
09:52:08.731312 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:09.430422 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
09:52:09.433994 [debug] [Thread-1  ]: finished collecting timing info
09:52:09.434800 [debug] [Thread-1  ]: On test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
09:52:09.554415 [info ] [Thread-1  ]: 6 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 0.87s]
09:52:09.556133 [debug] [Thread-1  ]: Finished running node test.dbt_tests.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
09:52:09.557281 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:52:09.558235 [info ] [Thread-1  ]: 7 of 12 START test source_not_null_sample_customer_c_custkey.................... [RUN]
09:52:09.560439 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:52:09.561423 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:52:09.561959 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:52:09.618064 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:52:09.620772 [debug] [Thread-1  ]: finished collecting timing info
09:52:09.621566 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:52:09.624193 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:52:09.627403 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"
09:52:09.627979 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
09:52:09.628412 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:10.272494 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
09:52:10.277131 [debug] [Thread-1  ]: finished collecting timing info
09:52:10.278239 [debug] [Thread-1  ]: On test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2: Close
09:52:10.467071 [info ] [Thread-1  ]: 7 of 12 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 0.91s]
09:52:10.470852 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_not_null_sample_customer_c_custkey.96001aaec2
09:52:10.473625 [debug] [Thread-1  ]: Began running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:52:10.476132 [info ] [Thread-1  ]: 8 of 12 START test source_unique_sample_customer_c_custkey...................... [RUN]
09:52:10.478160 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:52:10.479533 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:52:10.480783 [debug] [Thread-1  ]: Compiling test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:52:10.496805 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:52:10.499553 [debug] [Thread-1  ]: finished collecting timing info
09:52:10.500121 [debug] [Thread-1  ]: Began executing node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:52:10.502680 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:52:10.507416 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"
09:52:10.508763 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
09:52:10.509442 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:11.225945 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
09:52:11.230452 [debug] [Thread-1  ]: finished collecting timing info
09:52:11.231172 [debug] [Thread-1  ]: On test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
09:52:11.343981 [info ] [Thread-1  ]: 8 of 12 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 0.87s]
09:52:11.344839 [debug] [Thread-1  ]: Finished running node test.dbt_tests.source_unique_sample_customer_c_custkey.f7f30c39fd
09:52:11.346013 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:52:11.346919 [info ] [Thread-1  ]: 9 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
09:52:11.348666 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:52:11.349460 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:52:11.349999 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:52:11.364541 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:52:11.367808 [debug] [Thread-1  ]: finished collecting timing info
09:52:11.368630 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:52:11.374106 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:52:11.380395 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"
09:52:11.381362 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)select
    id as unique_field,
    count(*) as n_records

from __dbt__cte__my_first_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
09:52:11.382021 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:13.037836 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
09:52:13.041663 [debug] [Thread-1  ]: finished collecting timing info
09:52:13.042363 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_first_dbt_model_id.16e066b321: Close
09:52:13.181519 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.83s]
09:52:13.182743 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_first_dbt_model_id.16e066b321
09:52:13.183746 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:52:13.184730 [info ] [Thread-1  ]: 10 of 12 START test unique_my_second_dbt_model_id............................... [RUN]
09:52:13.186712 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:52:13.187272 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:52:13.188061 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:52:13.195398 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:52:13.198358 [debug] [Thread-1  ]: finished collecting timing info
09:52:13.199119 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:52:13.202842 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:52:13.210051 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"
09:52:13.210788 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
09:52:13.211248 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:15.269935 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.06 seconds
09:52:15.273172 [debug] [Thread-1  ]: finished collecting timing info
09:52:15.273931 [debug] [Thread-1  ]: On test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493: Close
09:52:15.676931 [info ] [Thread-1  ]: 10 of 12 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 2.49s]
09:52:15.678957 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_my_second_dbt_model_id.57a0f8c493
09:52:15.680309 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:52:15.682149 [info ] [Thread-1  ]: 11 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
09:52:15.684670 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:52:15.685695 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:52:15.686815 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:52:15.694150 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:52:15.699164 [debug] [Thread-1  ]: finished collecting timing info
09:52:15.700037 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:52:15.704244 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:52:15.709793 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"
09:52:15.710461 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.customer_model
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
09:52:15.711244 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:20.489989 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 4.78 seconds
09:52:20.497836 [debug] [Thread-1  ]: finished collecting timing info
09:52:20.499428 [debug] [Thread-1  ]: On test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550: Close
09:52:20.602587 [info ] [Thread-1  ]: 11 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 4.92s]
09:52:20.603521 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_playing_with_tests_c_custkey.b4337ce550
09:52:20.604498 [debug] [Thread-1  ]: Began running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:52:20.605263 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
09:52:20.606600 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:52:20.607223 [debug] [Thread-1  ]: Began compiling node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:52:20.607852 [debug] [Thread-1  ]: Compiling test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:52:20.613338 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:52:20.617493 [debug] [Thread-1  ]: finished collecting timing info
09:52:20.618515 [debug] [Thread-1  ]: Began executing node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:52:20.622196 [debug] [Thread-1  ]: Writing runtime SQL for node "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:52:20.626529 [debug] [Thread-1  ]: Using snowflake connection "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"
09:52:20.627441 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
09:52:20.627975 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:52:21.363453 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
09:52:21.370085 [debug] [Thread-1  ]: finished collecting timing info
09:52:21.371056 [debug] [Thread-1  ]: On test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
09:52:21.592729 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 0.99s]
09:52:21.593699 [debug] [Thread-1  ]: Finished running node test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f
09:52:21.627617 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:52:21.628412 [info ] [MainThread]: 
09:52:21.629302 [info ] [MainThread]: Running 3 on-run-end hooks
09:52:21.630593 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
09:52:21.635176 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
09:52:21.638706 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
09:52:21.639831 [debug] [MainThread]: Using snowflake connection "master"
09:52:21.640616 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:52:21.641350 [debug] [MainThread]: Opening a new connection, currently in state closed
09:52:22.231375 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
09:52:22.237270 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.60s]
09:52:22.239587 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
09:52:22.247446 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
09:52:22.256304 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
09:52:22.258160 [debug] [MainThread]: Using snowflake connection "master"
09:52:22.258985 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:52:22.395727 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:52:22.402168 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:52:22.404165 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
09:52:22.410194 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
09:52:22.414241 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
09:52:22.416701 [debug] [MainThread]: Using snowflake connection "master"
09:52:22.417890 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:52:22.505426 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
09:52:22.507553 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
09:52:22.508711 [info ] [MainThread]: 
09:52:22.510423 [debug] [MainThread]: On master: Close
09:52:22.664848 [info ] [MainThread]: 
09:52:22.665661 [info ] [MainThread]: Finished running 12 tests, 4 hooks in 22.02s.
09:52:22.666492 [debug] [MainThread]: Connection 'master' was properly closed.
09:52:22.667722 [debug] [MainThread]: Connection 'test.dbt_tests.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
09:52:22.681571 [info ] [MainThread]: 
09:52:22.682548 [info ] [MainThread]: [32mCompleted successfully[0m
09:52:22.684283 [info ] [MainThread]: 
09:52:22.686379 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
09:52:22.687530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874d085b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8748b21590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8748b21f50>]}


============================== 2022-02-16 05:11:05.210435 | c19c0174-50e0-4781-8702-fff93e6a9a96 ==============================
05:11:05.210435 [info ] [MainThread]: Running with dbt=1.0.1
05:11:05.211599 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:11:05.212194 [debug] [MainThread]: Tracking: tracking
05:11:05.212745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b937886d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b93788790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b93788890>]}
05:11:05.308506 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:11:05.309280 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:11:05.324784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c19c0174-50e0-4781-8702-fff93e6a9a96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b936a25d0>]}
05:11:05.340801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c19c0174-50e0-4781-8702-fff93e6a9a96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b937d64d0>]}
05:11:05.341580 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:11:05.344522 [info ] [MainThread]: 
05:11:05.345562 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:11:05.348957 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:11:05.371046 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:11:05.371713 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:11:05.372298 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:11:06.531318 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a25797-0000-2023-0000-000298a2f0e9
05:11:06.531971 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
05:11:06.532836 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
05:11:06.533276 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
05:11:06.533849 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:11:06.657463 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:11:06.664269 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:11:06.664775 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:11:06.665479 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:11:07.504203 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.84 seconds
05:11:07.506564 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:11:07.632587 [info ] [MainThread]: 
05:11:07.633877 [info ] [MainThread]: Running 1 on-run-start hook
05:11:07.635019 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:11:07.637967 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:11:07.644855 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:11:07.646622 [debug] [MainThread]: Using snowflake connection "master"
05:11:07.647214 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:11:07.647833 [debug] [MainThread]: Opening a new connection, currently in state init
05:11:08.306073 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a25797-0000-2022-0002-98a2000100ea
05:11:08.307480 [debug] [MainThread]: Snowflake adapter: Snowflake error: 090106 (22000): Cannot perform CREATE TABLE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
05:11:08.309215 [info ] [MainThread]: Database error while running on-run-start
05:11:08.311708 [debug] [MainThread]: On master: Close
05:11:08.474122 [debug] [MainThread]: Connection 'master' was properly closed.
05:11:08.475093 [debug] [MainThread]: Connection 'list_analytics_snapshots' was properly closed.
05:11:08.476569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b920b1290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b91fae190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b91fae790>]}


============================== 2022-02-16 05:13:01.588761 | c78ba593-24cc-457b-9427-962cb1c68b2b ==============================
05:13:01.588761 [info ] [MainThread]: Running with dbt=1.0.1
05:13:01.589781 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:13:01.590213 [debug] [MainThread]: Tracking: tracking
05:13:01.590812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a70e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a70e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a70e490>]}
05:13:01.677738 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:13:01.678653 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:13:01.689055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a626450>]}
05:13:01.708090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a7490d0>]}
05:13:01.708966 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:13:01.712965 [info ] [MainThread]: 
05:13:01.714052 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:13:01.716910 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
05:13:01.749700 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
05:13:01.750768 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
05:13:01.751550 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:13:02.802046 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.05 seconds
05:13:02.805297 [debug] [ThreadPool]: On list_analytics: Close
05:13:02.994520 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
05:13:02.995637 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
05:13:02.996756 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
05:13:03.008327 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
05:13:03.009840 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
05:13:03.011251 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:13:03.992557 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.98 seconds
05:13:03.996162 [debug] [ThreadPool]: On create_analytics_dbt: Close
05:13:04.167206 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:13:04.181090 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:13:04.181926 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:13:04.182833 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:13:05.264916 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.08 seconds
05:13:05.274603 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:13:05.436029 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:13:05.444455 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:13:05.445626 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:13:05.446681 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:13:06.080305 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.63 seconds
05:13:06.084486 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:13:06.263571 [info ] [MainThread]: 
05:13:06.266275 [info ] [MainThread]: Running 1 on-run-start hook
05:13:06.268014 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:13:06.272697 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:13:06.283690 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:13:06.285775 [debug] [MainThread]: Using snowflake connection "master"
05:13:06.287123 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:13:06.288074 [debug] [MainThread]: Opening a new connection, currently in state init
05:13:07.264199 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.98 seconds
05:13:07.267649 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.98s]
05:13:07.269139 [info ] [MainThread]: 
05:13:07.270605 [debug] [MainThread]: On master: Close
05:13:07.407825 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:13:07.409197 [info ] [MainThread]: 
05:13:07.412492 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
05:13:07.413896 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
05:13:07.415202 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:13:07.416471 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
05:13:07.417261 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
05:13:07.427023 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
05:13:07.430448 [debug] [Thread-1  ]: finished collecting timing info
05:13:07.431529 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
05:13:07.477825 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:13:07.478293 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
05:13:07.478914 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:09.850917 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.37 seconds
05:13:09.879533 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
05:13:09.884926 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:13:09.886106 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
05:13:12.138887 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.25 seconds
05:13:12.161435 [debug] [Thread-1  ]: finished collecting timing info
05:13:12.162398 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
05:13:12.326684 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a62c650>]}
05:13:12.328864 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 4.91s]
05:13:12.330249 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
05:13:12.332088 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
05:13:12.333119 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.dates........................................ [RUN]
05:13:12.335602 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
05:13:12.337457 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
05:13:12.339476 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
05:13:12.359569 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
05:13:12.363166 [debug] [Thread-1  ]: finished collecting timing info
05:13:12.364154 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
05:13:12.413194 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
05:13:12.417721 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
05:13:12.418559 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
05:13:12.419319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:14.349151 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.93 seconds
05:13:14.359100 [debug] [Thread-1  ]: finished collecting timing info
05:13:14.361495 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
05:13:14.531694 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a631f90>]}
05:13:14.534441 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.20s]
05:13:14.536641 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
05:13:14.538528 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
05:13:14.541220 [info ] [Thread-1  ]: 3 of 8 START incremental model dbt.incremental_time............................. [RUN]
05:13:14.543585 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
05:13:14.544820 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
05:13:14.546234 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
05:13:14.558671 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
05:13:14.562723 [debug] [Thread-1  ]: finished collecting timing info
05:13:14.563525 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
05:13:14.568703 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
05:13:14.569453 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
05:13:14.569911 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:15.810441 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
05:13:15.813779 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
05:13:15.817937 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
05:13:15.818501 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
05:13:16.910040 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
05:13:16.918494 [debug] [Thread-1  ]: finished collecting timing info
05:13:16.920075 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
05:13:17.070727 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f90a39190>]}
05:13:17.072010 [info ] [Thread-1  ]: 3 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.53s]
05:13:17.073165 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
05:13:17.073844 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:13:17.075193 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:13:17.076076 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:13:17.077114 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:13:17.099271 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:13:17.102473 [debug] [Thread-1  ]: finished collecting timing info
05:13:17.103977 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:13:17.106084 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
05:13:17.108187 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
05:13:17.109982 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
05:13:17.111663 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
05:13:17.112466 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
05:13:17.120084 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
05:13:17.124799 [debug] [Thread-1  ]: finished collecting timing info
05:13:17.125850 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
05:13:17.133568 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
05:13:17.134194 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
05:13:17.134760 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:18.252347 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
05:13:18.258543 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
05:13:18.264228 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
05:13:18.265149 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
05:13:23.794483 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.53 seconds
05:13:23.799993 [debug] [Thread-1  ]: finished collecting timing info
05:13:23.801544 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
05:13:23.983130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f823c1c50>]}
05:13:23.986559 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.87s]
05:13:23.990033 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
05:13:23.992310 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
05:13:23.996036 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
05:13:24.000543 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
05:13:24.002563 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
05:13:24.004901 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
05:13:24.015468 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
05:13:24.019873 [debug] [Thread-1  ]: finished collecting timing info
05:13:24.020649 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
05:13:24.029962 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
05:13:24.031585 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
05:13:24.032697 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:25.197611 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.16 seconds
05:13:25.199812 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
05:13:25.203553 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
05:13:25.204049 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
05:13:26.105740 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
05:13:26.119267 [debug] [Thread-1  ]: finished collecting timing info
05:13:26.120267 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
05:13:26.243231 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a71f050>]}
05:13:26.244790 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.24s]
05:13:26.252613 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
05:13:26.253860 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
05:13:26.255143 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
05:13:26.257719 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
05:13:26.258750 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
05:13:26.259579 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
05:13:26.267720 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
05:13:26.272506 [debug] [Thread-1  ]: finished collecting timing info
05:13:26.273822 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
05:13:26.278941 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
05:13:26.279550 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
05:13:26.279924 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:27.689293 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
05:13:27.691771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
05:13:27.695936 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
05:13:27.696435 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
05:13:28.902696 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.21 seconds
05:13:28.905212 [debug] [Thread-1  ]: finished collecting timing info
05:13:28.905804 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
05:13:29.054388 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f823c66d0>]}
05:13:29.055473 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.80s]
05:13:29.056906 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
05:13:29.058453 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
05:13:29.059527 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
05:13:29.061203 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
05:13:29.062700 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
05:13:29.063487 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
05:13:29.089860 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
05:13:29.096029 [debug] [Thread-1  ]: finished collecting timing info
05:13:29.096645 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
05:13:29.105788 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
05:13:29.108013 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
05:13:29.108842 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:30.101095 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
05:13:30.104568 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
05:13:30.109146 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
05:13:30.109891 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
05:13:31.188408 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
05:13:31.192706 [debug] [Thread-1  ]: finished collecting timing info
05:13:31.193639 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
05:13:31.352014 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f88045290>]}
05:13:31.353078 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.29s]
05:13:31.354129 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
05:13:31.355399 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
05:13:31.356259 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
05:13:31.357918 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
05:13:31.358745 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
05:13:31.359680 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
05:13:31.385338 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
05:13:31.388921 [debug] [Thread-1  ]: finished collecting timing info
05:13:31.389621 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
05:13:31.393975 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
05:13:31.394435 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
05:13:31.394818 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:13:32.460625 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
05:13:32.465177 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
05:13:32.472705 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
05:13:32.473666 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
-- where id = 1
-- union all
-- select 7 as id
      );
05:13:33.193309 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
05:13:33.203170 [debug] [Thread-1  ]: finished collecting timing info
05:13:33.204985 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
05:13:33.371432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c78ba593-24cc-457b-9427-962cb1c68b2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a7b6890>]}
05:13:33.373227 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.01s]
05:13:33.375601 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
05:13:33.428239 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:13:33.429298 [info ] [MainThread]: 
05:13:33.430514 [info ] [MainThread]: Running 3 on-run-end hooks
05:13:33.432651 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:13:33.438433 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:13:33.445723 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:13:33.447748 [debug] [MainThread]: Using snowflake connection "master"
05:13:33.449432 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:13:33.450190 [debug] [MainThread]: Opening a new connection, currently in state closed
05:13:34.116939 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.67 seconds
05:13:34.120091 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.67s]
05:13:34.121703 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:13:34.127591 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:13:34.133974 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:13:34.135702 [debug] [MainThread]: Using snowflake connection "master"
05:13:34.136774 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:13:34.332503 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.19 seconds
05:13:34.337829 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.20s]
05:13:34.340110 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:13:34.344354 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:13:34.350137 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:13:34.352602 [debug] [MainThread]: Using snowflake connection "master"
05:13:34.353302 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:13:34.462070 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
05:13:34.463719 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
05:13:34.465122 [info ] [MainThread]: 
05:13:34.466081 [debug] [MainThread]: On master: Close
05:13:34.624676 [info ] [MainThread]: 
05:13:34.628261 [info ] [MainThread]: Finished running 6 table models, 2 incremental models, 4 hooks in 32.91s.
05:13:34.631623 [debug] [MainThread]: Connection 'master' was properly closed.
05:13:34.633303 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
05:13:34.659197 [info ] [MainThread]: 
05:13:34.660010 [info ] [MainThread]: [32mCompleted successfully[0m
05:13:34.660733 [info ] [MainThread]: 
05:13:34.661461 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
05:13:34.662574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a612c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a6aa810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f8a6aa7d0>]}


============================== 2022-02-16 05:13:49.053095 | 5c076896-27f7-467a-ba67-a5ad49592726 ==============================
05:13:49.053095 [info ] [MainThread]: Running with dbt=1.0.1
05:13:49.054305 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:13:49.055055 [debug] [MainThread]: Tracking: tracking
05:13:49.056413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc649653610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc649653650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6496535d0>]}
05:13:49.161155 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:13:49.162080 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:13:49.172784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c076896-27f7-467a-ba67-a5ad49592726', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc648560350>]}
05:13:49.188300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c076896-27f7-467a-ba67-a5ad49592726', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc649696d50>]}
05:13:49.189177 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:13:49.192107 [info ] [MainThread]: 
05:13:49.193473 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:13:49.197288 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:13:49.224297 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:13:49.225666 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:13:49.226275 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:13:50.218474 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.99 seconds
05:13:50.222623 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:13:50.506229 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:13:50.515679 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:13:50.516999 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:13:50.519429 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:13:51.132631 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.61 seconds
05:13:51.136822 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:13:51.271599 [info ] [MainThread]: 
05:13:51.273092 [info ] [MainThread]: Running 1 on-run-start hook
05:13:51.274547 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:13:51.279365 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:13:51.291066 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:13:51.293993 [debug] [MainThread]: Using snowflake connection "master"
05:13:51.297796 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:13:51.298823 [debug] [MainThread]: Opening a new connection, currently in state init
05:13:52.146601 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.85 seconds
05:13:52.152713 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.86s]
05:13:52.154539 [info ] [MainThread]: 
05:13:52.157180 [debug] [MainThread]: On master: Close
05:13:52.327284 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:13:52.328573 [info ] [MainThread]: 
05:13:52.332992 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:13:52.334731 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:13:52.335664 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:13:52.337109 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:13:52.349981 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:13:52.353965 [debug] [Thread-1  ]: finished collecting timing info
05:13:52.355676 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:13:52.432500 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:13:52.433152 [info ] [MainThread]: 
05:13:52.433748 [info ] [MainThread]: Running 3 on-run-end hooks
05:13:52.434307 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:13:52.436504 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:13:52.440520 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:13:52.442250 [debug] [MainThread]: Using snowflake connection "master"
05:13:52.443522 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:13:52.444155 [debug] [MainThread]: Opening a new connection, currently in state closed
05:13:53.123491 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.68 seconds
05:13:53.128812 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.69s]
05:13:53.131725 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:13:53.136565 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:13:53.142184 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:13:53.144766 [debug] [MainThread]: Using snowflake connection "master"
05:13:53.145843 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:13:53.280766 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
05:13:53.282228 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
05:13:53.283281 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:13:53.285797 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:13:53.288818 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:13:53.291020 [debug] [MainThread]: Using snowflake connection "master"
05:13:53.292193 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:13:53.391888 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
05:13:53.393896 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
05:13:53.394951 [info ] [MainThread]: 
05:13:53.395941 [debug] [MainThread]: On master: Close
05:13:53.545490 [info ] [MainThread]: 
05:13:53.547724 [info ] [MainThread]: Finished running 4 hooks in 4.35s.
05:13:53.549658 [debug] [MainThread]: Connection 'master' was properly closed.
05:13:53.550922 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
05:13:53.573806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6430f4790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc649696d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc64961c810>]}


============================== 2022-02-16 05:14:51.849581 | ffe90e7d-3345-4591-a59f-33f1109fefc1 ==============================
05:14:51.849581 [info ] [MainThread]: Running with dbt=1.0.1
05:14:51.850728 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:14:51.851418 [debug] [MainThread]: Tracking: tracking
05:14:51.852047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4080bc67d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4080bc6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4080bc6850>]}
05:14:51.947249 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:14:51.948004 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:14:51.958172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ffe90e7d-3345-4591-a59f-33f1109fefc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4080ae1710>]}
05:14:51.974564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ffe90e7d-3345-4591-a59f-33f1109fefc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4081c3cf10>]}
05:14:51.975512 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:14:51.978242 [info ] [MainThread]: 
05:14:51.979589 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:14:51.981742 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:14:52.001515 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:14:52.002258 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:14:52.002751 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:14:52.853207 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.85 seconds
05:14:52.857065 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:14:52.995827 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:14:52.999570 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:14:53.000280 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:14:53.000815 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:14:53.776836 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.78 seconds
05:14:53.784275 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:14:53.972818 [info ] [MainThread]: 
05:14:53.974880 [info ] [MainThread]: Running 1 on-run-start hook
05:14:53.976257 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:14:53.979721 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:14:53.986412 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:14:53.987729 [debug] [MainThread]: Using snowflake connection "master"
05:14:53.988391 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:14:53.989089 [debug] [MainThread]: Opening a new connection, currently in state init
05:14:54.598482 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.61 seconds
05:14:54.604771 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.62s]
05:14:54.608143 [info ] [MainThread]: 
05:14:54.610440 [debug] [MainThread]: On master: Close
05:14:54.756130 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:14:54.759485 [info ] [MainThread]: 
05:14:54.766562 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:14:54.768061 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:14:54.769202 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:14:54.770204 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:14:54.777904 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:14:54.781731 [debug] [Thread-1  ]: finished collecting timing info
05:14:54.782713 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:14:54.866252 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:14:54.867389 [info ] [MainThread]: 
05:14:54.869149 [info ] [MainThread]: Running 3 on-run-end hooks
05:14:54.870817 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:14:54.873736 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:14:54.878229 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:14:54.880234 [debug] [MainThread]: Using snowflake connection "master"
05:14:54.881089 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:14:54.882073 [debug] [MainThread]: Opening a new connection, currently in state closed
05:14:55.690609 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.81 seconds
05:14:55.693190 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.81s]
05:14:55.694978 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:14:55.712136 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:14:55.716091 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:14:55.717639 [debug] [MainThread]: Using snowflake connection "master"
05:14:55.718246 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:14:55.828325 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
05:14:55.830051 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.11s]
05:14:55.831111 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:14:55.833317 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:14:55.836132 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:14:55.837227 [debug] [MainThread]: Using snowflake connection "master"
05:14:55.837607 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:14:55.931322 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
05:14:55.933605 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
05:14:55.934915 [info ] [MainThread]: 
05:14:55.935946 [debug] [MainThread]: On master: Close
05:14:56.096130 [info ] [MainThread]: 
05:14:56.097288 [info ] [MainThread]: Finished running 4 hooks in 4.12s.
05:14:56.097997 [debug] [MainThread]: Connection 'master' was properly closed.
05:14:56.098393 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
05:14:56.122000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4081c7cf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4080abaf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4080aba1d0>]}


============================== 2022-02-16 05:17:38.500845 | 78fa1171-9cd3-4aba-96ce-528cc40c34a4 ==============================
05:17:38.500845 [info ] [MainThread]: Running with dbt=1.0.1
05:17:38.502201 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.debug.DebugTask'>, config_dir=True, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='debug', write_json=None)
05:17:38.502850 [debug] [MainThread]: Tracking: tracking
05:17:38.511813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246987bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246987b410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246d4a1a10>]}
05:17:38.513297 [info ] [MainThread]: To view your profiles.yml file, run:

xdg-open /home/vagrant/.dbt
05:17:38.514988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246987bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246987b410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246987b350>]}


============================== 2022-02-16 05:17:55.244676 | ee9e7524-b1a3-4d45-9267-8207b47552d9 ==============================
05:17:55.244676 [info ] [MainThread]: Running with dbt=1.0.1
05:17:55.246178 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:17:55.247162 [debug] [MainThread]: Tracking: tracking
05:17:55.248040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf45514610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf455146d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf45514690>]}
05:17:55.336727 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:17:55.337446 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:17:55.348305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee9e7524-b1a3-4d45-9267-8207b47552d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf4542c610>]}
05:17:55.364622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee9e7524-b1a3-4d45-9267-8207b47552d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf45560ad0>]}
05:17:55.365609 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:17:55.368185 [info ] [MainThread]: 
05:17:55.369246 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:17:55.371822 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:17:55.391572 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:17:55.392080 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:17:55.392505 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:17:56.398311 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.01 seconds
05:17:56.401939 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:17:56.567108 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:17:56.572489 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:17:56.573086 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:17:56.573587 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:17:57.486911 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 0.91 seconds
05:17:57.498773 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:17:57.679620 [info ] [MainThread]: 
05:17:57.681488 [info ] [MainThread]: Running 1 on-run-start hook
05:17:57.682793 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:17:57.686337 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:17:57.693128 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:17:57.694586 [debug] [MainThread]: Using snowflake connection "master"
05:17:57.695218 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:17:57.696185 [debug] [MainThread]: Opening a new connection, currently in state init
05:17:58.229723 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
05:17:58.232066 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.54s]
05:17:58.233582 [info ] [MainThread]: 
05:17:58.238143 [debug] [MainThread]: On master: Close
05:17:58.353706 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:17:58.354765 [info ] [MainThread]: 
05:17:58.357767 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:17:58.358735 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:17:58.359335 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:17:58.359871 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:17:58.365705 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:17:58.369031 [debug] [Thread-1  ]: finished collecting timing info
05:17:58.370363 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:17:58.461115 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:17:58.463544 [info ] [MainThread]: 
05:17:58.465531 [info ] [MainThread]: Running 3 on-run-end hooks
05:17:58.467169 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:17:58.470799 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:17:58.474932 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:17:58.476392 [debug] [MainThread]: Using snowflake connection "master"
05:17:58.477095 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:17:58.477871 [debug] [MainThread]: Opening a new connection, currently in state closed
05:17:59.119317 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.64 seconds
05:17:59.122217 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.65s]
05:17:59.123896 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:17:59.127518 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:17:59.133826 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:17:59.136160 [debug] [MainThread]: Using snowflake connection "master"
05:17:59.137269 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:17:59.274782 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
05:17:59.276434 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
05:17:59.278377 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:17:59.280476 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:17:59.283022 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:17:59.284251 [debug] [MainThread]: Using snowflake connection "master"
05:17:59.284785 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:17:59.378597 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
05:17:59.380608 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
05:17:59.381772 [info ] [MainThread]: 
05:17:59.382610 [debug] [MainThread]: On master: Close
05:17:59.565852 [info ] [MainThread]: 
05:17:59.568678 [info ] [MainThread]: Finished running 4 hooks in 4.20s.
05:17:59.571556 [debug] [MainThread]: Connection 'master' was properly closed.
05:17:59.573108 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
05:17:59.593644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf45427f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf4d8720d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf4d872110>]}


============================== 2022-02-16 05:20:01.255172 | 4ce26fb7-5c72-470b-a3e9-9446fbad42f8 ==============================
05:20:01.255172 [info ] [MainThread]: Running with dbt=1.0.1
05:20:01.256272 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:20:01.257628 [debug] [MainThread]: Tracking: tracking
05:20:01.258398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a9e068610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a9e068650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a9e0685d0>]}
05:20:01.356886 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:20:01.357497 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:20:01.370291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ce26fb7-5c72-470b-a3e9-9446fbad42f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a9cf61550>]}
05:20:01.387229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ce26fb7-5c72-470b-a3e9-9446fbad42f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a9e09bad0>]}
05:20:01.388208 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:20:01.391296 [info ] [MainThread]: 
05:20:01.393045 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:20:01.397184 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:20:01.428764 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:20:01.429728 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:20:01.430554 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:20:02.513618 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.08 seconds
05:20:02.517622 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:20:02.723415 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:20:02.729539 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:20:02.730328 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:20:02.731051 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:20:03.403474 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a257a0-0000-2022-0002-98a20001015e
05:20:03.404864 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
05:20:03.407218 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
05:20:03.408292 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
05:20:03.409597 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:20:03.575042 [info ] [MainThread]: 
05:20:03.577894 [info ] [MainThread]: Running 1 on-run-start hook
05:20:03.580866 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:20:03.590551 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:20:03.597833 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:20:03.599275 [debug] [MainThread]: Using snowflake connection "master"
05:20:03.599978 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:20:03.600632 [debug] [MainThread]: Opening a new connection, currently in state init
05:20:04.382107 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a257a0-0000-2023-0000-000298a2f16d
05:20:04.384227 [debug] [MainThread]: Snowflake adapter: Snowflake error: 090106 (22000): Cannot perform CREATE TABLE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
05:20:04.386311 [info ] [MainThread]: Database error while running on-run-start
05:20:04.390130 [debug] [MainThread]: On master: Close
05:20:04.534611 [debug] [MainThread]: Connection 'master' was properly closed.
05:20:04.535479 [debug] [MainThread]: Connection 'list_analytics_dbt' was properly closed.
05:20:04.536662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a97a58ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a974f8990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a974f8850>]}


============================== 2022-02-16 05:20:25.184746 | 1ba93464-74f7-47b8-b3f4-65bfc66f5118 ==============================
05:20:25.184746 [info ] [MainThread]: Running with dbt=1.0.1
05:20:25.186052 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:20:25.186834 [debug] [MainThread]: Tracking: tracking
05:20:25.187733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f646bb43590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f646bb435d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f646bb43550>]}
05:20:25.289988 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:20:25.290780 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:20:25.301960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ba93464-74f7-47b8-b3f4-65bfc66f5118', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f646ba5c410>]}
05:20:25.319473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ba93464-74f7-47b8-b3f4-65bfc66f5118', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f646bb7a2d0>]}
05:20:25.320543 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:20:25.323415 [info ] [MainThread]: 
05:20:25.324973 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:20:25.328738 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:20:25.355611 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:20:25.356415 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:20:25.357012 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:20:26.330034 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.97 seconds
05:20:26.338076 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:20:26.512196 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:20:26.517911 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:20:26.518668 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:20:26.519382 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:20:27.246151 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a257a0-0000-2022-0002-98a200010166
05:20:27.250329 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
05:20:27.255615 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
05:20:27.258928 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
05:20:27.260789 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:20:27.442803 [info ] [MainThread]: 
05:20:27.446667 [info ] [MainThread]: Running 1 on-run-start hook
05:20:27.450729 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:20:27.466399 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:20:27.483157 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:20:27.485752 [debug] [MainThread]: Using snowflake connection "master"
05:20:27.487429 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:20:27.488384 [debug] [MainThread]: Opening a new connection, currently in state init
05:20:28.056359 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a257a0-0000-2022-0002-98a20001016a
05:20:28.057233 [debug] [MainThread]: Snowflake adapter: Snowflake error: 090106 (22000): Cannot perform CREATE TABLE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
05:20:28.058459 [info ] [MainThread]: Database error while running on-run-start
05:20:28.059817 [debug] [MainThread]: On master: Close
05:20:28.190298 [debug] [MainThread]: Connection 'master' was properly closed.
05:20:28.190972 [debug] [MainThread]: Connection 'list_analytics_dbt' was properly closed.
05:20:28.191876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6469536f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6468fd6850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6468fd67d0>]}


============================== 2022-02-16 05:20:42.635981 | 2f04e186-1777-4ea8-ba30-3704683ba093 ==============================
05:20:42.635981 [info ] [MainThread]: Running with dbt=1.0.1
05:20:42.636955 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:20:42.637415 [debug] [MainThread]: Tracking: tracking
05:20:42.638205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45ba4ec5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45ba4ec610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45ba4ec4d0>]}
05:20:42.743350 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:20:42.744146 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:20:42.756130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f04e186-1777-4ea8-ba30-3704683ba093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45b93e0350>]}
05:20:42.771354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f04e186-1777-4ea8-ba30-3704683ba093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45ba520650>]}
05:20:42.772273 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:20:42.776145 [info ] [MainThread]: 
05:20:42.777604 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:20:42.780109 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:20:42.806098 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:20:42.806863 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:20:42.807457 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:20:43.755796 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.95 seconds
05:20:43.760683 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:20:43.922109 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:20:43.926535 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:20:43.927099 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:20:43.927697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:20:44.630820 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a257a0-0000-2022-0002-98a20001016e
05:20:44.632956 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
05:20:44.635454 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
05:20:44.637087 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
05:20:44.638838 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:20:44.827223 [info ] [MainThread]: 
05:20:44.830358 [info ] [MainThread]: Running 1 on-run-start hook
05:20:44.837221 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:20:44.852918 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:20:44.861730 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:20:44.863319 [debug] [MainThread]: Using snowflake connection "master"
05:20:44.863842 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:20:44.864427 [debug] [MainThread]: Opening a new connection, currently in state init
05:20:45.490187 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a257a0-0000-2022-0002-98a200010172
05:20:45.492131 [debug] [MainThread]: Snowflake adapter: Snowflake error: 090106 (22000): Cannot perform CREATE TABLE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
05:20:45.495145 [info ] [MainThread]: Database error while running on-run-start
05:20:45.497956 [debug] [MainThread]: On master: Close
05:20:45.649858 [debug] [MainThread]: Connection 'master' was properly closed.
05:20:45.652098 [debug] [MainThread]: Connection 'list_analytics_dbt' was properly closed.
05:20:45.654002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45ba4741d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45b3f27790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45b3f78bd0>]}


============================== 2022-02-16 05:21:15.788873 | 218e8552-f43a-40a5-b7ba-ca1d5cba1915 ==============================
05:21:15.788873 [info ] [MainThread]: Running with dbt=1.0.1
05:21:15.790289 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:21:15.791434 [debug] [MainThread]: Tracking: tracking
05:21:15.792207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a744590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a7445d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a744550>]}
05:21:15.899889 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:21:15.900535 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:21:15.911962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a65d350>]}
05:21:15.927591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a7816d0>]}
05:21:15.928369 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:21:15.931577 [info ] [MainThread]: 
05:21:15.933273 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:21:15.936300 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
05:21:15.966944 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
05:21:15.967491 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
05:21:15.967892 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:21:16.869356 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.9 seconds
05:21:16.872851 [debug] [ThreadPool]: On list_analytics: Close
05:21:17.009181 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
05:21:17.010160 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
05:21:17.010852 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
05:21:17.019426 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
05:21:17.020286 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
05:21:17.020973 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:21:17.895248 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.87 seconds
05:21:17.907049 [debug] [ThreadPool]: On create_analytics_dbt: Close
05:21:18.035739 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:21:18.049727 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:21:18.050603 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:21:18.051590 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:21:18.685632 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.63 seconds
05:21:18.691842 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:21:18.846909 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:21:18.856918 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:21:18.858420 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:21:18.859560 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:21:19.697830 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.84 seconds
05:21:19.707170 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:21:19.878415 [info ] [MainThread]: 
05:21:19.881552 [info ] [MainThread]: Running 1 on-run-start hook
05:21:19.884068 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:21:19.890325 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:21:19.898326 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:21:19.899843 [debug] [MainThread]: Using snowflake connection "master"
05:21:19.900584 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:21:19.902583 [debug] [MainThread]: Opening a new connection, currently in state init
05:21:20.589485 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.69 seconds
05:21:20.592085 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.69s]
05:21:20.593774 [info ] [MainThread]: 
05:21:20.604763 [debug] [MainThread]: On master: Close
05:21:20.740451 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:21:20.741628 [info ] [MainThread]: 
05:21:20.746823 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
05:21:20.747881 [info ] [Thread-1  ]: 1 of 8 START table model dbt.cumulative_orders_by_date.......................... [RUN]
05:21:20.749726 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:21:20.750499 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
05:21:20.751129 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
05:21:20.762373 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
05:21:20.766113 [debug] [Thread-1  ]: finished collecting timing info
05:21:20.766970 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
05:21:20.800135 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:21:20.801053 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
05:21:20.801780 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:21.991877 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.19 seconds
05:21:22.012213 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
05:21:22.017439 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
05:21:22.017978 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
05:21:23.323289 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
05:21:23.363165 [debug] [Thread-1  ]: finished collecting timing info
05:21:23.363958 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
05:21:23.644758 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a664390>]}
05:21:23.645812 [info ] [Thread-1  ]: 1 of 8 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 2.90s]
05:21:23.646838 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
05:21:23.648148 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
05:21:23.649442 [info ] [Thread-1  ]: 2 of 8 START incremental model dbt.dates........................................ [RUN]
05:21:23.650939 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
05:21:23.651901 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
05:21:23.652477 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
05:21:23.679227 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
05:21:23.682686 [debug] [Thread-1  ]: finished collecting timing info
05:21:23.683503 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
05:21:23.734978 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
05:21:23.740183 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
05:21:23.740826 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
05:21:23.741418 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:25.421793 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
05:21:25.426025 [debug] [Thread-1  ]: finished collecting timing info
05:21:25.427175 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
05:21:25.600725 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a668750>]}
05:21:25.602674 [info ] [Thread-1  ]: 2 of 8 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 1.95s]
05:21:25.604489 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
05:21:25.606116 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
05:21:25.607999 [info ] [Thread-1  ]: 3 of 8 START incremental model dbt.incremental_time............................. [RUN]
05:21:25.610959 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
05:21:25.612134 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
05:21:25.613930 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
05:21:25.626998 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
05:21:25.631070 [debug] [Thread-1  ]: finished collecting timing info
05:21:25.631874 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
05:21:25.641800 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
05:21:25.642478 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
05:21:25.643156 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:26.623528 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
05:21:26.631755 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
05:21:26.639446 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
05:21:26.640492 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
05:21:27.687724 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
05:21:27.696899 [debug] [Thread-1  ]: finished collecting timing info
05:21:27.699041 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
05:21:27.829971 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a670fd0>]}
05:21:27.830910 [info ] [Thread-1  ]: 3 of 8 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.22s]
05:21:27.831808 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
05:21:27.832647 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:21:27.833743 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:21:27.834687 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:21:27.835488 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:21:27.845507 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:21:27.850524 [debug] [Thread-1  ]: finished collecting timing info
05:21:27.852453 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:21:27.853385 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
05:21:27.854713 [info ] [Thread-1  ]: 4 of 8 START table model dbt.customer_model..................................... [RUN]
05:21:27.856997 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
05:21:27.857651 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
05:21:27.858289 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
05:21:27.864011 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
05:21:27.866708 [debug] [Thread-1  ]: finished collecting timing info
05:21:27.867757 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
05:21:27.875067 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
05:21:27.876437 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
05:21:27.877892 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:29.072946 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.2 seconds
05:21:29.075433 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
05:21:29.079848 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
05:21:29.080701 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table analytics.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
05:21:34.494932 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.41 seconds
05:21:34.497167 [debug] [Thread-1  ]: finished collecting timing info
05:21:34.498161 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
05:21:34.626949 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71123de650>]}
05:21:34.631958 [info ] [Thread-1  ]: 4 of 8 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 6.77s]
05:21:34.633147 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
05:21:34.633845 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
05:21:34.635263 [info ] [Thread-1  ]: 5 of 8 START table model dbt.rename_segments_macro_test......................... [RUN]
05:21:34.637526 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
05:21:34.638626 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
05:21:34.639439 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
05:21:34.651737 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
05:21:34.656240 [debug] [Thread-1  ]: finished collecting timing info
05:21:34.657167 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
05:21:34.663158 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
05:21:34.664011 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
05:21:34.665474 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:35.682566 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
05:21:35.684907 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
05:21:35.690126 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
05:21:35.690997 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table analytics.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
05:21:36.528582 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
05:21:36.531612 [debug] [Thread-1  ]: finished collecting timing info
05:21:36.532301 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
05:21:36.682225 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f712a395c90>]}
05:21:36.683205 [info ] [Thread-1  ]: 5 of 8 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 2.05s]
05:21:36.684133 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
05:21:36.684679 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
05:21:36.685748 [info ] [Thread-1  ]: 6 of 8 START table model dbt.snowflake_customer_purchases....................... [RUN]
05:21:36.686863 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
05:21:36.687601 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
05:21:36.688668 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
05:21:36.694862 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
05:21:36.707039 [debug] [Thread-1  ]: finished collecting timing info
05:21:36.708399 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
05:21:36.713795 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
05:21:36.715689 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
05:21:36.717459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:37.656572 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
05:21:37.664628 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
05:21:37.670011 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
05:21:37.670904 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
05:21:38.772694 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
05:21:38.782989 [debug] [Thread-1  ]: finished collecting timing info
05:21:38.784674 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
05:21:38.916743 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a7ce390>]}
05:21:38.917760 [info ] [Thread-1  ]: 6 of 8 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
05:21:38.918472 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
05:21:38.919044 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
05:21:38.919870 [info ] [Thread-1  ]: 7 of 8 START table model dbt.sources_customer_orders............................ [RUN]
05:21:38.920829 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
05:21:38.921219 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
05:21:38.921985 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
05:21:38.938386 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
05:21:38.941512 [debug] [Thread-1  ]: finished collecting timing info
05:21:38.942415 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
05:21:38.950621 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
05:21:38.951412 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
05:21:38.951932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:40.320531 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
05:21:40.323425 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
05:21:40.328541 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
05:21:40.329208 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table analytics.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
05:21:41.331798 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
05:21:41.341409 [debug] [Thread-1  ]: finished collecting timing info
05:21:41.342807 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
05:21:41.514590 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711cf6d650>]}
05:21:41.515419 [info ] [Thread-1  ]: 7 of 8 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 2.59s]
05:21:41.516098 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
05:21:41.517137 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
05:21:41.517905 [info ] [Thread-1  ]: 8 of 8 START table model dbt.my_second_dbt_model................................ [RUN]
05:21:41.526679 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
05:21:41.527189 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
05:21:41.528772 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
05:21:41.557198 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
05:21:41.560105 [debug] [Thread-1  ]: finished collecting timing info
05:21:41.560880 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
05:21:41.569277 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
05:21:41.570023 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
05:21:41.570426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:21:42.581558 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
05:21:42.588081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
05:21:42.593606 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
05:21:42.594276 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
-- where id = 1
-- union all
-- select 7 as id
      );
05:21:43.281469 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.69 seconds
05:21:43.287923 [debug] [Thread-1  ]: finished collecting timing info
05:21:43.289860 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
05:21:43.454890 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '218e8552-f43a-40a5-b7ba-ca1d5cba1915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a720f10>]}
05:21:43.457220 [info ] [Thread-1  ]: 8 of 8 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.93s]
05:21:43.459497 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
05:21:43.552438 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:21:43.553228 [info ] [MainThread]: 
05:21:43.554002 [info ] [MainThread]: Running 3 on-run-end hooks
05:21:43.554852 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:21:43.558471 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:21:43.563527 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:21:43.565002 [debug] [MainThread]: Using snowflake connection "master"
05:21:43.566030 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:21:43.567018 [debug] [MainThread]: Opening a new connection, currently in state closed
05:21:44.362613 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.8 seconds
05:21:44.371287 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.81s]
05:21:44.374618 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:21:44.380471 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:21:44.387534 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:21:44.389190 [debug] [MainThread]: Using snowflake connection "master"
05:21:44.389969 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:21:44.554439 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
05:21:44.556542 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
05:21:44.557784 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:21:44.561986 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:21:44.566504 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:21:44.568424 [debug] [MainThread]: Using snowflake connection "master"
05:21:44.569234 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:21:44.678773 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
05:21:44.680280 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
05:21:44.681535 [info ] [MainThread]: 
05:21:44.684709 [debug] [MainThread]: On master: Close
05:21:44.833640 [info ] [MainThread]: 
05:21:44.836191 [info ] [MainThread]: Finished running 6 table models, 2 incremental models, 4 hooks in 28.90s.
05:21:44.838582 [debug] [MainThread]: Connection 'master' was properly closed.
05:21:44.841183 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
05:21:44.898763 [info ] [MainThread]: 
05:21:44.900084 [info ] [MainThread]: [32mCompleted successfully[0m
05:21:44.900802 [info ] [MainThread]: 
05:21:44.901849 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
05:21:44.903473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71212a2210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a6707d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f711a6709d0>]}


============================== 2022-02-16 05:22:28.586459 | 3ceeb2ac-66db-4afe-abd7-c2ab9d8125ed ==============================
05:22:28.586459 [info ] [MainThread]: Running with dbt=1.0.1
05:22:28.587536 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
05:22:28.587990 [debug] [MainThread]: Tracking: tracking
05:22:28.588581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e033550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e033590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e033510>]}
05:22:28.696629 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:22:28.697808 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
05:22:28.715680 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
05:22:28.739101 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
05:22:28.781360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ceeb2ac-66db-4afe-abd7-c2ab9d8125ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40ce0e2d0>]}
05:22:28.799375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ceeb2ac-66db-4afe-abd7-c2ab9d8125ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40cef5290>]}
05:22:28.800491 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
05:22:28.803343 [info ] [MainThread]: 
05:22:28.805182 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:22:28.807783 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
05:22:28.837929 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
05:22:28.838605 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
05:22:28.839210 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:22:29.786830 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.95 seconds
05:22:29.791623 [debug] [ThreadPool]: On list_analytics: Close
05:22:29.951090 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
05:22:29.951816 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
05:22:29.952489 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
05:22:29.962016 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
05:22:29.962596 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
05:22:29.963012 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:22:30.766811 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.8 seconds
05:22:30.772281 [debug] [ThreadPool]: On create_analytics_dbt: Close
05:22:30.910187 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
05:22:30.931003 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
05:22:30.931787 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
05:22:30.932437 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:22:31.501456 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.57 seconds
05:22:31.504536 [debug] [ThreadPool]: On list_analytics_snapshots: Close
05:22:31.644389 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
05:22:31.647164 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
05:22:31.648092 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
05:22:31.648837 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:22:32.645848 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.0 seconds
05:22:32.651132 [debug] [ThreadPool]: On list_analytics_dbt: Close
05:22:32.901712 [info ] [MainThread]: 
05:22:32.903869 [info ] [MainThread]: Running 1 on-run-start hook
05:22:32.907044 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
05:22:32.913132 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
05:22:32.920659 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
05:22:32.924021 [debug] [MainThread]: Using snowflake connection "master"
05:22:32.924600 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
05:22:32.925547 [debug] [MainThread]: Opening a new connection, currently in state init
05:22:33.839301 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.91 seconds
05:22:33.841042 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.92s]
05:22:33.842014 [info ] [MainThread]: 
05:22:33.842928 [debug] [MainThread]: On master: Close
05:22:34.051524 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:22:34.053220 [info ] [MainThread]: 
05:22:34.061982 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
05:22:34.063923 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
05:22:34.066016 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
05:22:34.067876 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
05:22:34.069159 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
05:22:34.083476 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
05:22:34.088048 [debug] [Thread-1  ]: finished collecting timing info
05:22:34.089169 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
05:22:34.151748 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
05:22:34.153713 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
05:22:34.155241 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:22:35.435322 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.28 seconds
05:22:35.483834 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
05:22:35.489971 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
05:22:35.490890 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
05:22:36.129090 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
05:22:36.168318 [debug] [Thread-1  ]: finished collecting timing info
05:22:36.169427 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
05:22:36.337246 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ceeb2ac-66db-4afe-abd7-c2ab9d8125ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40751de10>]}
05:22:36.338385 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.27s]
05:22:36.339393 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
05:22:36.404268 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:22:36.405155 [info ] [MainThread]: 
05:22:36.406152 [info ] [MainThread]: Running 3 on-run-end hooks
05:22:36.406959 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
05:22:36.412003 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
05:22:36.416171 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
05:22:36.417948 [debug] [MainThread]: Using snowflake connection "master"
05:22:36.418530 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
05:22:36.419168 [debug] [MainThread]: Opening a new connection, currently in state closed
05:22:37.064610 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
05:22:37.066591 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.65s]
05:22:37.067776 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
05:22:37.070599 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
05:22:37.074729 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
05:22:37.075857 [debug] [MainThread]: Using snowflake connection "master"
05:22:37.076453 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
05:22:37.196724 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
05:22:37.199113 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
05:22:37.200567 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
05:22:37.204516 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
05:22:37.208130 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
05:22:37.209624 [debug] [MainThread]: Using snowflake connection "master"
05:22:37.211148 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
05:22:37.298711 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.09 seconds
05:22:37.300834 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.09s]
05:22:37.302571 [info ] [MainThread]: 
05:22:37.304792 [debug] [MainThread]: On master: Close
05:22:37.439117 [info ] [MainThread]: 
05:22:37.440660 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.63s.
05:22:37.441774 [debug] [MainThread]: Connection 'master' was properly closed.
05:22:37.442364 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
05:22:37.509315 [info ] [MainThread]: 
05:22:37.511129 [info ] [MainThread]: [32mCompleted successfully[0m
05:22:37.512366 [info ] [MainThread]: 
05:22:37.513135 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
05:22:37.514398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe41435c910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4108658d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe410865ad0>]}


============================== 2022-02-21 14:38:50.266913 | bb24f665-7c3e-4988-9e30-50ec31bad318 ==============================
14:38:50.266913 [info ] [MainThread]: Running with dbt=1.0.1
14:38:50.268001 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:38:50.268481 [debug] [MainThread]: Tracking: tracking
14:38:50.269149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2f2fb290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2f2fb3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2f2fb1d0>]}
14:38:50.447892 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:38:50.448751 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:38:50.463372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb24f665-7c3e-4988-9e30-50ec31bad318', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2e1e5290>]}
14:38:50.483580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb24f665-7c3e-4988-9e30-50ec31bad318', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2f3372d0>]}
14:38:50.484648 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
14:38:50.487703 [info ] [MainThread]: 
14:38:50.488993 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:38:50.491674 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:38:50.524695 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:38:50.526954 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:38:50.527957 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:38:52.012367 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.48 seconds
14:38:52.015460 [debug] [ThreadPool]: On list_analytics: Close
14:38:52.182040 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
14:38:52.200569 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
14:38:52.201087 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
14:38:52.201609 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:38:52.896584 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.69 seconds
14:38:52.899255 [debug] [ThreadPool]: On list_analytics_snapshots: Close
14:38:53.056508 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:38:53.060964 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:38:53.061758 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:38:53.062381 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:38:53.928762 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.87 seconds
14:38:53.931468 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:38:54.078989 [info ] [MainThread]: 
14:38:54.080064 [info ] [MainThread]: Running 1 on-run-start hook
14:38:54.080984 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
14:38:54.084758 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
14:38:54.096220 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
14:38:54.098227 [debug] [MainThread]: Using snowflake connection "master"
14:38:54.098658 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
14:38:54.099317 [debug] [MainThread]: Opening a new connection, currently in state init
14:38:54.959969 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.86 seconds
14:38:54.961816 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.86s]
14:38:54.962939 [info ] [MainThread]: 
14:38:54.963878 [debug] [MainThread]: On master: Close
14:38:55.143901 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:38:55.145014 [info ] [MainThread]: 
14:38:55.152707 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:38:55.153886 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:38:55.156448 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:38:55.157864 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:38:55.160836 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:38:55.171191 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:38:55.178205 [debug] [Thread-1  ]: finished collecting timing info
14:38:55.179179 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:38:55.213508 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:38:55.214082 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
14:38:55.214594 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:38:56.866426 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
14:38:56.896187 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:38:56.901036 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:38:56.901680 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:38:57.614386 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
14:38:57.647558 [debug] [Thread-1  ]: finished collecting timing info
14:38:57.648514 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:38:57.808461 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb24f665-7c3e-4988-9e30-50ec31bad318', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2c838390>]}
14:38:57.810500 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.65s]
14:38:57.811614 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:38:57.844684 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:38:57.845539 [info ] [MainThread]: 
14:38:57.846440 [info ] [MainThread]: Running 3 on-run-end hooks
14:38:57.847899 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
14:38:57.852004 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
14:38:57.861906 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
14:38:57.864061 [debug] [MainThread]: Using snowflake connection "master"
14:38:57.865655 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
14:38:57.866916 [debug] [MainThread]: Opening a new connection, currently in state closed
14:38:58.574389 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.71 seconds
14:38:58.576710 [info ] [MainThread]: 1 of 3 OK hook: dbt_tests.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.71s]
14:38:58.577742 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-1
14:38:58.580375 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-1"
14:38:58.585165 [info ] [MainThread]: 2 of 3 START hook: dbt_tests.on-run-end.1....................................... [RUN]
14:38:58.587456 [debug] [MainThread]: Using snowflake connection "master"
14:38:58.588250 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
14:38:58.700004 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
14:38:58.701562 [info ] [MainThread]: 2 of 3 OK hook: dbt_tests.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.11s]
14:38:58.702828 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-2
14:38:58.707786 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-2"
14:38:58.710980 [info ] [MainThread]: 3 of 3 START hook: dbt_tests.on-run-end.2....................................... [RUN]
14:38:58.712225 [debug] [MainThread]: Using snowflake connection "master"
14:38:58.712739 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
14:38:58.811216 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
14:38:58.812964 [info ] [MainThread]: 3 of 3 OK hook: dbt_tests.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
14:38:58.813956 [info ] [MainThread]: 
14:38:58.815213 [debug] [MainThread]: On master: Close
14:38:58.969296 [info ] [MainThread]: 
14:38:58.972560 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.48s.
14:38:58.976661 [debug] [MainThread]: Connection 'master' was properly closed.
14:38:58.977962 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:38:59.015645 [info ] [MainThread]: 
14:38:59.016630 [info ] [MainThread]: [32mCompleted successfully[0m
14:38:59.018323 [info ] [MainThread]: 
14:38:59.021384 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:38:59.027546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f2cc9e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f1efe5410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f1efe5090>]}


============================== 2022-02-21 14:44:34.047257 | 457ac8e9-9922-44fe-9ea2-13729a211f08 ==============================
14:44:34.047257 [info ] [MainThread]: Running with dbt=1.0.1
14:44:34.048538 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:44:34.049577 [debug] [MainThread]: Tracking: tracking
14:44:34.050333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c34f0390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c34f0210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c34f02d0>]}
14:44:34.102550 [info ] [MainThread]: Unable to do partial parsing because profile has changed
14:44:34.103863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '457ac8e9-9922-44fe-9ea2-13729a211f08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c3474fd0>]}
14:44:34.191919 [debug] [MainThread]: Parsing macros/group_by.sql
14:44:34.194281 [debug] [MainThread]: Parsing macros/renaming_segments.sql
14:44:34.196549 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
14:44:34.200177 [debug] [MainThread]: Parsing macros/adapters.sql
14:44:34.296532 [debug] [MainThread]: Parsing macros/catalog.sql
14:44:34.300030 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:44:34.319396 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:44:34.328931 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:44:34.341509 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:44:34.343664 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:44:34.349015 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:44:34.352738 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:44:34.383005 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:44:34.391930 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:44:34.397222 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:44:34.412991 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:44:34.424566 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:44:34.444553 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:44:34.448963 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:44:34.466824 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:44:34.478434 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:44:34.481336 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:44:34.482926 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:44:34.485633 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:44:34.491088 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:44:34.494131 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:44:34.496950 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:44:34.505955 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:44:34.518815 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:44:34.529153 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:44:34.539300 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:44:34.561555 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:44:34.571232 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:44:34.593472 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:44:34.624243 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:44:34.629563 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:44:34.646396 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:44:34.652173 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:44:34.662488 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:44:34.665155 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:44:34.681380 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:44:34.717070 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:44:34.731776 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:44:34.752862 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:44:34.779595 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:44:34.782834 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:44:34.819790 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:44:34.826007 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:44:34.833765 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:44:34.841545 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:44:35.332784 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
14:44:35.361954 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
14:44:35.364504 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:44:35.381014 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:44:35.383938 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:44:35.394913 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:44:35.398573 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:44:35.411599 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:44:35.423410 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
14:44:35.431717 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
14:44:35.434303 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:44:35.445556 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
14:44:35.459485 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
14:44:35.461855 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:44:35.468150 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:44:35.850155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '457ac8e9-9922-44fe-9ea2-13729a211f08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c959af50>]}
14:44:35.877318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '457ac8e9-9922-44fe-9ea2-13729a211f08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c356c990>]}
14:44:35.878210 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
14:44:35.880860 [info ] [MainThread]: 
14:44:35.881960 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:44:35.883895 [debug] [ThreadPool]: Acquiring new snowflake connection "list_TEST_DB"
14:44:35.916251 [debug] [ThreadPool]: Using snowflake connection "list_TEST_DB"
14:44:35.917138 [debug] [ThreadPool]: On list_TEST_DB: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_TEST_DB"} */

    show terse schemas in database TEST_DB
    limit 10000
14:44:35.918144 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:44:37.917643 [debug] [ThreadPool]: Snowflake adapter: Got an error when attempting to open a snowflake connection. No retries attempted: '250001 (08001): Failed to connect to DB: SSIT.snowflakecomputing.com:443. Incorrect username or password was specified.'
14:44:37.921286 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_TEST_DB"} */

    show terse schemas in database TEST_DB
    limit 10000
14:44:37.922075 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
14:44:37.923196 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
14:44:37.923865 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
14:44:37.924569 [debug] [ThreadPool]: On list_TEST_DB: No close available on handle
14:44:37.927443 [debug] [MainThread]: Connection 'master' was properly closed.
14:44:37.929514 [debug] [MainThread]: Connection 'list_TEST_DB' was properly closed.
14:44:37.930524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c356ccd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c35839d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14c05a9d50>]}


============================== 2022-02-21 14:47:03.716036 | 397d82c7-54fc-491a-8f03-0fedba6947cf ==============================
14:47:03.716036 [info ] [MainThread]: Running with dbt=1.0.1
14:47:03.718920 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
14:47:03.723532 [debug] [MainThread]: Tracking: tracking
14:47:03.725571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a36b2a450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a36b2a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a36b2a410>]}
14:47:03.869641 [info ] [MainThread]: Unable to do partial parsing because profile has changed
14:47:03.872096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '397d82c7-54fc-491a-8f03-0fedba6947cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a36aaef90>]}
14:47:03.981409 [debug] [MainThread]: Parsing macros/group_by.sql
14:47:03.986352 [debug] [MainThread]: Parsing macros/renaming_segments.sql
14:47:03.990271 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
14:47:03.993783 [debug] [MainThread]: Parsing macros/adapters.sql
14:47:04.225809 [debug] [MainThread]: Parsing macros/catalog.sql
14:47:04.231757 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:47:04.289487 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:47:04.314597 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:47:04.343639 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:47:04.347663 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:47:04.367820 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:47:04.374828 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:47:04.458114 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:47:04.473775 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:47:04.484237 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:47:04.512248 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:47:04.537675 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:47:04.592745 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:47:04.611612 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:47:04.682218 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:47:04.696289 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:47:04.701517 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:47:04.703409 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:47:04.705119 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:47:04.706904 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:47:04.709833 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:47:04.714711 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:47:04.729198 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:47:04.750430 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:47:04.779210 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:47:04.808032 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:47:04.868671 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:47:04.875638 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:47:04.917778 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:47:04.975790 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:47:04.984349 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:47:05.026798 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:47:05.038966 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:47:05.057464 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:47:05.062571 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:47:05.105032 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:47:05.201018 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:47:05.232216 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:47:05.302446 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:47:05.386542 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:47:05.396536 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:47:05.501689 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:47:05.513880 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:47:05.532663 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:47:05.540593 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:47:06.596841 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
14:47:06.659606 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
14:47:06.664067 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:47:06.694463 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:47:06.701042 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:47:06.721870 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:47:06.727127 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:47:06.744381 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:47:06.763074 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
14:47:06.783815 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
14:47:06.788345 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:47:06.806129 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
14:47:06.832308 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
14:47:06.836196 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:47:06.849661 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:47:07.365257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '397d82c7-54fc-491a-8f03-0fedba6947cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a3ce41ed0>]}
14:47:07.386460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '397d82c7-54fc-491a-8f03-0fedba6947cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a36bb6410>]}
14:47:07.387513 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
14:47:07.391524 [info ] [MainThread]: 
14:47:07.394281 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:47:07.398157 [debug] [ThreadPool]: Acquiring new snowflake connection "list_TEST_DB"
14:47:07.439203 [debug] [ThreadPool]: Using snowflake connection "list_TEST_DB"
14:47:07.440036 [debug] [ThreadPool]: On list_TEST_DB: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_TEST_DB"} */

    show terse schemas in database TEST_DB
    limit 10000
14:47:07.440743 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:47:11.011216 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 3.57 seconds
14:47:11.015890 [debug] [ThreadPool]: On list_TEST_DB: Close
14:47:11.614800 [debug] [ThreadPool]: Acquiring new snowflake connection "create_TEST_DB_dbt"
14:47:11.622628 [debug] [ThreadPool]: Acquiring new snowflake connection "create_TEST_DB_dbt"
14:47:11.626508 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
14:47:11.707383 [debug] [ThreadPool]: Using snowflake connection "create_TEST_DB_dbt"
14:47:11.709907 [debug] [ThreadPool]: On create_TEST_DB_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_TEST_DB_dbt"} */
create schema if not exists TEST_DB.dbt
14:47:11.713639 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:47:19.269559 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 7.56 seconds
14:47:19.277066 [debug] [ThreadPool]: On create_TEST_DB_dbt: Close
14:47:19.938001 [debug] [ThreadPool]: Acquiring new snowflake connection "list_TEST_DB_dbt"
14:47:20.040482 [debug] [ThreadPool]: Using snowflake connection "list_TEST_DB_dbt"
14:47:20.041366 [debug] [ThreadPool]: On list_TEST_DB_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_TEST_DB_dbt"} */

    show terse objects in TEST_DB.dbt
14:47:20.042074 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:47:23.278999 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3.24 seconds
14:47:23.296451 [debug] [ThreadPool]: On list_TEST_DB_dbt: Close
14:47:24.031149 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
14:47:24.058404 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
14:47:24.061312 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
14:47:24.063811 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:47:26.501003 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a275f7-0403-aebc-0000-87b50007b0ca
14:47:26.508005 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
14:47:26.518505 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
14:47:26.520552 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
14:47:26.525575 [debug] [ThreadPool]: On list_analytics_snapshots: Close
14:47:27.308853 [info ] [MainThread]: 
14:47:27.312189 [info ] [MainThread]: Running 1 on-run-start hook
14:47:27.317854 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
14:47:27.361938 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
14:47:27.390683 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
14:47:27.392807 [debug] [MainThread]: Using snowflake connection "master"
14:47:27.393841 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
14:47:27.394619 [debug] [MainThread]: Opening a new connection, currently in state init
14:47:31.372254 [debug] [MainThread]: SQL status: SUCCESS 1 in 3.98 seconds
14:47:31.383849 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 3.99s]
14:47:31.392575 [info ] [MainThread]: 
14:47:31.399779 [debug] [MainThread]: On master: Close
14:47:32.706521 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:47:32.712462 [info ] [MainThread]: 
14:47:32.765466 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
14:47:32.777751 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
14:47:32.786263 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
14:47:32.787792 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
14:47:32.789513 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
14:47:32.815104 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
14:47:32.822950 [debug] [Thread-1  ]: finished collecting timing info
14:47:32.824041 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
14:47:32.890163 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:47:32.891516 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
14:47:32.892376 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:37.767462 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 4.88 seconds
14:47:37.912365 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
14:47:37.924677 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
14:47:37.926193 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table TEST_DB.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on TEST_DB.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
14:47:39.439777 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
14:47:39.490148 [debug] [Thread-1  ]: finished collecting timing info
14:47:39.491082 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
14:47:41.087999 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '397d82c7-54fc-491a-8f03-0fedba6947cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a2fb98090>]}
14:47:41.095846 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 8.30s]
14:47:41.100142 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
14:47:41.110254 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:47:41.114708 [info ] [MainThread]: 
14:47:41.117828 [info ] [MainThread]: Running 3 on-run-end hooks
14:47:41.120590 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
14:47:41.135137 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
14:47:41.143446 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
14:47:41.145001 [debug] [MainThread]: Using snowflake connection "master"
14:47:41.145749 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
14:47:41.146760 [debug] [MainThread]: Opening a new connection, currently in state closed
14:47:44.379471 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a275f7-0403-aebc-0000-87b50007b0da
14:47:44.382458 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Database 'ANALYTICS' does not exist or not authorized.
14:47:44.387246 [info ] [MainThread]: Database error while running on-run-end
14:47:44.398756 [debug] [MainThread]: On master: Close
14:47:45.082439 [debug] [MainThread]: Connection 'master' was properly closed.
14:47:45.084873 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
14:47:45.089957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a2fbe07d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a2e2f1c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a2e2f1550>]}


============================== 2022-02-21 15:02:00.867181 | 825c56d1-42bc-4d71-8eab-001827e12271 ==============================
15:02:00.867181 [info ] [MainThread]: Running with dbt=1.0.1
15:02:00.871164 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:02:00.872242 [debug] [MainThread]: Tracking: tracking
15:02:00.873575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba8477650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba84772d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba8477550>]}
15:02:00.934721 [info ] [MainThread]: Unable to do partial parsing because profile has changed
15:02:00.936809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '825c56d1-42bc-4d71-8eab-001827e12271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba73cff90>]}
15:02:01.038875 [debug] [MainThread]: Parsing macros/group_by.sql
15:02:01.042958 [debug] [MainThread]: Parsing macros/renaming_segments.sql
15:02:01.045115 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
15:02:01.048814 [debug] [MainThread]: Parsing macros/adapters.sql
15:02:01.193886 [debug] [MainThread]: Parsing macros/catalog.sql
15:02:01.202868 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:02:01.232586 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:02:01.249335 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:02:01.268656 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:02:01.272609 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:02:01.287713 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:02:01.292826 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:02:01.325951 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:02:01.332094 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:02:01.343783 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:02:01.374622 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:02:01.390343 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:02:01.420908 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:02:01.431641 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:02:01.458540 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:02:01.477623 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:02:01.482965 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:02:01.485342 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:02:01.491893 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:02:01.494954 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:02:01.500002 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:02:01.505676 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:02:01.515939 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:02:01.521616 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:02:01.533051 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:02:01.546549 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:02:01.581959 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:02:01.586564 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:02:01.627855 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:02:01.683676 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:02:01.691168 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:02:01.707621 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:02:01.715332 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:02:01.724036 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:02:01.729124 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:02:01.753653 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:02:01.811974 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:02:01.828991 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:02:01.860981 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:02:01.897653 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:02:01.904795 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:02:01.962874 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:02:01.972915 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:02:01.986700 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:02:01.994731 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:02:02.711595 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
15:02:02.753435 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
15:02:02.758018 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:02:02.786399 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:02:02.790640 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:02:02.805136 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:02:02.810482 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:02:02.822589 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:02:02.835778 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
15:02:02.850850 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
15:02:02.854405 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:02:02.866905 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
15:02:02.884132 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
15:02:02.889238 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:02:02.899839 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:02:03.498355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '825c56d1-42bc-4d71-8eab-001827e12271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae527210>]}
15:02:03.526196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '825c56d1-42bc-4d71-8eab-001827e12271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba84f6850>]}
15:02:03.527606 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:02:03.533120 [info ] [MainThread]: 
15:02:03.534712 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:02:03.536372 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
15:02:03.578528 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
15:02:03.579510 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
15:02:03.580411 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:02:07.297640 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 3.72 seconds
15:02:07.304636 [debug] [ThreadPool]: On list_test_db: Close
15:02:08.252045 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:02:08.255002 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:02:08.258610 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
15:02:08.295601 [debug] [ThreadPool]: Using snowflake connection "create_test_db_dbt"
15:02:08.296391 [debug] [ThreadPool]: On create_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_test_db_dbt"} */
create schema if not exists test_db.dbt
15:02:08.297507 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:02:11.131623 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2.83 seconds
15:02:11.142447 [debug] [ThreadPool]: On create_test_db_dbt: Close
15:02:12.020040 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
15:02:12.106123 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
15:02:12.108820 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
15:02:12.111100 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:02:15.123937 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3.01 seconds
15:02:15.138197 [debug] [ThreadPool]: On list_test_db_dbt: Close
15:02:15.809429 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:02:15.835258 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:02:15.838628 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:02:15.844703 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:02:19.227421 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27606-0403-aeb7-0000-87b50007a17e
15:02:19.230542 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:02:19.234694 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:02:19.238686 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:02:19.243242 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:02:19.998875 [info ] [MainThread]: 
15:02:20.003921 [info ] [MainThread]: Running 1 on-run-start hook
15:02:20.011824 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:02:20.039979 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:02:20.070049 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:02:20.079726 [debug] [MainThread]: Using snowflake connection "master"
15:02:20.082573 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:02:20.085631 [debug] [MainThread]: Opening a new connection, currently in state init
15:02:22.756552 [debug] [MainThread]: SQL status: SUCCESS 1 in 2.67 seconds
15:02:22.761692 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 2.69s]
15:02:22.763619 [info ] [MainThread]: 
15:02:22.765031 [debug] [MainThread]: On master: Close
15:02:23.876327 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:02:23.880168 [info ] [MainThread]: 
15:02:23.896744 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:02:23.900059 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
15:02:23.907202 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:02:23.911864 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:02:23.914431 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:02:23.951077 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:02:23.957447 [debug] [Thread-1  ]: finished collecting timing info
15:02:23.958823 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:02:24.055889 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:02:24.056924 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:02:24.057937 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:02:29.824711 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.77 seconds
15:02:29.877932 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:02:29.884482 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:02:29.886596 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:02:31.493531 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.61 seconds
15:02:31.552250 [debug] [Thread-1  ]: finished collecting timing info
15:02:31.554209 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:02:32.553818 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '825c56d1-42bc-4d71-8eab-001827e12271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba54e8d90>]}
15:02:32.560760 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 8.65s]
15:02:32.573197 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:02:32.684446 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:02:32.693765 [info ] [MainThread]: 
15:02:32.696409 [info ] [MainThread]: Running 3 on-run-end hooks
15:02:32.698089 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:02:32.705528 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:02:32.723847 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:02:32.726906 [debug] [MainThread]: Using snowflake connection "master"
15:02:32.728011 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:02:32.728960 [debug] [MainThread]: Opening a new connection, currently in state closed
15:02:35.781974 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a27606-0403-aeb7-0000-87b50007a182
15:02:35.783476 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Database 'ANALYTICS' does not exist or not authorized.
15:02:35.785713 [info ] [MainThread]: Database error while running on-run-end
15:02:35.788678 [debug] [MainThread]: On master: Close
15:02:36.705220 [debug] [MainThread]: Connection 'master' was properly closed.
15:02:36.706211 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
15:02:36.707406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba4451390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba44516d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ba4451310>]}


============================== 2022-02-21 15:16:17.783736 | 15ba44e0-36fb-4d19-b923-0b6a83c4a8fb ==============================
15:16:17.783736 [info ] [MainThread]: Running with dbt=1.0.1
15:16:17.785850 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:16:17.786972 [debug] [MainThread]: Tracking: tracking
15:16:17.788848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05586d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05586d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05586d450>]}
15:16:17.967859 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:16:17.969238 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:16:18.001066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15ba44e0-36fb-4d19-b923-0b6a83c4a8fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb054766290>]}
15:16:18.030805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15ba44e0-36fb-4d19-b923-0b6a83c4a8fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0558dd4d0>]}
15:16:18.032724 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:16:18.041657 [info ] [MainThread]: 
15:16:18.043879 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:16:18.047187 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
15:16:18.086269 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
15:16:18.087137 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
15:16:18.088360 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:16:21.593755 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 3.51 seconds
15:16:21.604841 [debug] [ThreadPool]: On list_test_db: Close
15:16:22.248092 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:16:22.292391 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:16:22.293006 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:16:22.293676 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:16:24.821578 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27614-0403-aeb4-0000-87b50007d006
15:16:24.822372 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:16:24.823532 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:16:24.824376 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:16:24.826985 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:16:25.427209 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
15:16:25.449754 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
15:16:25.453689 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
15:16:25.458727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:16:27.680437 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2.22 seconds
15:16:27.710479 [debug] [ThreadPool]: On list_test_db_dbt: Close
15:16:28.341662 [info ] [MainThread]: 
15:16:28.349001 [info ] [MainThread]: Running 1 on-run-start hook
15:16:28.357603 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:16:28.372750 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:16:28.404171 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:16:28.413899 [debug] [MainThread]: Using snowflake connection "master"
15:16:28.418583 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:16:28.421678 [debug] [MainThread]: Opening a new connection, currently in state init
15:16:30.882948 [debug] [MainThread]: SQL status: SUCCESS 1 in 2.46 seconds
15:16:30.885931 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 2.47s]
15:16:30.887742 [info ] [MainThread]: 
15:16:30.888869 [debug] [MainThread]: On master: Close
15:16:31.514586 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:16:31.522397 [info ] [MainThread]: 
15:16:31.530746 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:16:31.535039 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
15:16:31.540776 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:16:31.542177 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:16:31.543147 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:16:31.563038 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:16:31.567494 [debug] [Thread-1  ]: finished collecting timing info
15:16:31.568217 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:16:31.648068 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:16:31.648901 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:16:31.649741 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:35.537886 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.89 seconds
15:16:35.677437 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:16:35.695720 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:16:35.700147 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:16:36.900505 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.2 seconds
15:16:36.988761 [debug] [Thread-1  ]: finished collecting timing info
15:16:36.989894 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:16:37.593100 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ba44e0-36fb-4d19-b923-0b6a83c4a8fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb04ecb47d0>]}
15:16:37.597632 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 6.05s]
15:16:37.599762 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:16:37.683442 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:16:37.684678 [info ] [MainThread]: 
15:16:37.686459 [info ] [MainThread]: Running 3 on-run-end hooks
15:16:37.687937 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:16:37.692586 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:16:37.699469 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:16:37.704419 [debug] [MainThread]: Using snowflake connection "master"
15:16:37.705376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:16:37.705951 [debug] [MainThread]: Opening a new connection, currently in state closed
15:16:40.318002 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a27614-0403-aeb5-0000-87b50007c026
15:16:40.319459 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Database 'ANALYTICS' does not exist or not authorized.
15:16:40.320777 [info ] [MainThread]: Database error while running on-run-end
15:16:40.323102 [debug] [MainThread]: On master: Close
15:16:41.047214 [debug] [MainThread]: Connection 'master' was properly closed.
15:16:41.049288 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
15:16:41.053002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb04f25f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05586d910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05586da10>]}


============================== 2022-02-21 15:17:20.072681 | b21d946f-51e7-4b88-b445-14d2f0dade89 ==============================
15:17:20.072681 [info ] [MainThread]: Running with dbt=1.0.1
15:17:20.074544 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:17:20.075501 [debug] [MainThread]: Tracking: tracking
15:17:20.076890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b19bcb410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b19bcb3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b19bcb290>]}
15:17:20.261773 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:17:20.262983 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:17:20.287645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b21d946f-51e7-4b88-b445-14d2f0dade89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b19adff90>]}
15:17:20.324816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b21d946f-51e7-4b88-b445-14d2f0dade89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b1ac65650>]}
15:17:20.327140 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:17:20.332155 [info ] [MainThread]: 
15:17:20.336869 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:17:20.344815 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
15:17:20.406719 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
15:17:20.408521 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
15:17:20.410010 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:17:23.394893 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2.98 seconds
15:17:23.407456 [debug] [ThreadPool]: On list_test_db: Close
15:17:24.105144 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:17:24.109087 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:17:24.112614 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
15:17:24.162280 [debug] [ThreadPool]: Using snowflake connection "create_test_db_dbt"
15:17:24.164045 [debug] [ThreadPool]: On create_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_test_db_dbt"} */
create schema if not exists test_db.dbt
15:17:24.165862 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:17:26.680292 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2.51 seconds
15:17:26.688123 [debug] [ThreadPool]: On create_test_db_dbt: Close
15:17:27.477160 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
15:17:27.578298 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
15:17:27.581246 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
15:17:27.583603 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:17:29.831097 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2.25 seconds
15:17:29.849020 [debug] [ThreadPool]: On list_test_db_dbt: Close
15:17:30.478276 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:17:30.500815 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:17:30.503749 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:17:30.506578 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:17:33.098682 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27615-0403-aeb4-0000-87b50007d012
15:17:33.102177 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:17:33.105796 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:17:33.107775 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:17:33.110550 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:17:33.841949 [info ] [MainThread]: 
15:17:33.843772 [info ] [MainThread]: Running 1 on-run-start hook
15:17:33.844799 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:17:33.848191 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:17:33.855479 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:17:33.857730 [debug] [MainThread]: Using snowflake connection "master"
15:17:33.858909 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:17:33.860849 [debug] [MainThread]: Opening a new connection, currently in state init
15:17:36.407216 [debug] [MainThread]: SQL status: SUCCESS 1 in 2.55 seconds
15:17:36.410893 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 2.55s]
15:17:36.413438 [info ] [MainThread]: 
15:17:36.415112 [debug] [MainThread]: On master: Close
15:17:37.047115 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:17:37.054540 [info ] [MainThread]: 
15:17:37.066226 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:17:37.070857 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
15:17:37.080050 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:17:37.082196 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:17:37.084129 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:17:37.120602 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:17:37.127635 [debug] [Thread-1  ]: finished collecting timing info
15:17:37.129569 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:17:37.205417 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:17:37.206501 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:17:37.207506 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:17:40.604199 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.4 seconds
15:17:40.722776 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:17:40.729992 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:17:40.731201 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:17:41.777737 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
15:17:41.834804 [debug] [Thread-1  ]: finished collecting timing info
15:17:41.837689 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:17:42.463547 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b21d946f-51e7-4b88-b445-14d2f0dade89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b1811dc50>]}
15:17:42.467709 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 5.38s]
15:17:42.469846 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:17:42.571012 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:17:42.572026 [info ] [MainThread]: 
15:17:42.573093 [info ] [MainThread]: Running 3 on-run-end hooks
15:17:42.574621 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:17:42.578654 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:17:42.583621 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:17:42.585210 [debug] [MainThread]: Using snowflake connection "master"
15:17:42.586177 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:17:42.587592 [debug] [MainThread]: Opening a new connection, currently in state closed
15:17:45.352040 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a27615-0403-aebc-0000-87b50007b1f2
15:17:45.354197 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Database 'ANALYTICS' does not exist or not authorized.
15:17:45.357146 [info ] [MainThread]: Database error while running on-run-end
15:17:45.361942 [debug] [MainThread]: On master: Close
15:17:46.042594 [debug] [MainThread]: Connection 'master' was properly closed.
15:17:46.046145 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
15:17:46.049500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b1801e410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b18062310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b18062a50>]}


============================== 2022-02-21 15:30:13.149345 | 384586e7-85f2-4436-872d-72642d56dcf0 ==============================
15:30:13.149345 [info ] [MainThread]: Running with dbt=1.0.1
15:30:13.153497 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, indirect_selection='eager', log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, store_failures=False, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='test', write_json=None)
15:30:13.154748 [debug] [MainThread]: Tracking: tracking
15:30:13.156729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f782608e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f782608e090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f782608e350>]}
15:30:13.295394 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:30:13.298810 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:30:13.320745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '384586e7-85f2-4436-872d-72642d56dcf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78260aac90>]}
15:30:13.343615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '384586e7-85f2-4436-872d-72642d56dcf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78260fcc10>]}
15:30:13.344705 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:30:13.349746 [info ] [MainThread]: 
15:30:13.351130 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:30:13.354584 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:30:13.405035 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:30:13.405727 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:30:13.406405 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:30:16.224248 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27622-0403-aeb4-0000-87b50007d026
15:30:16.226630 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:30:16.229110 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:30:16.232439 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:30:16.237095 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:30:16.849222 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
15:30:16.869873 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
15:30:16.871825 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
15:30:16.874036 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:30:19.019983 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27622-0403-aebc-0000-87b50007b21a
15:30:19.023897 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:30:19.030831 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:30:19.033618 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:30:19.036577 [debug] [ThreadPool]: On list_test_db_dbt: Close
15:30:19.661923 [info ] [MainThread]: 
15:30:19.668299 [info ] [MainThread]: Running 1 on-run-start hook
15:30:19.674910 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:30:19.703472 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:30:19.731799 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:30:19.735439 [debug] [MainThread]: Using snowflake connection "master"
15:30:19.737687 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:30:19.742938 [debug] [MainThread]: Opening a new connection, currently in state init
15:30:22.161444 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a27622-0403-ab77-0000-87b5000790be
15:30:22.163943 [debug] [MainThread]: Snowflake adapter: Snowflake error: 090106 (22000): Cannot perform CREATE TABLE. This session does not have a current schema. Call 'USE SCHEMA', or use a qualified name.
15:30:22.166841 [info ] [MainThread]: Database error while running on-run-start
15:30:22.170810 [debug] [MainThread]: On master: Close
15:30:22.809068 [debug] [MainThread]: Connection 'master' was properly closed.
15:30:22.811072 [debug] [MainThread]: Connection 'list_test_db_dbt' was properly closed.
15:30:22.814553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f781f567910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f781f567450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f781f567610>]}


============================== 2022-02-21 15:31:07.465641 | c662f4a6-ceca-4437-993d-949fe67c18d5 ==============================
15:31:07.465641 [info ] [MainThread]: Running with dbt=1.0.1
15:31:07.467572 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:31:07.468680 [debug] [MainThread]: Tracking: tracking
15:31:07.469803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bf735450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bf735350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bf735090>]}
15:31:07.648245 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:31:07.649570 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:31:07.672841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30c616a4d0>]}
15:31:07.709568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bf7a4650>]}
15:31:07.711151 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:31:07.717278 [info ] [MainThread]: 
15:31:07.719104 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:31:07.722415 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
15:31:07.760148 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
15:31:07.760807 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
15:31:07.761609 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:31:10.616125 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2.85 seconds
15:31:10.624926 [debug] [ThreadPool]: On list_test_db: Close
15:31:11.300614 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:31:11.303328 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:31:11.307134 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
15:31:11.371106 [debug] [ThreadPool]: Using snowflake connection "create_test_db_dbt"
15:31:11.377526 [debug] [ThreadPool]: On create_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_test_db_dbt"} */
create schema if not exists test_db.dbt
15:31:11.383555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:31:13.601896 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2.22 seconds
15:31:13.614219 [debug] [ThreadPool]: On create_test_db_dbt: Close
15:31:14.279718 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
15:31:14.365479 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
15:31:14.366417 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
15:31:14.367256 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:31:16.843745 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2.48 seconds
15:31:16.864618 [debug] [ThreadPool]: On list_test_db_dbt: Close
15:31:17.490217 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:31:17.510843 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:31:17.512612 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:31:17.514792 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:31:19.888139 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27623-0403-aebc-0000-87b50007b222
15:31:19.889358 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:31:19.892137 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:31:19.895835 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:31:19.897640 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:31:20.534880 [info ] [MainThread]: 
15:31:20.542339 [info ] [MainThread]: Running 1 on-run-start hook
15:31:20.550076 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:31:20.568760 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:31:20.599595 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:31:20.612584 [debug] [MainThread]: Using snowflake connection "master"
15:31:20.615319 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:31:20.617526 [debug] [MainThread]: Opening a new connection, currently in state init
15:31:23.712114 [debug] [MainThread]: SQL status: SUCCESS 1 in 3.09 seconds
15:31:23.715632 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 3.11s]
15:31:23.718077 [info ] [MainThread]: 
15:31:23.719914 [debug] [MainThread]: On master: Close
15:31:24.321982 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:31:24.325214 [info ] [MainThread]: 
15:31:24.346099 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:31:24.350272 [info ] [Thread-1  ]: 1 of 9 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:31:24.360709 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:31:24.364512 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:31:24.366016 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:31:24.403772 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:31:24.417017 [debug] [Thread-1  ]: finished collecting timing info
15:31:24.421956 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:31:24.552616 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:31:24.553844 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
15:31:24.554868 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:31:27.435494 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.88 seconds
15:31:27.527333 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:31:27.534088 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:31:27.536075 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table test_db.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
15:31:29.535884 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
15:31:29.582366 [debug] [Thread-1  ]: finished collecting timing info
15:31:29.583726 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:31:30.176097 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bf70ee90>]}
15:31:30.179802 [info ] [Thread-1  ]: 1 of 9 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 5.82s]
15:31:30.183850 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:31:30.190145 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:31:30.194874 [info ] [Thread-1  ]: 2 of 9 START incremental model dbt.dates........................................ [RUN]
15:31:30.198744 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:31:30.203789 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:31:30.208515 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:31:30.258651 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:31:30.264487 [debug] [Thread-1  ]: finished collecting timing info
15:31:30.265602 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:31:30.371284 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:31:30.377655 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:31:30.378491 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table test_db.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
15:31:30.379449 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:31:34.522664 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 4.14 seconds
15:31:34.529175 [debug] [Thread-1  ]: finished collecting timing info
15:31:34.530874 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:31:35.139077 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc377410>]}
15:31:35.147462 [info ] [Thread-1  ]: 2 of 9 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.94s]
15:31:35.151640 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:31:35.154736 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:31:35.158755 [info ] [Thread-1  ]: 3 of 9 START incremental model dbt.incremental_time............................. [RUN]
15:31:35.173866 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:31:35.175982 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:31:35.178645 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:31:35.220500 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:31:35.230453 [debug] [Thread-1  ]: finished collecting timing info
15:31:35.232401 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:31:35.242677 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:31:35.244487 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:31:35.246876 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:31:38.399629 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.15 seconds
15:31:38.407972 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:31:38.425063 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:31:38.426691 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table test_db.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
15:31:40.369465 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.94 seconds
15:31:40.376627 [debug] [Thread-1  ]: finished collecting timing info
15:31:40.377704 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:31:40.966851 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc36bbd0>]}
15:31:40.969626 [info ] [Thread-1  ]: 3 of 9 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.80s]
15:31:40.973586 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:31:40.977329 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:31:40.983284 [info ] [Thread-1  ]: 4 of 9 START table model dbt.first_model........................................ [RUN]
15:31:40.996634 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:31:41.007835 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:31:41.015888 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:31:41.054433 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:31:41.064850 [debug] [Thread-1  ]: finished collecting timing info
15:31:41.067862 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:31:41.085420 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:31:41.086585 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:31:41.087615 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:31:44.075176 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.99 seconds
15:31:44.093069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:31:44.122043 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:31:44.127608 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:31:45.396424 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.26 seconds
15:31:45.400910 [debug] [Thread-1  ]: finished collecting timing info
15:31:45.401879 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:31:46.016872 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc3156d0>]}
15:31:46.020550 [info ] [Thread-1  ]: 4 of 9 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 5.02s]
15:31:46.022151 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:31:46.023751 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
15:31:46.026226 [info ] [Thread-1  ]: 5 of 9 START table model dbt.customer_model..................................... [RUN]
15:31:46.028219 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
15:31:46.029248 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
15:31:46.030477 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
15:31:46.049628 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
15:31:46.057072 [debug] [Thread-1  ]: finished collecting timing info
15:31:46.060608 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
15:31:46.073053 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
15:31:46.076121 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
15:31:46.079171 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:31:49.107080 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.03 seconds
15:31:49.120725 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
15:31:49.136171 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
15:31:49.140934 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table test_db.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
15:31:52.988479 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.84 seconds
15:31:53.014108 [debug] [Thread-1  ]: finished collecting timing info
15:31:53.022128 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
15:31:53.737970 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc33f210>]}
15:31:53.751866 [info ] [Thread-1  ]: 5 of 9 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 7.71s]
15:31:53.758897 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
15:31:53.765118 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
15:31:53.776119 [info ] [Thread-1  ]: 6 of 9 START table model dbt.rename_segments_macro_test......................... [RUN]
15:31:53.785684 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:31:53.792282 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
15:31:53.794924 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
15:31:53.816106 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
15:31:53.821977 [debug] [Thread-1  ]: finished collecting timing info
15:31:53.823851 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
15:31:53.835033 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:31:53.835571 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
15:31:53.836122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:31:56.858588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.02 seconds
15:31:56.867344 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
15:31:56.881886 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:31:56.883934 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table test_db.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
15:31:58.498061 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.61 seconds
15:31:58.503990 [debug] [Thread-1  ]: finished collecting timing info
15:31:58.505088 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
15:31:59.124594 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bcc81a50>]}
15:31:59.126205 [info ] [Thread-1  ]: 6 of 9 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 5.34s]
15:31:59.128027 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
15:31:59.129414 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:31:59.131787 [info ] [Thread-1  ]: 7 of 9 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:31:59.134311 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:31:59.135559 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:31:59.137197 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:31:59.149508 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:31:59.154554 [debug] [Thread-1  ]: finished collecting timing info
15:31:59.155753 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:31:59.166868 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:31:59.167716 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:31:59.168415 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:32:02.020048 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.85 seconds
15:32:02.035841 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:32:02.064085 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:32:02.066909 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table test_db.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:32:03.860614 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
15:32:03.869370 [debug] [Thread-1  ]: finished collecting timing info
15:32:03.870948 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:32:04.474532 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc328110>]}
15:32:04.476705 [info ] [Thread-1  ]: 7 of 9 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 5.34s]
15:32:04.478659 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:32:04.480044 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
15:32:04.482039 [info ] [Thread-1  ]: 8 of 9 START table model dbt.sources_customer_orders............................ [RUN]
15:32:04.484247 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
15:32:04.485345 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
15:32:04.486669 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
15:32:04.528900 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
15:32:04.537596 [debug] [Thread-1  ]: finished collecting timing info
15:32:04.540237 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
15:32:04.553959 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
15:32:04.557709 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
15:32:04.559220 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:32:07.750629 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.19 seconds
15:32:07.764229 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
15:32:07.791523 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
15:32:07.795611 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table test_db.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
15:32:09.604475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
15:32:09.608475 [debug] [Thread-1  ]: finished collecting timing info
15:32:09.609434 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
15:32:10.232196 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bcc71b10>]}
15:32:10.234516 [info ] [Thread-1  ]: 8 of 9 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 5.75s]
15:32:10.238209 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
15:32:10.240995 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:32:10.247314 [info ] [Thread-1  ]: 9 of 9 START table model dbt.my_second_dbt_model................................ [RUN]
15:32:10.251952 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:32:10.254113 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:32:10.255851 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:32:10.277851 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:32:10.293507 [debug] [Thread-1  ]: finished collecting timing info
15:32:10.295730 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:32:10.311893 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:32:10.313352 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:32:10.314551 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:32:13.402908 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.09 seconds
15:32:13.419556 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:32:13.439858 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:32:13.442280 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table test_db.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from test_db.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
15:32:14.809865 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
15:32:14.818451 [debug] [Thread-1  ]: finished collecting timing info
15:32:14.819904 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:32:15.443769 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c662f4a6-ceca-4437-993d-949fe67c18d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bcba1c10>]}
15:32:15.444749 [info ] [Thread-1  ]: 9 of 9 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 5.19s]
15:32:15.446179 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:32:15.469464 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:32:15.471787 [info ] [MainThread]: 
15:32:15.475587 [info ] [MainThread]: Running 3 on-run-end hooks
15:32:15.476810 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-end-0
15:32:15.479852 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-end-0"
15:32:15.484057 [info ] [MainThread]: 1 of 3 START hook: dbt_tests.on-run-end.0....................................... [RUN]
15:32:15.485733 [debug] [MainThread]: Using snowflake connection "master"
15:32:15.486213 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:32:15.486983 [debug] [MainThread]: Opening a new connection, currently in state closed
15:32:17.767407 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a27624-0403-aeb5-0000-87b50007c076
15:32:17.768792 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Database 'ANALYTICS' does not exist or not authorized.
15:32:17.770087 [info ] [MainThread]: Database error while running on-run-end
15:32:17.771603 [debug] [MainThread]: On master: Close
15:32:18.380578 [debug] [MainThread]: Connection 'master' was properly closed.
15:32:18.382466 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:32:18.386063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bf645510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc328950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30bc328790>]}


============================== 2022-02-21 15:34:08.572966 | 6b1b29dc-8503-4cce-8e0b-e9abf24fd79f ==============================
15:34:08.572966 [info ] [MainThread]: Running with dbt=1.0.1
15:34:08.574885 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=None, selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:34:08.576091 [debug] [MainThread]: Tracking: tracking
15:34:08.577502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2405e11310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f240bde5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2405e11290>]}
15:34:08.647479 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
15:34:08.648891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2404d8ef50>]}
15:34:08.731022 [debug] [MainThread]: Parsing macros/group_by.sql
15:34:08.735107 [debug] [MainThread]: Parsing macros/renaming_segments.sql
15:34:08.737432 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
15:34:08.742788 [debug] [MainThread]: Parsing macros/adapters.sql
15:34:08.857123 [debug] [MainThread]: Parsing macros/catalog.sql
15:34:08.861199 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:34:08.886936 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:34:08.902678 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:34:08.921862 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:34:08.925116 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:34:08.934367 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:34:08.940555 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:34:08.987095 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:34:09.000799 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:34:09.012194 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:34:09.031795 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:34:09.048363 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:34:09.075597 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:34:09.083756 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:34:09.109586 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:34:09.125885 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:34:09.128944 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:34:09.130860 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:34:09.133781 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:34:09.136161 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:34:09.141689 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:34:09.149513 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:34:09.157590 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:34:09.169215 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:34:09.177783 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:34:09.191063 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:34:09.218078 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:34:09.222428 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:34:09.258553 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:34:09.312960 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:34:09.325423 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:34:09.348014 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:34:09.356965 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:34:09.362211 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:34:09.365185 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:34:09.383540 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:34:09.423058 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:34:09.441613 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:34:09.469275 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:34:09.497338 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:34:09.503444 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:34:09.554392 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:34:09.566682 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:34:09.585999 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:34:09.594345 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:34:10.260831 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
15:34:10.303483 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
15:34:10.307539 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:34:10.333499 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:34:10.336971 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:34:10.347130 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:34:10.354484 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:34:10.365118 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:34:10.379953 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
15:34:10.394040 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
15:34:10.399486 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:34:10.408084 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
15:34:10.428702 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
15:34:10.432019 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:34:10.443304 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:34:10.949759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2405e88350>]}
15:34:10.976888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2405e8a5d0>]}
15:34:10.980126 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:34:10.983676 [info ] [MainThread]: 
15:34:10.985163 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:34:10.996036 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
15:34:11.042981 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
15:34:11.044235 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
15:34:11.045488 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:34:13.934220 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2.89 seconds
15:34:13.948231 [debug] [ThreadPool]: On list_test_db: Close
15:34:14.631711 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:34:14.637476 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
15:34:14.642015 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
15:34:14.693426 [debug] [ThreadPool]: Using snowflake connection "create_test_db_dbt"
15:34:14.694805 [debug] [ThreadPool]: On create_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_test_db_dbt"} */
create schema if not exists test_db.dbt
15:34:14.696088 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:34:17.277705 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2.58 seconds
15:34:17.285995 [debug] [ThreadPool]: On create_test_db_dbt: Close
15:34:17.945836 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
15:34:18.050295 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
15:34:18.051401 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
15:34:18.052479 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:34:20.363727 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2.31 seconds
15:34:20.380493 [debug] [ThreadPool]: On list_test_db_dbt: Close
15:34:21.015664 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:34:21.045977 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:34:21.047038 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:34:21.047949 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:34:23.393260 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a27626-0403-aeb7-0000-87b50007a1ea
15:34:23.398046 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
15:34:23.401731 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
15:34:23.403566 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
15:34:23.405984 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:34:24.052701 [info ] [MainThread]: 
15:34:24.057103 [info ] [MainThread]: Running 1 on-run-start hook
15:34:24.067782 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:34:24.083523 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:34:24.118106 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:34:24.124708 [debug] [MainThread]: Using snowflake connection "master"
15:34:24.128434 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:34:24.129768 [debug] [MainThread]: Opening a new connection, currently in state init
15:34:26.865659 [debug] [MainThread]: SQL status: SUCCESS 1 in 2.74 seconds
15:34:26.879417 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 2.76s]
15:34:26.884817 [info ] [MainThread]: 
15:34:26.888956 [debug] [MainThread]: On master: Close
15:34:27.516540 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:34:27.524815 [info ] [MainThread]: 
15:34:27.571999 [debug] [Thread-1  ]: Began running node model.dbt_tests.cumulative_orders_by_date
15:34:27.582285 [info ] [Thread-1  ]: 1 of 9 START table model dbt.cumulative_orders_by_date.......................... [RUN]
15:34:27.596217 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:34:27.599589 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.cumulative_orders_by_date
15:34:27.601710 [debug] [Thread-1  ]: Compiling model.dbt_tests.cumulative_orders_by_date
15:34:27.627686 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:34:27.631653 [debug] [Thread-1  ]: finished collecting timing info
15:34:27.632768 [debug] [Thread-1  ]: Began executing node model.dbt_tests.cumulative_orders_by_date
15:34:27.675423 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:34:27.676423 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */

        insert into dbt.audit (model, state, time) values ('cumulative_orders_by_date', 'starting model deployment', current_timestamp)
15:34:27.677170 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:34:30.612011 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.93 seconds
15:34:30.698806 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.cumulative_orders_by_date"
15:34:30.709795 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.cumulative_orders_by_date"
15:34:30.710932 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.cumulative_orders_by_date"} */


      create or replace transient table test_db.dbt.cumulative_orders_by_date  as
      (

-- select order_date
--       ,total_price
--       ,sum(total_price) over (order by order_date rows between unbounded preceding and current row) as cumulative_sales
-- from (select o_orderdate as order_date
--             ,sum(o_totalprice) as total_price
--       from snowflake_sample_data.tpch_sf1.orders
--       group by 1
--       )
-- order by 1

with orders as (
      SELECT * FROM snowflake_sample_data.tpch_sf1.orders
)

SELECT DISTINCT o_orderdate,
      SUM(o_totalprice) OVER (ORDER BY o_orderdate) AS cumulative_sales 
FROM orders


where year(o_orderdate) = 1996


ORDER BY o_orderdate
      );
15:34:32.165118 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
15:34:32.199237 [debug] [Thread-1  ]: finished collecting timing info
15:34:32.200414 [debug] [Thread-1  ]: On model.dbt_tests.cumulative_orders_by_date: Close
15:34:32.807102 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2405e8a4d0>]}
15:34:32.812616 [info ] [Thread-1  ]: 1 of 9 OK created table model dbt.cumulative_orders_by_date..................... [[32mSUCCESS 1[0m in 5.21s]
15:34:32.814596 [debug] [Thread-1  ]: Finished running node model.dbt_tests.cumulative_orders_by_date
15:34:32.815950 [debug] [Thread-1  ]: Began running node model.dbt_tests.dates
15:34:32.818199 [info ] [Thread-1  ]: 2 of 9 START incremental model dbt.dates........................................ [RUN]
15:34:32.820548 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.dates"
15:34:32.821540 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.dates
15:34:32.822728 [debug] [Thread-1  ]: Compiling model.dbt_tests.dates
15:34:32.837428 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.dates"
15:34:32.840901 [debug] [Thread-1  ]: finished collecting timing info
15:34:32.841696 [debug] [Thread-1  ]: Began executing node model.dbt_tests.dates
15:34:32.964866 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.dates"
15:34:32.969103 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.dates"
15:34:32.970448 [debug] [Thread-1  ]: On model.dbt_tests.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.dates"} */


      create or replace transient table test_db.dbt.dates  as
      (


SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."DATE_DIM"
WHERE d_date <= CURRENT_DATE



      );
15:34:32.971538 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:34:36.649133 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.68 seconds
15:34:36.661640 [debug] [Thread-1  ]: finished collecting timing info
15:34:36.665076 [debug] [Thread-1  ]: On model.dbt_tests.dates: Close
15:34:37.278424 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f6e475d0>]}
15:34:37.281796 [info ] [Thread-1  ]: 2 of 9 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.46s]
15:34:37.285767 [debug] [Thread-1  ]: Finished running node model.dbt_tests.dates
15:34:37.289171 [debug] [Thread-1  ]: Began running node model.dbt_tests.incremental_time
15:34:37.296617 [info ] [Thread-1  ]: 3 of 9 START incremental model dbt.incremental_time............................. [RUN]
15:34:37.300581 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.incremental_time"
15:34:37.304754 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.incremental_time
15:34:37.307817 [debug] [Thread-1  ]: Compiling model.dbt_tests.incremental_time
15:34:37.342898 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.incremental_time"
15:34:37.355823 [debug] [Thread-1  ]: finished collecting timing info
15:34:37.357898 [debug] [Thread-1  ]: Began executing node model.dbt_tests.incremental_time
15:34:37.372646 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:34:37.374002 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:34:37.375036 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:34:40.240213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.87 seconds
15:34:40.254931 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.incremental_time"
15:34:40.271949 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.incremental_time"
15:34:40.273962 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.incremental_time"} */


      create or replace transient table test_db.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
15:34:41.693510 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
15:34:41.711819 [debug] [Thread-1  ]: finished collecting timing info
15:34:41.714585 [debug] [Thread-1  ]: On model.dbt_tests.incremental_time: Close
15:34:42.660968 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f5626810>]}
15:34:42.664654 [info ] [Thread-1  ]: 3 of 9 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.36s]
15:34:42.667201 [debug] [Thread-1  ]: Finished running node model.dbt_tests.incremental_time
15:34:42.668551 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:34:42.670826 [info ] [Thread-1  ]: 4 of 9 START table model dbt.first_model........................................ [RUN]
15:34:42.672803 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:34:42.673829 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:34:42.675127 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:34:42.691879 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:34:42.696356 [debug] [Thread-1  ]: finished collecting timing info
15:34:42.697227 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:34:42.706084 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:34:42.707476 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:34:42.708275 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:34:45.675053 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.97 seconds
15:34:45.692880 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:34:45.716094 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:34:45.718282 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:34:46.827465 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.11 seconds
15:34:46.872114 [debug] [Thread-1  ]: finished collecting timing info
15:34:46.876950 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:34:47.509310 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f6e62b50>]}
15:34:47.510410 [info ] [Thread-1  ]: 4 of 9 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 4.84s]
15:34:47.511768 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:34:47.513086 [debug] [Thread-1  ]: Began running node model.dbt_tests.playing_with_tests
15:34:47.516967 [info ] [Thread-1  ]: 5 of 9 START table model dbt.customer_model..................................... [RUN]
15:34:47.518903 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.playing_with_tests"
15:34:47.519817 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.playing_with_tests
15:34:47.520775 [debug] [Thread-1  ]: Compiling model.dbt_tests.playing_with_tests
15:34:47.526657 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.playing_with_tests"
15:34:47.530495 [debug] [Thread-1  ]: finished collecting timing info
15:34:47.531373 [debug] [Thread-1  ]: Began executing node model.dbt_tests.playing_with_tests
15:34:47.543640 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
15:34:47.544827 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('customer_model', 'starting model deployment', current_timestamp)
15:34:47.545518 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:34:50.463482 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.92 seconds
15:34:50.476188 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.playing_with_tests"
15:34:50.498612 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.playing_with_tests"
15:34:50.500749 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.playing_with_tests"} */


      create or replace transient table test_db.dbt.customer_model  as
      (

with customer_data as (

    select c_custkey, c_mktsegment, c_acctbal
    from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."CUSTOMER"

)

select *
from customer_data
      );
15:34:54.026472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.52 seconds
15:34:54.047673 [debug] [Thread-1  ]: finished collecting timing info
15:34:54.051820 [debug] [Thread-1  ]: On model.dbt_tests.playing_with_tests: Close
15:34:54.719129 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f556a290>]}
15:34:54.724085 [info ] [Thread-1  ]: 5 of 9 OK created table model dbt.customer_model................................ [[32mSUCCESS 1[0m in 7.20s]
15:34:54.731791 [debug] [Thread-1  ]: Finished running node model.dbt_tests.playing_with_tests
15:34:54.732813 [debug] [Thread-1  ]: Began running node model.dbt_tests.rename_segments_macro_test
15:34:54.734694 [info ] [Thread-1  ]: 6 of 9 START table model dbt.rename_segments_macro_test......................... [RUN]
15:34:54.737754 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:34:54.739538 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.rename_segments_macro_test
15:34:54.741051 [debug] [Thread-1  ]: Compiling model.dbt_tests.rename_segments_macro_test
15:34:54.757542 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.rename_segments_macro_test"
15:34:54.768867 [debug] [Thread-1  ]: finished collecting timing info
15:34:54.770949 [debug] [Thread-1  ]: Began executing node model.dbt_tests.rename_segments_macro_test
15:34:54.782709 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:34:54.788807 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */

        insert into dbt.audit (model, state, time) values ('rename_segments_macro_test', 'starting model deployment', current_timestamp)
15:34:54.789962 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:34:57.781677 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.99 seconds
15:34:57.798269 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.rename_segments_macro_test"
15:34:57.819857 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.rename_segments_macro_test"
15:34:57.822512 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.rename_segments_macro_test"} */


      create or replace transient table test_db.dbt.rename_segments_macro_test  as
      (-- Styling with common table expression
with sample_customer as (
    SELECT * FROM snowflake_sample_data.tpch_sf1.customer
)

SELECT 
    c_custkey,
    c_mktsegment,
    
    CASE
        WHEN c_mktsegment in ('BULIDING', 'HOUSEHOLD', 'FURNITURE')
            THEN 'segments_1'
        ELSE 'segment_2'
    END 
 mkt_segment_adjusted
FROM sample_customer
      );
15:34:59.350378 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
15:34:59.353664 [debug] [Thread-1  ]: finished collecting timing info
15:34:59.354435 [debug] [Thread-1  ]: On model.dbt_tests.rename_segments_macro_test: Close
15:34:59.933757 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f556ad50>]}
15:34:59.935611 [info ] [Thread-1  ]: 6 of 9 OK created table model dbt.rename_segments_macro_test.................... [[32mSUCCESS 1[0m in 5.20s]
15:34:59.937361 [debug] [Thread-1  ]: Finished running node model.dbt_tests.rename_segments_macro_test
15:34:59.938436 [debug] [Thread-1  ]: Began running node model.dbt_tests.snowflake_customer_purchases
15:34:59.940096 [info ] [Thread-1  ]: 7 of 9 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:34:59.942010 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:34:59.943023 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.snowflake_customer_purchases
15:34:59.943704 [debug] [Thread-1  ]: Compiling model.dbt_tests.snowflake_customer_purchases
15:34:59.956660 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:34:59.960128 [debug] [Thread-1  ]: finished collecting timing info
15:34:59.961085 [debug] [Thread-1  ]: Began executing node model.dbt_tests.snowflake_customer_purchases
15:34:59.968683 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:34:59.970458 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:34:59.971582 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:03.101744 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.13 seconds
15:35:03.105689 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.snowflake_customer_purchases"
15:35:03.111218 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.snowflake_customer_purchases"
15:35:03.112592 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.snowflake_customer_purchases"} */


      create or replace transient table test_db.dbt.snowflake_customer_purchases  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" C
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" O
ON C.C_CUSTKEY = O.O_CUSTKEY
GROUP BY
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY
      );
15:35:04.609445 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
15:35:04.614006 [debug] [Thread-1  ]: finished collecting timing info
15:35:04.615063 [debug] [Thread-1  ]: On model.dbt_tests.snowflake_customer_purchases: Close
15:35:05.210029 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f5626390>]}
15:35:05.211309 [info ] [Thread-1  ]: 7 of 9 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 5.27s]
15:35:05.212315 [debug] [Thread-1  ]: Finished running node model.dbt_tests.snowflake_customer_purchases
15:35:05.212880 [debug] [Thread-1  ]: Began running node model.dbt_tests.sources_customer_orders
15:35:05.214058 [info ] [Thread-1  ]: 8 of 9 START table model dbt.sources_customer_orders............................ [RUN]
15:35:05.215926 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.sources_customer_orders"
15:35:05.216382 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.sources_customer_orders
15:35:05.217192 [debug] [Thread-1  ]: Compiling model.dbt_tests.sources_customer_orders
15:35:05.233407 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.sources_customer_orders"
15:35:05.237272 [debug] [Thread-1  ]: finished collecting timing info
15:35:05.238112 [debug] [Thread-1  ]: Began executing node model.dbt_tests.sources_customer_orders
15:35:05.250486 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
15:35:05.251454 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */

        insert into dbt.audit (model, state, time) values ('sources_customer_orders', 'starting model deployment', current_timestamp)
15:35:05.252071 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:08.292974 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.04 seconds
15:35:08.299914 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.sources_customer_orders"
15:35:08.319613 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.sources_customer_orders"
15:35:08.322129 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.sources_customer_orders"} */


      create or replace transient table test_db.dbt.sources_customer_orders  as
      (

SELECT 
    C.C_CUSTKEY,
    C.C_NAME,
    C.C_NATIONKEY AS NATION,
    SUM(O.O_TOTALPRICE) AS TOTAL_ORDER_PRICE 
FROM snowflake_sample_data.tpch_sf1.customer C
LEFT JOIN snowflake_sample_data.tpch_sf1.orders O
ON C.C_CUSTKEY = O.O_CUSTKEY

  GROUP BY
   
     1
      , 
   
     2
      , 
   
     3
     
   

-- GROUP BY
--     C.C_CUSTKEY,
--     C.C_NAME,
--     C.C_NATIONKEY
      );
15:35:10.258021 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.93 seconds
15:35:10.265376 [debug] [Thread-1  ]: finished collecting timing info
15:35:10.266324 [debug] [Thread-1  ]: On model.dbt_tests.sources_customer_orders: Close
15:35:10.978056 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f55804d0>]}
15:35:10.981743 [info ] [Thread-1  ]: 8 of 9 OK created table model dbt.sources_customer_orders....................... [[32mSUCCESS 1[0m in 5.76s]
15:35:10.984190 [debug] [Thread-1  ]: Finished running node model.dbt_tests.sources_customer_orders
15:35:10.986886 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_second_dbt_model
15:35:10.990743 [info ] [Thread-1  ]: 9 of 9 START table model dbt.my_second_dbt_model................................ [RUN]
15:35:10.995900 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_second_dbt_model"
15:35:11.008788 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_second_dbt_model
15:35:11.015241 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_second_dbt_model
15:35:11.048667 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_second_dbt_model"
15:35:11.058617 [debug] [Thread-1  ]: finished collecting timing info
15:35:11.059618 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_second_dbt_model
15:35:11.067793 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:35:11.068927 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:35:11.070109 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:14.116781 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.05 seconds
15:35:14.136215 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_second_dbt_model"
15:35:14.164315 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_second_dbt_model"
15:35:14.170488 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_second_dbt_model"} */


      create or replace transient table test_db.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from test_db.dbt.first_model
-- where id = 1
-- union all
-- select 7 as id
      );
15:35:15.335594 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.16 seconds
15:35:15.355673 [debug] [Thread-1  ]: finished collecting timing info
15:35:15.357609 [debug] [Thread-1  ]: On model.dbt_tests.my_second_dbt_model: Close
15:35:16.374531 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b1b29dc-8503-4cce-8e0b-e9abf24fd79f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f55874d0>]}
15:35:16.376402 [info ] [Thread-1  ]: 9 of 9 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 5.38s]
15:35:16.378201 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_second_dbt_model
15:35:16.436340 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:35:16.438356 [info ] [MainThread]: 
15:35:16.440790 [info ] [MainThread]: Finished running 7 table models, 2 incremental models, 1 hook in 65.45s.
15:35:16.443507 [debug] [MainThread]: Connection 'master' was properly closed.
15:35:16.445346 [debug] [MainThread]: Connection 'model.dbt_tests.my_second_dbt_model' was properly closed.
15:35:16.481150 [info ] [MainThread]: 
15:35:16.482287 [info ] [MainThread]: [32mCompleted successfully[0m
15:35:16.483932 [info ] [MainThread]: 
15:35:16.485144 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
15:35:16.486672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2405e83cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f6e2b250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f6e2bad0>]}


============================== 2022-02-24 15:40:59.012390 | 7c7e74eb-6fc3-472c-9a61-89b88b6ded9b ==============================
15:40:59.012390 [info ] [MainThread]: Running with dbt=1.0.1
15:40:59.013420 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
15:40:59.014037 [debug] [MainThread]: Tracking: tracking
15:40:59.014704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa887920650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa887920450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa887920490>]}
15:40:59.049534 [info ] [MainThread]: Unable to do partial parsing because profile has changed
15:40:59.050439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7c7e74eb-6fc3-472c-9a61-89b88b6ded9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8878a0f10>]}
15:40:59.144781 [debug] [MainThread]: Parsing macros/group_by.sql
15:40:59.147466 [debug] [MainThread]: Parsing macros/renaming_segments.sql
15:40:59.149197 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
15:40:59.151399 [debug] [MainThread]: Parsing macros/adapters.sql
15:40:59.212639 [debug] [MainThread]: Parsing macros/catalog.sql
15:40:59.217933 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:40:59.232834 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:40:59.239535 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:40:59.248729 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:40:59.250980 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:40:59.256178 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:40:59.259054 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:40:59.274550 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:40:59.279511 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:40:59.284514 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:40:59.295755 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:40:59.303602 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:40:59.325078 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:40:59.329342 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:40:59.342712 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:40:59.350632 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:40:59.353409 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:40:59.355162 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:40:59.357100 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:40:59.358692 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:40:59.361684 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:40:59.365014 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:40:59.369298 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:40:59.373557 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:40:59.380385 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:40:59.387924 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:40:59.404706 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:40:59.407799 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:40:59.427843 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:40:59.451366 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:40:59.458942 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:40:59.470611 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:40:59.475434 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:40:59.479698 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:40:59.482421 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:40:59.493219 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:40:59.525487 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:40:59.536367 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:40:59.559410 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:40:59.582153 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:40:59.585411 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:40:59.611562 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:40:59.615348 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:40:59.623201 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:40:59.626808 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:40:59.948751 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
15:40:59.970653 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
15:40:59.973198 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:40:59.985302 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:40:59.989055 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:40:59.996511 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:40:59.999602 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:41:00.006381 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:41:00.012954 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
15:41:00.021144 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
15:41:00.023655 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:41:00.031295 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
15:41:00.042507 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
15:41:00.044532 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:41:00.050304 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:41:00.320614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7c7e74eb-6fc3-472c-9a61-89b88b6ded9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8879a2790>]}
15:41:00.340466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7c7e74eb-6fc3-472c-9a61-89b88b6ded9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa88799be50>]}
15:41:00.341267 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:41:00.343714 [info ] [MainThread]: 
15:41:00.345115 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:41:00.346986 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:41:00.367779 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:41:00.368614 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:41:00.369320 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:41:01.675727 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.31 seconds
15:41:01.680665 [debug] [ThreadPool]: On list_analytics: Close
15:41:01.809491 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
15:41:01.810223 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
15:41:01.810957 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
15:41:01.819023 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
15:41:01.819535 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
15:41:01.819977 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:41:02.565608 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.75 seconds
15:41:02.568163 [debug] [ThreadPool]: On create_analytics_dbt: Close
15:41:02.690401 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:41:02.703559 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:41:02.704462 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:41:02.705382 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:41:03.259723 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.55 seconds
15:41:03.267995 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:41:03.418865 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
15:41:03.424536 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
15:41:03.429772 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
15:41:03.430879 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:41:03.967067 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.54 seconds
15:41:03.974502 [debug] [ThreadPool]: On list_analytics_snapshots: Close
15:41:04.107841 [info ] [MainThread]: 
15:41:04.110369 [info ] [MainThread]: Running 1 on-run-start hook
15:41:04.112397 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
15:41:04.116153 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
15:41:04.123587 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
15:41:04.125186 [debug] [MainThread]: Using snowflake connection "master"
15:41:04.125714 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:41:04.126480 [debug] [MainThread]: Opening a new connection, currently in state init
15:41:04.774982 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
15:41:04.779192 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.65s]
15:41:04.781380 [info ] [MainThread]: 
15:41:04.784232 [debug] [MainThread]: On master: Close
15:41:04.927398 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:41:04.928621 [info ] [MainThread]: 
15:41:04.941318 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
15:41:04.942343 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
15:41:04.943717 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
15:41:04.944266 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
15:41:04.945070 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
15:41:04.950777 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
15:41:04.955268 [debug] [Thread-1  ]: finished collecting timing info
15:41:04.955955 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
15:41:04.982091 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:41:04.982975 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:41:04.983458 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:41:08.065379 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.08 seconds
15:41:08.094171 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
15:41:08.099914 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
15:41:08.100593 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
15:41:08.749689 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
15:41:08.779787 [debug] [Thread-1  ]: finished collecting timing info
15:41:08.780479 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
15:41:08.903589 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c7e74eb-6fc3-472c-9a61-89b88b6ded9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa884dce150>]}
15:41:08.905102 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.96s]
15:41:08.906456 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
15:41:09.008596 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:41:09.014450 [info ] [MainThread]: 
15:41:09.017458 [info ] [MainThread]: Finished running 1 table model, 1 hook in 8.67s.
15:41:09.019298 [debug] [MainThread]: Connection 'master' was properly closed.
15:41:09.020682 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
15:41:09.037138 [info ] [MainThread]: 
15:41:09.038149 [info ] [MainThread]: [32mCompleted successfully[0m
15:41:09.039301 [info ] [MainThread]: 
15:41:09.040262 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:41:09.041395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa884897c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8879a20d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa887924d10>]}


============================== 2022-02-24 16:19:17.377139 | 3dd2f2b5-53fb-4b82-a7a9-02fd82421d55 ==============================
16:19:17.377139 [info ] [MainThread]: Running with dbt=1.0.1
16:19:17.378361 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
16:19:17.378921 [debug] [MainThread]: Tracking: tracking
16:19:17.379746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e18c550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e18c750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e18c690>]}
16:19:17.479454 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:19:17.480261 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:19:17.494962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3dd2f2b5-53fb-4b82-a7a9-02fd82421d55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e09b710>]}
16:19:17.512382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3dd2f2b5-53fb-4b82-a7a9-02fd82421d55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e13fd10>]}
16:19:17.513607 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:19:17.516560 [info ] [MainThread]: 
16:19:17.518038 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:19:17.519588 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:19:17.539461 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:19:17.540185 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:19:17.540821 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:19:18.365930 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
16:19:18.369280 [debug] [ThreadPool]: On list_analytics: Close
16:19:18.494946 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
16:19:18.496074 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
16:19:18.497120 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
16:19:18.505668 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
16:19:18.506350 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
16:19:18.506862 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:19:19.241317 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.73 seconds
16:19:19.243127 [debug] [ThreadPool]: On create_analytics_dbt: Close
16:19:19.420897 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
16:19:19.434118 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
16:19:19.434810 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
16:19:19.435453 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:19:20.268720 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.83 seconds
16:19:20.272889 [debug] [ThreadPool]: On list_analytics_snapshots: Close
16:19:20.460171 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:19:20.470287 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:19:20.471683 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:19:20.473039 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:19:21.048980 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.58 seconds
16:19:21.054637 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:19:21.190304 [info ] [MainThread]: 
16:19:21.193234 [info ] [MainThread]: Running 1 on-run-start hook
16:19:21.196203 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
16:19:21.203446 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
16:19:21.216215 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
16:19:21.218819 [debug] [MainThread]: Using snowflake connection "master"
16:19:21.219836 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:19:21.221117 [debug] [MainThread]: Opening a new connection, currently in state init
16:19:21.961253 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.74 seconds
16:19:21.966620 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.75s]
16:19:21.970368 [info ] [MainThread]: 
16:19:21.972913 [debug] [MainThread]: On master: Close
16:19:22.148259 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:19:22.152133 [info ] [MainThread]: 
16:19:22.161320 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
16:19:22.162908 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
16:19:22.165096 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
16:19:22.166098 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
16:19:22.167053 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
16:19:22.174495 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
16:19:22.178519 [debug] [Thread-1  ]: finished collecting timing info
16:19:22.179195 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
16:19:22.206410 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:19:22.206990 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
16:19:22.207449 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:19:23.422704 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
16:19:23.446277 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
16:19:23.450457 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
16:19:23.450959 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
16:19:25.290688 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
16:19:25.324183 [debug] [Thread-1  ]: finished collecting timing info
16:19:25.325387 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
16:19:25.451807 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3dd2f2b5-53fb-4b82-a7a9-02fd82421d55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e0a9650>]}
16:19:25.453055 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.29s]
16:19:25.454234 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
16:19:25.512206 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:19:25.514343 [info ] [MainThread]: 
16:19:25.515941 [info ] [MainThread]: Finished running 1 table model, 1 hook in 8.00s.
16:19:25.517474 [debug] [MainThread]: Connection 'master' was properly closed.
16:19:25.518396 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
16:19:25.532552 [info ] [MainThread]: 
16:19:25.533726 [info ] [MainThread]: [32mCompleted successfully[0m
16:19:25.534970 [info ] [MainThread]: 
16:19:25.536024 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
16:19:25.537175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7e1cda10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7cbffd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e7cbffe10>]}


============================== 2022-02-28 10:21:06.921487 | 96b3975c-07ad-44b4-90db-f289c5c00755 ==============================
10:21:06.921487 [info ] [MainThread]: Running with dbt=1.0.1
10:21:06.927208 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt/', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
10:21:06.928327 [debug] [MainThread]: Tracking: tracking
10:21:06.929596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94d4c750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94d4c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94d4c850>]}
10:21:07.108181 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:21:07.109286 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:21:07.131107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96b3975c-07ad-44b4-90db-f289c5c00755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94c640d0>]}
10:21:07.160305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96b3975c-07ad-44b4-90db-f289c5c00755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94dbc690>]}
10:21:07.161953 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
10:21:07.167434 [info ] [MainThread]: 
10:21:07.169926 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:21:07.172701 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:21:07.214682 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:21:07.215845 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:21:07.217046 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:21:19.120942 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 11.9 seconds
10:21:19.127075 [debug] [ThreadPool]: On list_analytics: Close
10:21:19.242994 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
10:21:19.244653 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
10:21:19.246226 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
10:21:19.263502 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
10:21:19.264908 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
10:21:19.265949 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:21:25.361841 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 6.1 seconds
10:21:25.370318 [debug] [ThreadPool]: On create_analytics_dbt: Close
10:21:25.534033 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
10:21:25.569284 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
10:21:25.570611 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
10:21:25.572048 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:21:31.697604 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 6.13 seconds
10:21:31.702155 [debug] [ThreadPool]: On list_analytics_snapshots: Close
10:21:31.863383 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:21:31.882857 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:21:31.884228 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:21:31.885788 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:21:37.756297 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 5.87 seconds
10:21:37.766596 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:21:37.902500 [info ] [MainThread]: 
10:21:37.906224 [info ] [MainThread]: Running 1 on-run-start hook
10:21:37.910241 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
10:21:37.919591 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
10:21:37.931323 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
10:21:37.933860 [debug] [MainThread]: Using snowflake connection "master"
10:21:37.934829 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
10:21:37.936043 [debug] [MainThread]: Opening a new connection, currently in state init
10:21:44.185066 [debug] [MainThread]: SQL status: SUCCESS 1 in 6.25 seconds
10:21:44.191549 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 6.26s]
10:21:44.195313 [info ] [MainThread]: 
10:21:44.198456 [debug] [MainThread]: On master: Close
10:21:44.352327 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:21:44.355516 [info ] [MainThread]: 
10:21:44.365607 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
10:21:44.367976 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
10:21:44.370731 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
10:21:44.371888 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
10:21:44.373076 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
10:21:44.386540 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
10:21:44.391420 [debug] [Thread-1  ]: finished collecting timing info
10:21:44.393227 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
10:21:44.443029 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
10:21:44.444204 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
10:21:44.445390 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:21:52.133151 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 7.69 seconds
10:21:52.171199 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
10:21:52.176747 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
10:21:52.177306 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on analytics.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'CA' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:21:52.816338 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
10:21:52.871923 [debug] [Thread-1  ]: finished collecting timing info
10:21:52.873260 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
10:21:53.046059 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96b3975c-07ad-44b4-90db-f289c5c00755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8f61b610>]}
10:21:53.049772 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 8.68s]
10:21:53.054855 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
10:21:53.159530 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:21:53.161973 [info ] [MainThread]: 
10:21:53.164095 [info ] [MainThread]: Finished running 1 table model, 1 hook in 45.99s.
10:21:53.166244 [debug] [MainThread]: Connection 'master' was properly closed.
10:21:53.167308 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
10:21:53.197074 [info ] [MainThread]: 
10:21:53.198164 [info ] [MainThread]: [32mCompleted successfully[0m
10:21:53.199295 [info ] [MainThread]: 
10:21:53.200223 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
10:21:53.202179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94082e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8f6b1f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a943be090>]}


============================== 2022-03-17 04:32:18.374607 | 6426a25b-0f56-426a-96c6-1c6443ffd264 ==============================
04:32:18.374607 [info ] [MainThread]: Running with dbt=1.0.1
04:32:18.376010 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:32:18.377193 [debug] [MainThread]: Tracking: tracking
04:32:18.377987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bca3ca8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bca3ca9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bca3caa10>]}
04:32:18.519212 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
04:32:18.520636 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
04:32:18.537948 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
04:32:18.560374 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
04:32:18.604726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6426a25b-0f56-426a-96c6-1c6443ffd264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bca23a050>]}
04:32:18.625148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6426a25b-0f56-426a-96c6-1c6443ffd264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bca240110>]}
04:32:18.626184 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:32:18.628630 [info ] [MainThread]: 
04:32:18.630156 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:32:18.632386 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
04:32:18.657792 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
04:32:18.658521 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
04:32:18.659086 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:32:20.270823 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.61 seconds
04:32:20.274266 [debug] [ThreadPool]: On list_analytics: Close
04:32:20.425965 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
04:32:20.428369 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
04:32:20.431301 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
04:32:20.447488 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
04:32:20.448444 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
04:32:20.466145 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:32:21.440332 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a2fa90-0000-234f-0002-98a20001800a
04:32:21.441054 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 000666 (57014): Your account is suspended due to lack of payment method.
04:32:21.441906 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
04:32:21.442487 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
04:32:21.443069 [debug] [ThreadPool]: On create_analytics_dbt: Close
04:32:21.575614 [debug] [MainThread]: Connection 'master' was properly closed.
04:32:21.576312 [debug] [MainThread]: Connection 'create_analytics_dbt' was properly closed.
04:32:21.577285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bca240950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bc8e11cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4bc8e113d0>]}


============================== 2022-03-17 04:37:07.440789 | 075d4f43-3a72-4fe8-82d0-0522d82a8eda ==============================
04:37:07.440789 [info ] [MainThread]: Running with dbt=1.0.1
04:37:07.441889 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:37:07.442787 [debug] [MainThread]: Tracking: tracking
04:37:07.443401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f94e9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f94ead0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f94eb10>]}
04:37:07.486790 [info ] [MainThread]: Unable to do partial parsing because profile has changed
04:37:07.488690 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
04:37:07.490989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '075d4f43-3a72-4fe8-82d0-0522d82a8eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f8ccf50>]}
04:37:07.563178 [debug] [MainThread]: Parsing macros/group_by.sql
04:37:07.565617 [debug] [MainThread]: Parsing macros/renaming_segments.sql
04:37:07.567100 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
04:37:07.569277 [debug] [MainThread]: Parsing macros/adapters.sql
04:37:07.625494 [debug] [MainThread]: Parsing macros/catalog.sql
04:37:07.630308 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
04:37:07.647907 [debug] [MainThread]: Parsing macros/materializations/merge.sql
04:37:07.654839 [debug] [MainThread]: Parsing macros/materializations/seed.sql
04:37:07.662972 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
04:37:07.665100 [debug] [MainThread]: Parsing macros/materializations/table.sql
04:37:07.670736 [debug] [MainThread]: Parsing macros/materializations/view.sql
04:37:07.673644 [debug] [MainThread]: Parsing macros/adapters/columns.sql
04:37:07.689862 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
04:37:07.695137 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
04:37:07.699972 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
04:37:07.711839 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
04:37:07.719771 [debug] [MainThread]: Parsing macros/adapters/relation.sql
04:37:07.734504 [debug] [MainThread]: Parsing macros/adapters/schema.sql
04:37:07.738774 [debug] [MainThread]: Parsing macros/etc/datetime.sql
04:37:07.751307 [debug] [MainThread]: Parsing macros/etc/statement.sql
04:37:07.759224 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
04:37:07.761976 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
04:37:07.763575 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
04:37:07.765567 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
04:37:07.767510 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
04:37:07.770744 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
04:37:07.773844 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
04:37:07.777993 [debug] [MainThread]: Parsing macros/materializations/configs.sql
04:37:07.782073 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
04:37:07.789970 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
04:37:07.797325 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
04:37:07.812656 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
04:37:07.815623 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
04:37:07.834461 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
04:37:07.856793 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
04:37:07.861764 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
04:37:07.873080 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
04:37:07.877482 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
04:37:07.881312 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
04:37:07.883705 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
04:37:07.894604 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
04:37:07.918431 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
04:37:07.928147 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
04:37:07.944293 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
04:37:07.961848 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
04:37:07.965242 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
04:37:07.990870 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
04:37:07.994373 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
04:37:08.001878 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
04:37:08.005862 [debug] [MainThread]: Parsing tests/generic/builtin.sql
04:37:08.341785 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
04:37:08.363241 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
04:37:08.366133 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
04:37:08.380348 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
04:37:08.383225 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
04:37:08.390614 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
04:37:08.393750 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
04:37:08.400567 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
04:37:08.407373 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
04:37:08.415949 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
04:37:08.418360 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
04:37:08.424726 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
04:37:08.434747 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
04:37:08.436866 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
04:37:08.442325 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
04:37:08.690054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '075d4f43-3a72-4fe8-82d0-0522d82a8eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f8d2e50>]}
04:37:08.706618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '075d4f43-3a72-4fe8-82d0-0522d82a8eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f9cac90>]}
04:37:08.707418 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:37:08.709970 [info ] [MainThread]: 
04:37:08.711189 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:37:08.712829 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
04:37:08.736227 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
04:37:08.736994 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
04:37:08.737965 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:37:10.955937 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2.22 seconds
04:37:10.959602 [debug] [ThreadPool]: On list_test_db: Close
04:37:11.622989 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
04:37:11.624053 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
04:37:11.624955 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
04:37:11.632585 [debug] [ThreadPool]: Using snowflake connection "create_test_db_dbt"
04:37:11.633104 [debug] [ThreadPool]: On create_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "create_test_db_dbt"} */
create schema if not exists test_db.dbt
04:37:11.633533 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:37:13.481274 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.85 seconds
04:37:13.482979 [debug] [ThreadPool]: On create_test_db_dbt: Close
04:37:14.144957 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:37:14.162071 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:37:14.162787 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:37:14.163508 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:37:16.284049 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a2fa95-0403-ca14-0000-87b50009104a
04:37:16.284934 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
04:37:16.285871 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
04:37:16.286383 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
04:37:16.287247 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:37:16.874464 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
04:37:16.877323 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
04:37:16.878138 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
04:37:16.878872 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:37:18.639127 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.76 seconds
04:37:18.641725 [debug] [ThreadPool]: On list_test_db_dbt: Close
04:37:19.228005 [info ] [MainThread]: 
04:37:19.229393 [info ] [MainThread]: Running 1 on-run-start hook
04:37:19.231159 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:37:19.235970 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:37:19.244449 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:37:19.247678 [debug] [MainThread]: Using snowflake connection "master"
04:37:19.248922 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:37:19.250574 [debug] [MainThread]: Opening a new connection, currently in state init
04:37:21.687044 [debug] [MainThread]: SQL status: SUCCESS 1 in 2.44 seconds
04:37:21.690159 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 2.44s]
04:37:21.691631 [info ] [MainThread]: 
04:37:21.692731 [debug] [MainThread]: On master: Close
04:37:22.285892 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:37:22.286974 [info ] [MainThread]: 
04:37:22.293913 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:37:22.294855 [info ] [Thread-1  ]: 1 of 1 START Empemeral model dbt.first_model.................................... [RUN]
04:37:22.296122 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:37:22.297070 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:37:22.298342 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:37:22.308498 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:37:22.312365 [debug] [Thread-1  ]: finished collecting timing info
04:37:22.313334 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:37:22.318333 [debug] [Thread-1  ]: finished collecting timing info
04:37:22.320114 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  No materialization 'Empemeral' was found for adapter snowflake! (searched types 'default' and 'snowflake')
04:37:22.321360 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '075d4f43-3a72-4fe8-82d0-0522d82a8eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383df8eb90>]}
04:37:22.322174 [error] [Thread-1  ]: 1 of 1 ERROR creating Empemeral model dbt.first_model........................... [[31mERROR[0m in 0.03s]
04:37:22.323123 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:37:22.394152 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:37:22.395870 [info ] [MainThread]: 
04:37:22.396892 [info ] [MainThread]: Finished running 1 Empemeral model, 1 hook in 13.69s.
04:37:22.397554 [debug] [MainThread]: Connection 'master' was properly closed.
04:37:22.398008 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:37:22.415032 [info ] [MainThread]: 
04:37:22.416992 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
04:37:22.417841 [info ] [MainThread]: 
04:37:22.418834 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
04:37:22.420403 [error] [MainThread]:   No materialization 'Empemeral' was found for adapter snowflake! (searched types 'default' and 'snowflake')
04:37:22.421995 [info ] [MainThread]: 
04:37:22.424641 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
04:37:22.428287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383f9c99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383df8e690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383df8e910>]}


============================== 2022-03-17 04:37:51.069111 | 07121f2a-9f6d-4011-8a26-577a45fb9ea2 ==============================
04:37:51.069111 [info ] [MainThread]: Running with dbt=1.0.1
04:37:51.070522 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:37:51.071736 [debug] [MainThread]: Tracking: tracking
04:37:51.072638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb2aace8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb2aace9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb2aacea10>]}
04:37:51.175617 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
04:37:51.176982 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
04:37:51.196077 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
04:37:51.218194 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
04:37:51.257461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07121f2a-9f6d-4011-8a26-577a45fb9ea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb298ef250>]}
04:37:51.273857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07121f2a-9f6d-4011-8a26-577a45fb9ea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb29976e90>]}
04:37:51.274805 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:37:51.277542 [info ] [MainThread]: 
04:37:51.279101 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:37:51.281644 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
04:37:51.311182 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
04:37:51.311710 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
04:37:51.312150 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:37:53.409189 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.1 seconds
04:37:53.412751 [debug] [ThreadPool]: On list_test_db: Close
04:37:54.031578 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:37:54.043199 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:37:54.044207 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:37:54.045080 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:37:56.150106 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a2fa95-0403-ca14-0000-87b50009104e
04:37:56.151587 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
04:37:56.153130 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
04:37:56.154650 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
04:37:56.155816 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:37:56.795189 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
04:37:56.797962 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
04:37:56.798813 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
04:37:56.799578 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:37:58.646698 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.85 seconds
04:37:58.649314 [debug] [ThreadPool]: On list_test_db_dbt: Close
04:37:59.278498 [info ] [MainThread]: 
04:37:59.281077 [info ] [MainThread]: Running 1 on-run-start hook
04:37:59.283832 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:37:59.293142 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:37:59.303301 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:37:59.306115 [debug] [MainThread]: Using snowflake connection "master"
04:37:59.308262 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:37:59.309301 [debug] [MainThread]: Opening a new connection, currently in state init
04:38:01.139750 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.83 seconds
04:38:01.145965 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.84s]
04:38:01.148669 [info ] [MainThread]: 
04:38:01.151077 [debug] [MainThread]: On master: Close
04:38:01.769934 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:38:01.772177 [info ] [MainThread]: 
04:38:01.781880 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:38:01.784373 [info ] [Thread-1  ]: 1 of 1 START Table model dbt.first_model........................................ [RUN]
04:38:01.786734 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:01.788248 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:38:01.789246 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:38:01.801900 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:38:01.805679 [debug] [Thread-1  ]: finished collecting timing info
04:38:01.806536 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:38:01.811530 [debug] [Thread-1  ]: finished collecting timing info
04:38:01.812899 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  No materialization 'Table' was found for adapter snowflake! (searched types 'default' and 'snowflake')
04:38:01.813802 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07121f2a-9f6d-4011-8a26-577a45fb9ea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb280eac90>]}
04:38:01.815587 [error] [Thread-1  ]: 1 of 1 ERROR creating Table model dbt.first_model............................... [[31mERROR[0m in 0.03s]
04:38:01.816989 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:38:01.880177 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:38:01.881590 [info ] [MainThread]: 
04:38:01.882590 [info ] [MainThread]: Finished running 1 Table model, 1 hook in 10.60s.
04:38:01.883859 [debug] [MainThread]: Connection 'master' was properly closed.
04:38:01.884665 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:38:01.902623 [info ] [MainThread]: 
04:38:01.904369 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
04:38:01.906065 [info ] [MainThread]: 
04:38:01.907101 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
04:38:01.908151 [error] [MainThread]:   No materialization 'Table' was found for adapter snowflake! (searched types 'default' and 'snowflake')
04:38:01.911743 [info ] [MainThread]: 
04:38:01.913055 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
04:38:01.914930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb2851e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb280d8bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb280d8850>]}


============================== 2022-03-17 04:38:31.382861 | b35f8e5c-d41d-424e-aa5a-9bce25546947 ==============================
04:38:31.382861 [info ] [MainThread]: Running with dbt=1.0.1
04:38:31.384037 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
04:38:31.385313 [debug] [MainThread]: Tracking: tracking
04:38:31.386259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ea8a5910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ea8a5850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ea8a5950>]}
04:38:31.496607 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
04:38:31.498184 [debug] [MainThread]: Partial parsing: updated file: dbt_tests://models/example/my_first_dbt_model.sql
04:38:31.515515 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
04:38:31.537404 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
04:38:31.596170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b35f8e5c-d41d-424e-aa5a-9bce25546947', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81e97ba2d0>]}
04:38:31.616360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b35f8e5c-d41d-424e-aa5a-9bce25546947', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81e975bad0>]}
04:38:31.617343 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
04:38:31.621294 [info ] [MainThread]: 
04:38:31.627911 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:38:31.631116 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
04:38:31.660543 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
04:38:31.661578 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
04:38:31.662586 [debug] [ThreadPool]: Opening a new connection, currently in state init
04:38:34.006067 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.34 seconds
04:38:34.009113 [debug] [ThreadPool]: On list_test_db: Close
04:38:34.667814 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
04:38:34.678778 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
04:38:34.679289 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
04:38:34.679754 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:38:36.674236 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a2fa96-0403-ca14-0000-87b500091056
04:38:36.680394 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
04:38:36.683844 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
04:38:36.685183 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
04:38:36.686258 [debug] [ThreadPool]: On list_analytics_snapshots: Close
04:38:37.286139 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
04:38:37.289162 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
04:38:37.289798 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
04:38:37.290506 [debug] [ThreadPool]: Opening a new connection, currently in state closed
04:38:39.070251 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.78 seconds
04:38:39.073113 [debug] [ThreadPool]: On list_test_db_dbt: Close
04:38:39.661200 [info ] [MainThread]: 
04:38:39.663284 [info ] [MainThread]: Running 1 on-run-start hook
04:38:39.665178 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
04:38:39.671588 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
04:38:39.685951 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
04:38:39.688495 [debug] [MainThread]: Using snowflake connection "master"
04:38:39.689379 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
04:38:39.690142 [debug] [MainThread]: Opening a new connection, currently in state init
04:38:41.497699 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.81 seconds
04:38:41.500313 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.81s]
04:38:41.501810 [info ] [MainThread]: 
04:38:41.503021 [debug] [MainThread]: On master: Close
04:38:42.118691 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
04:38:42.122713 [info ] [MainThread]: 
04:38:42.135362 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
04:38:42.137585 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
04:38:42.139821 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:42.141284 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
04:38:42.143098 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
04:38:42.154191 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
04:38:42.160762 [debug] [Thread-1  ]: finished collecting timing info
04:38:42.161800 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
04:38:42.198500 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:42.199219 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
04:38:42.200044 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
04:38:45.200827 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.0 seconds
04:38:45.231981 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
04:38:45.237051 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
04:38:45.237887 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
04:38:46.969452 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
04:38:46.994859 [debug] [Thread-1  ]: finished collecting timing info
04:38:46.995712 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
04:38:47.587588 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b35f8e5c-d41d-424e-aa5a-9bce25546947', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81e8144710>]}
04:38:47.588787 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 5.45s]
04:38:47.589785 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
04:38:47.676316 [debug] [MainThread]: Acquiring new snowflake connection "master"
04:38:47.677549 [info ] [MainThread]: 
04:38:47.678652 [info ] [MainThread]: Finished running 1 table model, 1 hook in 16.06s.
04:38:47.679964 [debug] [MainThread]: Connection 'master' was properly closed.
04:38:47.680994 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
04:38:47.699273 [info ] [MainThread]: 
04:38:47.700830 [info ] [MainThread]: [32mCompleted successfully[0m
04:38:47.701896 [info ] [MainThread]: 
04:38:47.702722 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
04:38:47.704234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ea8ae650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81e9700750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f2c034d0>]}


============================== 2022-03-18 03:09:47.620822 | 07fc82a4-58a9-4e3f-9822-34154ce4648c ==============================
03:09:47.620822 [info ] [MainThread]: Running with dbt=1.0.1
03:09:47.625918 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.debug.DebugTask'>, config_dir=False, debug=None, defer=None, event_buffer_size=None, fail_fast=None, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='debug', write_json=None)
03:09:47.626800 [debug] [MainThread]: Tracking: tracking
03:09:47.636677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f340a29b290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f340dec9810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f340dec9850>]}
03:09:48.161532 [debug] [MainThread]: Executing "git --help"
03:09:48.177527 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-c name=value]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThe most commonly used git commands are:\n   add        Add file contents to the index\n   bisect     Find by binary search the change that introduced a bug\n   branch     List, create, or delete branches\n   checkout   Checkout a branch or paths to the working tree\n   clone      Clone a repository into a new directory\n   commit     Record changes to the repository\n   diff       Show changes between commits, commit and working tree, etc\n   fetch      Download objects and refs from another repository\n   grep       Print lines matching a pattern\n   init       Create an empty Git repository or reinitialize an existing one\n   log        Show commit logs\n   merge      Join two or more development histories together\n   mv         Move or rename a file, a directory, or a symlink\n   pull       Fetch from and merge with another repository or a local branch\n   push       Update remote refs along with associated objects\n   rebase     Forward-port local commits to the updated upstream head\n   reset      Reset current HEAD to the specified state\n   rm         Remove files from the working tree and from the index\n   show       Show various types of objects\n   status     Show the working tree status\n   tag        Create, list, delete or verify a tag object signed with GPG\n\n'git help -a' and 'git help -g' lists available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\n""
03:09:48.179216 [debug] [MainThread]: STDERR: "b''"
03:09:48.191059 [debug] [MainThread]: Acquiring new snowflake connection "debug"
03:09:48.195592 [debug] [MainThread]: Using snowflake connection "debug"
03:09:48.196332 [debug] [MainThread]: On debug: select 1 as id
03:09:48.197524 [debug] [MainThread]: Opening a new connection, currently in state init
03:09:49.018975 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.82 seconds
03:09:49.022817 [debug] [MainThread]: On debug: Close
03:09:49.150118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3403ea3190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3403ea3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3403ea3290>]}
03:09:50.137866 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-03-18 03:10:34.169182 | 0e96b071-c535-461c-9c38-a1f2b07ea060 ==============================
03:10:34.169182 [info ] [MainThread]: Running with dbt=1.0.1
03:10:34.170488 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
03:10:34.171858 [debug] [MainThread]: Tracking: tracking
03:10:34.172666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae85885910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae858856d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae858858d0>]}
03:10:34.222858 [info ] [MainThread]: Unable to do partial parsing because profile has changed
03:10:34.223771 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
03:10:34.225066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0e96b071-c535-461c-9c38-a1f2b07ea060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae847cdf50>]}
03:10:34.303721 [debug] [MainThread]: Parsing macros/group_by.sql
03:10:34.306175 [debug] [MainThread]: Parsing macros/renaming_segments.sql
03:10:34.307673 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
03:10:34.309901 [debug] [MainThread]: Parsing macros/adapters.sql
03:10:34.369365 [debug] [MainThread]: Parsing macros/catalog.sql
03:10:34.375038 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
03:10:34.393071 [debug] [MainThread]: Parsing macros/materializations/merge.sql
03:10:34.409025 [debug] [MainThread]: Parsing macros/materializations/seed.sql
03:10:34.435002 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
03:10:34.437233 [debug] [MainThread]: Parsing macros/materializations/table.sql
03:10:34.443015 [debug] [MainThread]: Parsing macros/materializations/view.sql
03:10:34.446012 [debug] [MainThread]: Parsing macros/adapters/columns.sql
03:10:34.461678 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
03:10:34.466952 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
03:10:34.472025 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
03:10:34.483789 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
03:10:34.491303 [debug] [MainThread]: Parsing macros/adapters/relation.sql
03:10:34.506381 [debug] [MainThread]: Parsing macros/adapters/schema.sql
03:10:34.510365 [debug] [MainThread]: Parsing macros/etc/datetime.sql
03:10:34.525056 [debug] [MainThread]: Parsing macros/etc/statement.sql
03:10:34.534575 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
03:10:34.537198 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
03:10:34.538711 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
03:10:34.540503 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
03:10:34.542033 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
03:10:34.544951 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
03:10:34.547946 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
03:10:34.552862 [debug] [MainThread]: Parsing macros/materializations/configs.sql
03:10:34.556997 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
03:10:34.563509 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
03:10:34.571224 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
03:10:34.587052 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
03:10:34.590077 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
03:10:34.607825 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
03:10:34.637726 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
03:10:34.642940 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
03:10:34.655748 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
03:10:34.660388 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
03:10:34.664579 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
03:10:34.667196 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
03:10:34.680271 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
03:10:34.705701 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
03:10:34.716111 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
03:10:34.733254 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
03:10:34.751027 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
03:10:34.757263 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
03:10:34.796375 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
03:10:34.800486 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
03:10:34.808246 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
03:10:34.811812 [debug] [MainThread]: Parsing tests/generic/builtin.sql
03:10:35.176298 [debug] [MainThread]: 1603: static parser failed on example/cumulative_orders_by_date.sql
03:10:35.201482 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/cumulative_orders_by_date.sql
03:10:35.204106 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
03:10:35.216940 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
03:10:35.219533 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
03:10:35.226779 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
03:10:35.230475 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
03:10:35.237500 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
03:10:35.244052 [debug] [MainThread]: 1603: static parser failed on example/rename_segments_macro_test.sql
03:10:35.251979 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/rename_segments_macro_test.sql
03:10:35.254373 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
03:10:35.260838 [debug] [MainThread]: 1603: static parser failed on example/sources_customer_orders.sql
03:10:35.271462 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/sources_customer_orders.sql
03:10:35.273602 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
03:10:35.279152 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
03:10:35.543713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0e96b071-c535-461c-9c38-a1f2b07ea060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae8c3e3890>]}
03:10:35.562711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0e96b071-c535-461c-9c38-a1f2b07ea060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae859036d0>]}
03:10:35.563694 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
03:10:35.566611 [info ] [MainThread]: 
03:10:35.567818 [debug] [MainThread]: Acquiring new snowflake connection "master"
03:10:35.569934 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
03:10:35.596903 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
03:10:35.597538 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
03:10:35.598092 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:10:41.406096 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 5.81 seconds
03:10:41.409538 [debug] [ThreadPool]: On list_test_db: Close
03:10:41.566596 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
03:10:41.608103 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
03:10:41.608707 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
03:10:41.609350 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:10:42.241110 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a2ffde-0000-236c-0000-0003393a3005
03:10:42.242747 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
03:10:42.244586 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
03:10:42.245748 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
03:10:42.247093 [debug] [ThreadPool]: On list_analytics_snapshots: Close
03:10:42.407502 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
03:10:42.416908 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
03:10:42.418522 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
03:10:42.419884 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:10:43.025078 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.61 seconds
03:10:43.028923 [debug] [ThreadPool]: On list_test_db_dbt: Close
03:10:43.149617 [info ] [MainThread]: 
03:10:43.151069 [info ] [MainThread]: Running 1 on-run-start hook
03:10:43.152323 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
03:10:43.157190 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
03:10:43.168789 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
03:10:43.172270 [debug] [MainThread]: Using snowflake connection "master"
03:10:43.173134 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
03:10:43.173784 [debug] [MainThread]: Opening a new connection, currently in state init
03:10:44.090021 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.92 seconds
03:10:44.092220 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.92s]
03:10:44.093424 [info ] [MainThread]: 
03:10:44.094643 [debug] [MainThread]: On master: Close
03:10:44.223063 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
03:10:44.223876 [info ] [MainThread]: 
03:10:44.226556 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
03:10:44.227826 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
03:10:44.229090 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
03:10:44.229649 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
03:10:44.230859 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
03:10:44.243171 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
03:10:44.247767 [debug] [Thread-1  ]: finished collecting timing info
03:10:44.249030 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
03:10:44.302246 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
03:10:44.303549 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
03:10:44.304155 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
03:10:46.425334 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
03:10:46.443224 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
03:10:46.448057 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
03:10:46.448699 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
03:10:49.067019 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.62 seconds
03:10:49.091403 [debug] [Thread-1  ]: finished collecting timing info
03:10:49.092507 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
03:10:49.205746 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e96b071-c535-461c-9c38-a1f2b07ea060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae842cc890>]}
03:10:49.206991 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 4.98s]
03:10:49.207922 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
03:10:49.219886 [debug] [MainThread]: Acquiring new snowflake connection "master"
03:10:49.220962 [info ] [MainThread]: 
03:10:49.222947 [info ] [MainThread]: Finished running 1 table model, 1 hook in 13.65s.
03:10:49.226010 [debug] [MainThread]: Connection 'master' was properly closed.
03:10:49.226917 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
03:10:49.246074 [info ] [MainThread]: 
03:10:49.247744 [info ] [MainThread]: [32mCompleted successfully[0m
03:10:49.248730 [info ] [MainThread]: 
03:10:49.260477 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
03:10:49.262167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae85903f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae768b3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae768b3b90>]}


============================== 2022-03-18 03:11:44.131114 | 4e1e239f-6502-41e5-a161-cfde9f06b3a7 ==============================
03:11:44.131114 [info ] [MainThread]: Running with dbt=1.0.1
03:11:44.132326 [debug] [MainThread]: running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=None, defer=None, event_buffer_size=None, exclude=None, fail_fast=None, full_refresh=False, log_cache_events=False, log_format=None, partial_parse=None, printer_width=None, profile=None, profiles_dir='/home/vagrant/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', select=['example.my_first_dbt_model'], selector_name=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='run', write_json=None)
03:11:44.133454 [debug] [MainThread]: Tracking: tracking
03:11:44.134253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e8444fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e8444f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e8444f9d0>]}
03:11:44.240938 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
03:11:44.241716 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
03:11:44.252646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e1e239f-6502-41e5-a161-cfde9f06b3a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e8c6bb090>]}
03:11:44.269261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e1e239f-6502-41e5-a161-cfde9f06b3a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e844c1950>]}
03:11:44.270356 [info ] [MainThread]: Found 9 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 1 operation, 0 seed files, 2 sources, 0 exposures, 0 metrics
03:11:44.273097 [info ] [MainThread]: 
03:11:44.275079 [debug] [MainThread]: Acquiring new snowflake connection "master"
03:11:44.277812 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db"
03:11:44.309294 [debug] [ThreadPool]: Using snowflake connection "list_test_db"
03:11:44.311176 [debug] [ThreadPool]: On list_test_db: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db"} */

    show terse schemas in database test_db
    limit 10000
03:11:44.312607 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:11:45.232196 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.92 seconds
03:11:45.235777 [debug] [ThreadPool]: On list_test_db: Close
03:11:45.381741 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
03:11:45.382988 [debug] [ThreadPool]: Acquiring new snowflake connection "create_test_db_dbt"
03:11:45.384495 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='test_db', schema='dbt', identifier=None)"
03:11:45.395109 [debug] [ThreadPool]: Using snowflake connection "create_test_db_dbt"
03:11:45.396164 [debug] [ThreadPool]: On create_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "create_test_db_dbt"} */
create schema if not exists test_db.dbt
03:11:45.396806 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:11:46.080877 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.68 seconds
03:11:46.086993 [debug] [ThreadPool]: On create_test_db_dbt: Close
03:11:46.234086 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snapshots"
03:11:46.262655 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snapshots"
03:11:46.263550 [debug] [ThreadPool]: On list_analytics_snapshots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_analytics_snapshots"} */

    show terse objects in analytics.snapshots
03:11:46.264496 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:11:47.131594 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a2ffdf-0000-2372-0000-0003393a1159
03:11:47.133574 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
03:11:47.135289 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
03:11:47.136821 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
03:11:47.138171 [debug] [ThreadPool]: On list_analytics_snapshots: Close
03:11:47.290106 [debug] [ThreadPool]: Acquiring new snowflake connection "list_test_db_dbt"
03:11:47.296728 [debug] [ThreadPool]: Using snowflake connection "list_test_db_dbt"
03:11:47.298182 [debug] [ThreadPool]: On list_test_db_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "list_test_db_dbt"} */

    show terse objects in test_db.dbt
03:11:47.299543 [debug] [ThreadPool]: Opening a new connection, currently in state closed
03:11:47.896798 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.6 seconds
03:11:47.905372 [debug] [ThreadPool]: On list_test_db_dbt: Close
03:11:48.109924 [info ] [MainThread]: 
03:11:48.112268 [info ] [MainThread]: Running 1 on-run-start hook
03:11:48.114705 [debug] [MainThread]: Compiling operation.dbt_tests.dbt_tests-on-run-start-0
03:11:48.121599 [debug] [MainThread]: Writing injected SQL for node "operation.dbt_tests.dbt_tests-on-run-start-0"
03:11:48.131323 [info ] [MainThread]: 1 of 1 START hook: dbt_tests.on-run-start.0..................................... [RUN]
03:11:48.133365 [debug] [MainThread]: Using snowflake connection "master"
03:11:48.134876 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
03:11:48.135771 [debug] [MainThread]: Opening a new connection, currently in state init
03:11:48.785148 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
03:11:48.791788 [info ] [MainThread]: 1 of 1 OK hook: dbt_tests.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.66s]
03:11:48.794861 [info ] [MainThread]: 
03:11:48.797024 [debug] [MainThread]: On master: Close
03:11:48.929802 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
03:11:48.930977 [info ] [MainThread]: 
03:11:48.936015 [debug] [Thread-1  ]: Began running node model.dbt_tests.my_first_dbt_model
03:11:48.937571 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
03:11:48.939652 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.dbt_tests.my_first_dbt_model"
03:11:48.940593 [debug] [Thread-1  ]: Began compiling node model.dbt_tests.my_first_dbt_model
03:11:48.941567 [debug] [Thread-1  ]: Compiling model.dbt_tests.my_first_dbt_model
03:11:48.953517 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_tests.my_first_dbt_model"
03:11:48.959338 [debug] [Thread-1  ]: finished collecting timing info
03:11:48.960578 [debug] [Thread-1  ]: Began executing node model.dbt_tests.my_first_dbt_model
03:11:48.995734 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
03:11:48.996705 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
03:11:48.997430 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
03:11:49.935175 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
03:11:49.965973 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_tests.my_first_dbt_model"
03:11:49.971962 [debug] [Thread-1  ]: Using snowflake connection "model.dbt_tests.my_first_dbt_model"
03:11:49.972912 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "dbt-demo", "target_name": "dev", "node_id": "model.dbt_tests.my_first_dbt_model"} */


      create or replace transient table test_db.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    
*/




-- , post_hook='grant select on test_db.dbt.first_model to role analyst'

with source_data as (

    select 1 as id, 'TX' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2022-01-01 00:00:00.000'::timestamp as updated_at
    -- select 1 as id

)

select * -- , True as first_variable
from source_data
-- where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
03:11:51.585270 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.61 seconds
03:11:51.600968 [debug] [Thread-1  ]: finished collecting timing info
03:11:51.601585 [debug] [Thread-1  ]: On model.dbt_tests.my_first_dbt_model: Close
03:11:51.733965 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e1e239f-6502-41e5-a161-cfde9f06b3a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e81930150>]}
03:11:51.735409 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.79s]
03:11:51.736887 [debug] [Thread-1  ]: Finished running node model.dbt_tests.my_first_dbt_model
03:11:51.740478 [debug] [MainThread]: Acquiring new snowflake connection "master"
03:11:51.741757 [info ] [MainThread]: 
03:11:51.742772 [info ] [MainThread]: Finished running 1 table model, 1 hook in 7.47s.
03:11:51.743710 [debug] [MainThread]: Connection 'master' was properly closed.
03:11:51.744536 [debug] [MainThread]: Connection 'model.dbt_tests.my_first_dbt_model' was properly closed.
03:11:51.765897 [info ] [MainThread]: 
03:11:51.769620 [info ] [MainThread]: [32mCompleted successfully[0m
03:11:51.770723 [info ] [MainThread]: 
03:11:51.771981 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
03:11:51.774554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e81efc510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e81ed4f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e81930b10>]}
